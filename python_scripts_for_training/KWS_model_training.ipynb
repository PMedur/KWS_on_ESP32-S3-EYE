{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa01385e-459e-4dd6-8a05-645fa2bdb893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 12:26:09.630754: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-05 12:26:11.142727: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins::/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins::/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:\n",
      "2025-10-05 12:26:11.142859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins::/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins::/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:\n",
      "2025-10-05 12:26:11.142867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: 1 device(s)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from model_architectures import (\n",
    "    build_model_1, build_model_2, build_model_3, build_model_4, build_model_5,\n",
    "    build_model_6, build_model_7, build_model_8, build_model_9, build_model_10,\n",
    "    MODEL_REGISTRY\n",
    ")\n",
    "from model_training import cross_validate, precision_m, recall_m, f1_m\n",
    "from fine_tuning import finetune_all_folds, compare_before_after_finetuning\n",
    "from test_energy_measurement import measure_all_test_power\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd295a1-dc17-4649-82b6-9aca0de5f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.1\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Built with CUDA: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b6b6b1-a9ed-47a1-8518-d32b88f699b7",
   "metadata": {},
   "source": [
    "## Train Model with Cross-Validation\n",
    "\n",
    "This function trains a single model across all 10 folds using k-fold cross-validation. It:\n",
    "- Wraps the model builder to include custom metrics (precision, recall, F1)\n",
    "- Trains on each fold with early stopping (patience=5)\n",
    "- Monitors GPU/CPU energy consumption during training\n",
    "- Saves the best model for each fold based on validation loss\n",
    "- Returns aggregated metrics across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817f1e9e-161c-496b-8148-76ed1a751309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_metrics(model_builder, model_name, early_stopping_patience=5, monitor_resources=True):\n",
    "    \"\"\"Wrapper to pass metrics to model builder.\"\"\"\n",
    "    def builder_with_metrics(input_shape):\n",
    "        return model_builder(\n",
    "            input_shape=input_shape,\n",
    "            metrics=['accuracy', precision_m, recall_m, f1_m]\n",
    "        )\n",
    "    \n",
    "    metrics = cross_validate(\n",
    "        model_builder=builder_with_metrics,\n",
    "        model_name=model_name,\n",
    "        folds_dir='new_Data_particions',\n",
    "        num_folds=10,\n",
    "        epochs=30,\n",
    "        batch_size=128,\n",
    "        save_dir='trained_models',\n",
    "        monitor_resources=monitor_resources,\n",
    "        early_stopping_patience=5\n",
    "    )\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ddd869-a37d-4044-9e84-b89519ff71dd",
   "metadata": {},
   "source": [
    "## Train Individual Model\n",
    "\n",
    "Train a specific model architecture by changing the parameters:\n",
    "- `build_model_X` - Replace X with model number (1-10) to select architecture\n",
    "- `'model_X'` - Model name for saving (use same number as build function)\n",
    "- Early stopping with patience of 5 epochs\n",
    "- Resource monitoring enabled (tracks CPU/GPU energy consumption)\n",
    "- Results saved to `trained_models/model_1_fold_X_best.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "138a0fd0-29bd-4d1d-b3f8-4e913023ecc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "STARTING 10-FOLD CROSS-VALIDATION FOR model_1\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 1 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77912, Val=8253, Test=7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 19:20:45.728773: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "603/609 [============================>.] - ETA: 0s - loss: 3.1186 - accuracy: 0.1250 - precision_m: 0.2136 - recall_m: 0.0043 - f1_m: 0.0084\n",
      "Epoch 1: val_loss improved from inf to 2.73371, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2007 | Precision: 0.5366 | Recall: 0.0183 | F1: 0.0351\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 5s 7ms/step - loss: 3.1144 - accuracy: 0.1259 - precision_m: 0.2151 - recall_m: 0.0044 - f1_m: 0.0086 - val_loss: 2.7337 - val_accuracy: 0.2007 - val_precision_m: 0.5366 - val_recall_m: 0.0183 - val_f1_m: 0.0351\n",
      "Epoch 2/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 2.5019 - accuracy: 0.2668 - precision_m: 0.6456 - recall_m: 0.0366 - f1_m: 0.0687\n",
      "Epoch 2: val_loss improved from 2.73371 to 2.40942, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3049 | Precision: 0.6656 | Recall: 0.0537 | F1: 0.0984\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.5015 - accuracy: 0.2669 - precision_m: 0.6453 - recall_m: 0.0366 - f1_m: 0.0687 - val_loss: 2.4094 - val_accuracy: 0.3049 - val_precision_m: 0.6656 - val_recall_m: 0.0537 - val_f1_m: 0.0984\n",
      "Epoch 3/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 2.3217 - accuracy: 0.3169 - precision_m: 0.6886 - recall_m: 0.0655 - f1_m: 0.1189\n",
      "Epoch 3: val_loss improved from 2.40942 to 2.29840, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3337 | Precision: 0.7053 | Recall: 0.0746 | F1: 0.1338\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.3216 - accuracy: 0.3170 - precision_m: 0.6888 - recall_m: 0.0655 - f1_m: 0.1190 - val_loss: 2.2984 - val_accuracy: 0.3337 - val_precision_m: 0.7053 - val_recall_m: 0.0746 - val_f1_m: 0.1338\n",
      "Epoch 4/30\n",
      "603/609 [============================>.] - ETA: 0s - loss: 2.2323 - accuracy: 0.3441 - precision_m: 0.7041 - recall_m: 0.0884 - f1_m: 0.1561\n",
      "Epoch 4: val_loss improved from 2.29840 to 2.22864, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.3504 | Precision: 0.6931 | Recall: 0.1030 | F1: 0.1777\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.2319 - accuracy: 0.3443 - precision_m: 0.7040 - recall_m: 0.0884 - f1_m: 0.1562 - val_loss: 2.2286 - val_accuracy: 0.3504 - val_precision_m: 0.6931 - val_recall_m: 0.1030 - val_f1_m: 0.1777\n",
      "Epoch 5/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 2.1658 - accuracy: 0.3622 - precision_m: 0.7077 - recall_m: 0.1071 - f1_m: 0.1850\n",
      "Epoch 5: val_loss improved from 2.22864 to 2.20796, saving model to trained_models/model_1_fold_1_best.h5\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.1658 - accuracy: 0.3623 - precision_m: 0.7080 - recall_m: 0.1071 - f1_m: 0.1850 - val_loss: 2.2080 - val_accuracy: 0.3503 - val_precision_m: 0.6946 - val_recall_m: 0.1146 - val_f1_m: 0.1950\n",
      "Epoch 6/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 2.1206 - accuracy: 0.3745 - precision_m: 0.7069 - recall_m: 0.1226 - f1_m: 0.2079\n",
      "Epoch 6: val_loss improved from 2.20796 to 2.19931, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.3593 | Precision: 0.6741 | Recall: 0.1348 | F1: 0.2228\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.1209 - accuracy: 0.3744 - precision_m: 0.7073 - recall_m: 0.1226 - f1_m: 0.2079 - val_loss: 2.1993 - val_accuracy: 0.3593 - val_precision_m: 0.6741 - val_recall_m: 0.1348 - val_f1_m: 0.2228\n",
      "Epoch 7/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 2.0849 - accuracy: 0.3816 - precision_m: 0.7038 - recall_m: 0.1335 - f1_m: 0.2233\n",
      "Epoch 7: val_loss improved from 2.19931 to 2.11659, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.3770 | Precision: 0.6947 | Recall: 0.1367 | F1: 0.2261\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.0848 - accuracy: 0.3818 - precision_m: 0.7041 - recall_m: 0.1336 - f1_m: 0.2235 - val_loss: 2.1166 - val_accuracy: 0.3770 - val_precision_m: 0.6947 - val_recall_m: 0.1367 - val_f1_m: 0.2261\n",
      "Epoch 8/30\n",
      "603/609 [============================>.] - ETA: 0s - loss: 2.0603 - accuracy: 0.3900 - precision_m: 0.7021 - recall_m: 0.1413 - f1_m: 0.2343\n",
      "Epoch 8: val_loss improved from 2.11659 to 2.10915, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.3789 | Precision: 0.6853 | Recall: 0.1396 | F1: 0.2299\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.0589 - accuracy: 0.3901 - precision_m: 0.7016 - recall_m: 0.1413 - f1_m: 0.2343 - val_loss: 2.1091 - val_accuracy: 0.3789 - val_precision_m: 0.6853 - val_recall_m: 0.1396 - val_f1_m: 0.2299\n",
      "Epoch 9/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 2.0358 - accuracy: 0.3964 - precision_m: 0.7054 - recall_m: 0.1490 - f1_m: 0.2450\n",
      "Epoch 9: val_loss improved from 2.10915 to 2.07702, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.3887 | Precision: 0.6823 | Recall: 0.1547 | F1: 0.2501\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.0360 - accuracy: 0.3963 - precision_m: 0.7050 - recall_m: 0.1489 - f1_m: 0.2448 - val_loss: 2.0770 - val_accuracy: 0.3887 - val_precision_m: 0.6823 - val_recall_m: 0.1547 - val_f1_m: 0.2501\n",
      "Epoch 10/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 2.0147 - accuracy: 0.4014 - precision_m: 0.6985 - recall_m: 0.1538 - f1_m: 0.2511\n",
      "Epoch 10: val_loss improved from 2.07702 to 2.06658, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.3889 | Precision: 0.7043 | Recall: 0.1441 | F1: 0.2372\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.0146 - accuracy: 0.4014 - precision_m: 0.6983 - recall_m: 0.1538 - f1_m: 0.2510 - val_loss: 2.0666 - val_accuracy: 0.3889 - val_precision_m: 0.7043 - val_recall_m: 0.1441 - val_f1_m: 0.2372\n",
      "Epoch 11/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 2.0040 - accuracy: 0.4049 - precision_m: 0.7008 - recall_m: 0.1582 - f1_m: 0.2570\n",
      "Epoch 11: val_loss improved from 2.06658 to 2.06513, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.3936 | Precision: 0.6679 | Recall: 0.1590 | F1: 0.2548\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.0040 - accuracy: 0.4048 - precision_m: 0.7009 - recall_m: 0.1581 - f1_m: 0.2569 - val_loss: 2.0651 - val_accuracy: 0.3936 - val_precision_m: 0.6679 - val_recall_m: 0.1590 - val_f1_m: 0.2548\n",
      "Epoch 12/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 1.9869 - accuracy: 0.4097 - precision_m: 0.6998 - recall_m: 0.1625 - f1_m: 0.2627\n",
      "Epoch 12: val_loss improved from 2.06513 to 2.03378, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.4000 | Precision: 0.6977 | Recall: 0.1615 | F1: 0.2604\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9873 - accuracy: 0.4096 - precision_m: 0.6997 - recall_m: 0.1625 - f1_m: 0.2627 - val_loss: 2.0338 - val_accuracy: 0.4000 - val_precision_m: 0.6977 - val_recall_m: 0.1615 - val_f1_m: 0.2604\n",
      "Epoch 13/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.9736 - accuracy: 0.4123 - precision_m: 0.7004 - recall_m: 0.1676 - f1_m: 0.2694\n",
      "Epoch 13: val_loss did not improve from 2.03378\n",
      "609/609 [==============================] - 5s 8ms/step - loss: 1.9736 - accuracy: 0.4123 - precision_m: 0.7004 - recall_m: 0.1676 - f1_m: 0.2694 - val_loss: 2.0497 - val_accuracy: 0.3932 - val_precision_m: 0.6909 - val_recall_m: 0.1681 - val_f1_m: 0.2685\n",
      "Epoch 14/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 1.9638 - accuracy: 0.4157 - precision_m: 0.7003 - recall_m: 0.1710 - f1_m: 0.2738\n",
      "Epoch 14: val_loss improved from 2.03378 to 2.02718, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.4030 | Precision: 0.6882 | Recall: 0.1748 | F1: 0.2766\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 5s 8ms/step - loss: 1.9643 - accuracy: 0.4156 - precision_m: 0.6999 - recall_m: 0.1708 - f1_m: 0.2736 - val_loss: 2.0272 - val_accuracy: 0.4030 - val_precision_m: 0.6882 - val_recall_m: 0.1748 - val_f1_m: 0.2766\n",
      "Epoch 15/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 1.9530 - accuracy: 0.4188 - precision_m: 0.7007 - recall_m: 0.1738 - f1_m: 0.2774\n",
      "Epoch 15: val_loss improved from 2.02718 to 2.01588, saving model to trained_models/model_1_fold_1_best.h5\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9532 - accuracy: 0.4188 - precision_m: 0.7008 - recall_m: 0.1738 - f1_m: 0.2774 - val_loss: 2.0159 - val_accuracy: 0.4018 - val_precision_m: 0.6963 - val_recall_m: 0.1794 - val_f1_m: 0.2837\n",
      "Epoch 16/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.9420 - accuracy: 0.4215 - precision_m: 0.7040 - recall_m: 0.1797 - f1_m: 0.2852\n",
      "Epoch 16: val_loss did not improve from 2.01588\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9418 - accuracy: 0.4216 - precision_m: 0.7041 - recall_m: 0.1796 - f1_m: 0.2850 - val_loss: 2.0578 - val_accuracy: 0.3927 - val_precision_m: 0.6659 - val_recall_m: 0.1687 - val_f1_m: 0.2674\n",
      "Epoch 17/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 1.9312 - accuracy: 0.4279 - precision_m: 0.7041 - recall_m: 0.1816 - f1_m: 0.2877\n",
      "Epoch 17: val_loss improved from 2.01588 to 1.99102, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.4133 | Precision: 0.6871 | Recall: 0.1850 | F1: 0.2893\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9315 - accuracy: 0.4278 - precision_m: 0.7040 - recall_m: 0.1817 - f1_m: 0.2878 - val_loss: 1.9910 - val_accuracy: 0.4133 - val_precision_m: 0.6871 - val_recall_m: 0.1850 - val_f1_m: 0.2893\n",
      "Epoch 18/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.9265 - accuracy: 0.4274 - precision_m: 0.7014 - recall_m: 0.1859 - f1_m: 0.2929\n",
      "Epoch 18: val_loss did not improve from 1.99102\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9258 - accuracy: 0.4275 - precision_m: 0.7016 - recall_m: 0.1862 - f1_m: 0.2932 - val_loss: 2.0014 - val_accuracy: 0.4129 - val_precision_m: 0.6807 - val_recall_m: 0.1895 - val_f1_m: 0.2944\n",
      "Epoch 19/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.9197 - accuracy: 0.4292 - precision_m: 0.7052 - recall_m: 0.1887 - f1_m: 0.2967\n",
      "Epoch 19: val_loss improved from 1.99102 to 1.98291, saving model to trained_models/model_1_fold_1_best.h5\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9199 - accuracy: 0.4291 - precision_m: 0.7051 - recall_m: 0.1887 - f1_m: 0.2968 - val_loss: 1.9829 - val_accuracy: 0.4104 - val_precision_m: 0.6926 - val_recall_m: 0.1907 - val_f1_m: 0.2969\n",
      "Epoch 20/30\n",
      "602/609 [============================>.] - ETA: 0s - loss: 1.9102 - accuracy: 0.4323 - precision_m: 0.7099 - recall_m: 0.1935 - f1_m: 0.3030\n",
      "Epoch 20: val_loss did not improve from 1.98291\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9103 - accuracy: 0.4322 - precision_m: 0.7094 - recall_m: 0.1933 - f1_m: 0.3027 - val_loss: 1.9903 - val_accuracy: 0.4105 - val_precision_m: 0.6745 - val_recall_m: 0.1868 - val_f1_m: 0.2903\n",
      "Epoch 21/30\n",
      "603/609 [============================>.] - ETA: 0s - loss: 1.9088 - accuracy: 0.4322 - precision_m: 0.7087 - recall_m: 0.1956 - f1_m: 0.3056\n",
      "Epoch 21: val_loss did not improve from 1.98291\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 21\n",
      "Accuracy: 0.4148 | Precision: 0.6819 | Recall: 0.1938 | F1: 0.2999\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9083 - accuracy: 0.4323 - precision_m: 0.7089 - recall_m: 0.1957 - f1_m: 0.3057 - val_loss: 2.0146 - val_accuracy: 0.4148 - val_precision_m: 0.6819 - val_recall_m: 0.1938 - val_f1_m: 0.2999\n",
      "Epoch 22/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.9012 - accuracy: 0.4354 - precision_m: 0.7100 - recall_m: 0.1989 - f1_m: 0.3095\n",
      "Epoch 22: val_loss improved from 1.98291 to 1.97084, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 22\n",
      "Accuracy: 0.4154 | Precision: 0.6869 | Recall: 0.2007 | F1: 0.3087\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9012 - accuracy: 0.4354 - precision_m: 0.7100 - recall_m: 0.1989 - f1_m: 0.3095 - val_loss: 1.9708 - val_accuracy: 0.4154 - val_precision_m: 0.6869 - val_recall_m: 0.2007 - val_f1_m: 0.3087\n",
      "Epoch 23/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.8985 - accuracy: 0.4361 - precision_m: 0.7114 - recall_m: 0.1996 - f1_m: 0.3107\n",
      "Epoch 23: val_loss did not improve from 1.97084\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8986 - accuracy: 0.4361 - precision_m: 0.7118 - recall_m: 0.1994 - f1_m: 0.3105 - val_loss: 1.9993 - val_accuracy: 0.4121 - val_precision_m: 0.6759 - val_recall_m: 0.1951 - val_f1_m: 0.3009\n",
      "Epoch 24/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 1.8895 - accuracy: 0.4400 - precision_m: 0.7067 - recall_m: 0.2030 - f1_m: 0.3142\n",
      "Epoch 24: val_loss did not improve from 1.97084\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 24\n",
      "Accuracy: 0.4188 | Precision: 0.6843 | Recall: 0.1969 | F1: 0.3040\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8896 - accuracy: 0.4399 - precision_m: 0.7068 - recall_m: 0.2030 - f1_m: 0.3142 - val_loss: 1.9766 - val_accuracy: 0.4188 - val_precision_m: 0.6843 - val_recall_m: 0.1969 - val_f1_m: 0.3040\n",
      "Epoch 25/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.8858 - accuracy: 0.4409 - precision_m: 0.7115 - recall_m: 0.2033 - f1_m: 0.3152\n",
      "Epoch 25: val_loss did not improve from 1.97084\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.4202 | Precision: 0.6909 | Recall: 0.1991 | F1: 0.3070\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8858 - accuracy: 0.4409 - precision_m: 0.7116 - recall_m: 0.2035 - f1_m: 0.3154 - val_loss: 1.9908 - val_accuracy: 0.4202 - val_precision_m: 0.6909 - val_recall_m: 0.1991 - val_f1_m: 0.3070\n",
      "Epoch 26/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.8813 - accuracy: 0.4399 - precision_m: 0.7075 - recall_m: 0.2063 - f1_m: 0.3184\n",
      "Epoch 26: val_loss did not improve from 1.97084\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8815 - accuracy: 0.4398 - precision_m: 0.7074 - recall_m: 0.2063 - f1_m: 0.3185 - val_loss: 2.0233 - val_accuracy: 0.4034 - val_precision_m: 0.6571 - val_recall_m: 0.1957 - val_f1_m: 0.2996\n",
      "Epoch 27/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 1.8772 - accuracy: 0.4427 - precision_m: 0.7102 - recall_m: 0.2070 - f1_m: 0.3194\n",
      "Epoch 27: val_loss improved from 1.97084 to 1.95882, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 27\n",
      "Accuracy: 0.4231 | Precision: 0.6903 | Recall: 0.2003 | F1: 0.3087\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8779 - accuracy: 0.4425 - precision_m: 0.7098 - recall_m: 0.2070 - f1_m: 0.3193 - val_loss: 1.9588 - val_accuracy: 0.4231 - val_precision_m: 0.6903 - val_recall_m: 0.2003 - val_f1_m: 0.3087\n",
      "Epoch 28/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.8748 - accuracy: 0.4433 - precision_m: 0.7103 - recall_m: 0.2094 - f1_m: 0.3222\n",
      "Epoch 28: val_loss did not improve from 1.95882\n",
      "609/609 [==============================] - 5s 8ms/step - loss: 1.8747 - accuracy: 0.4434 - precision_m: 0.7099 - recall_m: 0.2094 - f1_m: 0.3221 - val_loss: 1.9752 - val_accuracy: 0.4183 - val_precision_m: 0.6884 - val_recall_m: 0.1998 - val_f1_m: 0.3077\n",
      "Epoch 29/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.8682 - accuracy: 0.4447 - precision_m: 0.7141 - recall_m: 0.2114 - f1_m: 0.3251\n",
      "Epoch 29: val_loss did not improve from 1.95882\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8686 - accuracy: 0.4446 - precision_m: 0.7139 - recall_m: 0.2113 - f1_m: 0.3250 - val_loss: 1.9837 - val_accuracy: 0.4171 - val_precision_m: 0.6720 - val_recall_m: 0.2075 - val_f1_m: 0.3152\n",
      "Epoch 30/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.8673 - accuracy: 0.4460 - precision_m: 0.7129 - recall_m: 0.2124 - f1_m: 0.3261\n",
      "Epoch 30: val_loss improved from 1.95882 to 1.95422, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 30\n",
      "Accuracy: 0.4272 | Precision: 0.6890 | Recall: 0.2112 | F1: 0.3216\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8672 - accuracy: 0.4461 - precision_m: 0.7134 - recall_m: 0.2124 - f1_m: 0.3261 - val_loss: 1.9542 - val_accuracy: 0.4272 - val_precision_m: 0.6890 - val_recall_m: 0.2112 - val_f1_m: 0.3216\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 131.7 seconds (2.2 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 73.6%\n",
      "  Usage (max):  85.9%\n",
      "  Frequency:    3993 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 79.0%\n",
      "  Usage (max):  80.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  15.7%\n",
      "  Usage (max):   44.0%\n",
      "  Memory (mean): 609 MB\n",
      "  Memory (max):  658 MB\n",
      "  Power (mean):  20.8 W\n",
      "  Power (max):   41.7 W\n",
      "  Energy used:   0.763 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 RESULTS\n",
      "================================================================================\n",
      "Validation - Loss: 1.9542, Acc: 42.72%\n",
      "Test       - Loss: 1.9686, Acc: 42.43%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 2 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77821, Val=8256, Test=7524\n",
      "Epoch 1/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 2.7274 - accuracy: 0.2362 - precision_m: 0.4929 - recall_m: 0.0374 - f1_m: 0.0679\n",
      "Epoch 1: val_loss improved from inf to 2.29576, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.3438 | Precision: 0.6819 | Recall: 0.0962 | F1: 0.1671\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 5s 7ms/step - loss: 2.7274 - accuracy: 0.2362 - precision_m: 0.4929 - recall_m: 0.0374 - f1_m: 0.0679 - val_loss: 2.2958 - val_accuracy: 0.3438 - val_precision_m: 0.6819 - val_recall_m: 0.0962 - val_f1_m: 0.1671\n",
      "Epoch 2/30\n",
      "603/608 [============================>.] - ETA: 0s - loss: 2.1510 - accuracy: 0.3796 - precision_m: 0.7083 - recall_m: 0.1355 - f1_m: 0.2259\n",
      "Epoch 2: val_loss improved from 2.29576 to 2.12112, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3920 | Precision: 0.6897 | Recall: 0.1558 | F1: 0.2521\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 2.1508 - accuracy: 0.3799 - precision_m: 0.7078 - recall_m: 0.1356 - f1_m: 0.2261 - val_loss: 2.1211 - val_accuracy: 0.3920 - val_precision_m: 0.6897 - val_recall_m: 0.1558 - val_f1_m: 0.2521\n",
      "Epoch 3/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 2.0032 - accuracy: 0.4199 - precision_m: 0.7248 - recall_m: 0.1841 - f1_m: 0.2924\n",
      "Epoch 3: val_loss improved from 2.12112 to 2.02450, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.4175 | Precision: 0.7199 | Recall: 0.1839 | F1: 0.2912\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 5s 7ms/step - loss: 2.0033 - accuracy: 0.4199 - precision_m: 0.7250 - recall_m: 0.1842 - f1_m: 0.2924 - val_loss: 2.0245 - val_accuracy: 0.4175 - val_precision_m: 0.7199 - val_recall_m: 0.1839 - val_f1_m: 0.2912\n",
      "Epoch 4/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 1.9170 - accuracy: 0.4439 - precision_m: 0.7356 - recall_m: 0.2131 - f1_m: 0.3292\n",
      "Epoch 4: val_loss improved from 2.02450 to 1.99645, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.4251 | Precision: 0.7016 | Recall: 0.2102 | F1: 0.3212\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.9170 - accuracy: 0.4439 - precision_m: 0.7356 - recall_m: 0.2131 - f1_m: 0.3292 - val_loss: 1.9964 - val_accuracy: 0.4251 - val_precision_m: 0.7016 - val_recall_m: 0.2102 - val_f1_m: 0.3212\n",
      "Epoch 5/30\n",
      "601/608 [============================>.] - ETA: 0s - loss: 1.8556 - accuracy: 0.4581 - precision_m: 0.7411 - recall_m: 0.2359 - f1_m: 0.3567\n",
      "Epoch 5: val_loss improved from 1.99645 to 1.91614, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.4530 | Precision: 0.7222 | Recall: 0.2262 | F1: 0.3427\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.8554 - accuracy: 0.4579 - precision_m: 0.7406 - recall_m: 0.2356 - f1_m: 0.3563 - val_loss: 1.9161 - val_accuracy: 0.4530 - val_precision_m: 0.7222 - val_recall_m: 0.2262 - val_f1_m: 0.3427\n",
      "Epoch 6/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 1.8040 - accuracy: 0.4718 - precision_m: 0.7462 - recall_m: 0.2512 - f1_m: 0.3747\n",
      "Epoch 6: val_loss improved from 1.91614 to 1.89187, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.4562 | Precision: 0.7206 | Recall: 0.2433 | F1: 0.3619\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.8040 - accuracy: 0.4717 - precision_m: 0.7464 - recall_m: 0.2512 - f1_m: 0.3747 - val_loss: 1.8919 - val_accuracy: 0.4562 - val_precision_m: 0.7206 - val_recall_m: 0.2433 - val_f1_m: 0.3619\n",
      "Epoch 7/30\n",
      "600/608 [============================>.] - ETA: 0s - loss: 1.7633 - accuracy: 0.4819 - precision_m: 0.7480 - recall_m: 0.2687 - f1_m: 0.3943\n",
      "Epoch 7: val_loss improved from 1.89187 to 1.86321, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.4627 | Precision: 0.7086 | Recall: 0.2554 | F1: 0.3739\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.7634 - accuracy: 0.4819 - precision_m: 0.7480 - recall_m: 0.2688 - f1_m: 0.3944 - val_loss: 1.8632 - val_accuracy: 0.4627 - val_precision_m: 0.7086 - val_recall_m: 0.2554 - val_f1_m: 0.3739\n",
      "Epoch 8/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.7276 - accuracy: 0.4921 - precision_m: 0.7516 - recall_m: 0.2827 - f1_m: 0.4098\n",
      "Epoch 8: val_loss improved from 1.86321 to 1.81874, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.4746 | Precision: 0.7153 | Recall: 0.2666 | F1: 0.3864\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.7278 - accuracy: 0.4921 - precision_m: 0.7515 - recall_m: 0.2826 - f1_m: 0.4097 - val_loss: 1.8187 - val_accuracy: 0.4746 - val_precision_m: 0.7153 - val_recall_m: 0.2666 - val_f1_m: 0.3864\n",
      "Epoch 9/30\n",
      "603/608 [============================>.] - ETA: 0s - loss: 1.6962 - accuracy: 0.4997 - precision_m: 0.7553 - recall_m: 0.2948 - f1_m: 0.4231\n",
      "Epoch 9: val_loss improved from 1.81874 to 1.81624, saving model to trained_models/model_1_fold_2_best.h5\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.6959 - accuracy: 0.4997 - precision_m: 0.7556 - recall_m: 0.2951 - f1_m: 0.4235 - val_loss: 1.8162 - val_accuracy: 0.4738 - val_precision_m: 0.7109 - val_recall_m: 0.2738 - val_f1_m: 0.3932\n",
      "Epoch 10/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 1.6722 - accuracy: 0.5051 - precision_m: 0.7538 - recall_m: 0.3037 - f1_m: 0.4319\n",
      "Epoch 10: val_loss improved from 1.81624 to 1.79593, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.4758 | Precision: 0.7145 | Recall: 0.2797 | F1: 0.4001\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.6722 - accuracy: 0.5052 - precision_m: 0.7536 - recall_m: 0.3038 - f1_m: 0.4320 - val_loss: 1.7959 - val_accuracy: 0.4758 - val_precision_m: 0.7145 - val_recall_m: 0.2797 - val_f1_m: 0.4001\n",
      "Epoch 11/30\n",
      "603/608 [============================>.] - ETA: 0s - loss: 1.6513 - accuracy: 0.5118 - precision_m: 0.7555 - recall_m: 0.3145 - f1_m: 0.4431\n",
      "Epoch 11: val_loss improved from 1.79593 to 1.78251, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.4839 | Precision: 0.7162 | Recall: 0.2840 | F1: 0.4051\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.6503 - accuracy: 0.5120 - precision_m: 0.7556 - recall_m: 0.3146 - f1_m: 0.4432 - val_loss: 1.7825 - val_accuracy: 0.4839 - val_precision_m: 0.7162 - val_recall_m: 0.2840 - val_f1_m: 0.4051\n",
      "Epoch 12/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 1.6341 - accuracy: 0.5181 - precision_m: 0.7569 - recall_m: 0.3212 - f1_m: 0.4500\n",
      "Epoch 12: val_loss improved from 1.78251 to 1.77070, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.4845 | Precision: 0.7312 | Recall: 0.2962 | F1: 0.4198\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.6335 - accuracy: 0.5183 - precision_m: 0.7570 - recall_m: 0.3214 - f1_m: 0.4502 - val_loss: 1.7707 - val_accuracy: 0.4845 - val_precision_m: 0.7312 - val_recall_m: 0.2962 - val_f1_m: 0.4198\n",
      "Epoch 13/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 1.6168 - accuracy: 0.5220 - precision_m: 0.7571 - recall_m: 0.3295 - f1_m: 0.4581\n",
      "Epoch 13: val_loss improved from 1.77070 to 1.74633, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 13\n",
      "Accuracy: 0.4919 | Precision: 0.7223 | Recall: 0.3071 | F1: 0.4295\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 5s 8ms/step - loss: 1.6171 - accuracy: 0.5219 - precision_m: 0.7571 - recall_m: 0.3294 - f1_m: 0.4580 - val_loss: 1.7463 - val_accuracy: 0.4919 - val_precision_m: 0.7223 - val_recall_m: 0.3071 - val_f1_m: 0.4295\n",
      "Epoch 14/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 1.6072 - accuracy: 0.5229 - precision_m: 0.7557 - recall_m: 0.3337 - f1_m: 0.4620\n",
      "Epoch 14: val_loss did not improve from 1.74633\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.6075 - accuracy: 0.5230 - precision_m: 0.7555 - recall_m: 0.3334 - f1_m: 0.4617 - val_loss: 1.7539 - val_accuracy: 0.4908 - val_precision_m: 0.7217 - val_recall_m: 0.2986 - val_f1_m: 0.4206\n",
      "Epoch 15/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 1.5985 - accuracy: 0.5252 - precision_m: 0.7573 - recall_m: 0.3387 - f1_m: 0.4671\n",
      "Epoch 15: val_loss did not improve from 1.74633\n",
      "608/608 [==============================] - 5s 7ms/step - loss: 1.5990 - accuracy: 0.5249 - precision_m: 0.7572 - recall_m: 0.3384 - f1_m: 0.4668 - val_loss: 1.7725 - val_accuracy: 0.4840 - val_precision_m: 0.7103 - val_recall_m: 0.3048 - val_f1_m: 0.4251\n",
      "Epoch 16/30\n",
      "603/608 [============================>.] - ETA: 0s - loss: 1.5898 - accuracy: 0.5284 - precision_m: 0.7577 - recall_m: 0.3409 - f1_m: 0.4692\n",
      "Epoch 16: val_loss did not improve from 1.74633\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.4922 | Precision: 0.7187 | Recall: 0.3090 | F1: 0.4305\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 5s 8ms/step - loss: 1.5893 - accuracy: 0.5285 - precision_m: 0.7577 - recall_m: 0.3411 - f1_m: 0.4694 - val_loss: 1.7535 - val_accuracy: 0.4922 - val_precision_m: 0.7187 - val_recall_m: 0.3090 - val_f1_m: 0.4305\n",
      "Epoch 17/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 1.5784 - accuracy: 0.5318 - precision_m: 0.7582 - recall_m: 0.3483 - f1_m: 0.4763\n",
      "Epoch 17: val_loss improved from 1.74633 to 1.73764, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.4937 | Precision: 0.7233 | Recall: 0.3175 | F1: 0.4399\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 5s 7ms/step - loss: 1.5784 - accuracy: 0.5318 - precision_m: 0.7582 - recall_m: 0.3483 - f1_m: 0.4763 - val_loss: 1.7376 - val_accuracy: 0.4937 - val_precision_m: 0.7233 - val_recall_m: 0.3175 - val_f1_m: 0.4399\n",
      "Epoch 18/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 1.5691 - accuracy: 0.5332 - precision_m: 0.7573 - recall_m: 0.3498 - f1_m: 0.4776\n",
      "Epoch 18: val_loss improved from 1.73764 to 1.73704, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.4954 | Precision: 0.7161 | Recall: 0.3172 | F1: 0.4382\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.5692 - accuracy: 0.5332 - precision_m: 0.7575 - recall_m: 0.3498 - f1_m: 0.4776 - val_loss: 1.7370 - val_accuracy: 0.4954 - val_precision_m: 0.7161 - val_recall_m: 0.3172 - val_f1_m: 0.4382\n",
      "Epoch 19/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 1.5626 - accuracy: 0.5362 - precision_m: 0.7597 - recall_m: 0.3541 - f1_m: 0.4822\n",
      "Epoch 19: val_loss improved from 1.73704 to 1.72724, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 19\n",
      "Accuracy: 0.5004 | Precision: 0.7153 | Recall: 0.3262 | F1: 0.4469\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.5627 - accuracy: 0.5361 - precision_m: 0.7598 - recall_m: 0.3540 - f1_m: 0.4821 - val_loss: 1.7272 - val_accuracy: 0.5004 - val_precision_m: 0.7153 - val_recall_m: 0.3262 - val_f1_m: 0.4469\n",
      "Epoch 20/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.5616 - accuracy: 0.5348 - precision_m: 0.7565 - recall_m: 0.3563 - f1_m: 0.4835\n",
      "Epoch 20: val_loss did not improve from 1.72724\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 20\n",
      "Accuracy: 0.5016 | Precision: 0.7186 | Recall: 0.3331 | F1: 0.4538\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.5618 - accuracy: 0.5347 - precision_m: 0.7563 - recall_m: 0.3563 - f1_m: 0.4834 - val_loss: 1.7313 - val_accuracy: 0.5016 - val_precision_m: 0.7186 - val_recall_m: 0.3331 - val_f1_m: 0.4538\n",
      "Epoch 21/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.5539 - accuracy: 0.5386 - precision_m: 0.7597 - recall_m: 0.3600 - f1_m: 0.4875\n",
      "Epoch 21: val_loss improved from 1.72724 to 1.72517, saving model to trained_models/model_1_fold_2_best.h5\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.5540 - accuracy: 0.5387 - precision_m: 0.7597 - recall_m: 0.3599 - f1_m: 0.4874 - val_loss: 1.7252 - val_accuracy: 0.4996 - val_precision_m: 0.7178 - val_recall_m: 0.3282 - val_f1_m: 0.4489\n",
      "Epoch 22/30\n",
      "603/608 [============================>.] - ETA: 0s - loss: 1.5467 - accuracy: 0.5419 - precision_m: 0.7642 - recall_m: 0.3613 - f1_m: 0.4898\n",
      "Epoch 22: val_loss improved from 1.72517 to 1.72153, saving model to trained_models/model_1_fold_2_best.h5\n",
      "608/608 [==============================] - 5s 7ms/step - loss: 1.5469 - accuracy: 0.5421 - precision_m: 0.7644 - recall_m: 0.3613 - f1_m: 0.4898 - val_loss: 1.7215 - val_accuracy: 0.5015 - val_precision_m: 0.7170 - val_recall_m: 0.3331 - val_f1_m: 0.4535\n",
      "Epoch 23/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 1.5414 - accuracy: 0.5412 - precision_m: 0.7613 - recall_m: 0.3637 - f1_m: 0.4912\n",
      "Epoch 23: val_loss did not improve from 1.72153\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.5410 - accuracy: 0.5413 - precision_m: 0.7612 - recall_m: 0.3637 - f1_m: 0.4912 - val_loss: 1.7458 - val_accuracy: 0.4915 - val_precision_m: 0.7141 - val_recall_m: 0.3187 - val_f1_m: 0.4396\n",
      "Epoch 24/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 1.5347 - accuracy: 0.5441 - precision_m: 0.7618 - recall_m: 0.3661 - f1_m: 0.4935\n",
      "Epoch 24: val_loss did not improve from 1.72153\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 24\n",
      "Accuracy: 0.5046 | Precision: 0.7198 | Recall: 0.3282 | F1: 0.4497\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.5347 - accuracy: 0.5441 - precision_m: 0.7618 - recall_m: 0.3661 - f1_m: 0.4935 - val_loss: 1.7221 - val_accuracy: 0.5046 - val_precision_m: 0.7198 - val_recall_m: 0.3282 - val_f1_m: 0.4497\n",
      "Epoch 25/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.5472 - precision_m: 0.7656 - recall_m: 0.3706 - f1_m: 0.4985\n",
      "Epoch 25: val_loss improved from 1.72153 to 1.71231, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.5059 | Precision: 0.7089 | Recall: 0.3389 | F1: 0.4575\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.5281 - accuracy: 0.5470 - precision_m: 0.7655 - recall_m: 0.3704 - f1_m: 0.4983 - val_loss: 1.7123 - val_accuracy: 0.5059 - val_precision_m: 0.7089 - val_recall_m: 0.3389 - val_f1_m: 0.4575\n",
      "Epoch 26/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 1.5222 - accuracy: 0.5478 - precision_m: 0.7628 - recall_m: 0.3721 - f1_m: 0.4994\n",
      "Epoch 26: val_loss did not improve from 1.71231\n",
      "608/608 [==============================] - 5s 7ms/step - loss: 1.5224 - accuracy: 0.5477 - precision_m: 0.7629 - recall_m: 0.3721 - f1_m: 0.4994 - val_loss: 1.7289 - val_accuracy: 0.5002 - val_precision_m: 0.7140 - val_recall_m: 0.3281 - val_f1_m: 0.4485\n",
      "Epoch 27/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 1.5204 - accuracy: 0.5483 - precision_m: 0.7648 - recall_m: 0.3732 - f1_m: 0.5008\n",
      "Epoch 27: val_loss improved from 1.71231 to 1.70118, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 27\n",
      "Accuracy: 0.5078 | Precision: 0.7178 | Recall: 0.3395 | F1: 0.4594\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.5204 - accuracy: 0.5483 - precision_m: 0.7648 - recall_m: 0.3731 - f1_m: 0.5007 - val_loss: 1.7012 - val_accuracy: 0.5078 - val_precision_m: 0.7178 - val_recall_m: 0.3395 - val_f1_m: 0.4594\n",
      "Epoch 28/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.5172 - accuracy: 0.5490 - precision_m: 0.7648 - recall_m: 0.3759 - f1_m: 0.5032\n",
      "Epoch 28: val_loss did not improve from 1.70118\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.5171 - accuracy: 0.5491 - precision_m: 0.7648 - recall_m: 0.3758 - f1_m: 0.5031 - val_loss: 1.7092 - val_accuracy: 0.5057 - val_precision_m: 0.7147 - val_recall_m: 0.3388 - val_f1_m: 0.4582\n",
      "Epoch 29/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.5110 - accuracy: 0.5503 - precision_m: 0.7647 - recall_m: 0.3767 - f1_m: 0.5038\n",
      "Epoch 29: val_loss did not improve from 1.70118\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 29\n",
      "Accuracy: 0.5122 | Precision: 0.7202 | Recall: 0.3494 | F1: 0.4690\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 5s 7ms/step - loss: 1.5113 - accuracy: 0.5503 - precision_m: 0.7646 - recall_m: 0.3766 - f1_m: 0.5037 - val_loss: 1.7053 - val_accuracy: 0.5122 - val_precision_m: 0.7202 - val_recall_m: 0.3494 - val_f1_m: 0.4690\n",
      "Epoch 30/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.5058 - accuracy: 0.5526 - precision_m: 0.7661 - recall_m: 0.3798 - f1_m: 0.5070\n",
      "Epoch 30: val_loss improved from 1.70118 to 1.68918, saving model to trained_models/model_1_fold_2_best.h5\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.5057 - accuracy: 0.5527 - precision_m: 0.7662 - recall_m: 0.3799 - f1_m: 0.5071 - val_loss: 1.6892 - val_accuracy: 0.5116 - val_precision_m: 0.7202 - val_recall_m: 0.3547 - val_f1_m: 0.4739\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 135.0 seconds (2.3 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 74.9%\n",
      "  Usage (max):  91.4%\n",
      "  Frequency:    3990 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 82.7%\n",
      "  Usage (max):  83.9%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  15.9%\n",
      "  Usage (max):   43.0%\n",
      "  Memory (mean): 618 MB\n",
      "  Memory (max):  665 MB\n",
      "  Power (mean):  17.1 W\n",
      "  Power (max):   19.7 W\n",
      "  Energy used:   0.643 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 RESULTS\n",
      "================================================================================\n",
      "Validation - Loss: 1.6892, Acc: 51.16%\n",
      "Test       - Loss: 1.6769, Acc: 51.78%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 3 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77973, Val=8263, Test=7405\n",
      "Epoch 1/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.8416 - accuracy: 0.2110 - precision_m: 0.4481 - recall_m: 0.0217 - f1_m: 0.0407\n",
      "Epoch 1: val_loss improved from inf to 2.49156, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2874 | Precision: 0.6454 | Recall: 0.0674 | F1: 0.1207\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 2.8386 - accuracy: 0.2116 - precision_m: 0.4496 - recall_m: 0.0221 - f1_m: 0.0413 - val_loss: 2.4916 - val_accuracy: 0.2874 - val_precision_m: 0.6454 - val_recall_m: 0.0674 - val_f1_m: 0.1207\n",
      "Epoch 2/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.3425 - accuracy: 0.3215 - precision_m: 0.6735 - recall_m: 0.0780 - f1_m: 0.1388\n",
      "Epoch 2: val_loss improved from 2.49156 to 2.34107, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3240 | Precision: 0.6790 | Recall: 0.0932 | F1: 0.1627\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 7ms/step - loss: 2.3420 - accuracy: 0.3216 - precision_m: 0.6738 - recall_m: 0.0783 - f1_m: 0.1392 - val_loss: 2.3411 - val_accuracy: 0.3240 - val_precision_m: 0.6790 - val_recall_m: 0.0932 - val_f1_m: 0.1627\n",
      "Epoch 3/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 2.2147 - accuracy: 0.3551 - precision_m: 0.6915 - recall_m: 0.1070 - f1_m: 0.1842\n",
      "Epoch 3: val_loss improved from 2.34107 to 2.24212, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3471 | Precision: 0.6693 | Recall: 0.1237 | F1: 0.2070\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.2136 - accuracy: 0.3550 - precision_m: 0.6918 - recall_m: 0.1072 - f1_m: 0.1844 - val_loss: 2.2421 - val_accuracy: 0.3471 - val_precision_m: 0.6693 - val_recall_m: 0.1237 - val_f1_m: 0.2070\n",
      "Epoch 4/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 2.1266 - accuracy: 0.3778 - precision_m: 0.7024 - recall_m: 0.1308 - f1_m: 0.2194\n",
      "Epoch 4: val_loss improved from 2.24212 to 2.15815, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.3769 | Precision: 0.6979 | Recall: 0.1332 | F1: 0.2217\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1267 - accuracy: 0.3778 - precision_m: 0.7024 - recall_m: 0.1309 - f1_m: 0.2196 - val_loss: 2.1582 - val_accuracy: 0.3769 - val_precision_m: 0.6979 - val_recall_m: 0.1332 - val_f1_m: 0.2217\n",
      "Epoch 5/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.0626 - accuracy: 0.3948 - precision_m: 0.7077 - recall_m: 0.1490 - f1_m: 0.2449\n",
      "Epoch 5: val_loss did not improve from 2.15815\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.0621 - accuracy: 0.3950 - precision_m: 0.7078 - recall_m: 0.1493 - f1_m: 0.2453 - val_loss: 2.1746 - val_accuracy: 0.3754 - val_precision_m: 0.6866 - val_recall_m: 0.1537 - val_f1_m: 0.2493\n",
      "Epoch 6/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 2.0046 - accuracy: 0.4115 - precision_m: 0.7121 - recall_m: 0.1678 - f1_m: 0.2704\n",
      "Epoch 6: val_loss improved from 2.15815 to 2.08160, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.3951 | Precision: 0.6921 | Recall: 0.1705 | F1: 0.2710\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.0046 - accuracy: 0.4115 - precision_m: 0.7121 - recall_m: 0.1678 - f1_m: 0.2704 - val_loss: 2.0816 - val_accuracy: 0.3951 - val_precision_m: 0.6921 - val_recall_m: 0.1705 - val_f1_m: 0.2710\n",
      "Epoch 7/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 1.9594 - accuracy: 0.4234 - precision_m: 0.7136 - recall_m: 0.1809 - f1_m: 0.2875\n",
      "Epoch 7: val_loss improved from 2.08160 to 2.04967, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.4022 | Precision: 0.6836 | Recall: 0.1741 | F1: 0.2750\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.9593 - accuracy: 0.4234 - precision_m: 0.7136 - recall_m: 0.1809 - f1_m: 0.2876 - val_loss: 2.0497 - val_accuracy: 0.4022 - val_precision_m: 0.6836 - val_recall_m: 0.1741 - val_f1_m: 0.2750\n",
      "Epoch 8/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 1.9171 - accuracy: 0.4347 - precision_m: 0.7177 - recall_m: 0.1960 - f1_m: 0.3066\n",
      "Epoch 8: val_loss improved from 2.04967 to 2.00798, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.4169 | Precision: 0.6869 | Recall: 0.1850 | F1: 0.2890\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.9171 - accuracy: 0.4347 - precision_m: 0.7177 - recall_m: 0.1960 - f1_m: 0.3066 - val_loss: 2.0080 - val_accuracy: 0.4169 - val_precision_m: 0.6869 - val_recall_m: 0.1850 - val_f1_m: 0.2890\n",
      "Epoch 9/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.8889 - accuracy: 0.4424 - precision_m: 0.7201 - recall_m: 0.2077 - f1_m: 0.3212\n",
      "Epoch 9: val_loss did not improve from 2.00798\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.8888 - accuracy: 0.4424 - precision_m: 0.7203 - recall_m: 0.2078 - f1_m: 0.3214 - val_loss: 2.0229 - val_accuracy: 0.4075 - val_precision_m: 0.6741 - val_recall_m: 0.1920 - val_f1_m: 0.2969\n",
      "Epoch 10/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.8656 - accuracy: 0.4470 - precision_m: 0.7220 - recall_m: 0.2191 - f1_m: 0.3351\n",
      "Epoch 10: val_loss improved from 2.00798 to 1.96892, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.4213 | Precision: 0.6915 | Recall: 0.1986 | F1: 0.3060\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.8655 - accuracy: 0.4471 - precision_m: 0.7222 - recall_m: 0.2191 - f1_m: 0.3352 - val_loss: 1.9689 - val_accuracy: 0.4213 - val_precision_m: 0.6915 - val_recall_m: 0.1986 - val_f1_m: 0.3060\n",
      "Epoch 11/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.8412 - accuracy: 0.4542 - precision_m: 0.7228 - recall_m: 0.2260 - f1_m: 0.3432\n",
      "Epoch 11: val_loss improved from 1.96892 to 1.92715, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.4348 | Precision: 0.7032 | Recall: 0.2149 | F1: 0.3267\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.8411 - accuracy: 0.4542 - precision_m: 0.7229 - recall_m: 0.2261 - f1_m: 0.3433 - val_loss: 1.9271 - val_accuracy: 0.4348 - val_precision_m: 0.7032 - val_recall_m: 0.2149 - val_f1_m: 0.3267\n",
      "Epoch 12/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 1.8257 - accuracy: 0.4579 - precision_m: 0.7198 - recall_m: 0.2335 - f1_m: 0.3516\n",
      "Epoch 12: val_loss did not improve from 1.92715\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.8261 - accuracy: 0.4577 - precision_m: 0.7196 - recall_m: 0.2334 - f1_m: 0.3514 - val_loss: 1.9737 - val_accuracy: 0.4209 - val_precision_m: 0.6660 - val_recall_m: 0.2122 - val_f1_m: 0.3194\n",
      "Epoch 13/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.8158 - accuracy: 0.4600 - precision_m: 0.7199 - recall_m: 0.2392 - f1_m: 0.3580\n",
      "Epoch 13: val_loss did not improve from 1.92715\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.8158 - accuracy: 0.4601 - precision_m: 0.7199 - recall_m: 0.2392 - f1_m: 0.3580 - val_loss: 1.9831 - val_accuracy: 0.4201 - val_precision_m: 0.6748 - val_recall_m: 0.2205 - val_f1_m: 0.3301\n",
      "Epoch 14/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.7967 - accuracy: 0.4662 - precision_m: 0.7222 - recall_m: 0.2453 - f1_m: 0.3650\n",
      "Epoch 14: val_loss did not improve from 1.92715\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.4354 | Precision: 0.6996 | Recall: 0.2266 | F1: 0.3401\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7967 - accuracy: 0.4662 - precision_m: 0.7222 - recall_m: 0.2451 - f1_m: 0.3648 - val_loss: 1.9426 - val_accuracy: 0.4354 - val_precision_m: 0.6996 - val_recall_m: 0.2266 - val_f1_m: 0.3401\n",
      "Epoch 15/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.7923 - accuracy: 0.4681 - precision_m: 0.7238 - recall_m: 0.2486 - f1_m: 0.3690\n",
      "Epoch 15: val_loss improved from 1.92715 to 1.92066, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 15\n",
      "Accuracy: 0.4416 | Precision: 0.7010 | Recall: 0.2313 | F1: 0.3456\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7930 - accuracy: 0.4678 - precision_m: 0.7231 - recall_m: 0.2486 - f1_m: 0.3689 - val_loss: 1.9207 - val_accuracy: 0.4416 - val_precision_m: 0.7010 - val_recall_m: 0.2313 - val_f1_m: 0.3456\n",
      "Epoch 16/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.7827 - accuracy: 0.4693 - precision_m: 0.7267 - recall_m: 0.2541 - f1_m: 0.3754\n",
      "Epoch 16: val_loss improved from 1.92066 to 1.90128, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.4437 | Precision: 0.6984 | Recall: 0.2331 | F1: 0.3470\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7831 - accuracy: 0.4692 - precision_m: 0.7265 - recall_m: 0.2541 - f1_m: 0.3753 - val_loss: 1.9013 - val_accuracy: 0.4437 - val_precision_m: 0.6984 - val_recall_m: 0.2331 - val_f1_m: 0.3470\n",
      "Epoch 17/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.7684 - accuracy: 0.4740 - precision_m: 0.7270 - recall_m: 0.2589 - f1_m: 0.3807\n",
      "Epoch 17: val_loss improved from 1.90128 to 1.89457, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.4446 | Precision: 0.6955 | Recall: 0.2407 | F1: 0.3550\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7685 - accuracy: 0.4739 - precision_m: 0.7269 - recall_m: 0.2588 - f1_m: 0.3806 - val_loss: 1.8946 - val_accuracy: 0.4446 - val_precision_m: 0.6955 - val_recall_m: 0.2407 - val_f1_m: 0.3550\n",
      "Epoch 18/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 1.7632 - accuracy: 0.4747 - precision_m: 0.7255 - recall_m: 0.2621 - f1_m: 0.3840\n",
      "Epoch 18: val_loss did not improve from 1.89457\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.4468 | Precision: 0.6853 | Recall: 0.2458 | F1: 0.3595\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7638 - accuracy: 0.4746 - precision_m: 0.7250 - recall_m: 0.2619 - f1_m: 0.3837 - val_loss: 1.8958 - val_accuracy: 0.4468 - val_precision_m: 0.6853 - val_recall_m: 0.2458 - val_f1_m: 0.3595\n",
      "Epoch 19/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.7581 - accuracy: 0.4775 - precision_m: 0.7276 - recall_m: 0.2627 - f1_m: 0.3850\n",
      "Epoch 19: val_loss did not improve from 1.89457\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7582 - accuracy: 0.4773 - precision_m: 0.7271 - recall_m: 0.2625 - f1_m: 0.3846 - val_loss: 1.9341 - val_accuracy: 0.4381 - val_precision_m: 0.6838 - val_recall_m: 0.2478 - val_f1_m: 0.3618\n",
      "Epoch 20/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 1.7510 - accuracy: 0.4801 - precision_m: 0.7255 - recall_m: 0.2682 - f1_m: 0.3905\n",
      "Epoch 20: val_loss improved from 1.89457 to 1.88500, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 20\n",
      "Accuracy: 0.4481 | Precision: 0.7022 | Recall: 0.2463 | F1: 0.3622\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7512 - accuracy: 0.4803 - precision_m: 0.7261 - recall_m: 0.2683 - f1_m: 0.3907 - val_loss: 1.8850 - val_accuracy: 0.4481 - val_precision_m: 0.7022 - val_recall_m: 0.2463 - val_f1_m: 0.3622\n",
      "Epoch 21/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.7432 - accuracy: 0.4806 - precision_m: 0.7265 - recall_m: 0.2700 - f1_m: 0.3926\n",
      "Epoch 21: val_loss did not improve from 1.88500\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7433 - accuracy: 0.4806 - precision_m: 0.7261 - recall_m: 0.2699 - f1_m: 0.3924 - val_loss: 1.8968 - val_accuracy: 0.4461 - val_precision_m: 0.6896 - val_recall_m: 0.2499 - val_f1_m: 0.3646\n",
      "Epoch 22/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 1.7391 - accuracy: 0.4816 - precision_m: 0.7245 - recall_m: 0.2716 - f1_m: 0.3941\n",
      "Epoch 22: val_loss improved from 1.88500 to 1.86264, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 22\n",
      "Accuracy: 0.4553 | Precision: 0.6999 | Recall: 0.2504 | F1: 0.3666\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7386 - accuracy: 0.4821 - precision_m: 0.7249 - recall_m: 0.2717 - f1_m: 0.3943 - val_loss: 1.8626 - val_accuracy: 0.4553 - val_precision_m: 0.6999 - val_recall_m: 0.2504 - val_f1_m: 0.3666\n",
      "Epoch 23/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.7345 - accuracy: 0.4829 - precision_m: 0.7254 - recall_m: 0.2755 - f1_m: 0.3983\n",
      "Epoch 23: val_loss did not improve from 1.86264\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7347 - accuracy: 0.4829 - precision_m: 0.7249 - recall_m: 0.2754 - f1_m: 0.3981 - val_loss: 1.8802 - val_accuracy: 0.4531 - val_precision_m: 0.6891 - val_recall_m: 0.2588 - val_f1_m: 0.3744\n",
      "Epoch 24/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 1.7282 - accuracy: 0.4855 - precision_m: 0.7295 - recall_m: 0.2771 - f1_m: 0.4006\n",
      "Epoch 24: val_loss did not improve from 1.86264\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7282 - accuracy: 0.4855 - precision_m: 0.7296 - recall_m: 0.2771 - f1_m: 0.4007 - val_loss: 1.8829 - val_accuracy: 0.4537 - val_precision_m: 0.6952 - val_recall_m: 0.2529 - val_f1_m: 0.3686\n",
      "Epoch 25/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 1.7260 - accuracy: 0.4862 - precision_m: 0.7281 - recall_m: 0.2800 - f1_m: 0.4034\n",
      "Epoch 25: val_loss improved from 1.86264 to 1.85998, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.4573 | Precision: 0.6957 | Recall: 0.2593 | F1: 0.3755\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7260 - accuracy: 0.4862 - precision_m: 0.7281 - recall_m: 0.2800 - f1_m: 0.4034 - val_loss: 1.8600 - val_accuracy: 0.4573 - val_precision_m: 0.6957 - val_recall_m: 0.2593 - val_f1_m: 0.3755\n",
      "Epoch 26/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 1.7161 - accuracy: 0.4892 - precision_m: 0.7291 - recall_m: 0.2816 - f1_m: 0.4052\n",
      "Epoch 26: val_loss did not improve from 1.85998\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 26\n",
      "Accuracy: 0.4576 | Precision: 0.6941 | Recall: 0.2655 | F1: 0.3815\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7162 - accuracy: 0.4892 - precision_m: 0.7291 - recall_m: 0.2817 - f1_m: 0.4053 - val_loss: 1.8721 - val_accuracy: 0.4576 - val_precision_m: 0.6941 - val_recall_m: 0.2655 - val_f1_m: 0.3815\n",
      "Epoch 27/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.7164 - accuracy: 0.4904 - precision_m: 0.7304 - recall_m: 0.2844 - f1_m: 0.4083\n",
      "Epoch 27: val_loss did not improve from 1.85998\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7163 - accuracy: 0.4904 - precision_m: 0.7303 - recall_m: 0.2845 - f1_m: 0.4084 - val_loss: 1.8870 - val_accuracy: 0.4507 - val_precision_m: 0.6936 - val_recall_m: 0.2576 - val_f1_m: 0.3738\n",
      "Epoch 28/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.7111 - accuracy: 0.4902 - precision_m: 0.7320 - recall_m: 0.2855 - f1_m: 0.4098\n",
      "Epoch 28: val_loss did not improve from 1.85998\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 28\n",
      "Accuracy: 0.4673 | Precision: 0.6893 | Recall: 0.2705 | F1: 0.3867\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7106 - accuracy: 0.4902 - precision_m: 0.7317 - recall_m: 0.2858 - f1_m: 0.4100 - val_loss: 1.8609 - val_accuracy: 0.4673 - val_precision_m: 0.6893 - val_recall_m: 0.2705 - val_f1_m: 0.3867\n",
      "Epoch 29/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 1.7080 - accuracy: 0.4911 - precision_m: 0.7295 - recall_m: 0.2877 - f1_m: 0.4114\n",
      "Epoch 29: val_loss did not improve from 1.85998\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7077 - accuracy: 0.4913 - precision_m: 0.7295 - recall_m: 0.2879 - f1_m: 0.4116 - val_loss: 1.8729 - val_accuracy: 0.4543 - val_precision_m: 0.6850 - val_recall_m: 0.2660 - val_f1_m: 0.3812\n",
      "Epoch 30/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.7017 - accuracy: 0.4927 - precision_m: 0.7348 - recall_m: 0.2885 - f1_m: 0.4132\n",
      "Epoch 30: val_loss improved from 1.85998 to 1.85466, saving model to trained_models/model_1_fold_3_best.h5\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.7026 - accuracy: 0.4926 - precision_m: 0.7348 - recall_m: 0.2887 - f1_m: 0.4134 - val_loss: 1.8547 - val_accuracy: 0.4665 - val_precision_m: 0.6889 - val_recall_m: 0.2743 - val_f1_m: 0.3903\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 121.7 seconds (2.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 68.5%\n",
      "  Usage (max):  79.5%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 82.5%\n",
      "  Usage (max):  85.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  4.1%\n",
      "  Usage (max):   28.0%\n",
      "  Memory (mean): 606 MB\n",
      "  Memory (max):  607 MB\n",
      "  Power (mean):  15.9 W\n",
      "  Power (max):   16.8 W\n",
      "  Energy used:   0.539 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 RESULTS\n",
      "================================================================================\n",
      "Validation - Loss: 1.8547, Acc: 46.65%\n",
      "Test       - Loss: 1.7861, Acc: 48.02%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 4 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77820, Val=8281, Test=7550\n",
      "Epoch 1/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 2.8480 - accuracy: 0.1919 - precision_m: 0.3825 - recall_m: 0.0164 - f1_m: 0.0309\n",
      "Epoch 1: val_loss improved from inf to 2.41144, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.3002 | Precision: 0.6487 | Recall: 0.0593 | F1: 0.1076\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 5s 7ms/step - loss: 2.8434 - accuracy: 0.1930 - precision_m: 0.3856 - recall_m: 0.0170 - f1_m: 0.0320 - val_loss: 2.4114 - val_accuracy: 0.3002 - val_precision_m: 0.6487 - val_recall_m: 0.0593 - val_f1_m: 0.1076\n",
      "Epoch 2/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 2.2682 - accuracy: 0.3354 - precision_m: 0.6761 - recall_m: 0.0845 - f1_m: 0.1489\n",
      "Epoch 2: val_loss improved from 2.41144 to 2.22047, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3526 | Precision: 0.6926 | Recall: 0.1093 | F1: 0.1872\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 2.2677 - accuracy: 0.3355 - precision_m: 0.6762 - recall_m: 0.0845 - f1_m: 0.1489 - val_loss: 2.2205 - val_accuracy: 0.3526 - val_precision_m: 0.6926 - val_recall_m: 0.1093 - val_f1_m: 0.1872\n",
      "Epoch 3/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 2.1397 - accuracy: 0.3693 - precision_m: 0.6938 - recall_m: 0.1253 - f1_m: 0.2112\n",
      "Epoch 3: val_loss improved from 2.22047 to 2.16858, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3608 | Precision: 0.6928 | Recall: 0.1271 | F1: 0.2129\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 2.1393 - accuracy: 0.3696 - precision_m: 0.6939 - recall_m: 0.1253 - f1_m: 0.2111 - val_loss: 2.1686 - val_accuracy: 0.3608 - val_precision_m: 0.6928 - val_recall_m: 0.1271 - val_f1_m: 0.2129\n",
      "Epoch 4/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 2.0718 - accuracy: 0.3871 - precision_m: 0.7038 - recall_m: 0.1461 - f1_m: 0.2409\n",
      "Epoch 4: val_loss improved from 2.16858 to 2.12912, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.3781 | Precision: 0.6916 | Recall: 0.1543 | F1: 0.2509\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 2.0718 - accuracy: 0.3872 - precision_m: 0.7044 - recall_m: 0.1464 - f1_m: 0.2413 - val_loss: 2.1291 - val_accuracy: 0.3781 - val_precision_m: 0.6916 - val_recall_m: 0.1543 - val_f1_m: 0.2509\n",
      "Epoch 5/30\n",
      "601/608 [============================>.] - ETA: 0s - loss: 2.0237 - accuracy: 0.4032 - precision_m: 0.7116 - recall_m: 0.1624 - f1_m: 0.2632\n",
      "Epoch 5: val_loss improved from 2.12912 to 2.09616, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.3880 | Precision: 0.7094 | Recall: 0.1606 | F1: 0.2603\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 2.0239 - accuracy: 0.4032 - precision_m: 0.7109 - recall_m: 0.1623 - f1_m: 0.2630 - val_loss: 2.0962 - val_accuracy: 0.3880 - val_precision_m: 0.7094 - val_recall_m: 0.1606 - val_f1_m: 0.2603\n",
      "Epoch 6/30\n",
      "603/608 [============================>.] - ETA: 0s - loss: 1.9865 - accuracy: 0.4126 - precision_m: 0.7112 - recall_m: 0.1737 - f1_m: 0.2780\n",
      "Epoch 6: val_loss improved from 2.09616 to 2.07093, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.3890 | Precision: 0.6884 | Recall: 0.1734 | F1: 0.2753\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.9860 - accuracy: 0.4128 - precision_m: 0.7120 - recall_m: 0.1739 - f1_m: 0.2783 - val_loss: 2.0709 - val_accuracy: 0.3890 - val_precision_m: 0.6884 - val_recall_m: 0.1734 - val_f1_m: 0.2753\n",
      "Epoch 7/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 1.9593 - accuracy: 0.4196 - precision_m: 0.7155 - recall_m: 0.1845 - f1_m: 0.2922\n",
      "Epoch 7: val_loss improved from 2.07093 to 2.03063, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.3980 | Precision: 0.6967 | Recall: 0.1746 | F1: 0.2776\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.9593 - accuracy: 0.4196 - precision_m: 0.7155 - recall_m: 0.1845 - f1_m: 0.2922 - val_loss: 2.0306 - val_accuracy: 0.3980 - val_precision_m: 0.6967 - val_recall_m: 0.1746 - val_f1_m: 0.2776\n",
      "Epoch 8/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.9331 - accuracy: 0.4270 - precision_m: 0.7188 - recall_m: 0.1935 - f1_m: 0.3037\n",
      "Epoch 8: val_loss improved from 2.03063 to 2.01968, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.3983 | Precision: 0.6804 | Recall: 0.1897 | F1: 0.2952\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.9330 - accuracy: 0.4269 - precision_m: 0.7189 - recall_m: 0.1934 - f1_m: 0.3036 - val_loss: 2.0197 - val_accuracy: 0.3983 - val_precision_m: 0.6804 - val_recall_m: 0.1897 - val_f1_m: 0.2952\n",
      "Epoch 9/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.9101 - accuracy: 0.4352 - precision_m: 0.7189 - recall_m: 0.2038 - f1_m: 0.3164\n",
      "Epoch 9: val_loss improved from 2.01968 to 1.98678, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.4132 | Precision: 0.6891 | Recall: 0.1994 | F1: 0.3074\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.9098 - accuracy: 0.4353 - precision_m: 0.7190 - recall_m: 0.2038 - f1_m: 0.3165 - val_loss: 1.9868 - val_accuracy: 0.4132 - val_precision_m: 0.6891 - val_recall_m: 0.1994 - val_f1_m: 0.3074\n",
      "Epoch 10/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 1.8951 - accuracy: 0.4366 - precision_m: 0.7201 - recall_m: 0.2090 - f1_m: 0.3228\n",
      "Epoch 10: val_loss improved from 1.98678 to 1.97671, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.4188 | Precision: 0.6882 | Recall: 0.2050 | F1: 0.3143\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.8951 - accuracy: 0.4366 - precision_m: 0.7201 - recall_m: 0.2090 - f1_m: 0.3228 - val_loss: 1.9767 - val_accuracy: 0.4188 - val_precision_m: 0.6882 - val_recall_m: 0.2050 - val_f1_m: 0.3143\n",
      "Epoch 11/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.8749 - accuracy: 0.4425 - precision_m: 0.7229 - recall_m: 0.2168 - f1_m: 0.3324\n",
      "Epoch 11: val_loss did not improve from 1.97671\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.8744 - accuracy: 0.4426 - precision_m: 0.7230 - recall_m: 0.2168 - f1_m: 0.3325 - val_loss: 1.9853 - val_accuracy: 0.4153 - val_precision_m: 0.6791 - val_recall_m: 0.2043 - val_f1_m: 0.3123\n",
      "Epoch 12/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 1.8624 - accuracy: 0.4474 - precision_m: 0.7216 - recall_m: 0.2221 - f1_m: 0.3386\n",
      "Epoch 12: val_loss improved from 1.97671 to 1.94916, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.4228 | Precision: 0.6872 | Recall: 0.2143 | F1: 0.3250\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.8621 - accuracy: 0.4473 - precision_m: 0.7218 - recall_m: 0.2221 - f1_m: 0.3386 - val_loss: 1.9492 - val_accuracy: 0.4228 - val_precision_m: 0.6872 - val_recall_m: 0.2143 - val_f1_m: 0.3250\n",
      "Epoch 13/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 1.8489 - accuracy: 0.4509 - precision_m: 0.7227 - recall_m: 0.2284 - f1_m: 0.3461\n",
      "Epoch 13: val_loss did not improve from 1.94916\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.8483 - accuracy: 0.4511 - precision_m: 0.7230 - recall_m: 0.2286 - f1_m: 0.3462 - val_loss: 1.9920 - val_accuracy: 0.4111 - val_precision_m: 0.6805 - val_recall_m: 0.2069 - val_f1_m: 0.3155\n",
      "Epoch 14/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 1.8401 - accuracy: 0.4534 - precision_m: 0.7235 - recall_m: 0.2325 - f1_m: 0.3508\n",
      "Epoch 14: val_loss did not improve from 1.94916\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.8400 - accuracy: 0.4537 - precision_m: 0.7239 - recall_m: 0.2326 - f1_m: 0.3509 - val_loss: 1.9513 - val_accuracy: 0.4207 - val_precision_m: 0.6830 - val_recall_m: 0.2181 - val_f1_m: 0.3287\n",
      "Epoch 15/30\n",
      "601/608 [============================>.] - ETA: 0s - loss: 1.8303 - accuracy: 0.4563 - precision_m: 0.7246 - recall_m: 0.2348 - f1_m: 0.3535\n",
      "Epoch 15: val_loss did not improve from 1.94916\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.8295 - accuracy: 0.4561 - precision_m: 0.7244 - recall_m: 0.2348 - f1_m: 0.3535 - val_loss: 1.9493 - val_accuracy: 0.4199 - val_precision_m: 0.6918 - val_recall_m: 0.2260 - val_f1_m: 0.3389\n",
      "Epoch 16/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.8201 - accuracy: 0.4592 - precision_m: 0.7271 - recall_m: 0.2407 - f1_m: 0.3606\n",
      "Epoch 16: val_loss improved from 1.94916 to 1.92590, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.4334 | Precision: 0.6806 | Recall: 0.2281 | F1: 0.3401\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.8198 - accuracy: 0.4592 - precision_m: 0.7270 - recall_m: 0.2407 - f1_m: 0.3605 - val_loss: 1.9259 - val_accuracy: 0.4334 - val_precision_m: 0.6806 - val_recall_m: 0.2281 - val_f1_m: 0.3401\n",
      "Epoch 17/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 1.8108 - accuracy: 0.4611 - precision_m: 0.7261 - recall_m: 0.2432 - f1_m: 0.3633\n",
      "Epoch 17: val_loss improved from 1.92590 to 1.90966, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.4396 | Precision: 0.7002 | Recall: 0.2259 | F1: 0.3395\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.8108 - accuracy: 0.4611 - precision_m: 0.7261 - recall_m: 0.2432 - f1_m: 0.3633 - val_loss: 1.9097 - val_accuracy: 0.4396 - val_precision_m: 0.7002 - val_recall_m: 0.2259 - val_f1_m: 0.3395\n",
      "Epoch 18/30\n",
      "603/608 [============================>.] - ETA: 0s - loss: 1.7999 - accuracy: 0.4659 - precision_m: 0.7292 - recall_m: 0.2480 - f1_m: 0.3690\n",
      "Epoch 18: val_loss improved from 1.90966 to 1.90000, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.4411 | Precision: 0.7037 | Recall: 0.2335 | F1: 0.3485\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.8001 - accuracy: 0.4659 - precision_m: 0.7291 - recall_m: 0.2481 - f1_m: 0.3691 - val_loss: 1.9000 - val_accuracy: 0.4411 - val_precision_m: 0.7037 - val_recall_m: 0.2335 - val_f1_m: 0.3485\n",
      "Epoch 19/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 1.7940 - accuracy: 0.4655 - precision_m: 0.7289 - recall_m: 0.2500 - f1_m: 0.3713\n",
      "Epoch 19: val_loss did not improve from 1.90000\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.7940 - accuracy: 0.4655 - precision_m: 0.7291 - recall_m: 0.2501 - f1_m: 0.3713 - val_loss: 1.9110 - val_accuracy: 0.4367 - val_precision_m: 0.6908 - val_recall_m: 0.2419 - val_f1_m: 0.3561\n",
      "Epoch 20/30\n",
      "601/608 [============================>.] - ETA: 0s - loss: 1.7921 - accuracy: 0.4669 - precision_m: 0.7276 - recall_m: 0.2534 - f1_m: 0.3749\n",
      "Epoch 20: val_loss did not improve from 1.90000\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 20\n",
      "Accuracy: 0.4414 | Precision: 0.6943 | Recall: 0.2376 | F1: 0.3522\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.7921 - accuracy: 0.4667 - precision_m: 0.7272 - recall_m: 0.2534 - f1_m: 0.3748 - val_loss: 1.9010 - val_accuracy: 0.4414 - val_precision_m: 0.6943 - val_recall_m: 0.2376 - val_f1_m: 0.3522\n",
      "Epoch 21/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 1.7812 - accuracy: 0.4720 - precision_m: 0.7317 - recall_m: 0.2559 - f1_m: 0.3781\n",
      "Epoch 21: val_loss improved from 1.90000 to 1.89703, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.7814 - accuracy: 0.4717 - precision_m: 0.7314 - recall_m: 0.2557 - f1_m: 0.3779 - val_loss: 1.8970 - val_accuracy: 0.4398 - val_precision_m: 0.6881 - val_recall_m: 0.2403 - val_f1_m: 0.3544\n",
      "Epoch 22/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 1.7772 - accuracy: 0.4725 - precision_m: 0.7278 - recall_m: 0.2591 - f1_m: 0.3811\n",
      "Epoch 22: val_loss improved from 1.89703 to 1.88849, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 22\n",
      "Accuracy: 0.4429 | Precision: 0.6868 | Recall: 0.2419 | F1: 0.3560\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.7769 - accuracy: 0.4723 - precision_m: 0.7279 - recall_m: 0.2590 - f1_m: 0.3810 - val_loss: 1.8885 - val_accuracy: 0.4429 - val_precision_m: 0.6868 - val_recall_m: 0.2419 - val_f1_m: 0.3560\n",
      "Epoch 23/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 1.7692 - accuracy: 0.4743 - precision_m: 0.7281 - recall_m: 0.2594 - f1_m: 0.3814\n",
      "Epoch 23: val_loss improved from 1.88849 to 1.87794, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 23\n",
      "Accuracy: 0.4489 | Precision: 0.6976 | Recall: 0.2457 | F1: 0.3615\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.7688 - accuracy: 0.4745 - precision_m: 0.7282 - recall_m: 0.2596 - f1_m: 0.3817 - val_loss: 1.8779 - val_accuracy: 0.4489 - val_precision_m: 0.6976 - val_recall_m: 0.2457 - val_f1_m: 0.3615\n",
      "Epoch 24/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.7624 - accuracy: 0.4783 - precision_m: 0.7345 - recall_m: 0.2646 - f1_m: 0.3879\n",
      "Epoch 24: val_loss did not improve from 1.87794\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.7624 - accuracy: 0.4783 - precision_m: 0.7344 - recall_m: 0.2645 - f1_m: 0.3878 - val_loss: 1.8935 - val_accuracy: 0.4416 - val_precision_m: 0.6998 - val_recall_m: 0.2443 - val_f1_m: 0.3600\n",
      "Epoch 25/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 1.7592 - accuracy: 0.4768 - precision_m: 0.7309 - recall_m: 0.2643 - f1_m: 0.3871\n",
      "Epoch 25: val_loss improved from 1.87794 to 1.87343, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.4492 | Precision: 0.7064 | Recall: 0.2467 | F1: 0.3635\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.7592 - accuracy: 0.4768 - precision_m: 0.7309 - recall_m: 0.2643 - f1_m: 0.3871 - val_loss: 1.8734 - val_accuracy: 0.4492 - val_precision_m: 0.7064 - val_recall_m: 0.2467 - val_f1_m: 0.3635\n",
      "Epoch 26/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.7505 - accuracy: 0.4806 - precision_m: 0.7354 - recall_m: 0.2686 - f1_m: 0.3926\n",
      "Epoch 26: val_loss improved from 1.87343 to 1.86402, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.7504 - accuracy: 0.4805 - precision_m: 0.7353 - recall_m: 0.2686 - f1_m: 0.3925 - val_loss: 1.8640 - val_accuracy: 0.4483 - val_precision_m: 0.6873 - val_recall_m: 0.2574 - val_f1_m: 0.3725\n",
      "Epoch 27/30\n",
      "601/608 [============================>.] - ETA: 0s - loss: 1.7485 - accuracy: 0.4819 - precision_m: 0.7338 - recall_m: 0.2703 - f1_m: 0.3940\n",
      "Epoch 27: val_loss improved from 1.86402 to 1.86232, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.7490 - accuracy: 0.4816 - precision_m: 0.7340 - recall_m: 0.2703 - f1_m: 0.3940 - val_loss: 1.8623 - val_accuracy: 0.4492 - val_precision_m: 0.6932 - val_recall_m: 0.2546 - val_f1_m: 0.3705\n",
      "Epoch 28/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.7441 - accuracy: 0.4808 - precision_m: 0.7336 - recall_m: 0.2708 - f1_m: 0.3945\n",
      "Epoch 28: val_loss improved from 1.86232 to 1.85776, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 28\n",
      "Accuracy: 0.4532 | Precision: 0.6927 | Recall: 0.2582 | F1: 0.3745\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.7441 - accuracy: 0.4809 - precision_m: 0.7336 - recall_m: 0.2709 - f1_m: 0.3946 - val_loss: 1.8578 - val_accuracy: 0.4532 - val_precision_m: 0.6927 - val_recall_m: 0.2582 - val_f1_m: 0.3745\n",
      "Epoch 29/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 1.7356 - accuracy: 0.4850 - precision_m: 0.7347 - recall_m: 0.2740 - f1_m: 0.3979\n",
      "Epoch 29: val_loss did not improve from 1.85776\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 29\n",
      "Accuracy: 0.4559 | Precision: 0.6978 | Recall: 0.2587 | F1: 0.3753\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 4s 7ms/step - loss: 1.7356 - accuracy: 0.4850 - precision_m: 0.7347 - recall_m: 0.2740 - f1_m: 0.3979 - val_loss: 1.8682 - val_accuracy: 0.4559 - val_precision_m: 0.6978 - val_recall_m: 0.2587 - val_f1_m: 0.3753\n",
      "Epoch 30/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 1.7337 - accuracy: 0.4852 - precision_m: 0.7334 - recall_m: 0.2754 - f1_m: 0.3994\n",
      "Epoch 30: val_loss did not improve from 1.85776\n",
      "608/608 [==============================] - 4s 6ms/step - loss: 1.7342 - accuracy: 0.4851 - precision_m: 0.7332 - recall_m: 0.2754 - f1_m: 0.3994 - val_loss: 1.8648 - val_accuracy: 0.4509 - val_precision_m: 0.6908 - val_recall_m: 0.2658 - val_f1_m: 0.3821\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 120.6 seconds (2.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 67.3%\n",
      "  Usage (max):  84.1%\n",
      "  Frequency:    3982 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 83.9%\n",
      "  Usage (max):  84.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  2.1%\n",
      "  Usage (max):   7.0%\n",
      "  Memory (mean): 595 MB\n",
      "  Memory (max):  606 MB\n",
      "  Power (mean):  15.9 W\n",
      "  Power (max):   16.3 W\n",
      "  Energy used:   0.533 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 RESULTS\n",
      "================================================================================\n",
      "Validation - Loss: 1.8578, Acc: 45.32%\n",
      "Test       - Loss: 1.8223, Acc: 45.99%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 5 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=78003, Val=8252, Test=7409\n",
      "Epoch 1/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.8188 - accuracy: 0.2142 - precision_m: 0.5026 - recall_m: 0.0286 - f1_m: 0.0526\n",
      "Epoch 1: val_loss improved from inf to 2.35697, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.3185 | Precision: 0.7061 | Recall: 0.0908 | F1: 0.1594\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 7ms/step - loss: 2.8160 - accuracy: 0.2147 - precision_m: 0.5037 - recall_m: 0.0289 - f1_m: 0.0532 - val_loss: 2.3570 - val_accuracy: 0.3185 - val_precision_m: 0.7061 - val_recall_m: 0.0908 - val_f1_m: 0.1594\n",
      "Epoch 2/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.1456 - accuracy: 0.3770 - precision_m: 0.7209 - recall_m: 0.1340 - f1_m: 0.2241\n",
      "Epoch 2: val_loss improved from 2.35697 to 2.07811, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.4034 | Precision: 0.7483 | Recall: 0.1649 | F1: 0.2681\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 2.1449 - accuracy: 0.3773 - precision_m: 0.7212 - recall_m: 0.1344 - f1_m: 0.2247 - val_loss: 2.0781 - val_accuracy: 0.4034 - val_precision_m: 0.7483 - val_recall_m: 0.1649 - val_f1_m: 0.2681\n",
      "Epoch 3/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 1.9773 - accuracy: 0.4238 - precision_m: 0.7354 - recall_m: 0.1923 - f1_m: 0.3036\n",
      "Epoch 3: val_loss improved from 2.07811 to 1.99315, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.4254 | Precision: 0.7104 | Recall: 0.2082 | F1: 0.3196\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 6ms/step - loss: 1.9769 - accuracy: 0.4239 - precision_m: 0.7354 - recall_m: 0.1924 - f1_m: 0.3037 - val_loss: 1.9931 - val_accuracy: 0.4254 - val_precision_m: 0.7104 - val_recall_m: 0.2082 - val_f1_m: 0.3196\n",
      "Epoch 4/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 1.8952 - accuracy: 0.4458 - precision_m: 0.7349 - recall_m: 0.2218 - f1_m: 0.3396\n",
      "Epoch 4: val_loss improved from 1.99315 to 1.92019, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.4458 | Precision: 0.7268 | Recall: 0.2220 | F1: 0.3382\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.8949 - accuracy: 0.4458 - precision_m: 0.7348 - recall_m: 0.2217 - f1_m: 0.3395 - val_loss: 1.9202 - val_accuracy: 0.4458 - val_precision_m: 0.7268 - val_recall_m: 0.2220 - val_f1_m: 0.3382\n",
      "Epoch 5/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.8392 - accuracy: 0.4614 - precision_m: 0.7361 - recall_m: 0.2427 - f1_m: 0.3639\n",
      "Epoch 5: val_loss improved from 1.92019 to 1.92015, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.4466 | Precision: 0.7063 | Recall: 0.2430 | F1: 0.3598\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.8390 - accuracy: 0.4616 - precision_m: 0.7361 - recall_m: 0.2427 - f1_m: 0.3640 - val_loss: 1.9202 - val_accuracy: 0.4466 - val_precision_m: 0.7063 - val_recall_m: 0.2430 - val_f1_m: 0.3598\n",
      "Epoch 6/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.7969 - accuracy: 0.4725 - precision_m: 0.7409 - recall_m: 0.2598 - f1_m: 0.3837\n",
      "Epoch 6: val_loss improved from 1.92015 to 1.84352, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.4690 | Precision: 0.7403 | Recall: 0.2533 | F1: 0.3757\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7967 - accuracy: 0.4724 - precision_m: 0.7409 - recall_m: 0.2599 - f1_m: 0.3837 - val_loss: 1.8435 - val_accuracy: 0.4690 - val_precision_m: 0.7403 - val_recall_m: 0.2533 - val_f1_m: 0.3757\n",
      "Epoch 7/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.7661 - accuracy: 0.4817 - precision_m: 0.7436 - recall_m: 0.2713 - f1_m: 0.3964\n",
      "Epoch 7: val_loss did not improve from 1.84352\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7664 - accuracy: 0.4815 - precision_m: 0.7436 - recall_m: 0.2712 - f1_m: 0.3964 - val_loss: 1.8735 - val_accuracy: 0.4543 - val_precision_m: 0.6973 - val_recall_m: 0.2676 - val_f1_m: 0.3850\n",
      "Epoch 8/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.7395 - accuracy: 0.4894 - precision_m: 0.7465 - recall_m: 0.2827 - f1_m: 0.4090\n",
      "Epoch 8: val_loss improved from 1.84352 to 1.81550, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.4790 | Precision: 0.7210 | Recall: 0.2736 | F1: 0.3951\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7395 - accuracy: 0.4893 - precision_m: 0.7464 - recall_m: 0.2827 - f1_m: 0.4089 - val_loss: 1.8155 - val_accuracy: 0.4790 - val_precision_m: 0.7210 - val_recall_m: 0.2736 - val_f1_m: 0.3951\n",
      "Epoch 9/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.7143 - accuracy: 0.4956 - precision_m: 0.7472 - recall_m: 0.2922 - f1_m: 0.4191\n",
      "Epoch 9: val_loss improved from 1.81550 to 1.80016, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.4862 | Precision: 0.7211 | Recall: 0.2853 | F1: 0.4068\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7141 - accuracy: 0.4957 - precision_m: 0.7472 - recall_m: 0.2920 - f1_m: 0.4189 - val_loss: 1.8002 - val_accuracy: 0.4862 - val_precision_m: 0.7211 - val_recall_m: 0.2853 - val_f1_m: 0.4068\n",
      "Epoch 10/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 1.6944 - accuracy: 0.5013 - precision_m: 0.7509 - recall_m: 0.3028 - f1_m: 0.4306\n",
      "Epoch 10: val_loss improved from 1.80016 to 1.78727, saving model to trained_models/model_1_fold_5_best.h5\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.6945 - accuracy: 0.5011 - precision_m: 0.7506 - recall_m: 0.3027 - f1_m: 0.4304 - val_loss: 1.7873 - val_accuracy: 0.4857 - val_precision_m: 0.7281 - val_recall_m: 0.2887 - val_f1_m: 0.4117\n",
      "Epoch 11/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.6755 - accuracy: 0.5062 - precision_m: 0.7515 - recall_m: 0.3078 - f1_m: 0.4357\n",
      "Epoch 11: val_loss did not improve from 1.78727\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.6754 - accuracy: 0.5062 - precision_m: 0.7515 - recall_m: 0.3079 - f1_m: 0.4357 - val_loss: 1.7882 - val_accuracy: 0.4861 - val_precision_m: 0.7112 - val_recall_m: 0.3017 - val_f1_m: 0.4218\n",
      "Epoch 12/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.6544 - accuracy: 0.5112 - precision_m: 0.7532 - recall_m: 0.3163 - f1_m: 0.4446\n",
      "Epoch 12: val_loss did not improve from 1.78727\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.6543 - accuracy: 0.5112 - precision_m: 0.7532 - recall_m: 0.3163 - f1_m: 0.4446 - val_loss: 1.7935 - val_accuracy: 0.4784 - val_precision_m: 0.7048 - val_recall_m: 0.3059 - val_f1_m: 0.4251\n",
      "Epoch 13/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.6382 - accuracy: 0.5177 - precision_m: 0.7552 - recall_m: 0.3240 - f1_m: 0.4526\n",
      "Epoch 13: val_loss improved from 1.78727 to 1.77472, saving model to trained_models/model_1_fold_5_best.h5\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.6379 - accuracy: 0.5177 - precision_m: 0.7555 - recall_m: 0.3240 - f1_m: 0.4526 - val_loss: 1.7747 - val_accuracy: 0.4862 - val_precision_m: 0.7084 - val_recall_m: 0.3032 - val_f1_m: 0.4232\n",
      "Epoch 14/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 1.6214 - accuracy: 0.5198 - precision_m: 0.7552 - recall_m: 0.3295 - f1_m: 0.4578\n",
      "Epoch 14: val_loss improved from 1.77472 to 1.72942, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.4988 | Precision: 0.7257 | Recall: 0.3146 | F1: 0.4375\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.6217 - accuracy: 0.5200 - precision_m: 0.7553 - recall_m: 0.3295 - f1_m: 0.4578 - val_loss: 1.7294 - val_accuracy: 0.4988 - val_precision_m: 0.7257 - val_recall_m: 0.3146 - val_f1_m: 0.4375\n",
      "Epoch 15/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 1.6046 - accuracy: 0.5237 - precision_m: 0.7522 - recall_m: 0.3342 - f1_m: 0.4618\n",
      "Epoch 15: val_loss improved from 1.72942 to 1.70763, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 15\n",
      "Accuracy: 0.5042 | Precision: 0.7310 | Recall: 0.3244 | F1: 0.4477\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.6045 - accuracy: 0.5235 - precision_m: 0.7519 - recall_m: 0.3341 - f1_m: 0.4616 - val_loss: 1.7076 - val_accuracy: 0.5042 - val_precision_m: 0.7310 - val_recall_m: 0.3244 - val_f1_m: 0.4477\n",
      "Epoch 16/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 1.5906 - accuracy: 0.5274 - precision_m: 0.7539 - recall_m: 0.3402 - f1_m: 0.4680\n",
      "Epoch 16: val_loss did not improve from 1.70763\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.5900 - accuracy: 0.5273 - precision_m: 0.7541 - recall_m: 0.3404 - f1_m: 0.4682 - val_loss: 1.7291 - val_accuracy: 0.4954 - val_precision_m: 0.7107 - val_recall_m: 0.3240 - val_f1_m: 0.4433\n",
      "Epoch 17/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.5840 - accuracy: 0.5301 - precision_m: 0.7549 - recall_m: 0.3463 - f1_m: 0.4739\n",
      "Epoch 17: val_loss did not improve from 1.70763\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.5841 - accuracy: 0.5299 - precision_m: 0.7548 - recall_m: 0.3461 - f1_m: 0.4736 - val_loss: 1.7322 - val_accuracy: 0.4955 - val_precision_m: 0.7069 - val_recall_m: 0.3147 - val_f1_m: 0.4340\n",
      "Epoch 18/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.5705 - accuracy: 0.5332 - precision_m: 0.7542 - recall_m: 0.3478 - f1_m: 0.4750\n",
      "Epoch 18: val_loss did not improve from 1.70763\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.5700 - accuracy: 0.5332 - precision_m: 0.7541 - recall_m: 0.3477 - f1_m: 0.4749 - val_loss: 1.7259 - val_accuracy: 0.4952 - val_precision_m: 0.7029 - val_recall_m: 0.3299 - val_f1_m: 0.4478\n",
      "Epoch 19/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 1.5597 - accuracy: 0.5341 - precision_m: 0.7528 - recall_m: 0.3530 - f1_m: 0.4797\n",
      "Epoch 19: val_loss did not improve from 1.70763\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 19\n",
      "Accuracy: 0.5050 | Precision: 0.7180 | Recall: 0.3383 | F1: 0.4584\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 7ms/step - loss: 1.5593 - accuracy: 0.5343 - precision_m: 0.7529 - recall_m: 0.3531 - f1_m: 0.4798 - val_loss: 1.7085 - val_accuracy: 0.5050 - val_precision_m: 0.7180 - val_recall_m: 0.3383 - val_f1_m: 0.4584\n",
      "Epoch 20/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 1.5511 - accuracy: 0.5374 - precision_m: 0.7567 - recall_m: 0.3562 - f1_m: 0.4834\n",
      "Epoch 20: val_loss did not improve from 1.70763\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.5511 - accuracy: 0.5376 - precision_m: 0.7568 - recall_m: 0.3562 - f1_m: 0.4834 - val_loss: 1.7466 - val_accuracy: 0.4937 - val_precision_m: 0.7151 - val_recall_m: 0.3319 - val_f1_m: 0.4517\n",
      "Epoch 21/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.5440 - accuracy: 0.5398 - precision_m: 0.7553 - recall_m: 0.3591 - f1_m: 0.4859\n",
      "Epoch 21: val_loss improved from 1.70763 to 1.68409, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 21\n",
      "Accuracy: 0.5090 | Precision: 0.7255 | Recall: 0.3430 | F1: 0.4642\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.5438 - accuracy: 0.5397 - precision_m: 0.7552 - recall_m: 0.3591 - f1_m: 0.4859 - val_loss: 1.6841 - val_accuracy: 0.5090 - val_precision_m: 0.7255 - val_recall_m: 0.3430 - val_f1_m: 0.4642\n",
      "Epoch 22/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.5394 - accuracy: 0.5393 - precision_m: 0.7550 - recall_m: 0.3604 - f1_m: 0.4870\n",
      "Epoch 22: val_loss improved from 1.68409 to 1.67691, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 22\n",
      "Accuracy: 0.5137 | Precision: 0.7247 | Recall: 0.3396 | F1: 0.4614\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.5396 - accuracy: 0.5392 - precision_m: 0.7549 - recall_m: 0.3602 - f1_m: 0.4868 - val_loss: 1.6769 - val_accuracy: 0.5137 - val_precision_m: 0.7247 - val_recall_m: 0.3396 - val_f1_m: 0.4614\n",
      "Epoch 23/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.5434 - precision_m: 0.7583 - recall_m: 0.3647 - f1_m: 0.4916\n",
      "Epoch 23: val_loss did not improve from 1.67691\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.5279 - accuracy: 0.5435 - precision_m: 0.7582 - recall_m: 0.3646 - f1_m: 0.4916 - val_loss: 1.7114 - val_accuracy: 0.5061 - val_precision_m: 0.7014 - val_recall_m: 0.3480 - val_f1_m: 0.4638\n",
      "Epoch 24/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 1.5236 - accuracy: 0.5454 - precision_m: 0.7548 - recall_m: 0.3686 - f1_m: 0.4944\n",
      "Epoch 24: val_loss did not improve from 1.67691\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.5237 - accuracy: 0.5452 - precision_m: 0.7546 - recall_m: 0.3684 - f1_m: 0.4942 - val_loss: 1.6962 - val_accuracy: 0.5068 - val_precision_m: 0.7088 - val_recall_m: 0.3525 - val_f1_m: 0.4692\n",
      "Epoch 25/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.5172 - accuracy: 0.5475 - precision_m: 0.7611 - recall_m: 0.3715 - f1_m: 0.4984\n",
      "Epoch 25: val_loss improved from 1.67691 to 1.66385, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.5187 | Precision: 0.7259 | Recall: 0.3570 | F1: 0.4770\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.5170 - accuracy: 0.5475 - precision_m: 0.7610 - recall_m: 0.3715 - f1_m: 0.4984 - val_loss: 1.6639 - val_accuracy: 0.5187 - val_precision_m: 0.7259 - val_recall_m: 0.3570 - val_f1_m: 0.4770\n",
      "Epoch 26/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.5125 - accuracy: 0.5480 - precision_m: 0.7588 - recall_m: 0.3722 - f1_m: 0.4985\n",
      "Epoch 26: val_loss did not improve from 1.66385\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 1.5119 - accuracy: 0.5481 - precision_m: 0.7586 - recall_m: 0.3722 - f1_m: 0.4985 - val_loss: 1.6695 - val_accuracy: 0.5148 - val_precision_m: 0.7173 - val_recall_m: 0.3483 - val_f1_m: 0.4673\n",
      "Epoch 27/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 1.5071 - accuracy: 0.5496 - precision_m: 0.7581 - recall_m: 0.3749 - f1_m: 0.5007\n",
      "Epoch 27: val_loss did not improve from 1.66385\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.5074 - accuracy: 0.5494 - precision_m: 0.7580 - recall_m: 0.3750 - f1_m: 0.5008 - val_loss: 1.6891 - val_accuracy: 0.5125 - val_precision_m: 0.7211 - val_recall_m: 0.3441 - val_f1_m: 0.4643\n",
      "Epoch 28/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.5039 - accuracy: 0.5507 - precision_m: 0.7593 - recall_m: 0.3767 - f1_m: 0.5027\n",
      "Epoch 28: val_loss improved from 1.66385 to 1.65884, saving model to trained_models/model_1_fold_5_best.h5\n",
      "610/610 [==============================] - 5s 7ms/step - loss: 1.5035 - accuracy: 0.5508 - precision_m: 0.7594 - recall_m: 0.3769 - f1_m: 0.5029 - val_loss: 1.6588 - val_accuracy: 0.5173 - val_precision_m: 0.7193 - val_recall_m: 0.3603 - val_f1_m: 0.4787\n",
      "Epoch 29/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 1.5042 - accuracy: 0.5513 - precision_m: 0.7556 - recall_m: 0.3765 - f1_m: 0.5017\n",
      "Epoch 29: val_loss did not improve from 1.65884\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.5038 - accuracy: 0.5515 - precision_m: 0.7559 - recall_m: 0.3767 - f1_m: 0.5020 - val_loss: 1.6695 - val_accuracy: 0.5182 - val_precision_m: 0.7216 - val_recall_m: 0.3501 - val_f1_m: 0.4700\n",
      "Epoch 30/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.4981 - accuracy: 0.5526 - precision_m: 0.7575 - recall_m: 0.3781 - f1_m: 0.5034\n",
      "Epoch 30: val_loss did not improve from 1.65884\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.4980 - accuracy: 0.5525 - precision_m: 0.7578 - recall_m: 0.3784 - f1_m: 0.5038 - val_loss: 1.6613 - val_accuracy: 0.5158 - val_precision_m: 0.7238 - val_recall_m: 0.3587 - val_f1_m: 0.4782\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 131.7 seconds (2.2 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 74.0%\n",
      "  Usage (max):  91.2%\n",
      "  Frequency:    3970 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 85.8%\n",
      "  Usage (max):  86.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  10.5%\n",
      "  Usage (max):   41.0%\n",
      "  Memory (mean): 608 MB\n",
      "  Memory (max):  641 MB\n",
      "  Power (mean):  23.7 W\n",
      "  Power (max):   42.5 W\n",
      "  Energy used:   0.867 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 RESULTS\n",
      "================================================================================\n",
      "Validation - Loss: 1.6588, Acc: 51.73%\n",
      "Test       - Loss: 1.6508, Acc: 51.59%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 6 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77987, Val=8298, Test=7371\n",
      "Epoch 1/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 3.2375 - accuracy: 0.1146 - precision_m: 0.0554 - recall_m: 5.7823e-04 - f1_m: 0.0011\n",
      "Epoch 1: val_loss improved from inf to 2.95290, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.1693 | Precision: 0.3127 | Recall: 0.0058 | F1: 0.0112\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 3.2364 - accuracy: 0.1148 - precision_m: 0.0552 - recall_m: 5.7633e-04 - f1_m: 0.0011 - val_loss: 2.9529 - val_accuracy: 0.1693 - val_precision_m: 0.3127 - val_recall_m: 0.0058 - val_f1_m: 0.0112\n",
      "Epoch 2/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.7961 - accuracy: 0.1975 - precision_m: 0.4885 - recall_m: 0.0081 - f1_m: 0.0159\n",
      "Epoch 2: val_loss improved from 2.95290 to 2.69215, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.2154 | Precision: 0.5493 | Recall: 0.0184 | F1: 0.0352\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.7956 - accuracy: 0.1975 - precision_m: 0.4899 - recall_m: 0.0082 - f1_m: 0.0161 - val_loss: 2.6922 - val_accuracy: 0.2154 - val_precision_m: 0.5493 - val_recall_m: 0.0184 - val_f1_m: 0.0352\n",
      "Epoch 3/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 2.5604 - accuracy: 0.2433 - precision_m: 0.6215 - recall_m: 0.0312 - f1_m: 0.0589\n",
      "Epoch 3: val_loss improved from 2.69215 to 2.52306, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.2548 | Precision: 0.6241 | Recall: 0.0499 | F1: 0.0913\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 2.5604 - accuracy: 0.2433 - precision_m: 0.6215 - recall_m: 0.0312 - f1_m: 0.0589 - val_loss: 2.5231 - val_accuracy: 0.2548 - val_precision_m: 0.6241 - val_recall_m: 0.0499 - val_f1_m: 0.0913\n",
      "Epoch 4/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.4315 - accuracy: 0.2757 - precision_m: 0.6480 - recall_m: 0.0479 - f1_m: 0.0886\n",
      "Epoch 4: val_loss improved from 2.52306 to 2.42378, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.2727 | Precision: 0.6211 | Recall: 0.0563 | F1: 0.1020\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 2.4311 - accuracy: 0.2757 - precision_m: 0.6492 - recall_m: 0.0482 - f1_m: 0.0890 - val_loss: 2.4238 - val_accuracy: 0.2727 - val_precision_m: 0.6211 - val_recall_m: 0.0563 - val_f1_m: 0.1020\n",
      "Epoch 5/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 2.3826 - accuracy: 0.2861 - precision_m: 0.6642 - recall_m: 0.0558 - f1_m: 0.1022\n",
      "Epoch 5: val_loss improved from 2.42378 to 2.41355, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.2807 | Precision: 0.6001 | Recall: 0.0658 | F1: 0.1173\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.3826 - accuracy: 0.2861 - precision_m: 0.6644 - recall_m: 0.0559 - f1_m: 0.1023 - val_loss: 2.4135 - val_accuracy: 0.2807 - val_precision_m: 0.6001 - val_recall_m: 0.0658 - val_f1_m: 0.1173\n",
      "Epoch 6/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 2.3448 - accuracy: 0.2995 - precision_m: 0.6733 - recall_m: 0.0612 - f1_m: 0.1113\n",
      "Epoch 6: val_loss improved from 2.41355 to 2.38449, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.2892 | Precision: 0.6102 | Recall: 0.0727 | F1: 0.1283\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.3450 - accuracy: 0.2995 - precision_m: 0.6722 - recall_m: 0.0611 - f1_m: 0.1112 - val_loss: 2.3845 - val_accuracy: 0.2892 - val_precision_m: 0.6102 - val_recall_m: 0.0727 - val_f1_m: 0.1283\n",
      "Epoch 7/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.3175 - accuracy: 0.3063 - precision_m: 0.6659 - recall_m: 0.0652 - f1_m: 0.1181\n",
      "Epoch 7: val_loss improved from 2.38449 to 2.35850, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.2940 | Precision: 0.6278 | Recall: 0.0683 | F1: 0.1219\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.3181 - accuracy: 0.3063 - precision_m: 0.6664 - recall_m: 0.0651 - f1_m: 0.1179 - val_loss: 2.3585 - val_accuracy: 0.2940 - val_precision_m: 0.6278 - val_recall_m: 0.0683 - val_f1_m: 0.1219\n",
      "Epoch 8/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 2.2900 - accuracy: 0.3166 - precision_m: 0.6675 - recall_m: 0.0706 - f1_m: 0.1270\n",
      "Epoch 8: val_loss improved from 2.35850 to 2.35515, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.2965 | Precision: 0.6195 | Recall: 0.0722 | F1: 0.1280\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.2900 - accuracy: 0.3165 - precision_m: 0.6674 - recall_m: 0.0707 - f1_m: 0.1270 - val_loss: 2.3551 - val_accuracy: 0.2965 - val_precision_m: 0.6195 - val_recall_m: 0.0722 - val_f1_m: 0.1280\n",
      "Epoch 9/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.2693 - accuracy: 0.3221 - precision_m: 0.6715 - recall_m: 0.0740 - f1_m: 0.1325\n",
      "Epoch 9: val_loss improved from 2.35515 to 2.30808, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.3085 | Precision: 0.6380 | Recall: 0.0730 | F1: 0.1295\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 7ms/step - loss: 2.2698 - accuracy: 0.3220 - precision_m: 0.6709 - recall_m: 0.0739 - f1_m: 0.1323 - val_loss: 2.3081 - val_accuracy: 0.3085 - val_precision_m: 0.6380 - val_recall_m: 0.0730 - val_f1_m: 0.1295\n",
      "Epoch 10/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 2.2476 - accuracy: 0.3294 - precision_m: 0.6798 - recall_m: 0.0798 - f1_m: 0.1420\n",
      "Epoch 10: val_loss improved from 2.30808 to 2.28879, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.3154 | Precision: 0.6406 | Recall: 0.0861 | F1: 0.1505\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.2473 - accuracy: 0.3295 - precision_m: 0.6804 - recall_m: 0.0799 - f1_m: 0.1421 - val_loss: 2.2888 - val_accuracy: 0.3154 - val_precision_m: 0.6406 - val_recall_m: 0.0861 - val_f1_m: 0.1505\n",
      "Epoch 11/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 2.2261 - accuracy: 0.3358 - precision_m: 0.6729 - recall_m: 0.0831 - f1_m: 0.1471\n",
      "Epoch 11: val_loss improved from 2.28879 to 2.26500, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.3228 | Precision: 0.6344 | Recall: 0.0836 | F1: 0.1464\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.2262 - accuracy: 0.3359 - precision_m: 0.6720 - recall_m: 0.0829 - f1_m: 0.1468 - val_loss: 2.2650 - val_accuracy: 0.3228 - val_precision_m: 0.6344 - val_recall_m: 0.0836 - val_f1_m: 0.1464\n",
      "Epoch 12/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.2092 - accuracy: 0.3401 - precision_m: 0.6793 - recall_m: 0.0872 - f1_m: 0.1537\n",
      "Epoch 12: val_loss improved from 2.26500 to 2.24934, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.3277 | Precision: 0.6674 | Recall: 0.0855 | F1: 0.1498\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.2098 - accuracy: 0.3400 - precision_m: 0.6803 - recall_m: 0.0872 - f1_m: 0.1537 - val_loss: 2.2493 - val_accuracy: 0.3277 - val_precision_m: 0.6674 - val_recall_m: 0.0855 - val_f1_m: 0.1498\n",
      "Epoch 13/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 2.1911 - accuracy: 0.3454 - precision_m: 0.6817 - recall_m: 0.0918 - f1_m: 0.1610\n",
      "Epoch 13: val_loss improved from 2.24934 to 2.23925, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 13\n",
      "Accuracy: 0.3378 | Precision: 0.6602 | Recall: 0.0993 | F1: 0.1707\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1912 - accuracy: 0.3453 - precision_m: 0.6814 - recall_m: 0.0918 - f1_m: 0.1610 - val_loss: 2.2393 - val_accuracy: 0.3378 - val_precision_m: 0.6602 - val_recall_m: 0.0993 - val_f1_m: 0.1707\n",
      "Epoch 14/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.1763 - accuracy: 0.3496 - precision_m: 0.6827 - recall_m: 0.0961 - f1_m: 0.1677\n",
      "Epoch 14: val_loss improved from 2.23925 to 2.23006, saving model to trained_models/model_1_fold_6_best.h5\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1762 - accuracy: 0.3497 - precision_m: 0.6829 - recall_m: 0.0961 - f1_m: 0.1677 - val_loss: 2.2301 - val_accuracy: 0.3372 - val_precision_m: 0.6592 - val_recall_m: 0.1112 - val_f1_m: 0.1881\n",
      "Epoch 15/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.1636 - accuracy: 0.3529 - precision_m: 0.6802 - recall_m: 0.0991 - f1_m: 0.1720\n",
      "Epoch 15: val_loss improved from 2.23006 to 2.20369, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 15\n",
      "Accuracy: 0.3407 | Precision: 0.6638 | Recall: 0.1014 | F1: 0.1740\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1637 - accuracy: 0.3528 - precision_m: 0.6804 - recall_m: 0.0991 - f1_m: 0.1721 - val_loss: 2.2037 - val_accuracy: 0.3407 - val_precision_m: 0.6638 - val_recall_m: 0.1014 - val_f1_m: 0.1740\n",
      "Epoch 16/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.1484 - accuracy: 0.3566 - precision_m: 0.6792 - recall_m: 0.1022 - f1_m: 0.1767\n",
      "Epoch 16: val_loss did not improve from 2.20369\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.3415 | Precision: 0.6361 | Recall: 0.1116 | F1: 0.1876\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1485 - accuracy: 0.3565 - precision_m: 0.6798 - recall_m: 0.1023 - f1_m: 0.1769 - val_loss: 2.2220 - val_accuracy: 0.3415 - val_precision_m: 0.6361 - val_recall_m: 0.1116 - val_f1_m: 0.1876\n",
      "Epoch 17/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.1386 - accuracy: 0.3602 - precision_m: 0.6871 - recall_m: 0.1052 - f1_m: 0.1816\n",
      "Epoch 17: val_loss did not improve from 2.20369\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1385 - accuracy: 0.3603 - precision_m: 0.6872 - recall_m: 0.1054 - f1_m: 0.1820 - val_loss: 2.2257 - val_accuracy: 0.3350 - val_precision_m: 0.6256 - val_recall_m: 0.1184 - val_f1_m: 0.1972\n",
      "Epoch 18/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.1295 - accuracy: 0.3625 - precision_m: 0.6864 - recall_m: 0.1085 - f1_m: 0.1864\n",
      "Epoch 18: val_loss improved from 2.20369 to 2.20083, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.3418 | Precision: 0.6358 | Recall: 0.1115 | F1: 0.1877\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1292 - accuracy: 0.3626 - precision_m: 0.6869 - recall_m: 0.1085 - f1_m: 0.1864 - val_loss: 2.2008 - val_accuracy: 0.3418 - val_precision_m: 0.6358 - val_recall_m: 0.1115 - val_f1_m: 0.1877\n",
      "Epoch 19/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 2.1182 - accuracy: 0.3658 - precision_m: 0.6846 - recall_m: 0.1119 - f1_m: 0.1913\n",
      "Epoch 19: val_loss did not improve from 2.20083\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 19\n",
      "Accuracy: 0.3445 | Precision: 0.6504 | Recall: 0.1049 | F1: 0.1790\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1182 - accuracy: 0.3658 - precision_m: 0.6846 - recall_m: 0.1119 - f1_m: 0.1913 - val_loss: 2.2207 - val_accuracy: 0.3445 - val_precision_m: 0.6504 - val_recall_m: 0.1049 - val_f1_m: 0.1790\n",
      "Epoch 20/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 2.1096 - accuracy: 0.3690 - precision_m: 0.6833 - recall_m: 0.1138 - f1_m: 0.1941\n",
      "Epoch 20: val_loss improved from 2.20083 to 2.18197, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 20\n",
      "Accuracy: 0.3565 | Precision: 0.6335 | Recall: 0.1214 | F1: 0.2017\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1094 - accuracy: 0.3690 - precision_m: 0.6836 - recall_m: 0.1139 - f1_m: 0.1942 - val_loss: 2.1820 - val_accuracy: 0.3565 - val_precision_m: 0.6335 - val_recall_m: 0.1214 - val_f1_m: 0.2017\n",
      "Epoch 21/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.1016 - accuracy: 0.3702 - precision_m: 0.6842 - recall_m: 0.1161 - f1_m: 0.1975\n",
      "Epoch 21: val_loss improved from 2.18197 to 2.15983, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 21\n",
      "Accuracy: 0.3614 | Precision: 0.6481 | Recall: 0.1231 | F1: 0.2052\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1016 - accuracy: 0.3701 - precision_m: 0.6843 - recall_m: 0.1161 - f1_m: 0.1974 - val_loss: 2.1598 - val_accuracy: 0.3614 - val_precision_m: 0.6481 - val_recall_m: 0.1231 - val_f1_m: 0.2052\n",
      "Epoch 22/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.0956 - accuracy: 0.3740 - precision_m: 0.6823 - recall_m: 0.1186 - f1_m: 0.2012\n",
      "Epoch 22: val_loss improved from 2.15983 to 2.15547, saving model to trained_models/model_1_fold_6_best.h5\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.0956 - accuracy: 0.3739 - precision_m: 0.6821 - recall_m: 0.1185 - f1_m: 0.2011 - val_loss: 2.1555 - val_accuracy: 0.3614 - val_precision_m: 0.6479 - val_recall_m: 0.1254 - val_f1_m: 0.2085\n",
      "Epoch 23/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.0874 - accuracy: 0.3745 - precision_m: 0.6863 - recall_m: 0.1219 - f1_m: 0.2060\n",
      "Epoch 23: val_loss improved from 2.15547 to 2.13773, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 23\n",
      "Accuracy: 0.3679 | Precision: 0.6636 | Recall: 0.1234 | F1: 0.2061\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.0878 - accuracy: 0.3748 - precision_m: 0.6865 - recall_m: 0.1219 - f1_m: 0.2060 - val_loss: 2.1377 - val_accuracy: 0.3679 - val_precision_m: 0.6636 - val_recall_m: 0.1234 - val_f1_m: 0.2061\n",
      "Epoch 24/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.0794 - accuracy: 0.3793 - precision_m: 0.6847 - recall_m: 0.1222 - f1_m: 0.2065\n",
      "Epoch 24: val_loss did not improve from 2.13773\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.0796 - accuracy: 0.3792 - precision_m: 0.6846 - recall_m: 0.1222 - f1_m: 0.2064 - val_loss: 2.1507 - val_accuracy: 0.3650 - val_precision_m: 0.6307 - val_recall_m: 0.1304 - val_f1_m: 0.2140\n",
      "Epoch 25/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.0769 - accuracy: 0.3791 - precision_m: 0.6859 - recall_m: 0.1247 - f1_m: 0.2100\n",
      "Epoch 25: val_loss did not improve from 2.13773\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.0770 - accuracy: 0.3791 - precision_m: 0.6859 - recall_m: 0.1246 - f1_m: 0.2099 - val_loss: 2.1742 - val_accuracy: 0.3619 - val_precision_m: 0.6323 - val_recall_m: 0.1267 - val_f1_m: 0.2091\n",
      "Epoch 26/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.0708 - accuracy: 0.3832 - precision_m: 0.6851 - recall_m: 0.1271 - f1_m: 0.2133\n",
      "Epoch 26: val_loss did not improve from 2.13773\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 26\n",
      "Accuracy: 0.3682 | Precision: 0.6461 | Recall: 0.1227 | F1: 0.2045\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 2.0710 - accuracy: 0.3831 - precision_m: 0.6854 - recall_m: 0.1270 - f1_m: 0.2132 - val_loss: 2.1471 - val_accuracy: 0.3682 - val_precision_m: 0.6461 - val_recall_m: 0.1227 - val_f1_m: 0.2045\n",
      "Epoch 27/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.0670 - accuracy: 0.3810 - precision_m: 0.6886 - recall_m: 0.1284 - f1_m: 0.2155\n",
      "Epoch 27: val_loss did not improve from 2.13773\n",
      "610/610 [==============================] - 5s 7ms/step - loss: 2.0675 - accuracy: 0.3806 - precision_m: 0.6886 - recall_m: 0.1281 - f1_m: 0.2151 - val_loss: 2.1468 - val_accuracy: 0.3673 - val_precision_m: 0.6580 - val_recall_m: 0.1290 - val_f1_m: 0.2140\n",
      "Epoch 28/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 2.0606 - accuracy: 0.3845 - precision_m: 0.6878 - recall_m: 0.1303 - f1_m: 0.2181\n",
      "Epoch 28: val_loss did not improve from 2.13773\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 2.0609 - accuracy: 0.3847 - precision_m: 0.6883 - recall_m: 0.1304 - f1_m: 0.2183 - val_loss: 2.1381 - val_accuracy: 0.3641 - val_precision_m: 0.6442 - val_recall_m: 0.1279 - val_f1_m: 0.2117\n",
      "Epoch 29/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.0564 - accuracy: 0.3857 - precision_m: 0.6875 - recall_m: 0.1334 - f1_m: 0.2224\n",
      "Epoch 29: val_loss improved from 2.13773 to 2.13117, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 29\n",
      "Accuracy: 0.3723 | Precision: 0.6511 | Recall: 0.1288 | F1: 0.2133\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 2.0568 - accuracy: 0.3857 - precision_m: 0.6879 - recall_m: 0.1337 - f1_m: 0.2227 - val_loss: 2.1312 - val_accuracy: 0.3723 - val_precision_m: 0.6511 - val_recall_m: 0.1288 - val_f1_m: 0.2133\n",
      "Epoch 30/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.0515 - accuracy: 0.3863 - precision_m: 0.6882 - recall_m: 0.1336 - f1_m: 0.2228\n",
      "Epoch 30: val_loss improved from 2.13117 to 2.11143, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 30\n",
      "Accuracy: 0.3732 | Precision: 0.6623 | Recall: 0.1309 | F1: 0.2170\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 8ms/step - loss: 2.0512 - accuracy: 0.3862 - precision_m: 0.6886 - recall_m: 0.1338 - f1_m: 0.2231 - val_loss: 2.1114 - val_accuracy: 0.3732 - val_precision_m: 0.6623 - val_recall_m: 0.1309 - val_f1_m: 0.2170\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 135.0 seconds (2.3 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 75.1%\n",
      "  Usage (max):  88.7%\n",
      "  Frequency:    3991 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 87.0%\n",
      "  Usage (max):  90.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  13.9%\n",
      "  Usage (max):   47.0%\n",
      "  Memory (mean): 626 MB\n",
      "  Memory (max):  659 MB\n",
      "  Power (mean):  25.3 W\n",
      "  Power (max):   43.1 W\n",
      "  Energy used:   0.950 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 RESULTS\n",
      "================================================================================\n",
      "Validation - Loss: 2.1114, Acc: 37.32%\n",
      "Test       - Loss: 2.1461, Acc: 36.73%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 7 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=78139, Val=8252, Test=7309\n",
      "Epoch 1/30\n",
      "610/611 [============================>.] - ETA: 0s - loss: 3.4176 - accuracy: 0.0611 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 3.17802, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.0870 | Precision: 0.0154 | Recall: 0.0001 | F1: 0.0002\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 6s 9ms/step - loss: 3.4175 - accuracy: 0.0611 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 3.1780 - val_accuracy: 0.0870 - val_precision_m: 0.0154 - val_recall_m: 1.2019e-04 - val_f1_m: 2.3852e-04\n",
      "Epoch 2/30\n",
      "610/611 [============================>.] - ETA: 0s - loss: 3.0619 - accuracy: 0.1144 - precision_m: 0.0082 - recall_m: 6.4037e-05 - f1_m: 1.2708e-04\n",
      "Epoch 2: val_loss improved from 3.17802 to 3.00675, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.1361 | Precision: 0.0615 | Recall: 0.0006 | F1: 0.0012\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 5s 8ms/step - loss: 3.0619 - accuracy: 0.1144 - precision_m: 0.0082 - recall_m: 6.3932e-05 - f1_m: 1.2687e-04 - val_loss: 3.0067 - val_accuracy: 0.1361 - val_precision_m: 0.0615 - val_recall_m: 6.0096e-04 - val_f1_m: 0.0012\n",
      "Epoch 3/30\n",
      "606/611 [============================>.] - ETA: 0s - loss: 2.9574 - accuracy: 0.1389 - precision_m: 0.0396 - recall_m: 3.4808e-04 - f1_m: 6.8959e-04\n",
      "Epoch 3: val_loss improved from 3.00675 to 2.94417, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.1480 | Precision: 0.1077 | Recall: 0.0011 | F1: 0.0021\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 5s 8ms/step - loss: 2.9571 - accuracy: 0.1392 - precision_m: 0.0393 - recall_m: 3.4523e-04 - f1_m: 6.8394e-04 - val_loss: 2.9442 - val_accuracy: 0.1480 - val_precision_m: 0.1077 - val_recall_m: 0.0011 - val_f1_m: 0.0021\n",
      "Epoch 4/30\n",
      "606/611 [============================>.] - ETA: 0s - loss: 2.9008 - accuracy: 0.1524 - precision_m: 0.0883 - recall_m: 7.4773e-04 - f1_m: 0.0015\n",
      "Epoch 4: val_loss improved from 2.94417 to 2.91828, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.1510 | Precision: 0.0769 | Recall: 0.0008 | F1: 0.0017\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 5s 8ms/step - loss: 2.9006 - accuracy: 0.1523 - precision_m: 0.0876 - recall_m: 7.4161e-04 - f1_m: 0.0015 - val_loss: 2.9183 - val_accuracy: 0.1510 - val_precision_m: 0.0769 - val_recall_m: 8.4135e-04 - val_f1_m: 0.0017\n",
      "Epoch 5/30\n",
      "606/611 [============================>.] - ETA: 0s - loss: 2.8597 - accuracy: 0.1595 - precision_m: 0.1180 - recall_m: 0.0011 - f1_m: 0.0021\n",
      "Epoch 5: val_loss improved from 2.91828 to 2.88445, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.1575 | Precision: 0.1385 | Recall: 0.0017 | F1: 0.0033\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 5s 8ms/step - loss: 2.8601 - accuracy: 0.1594 - precision_m: 0.1187 - recall_m: 0.0011 - f1_m: 0.0022 - val_loss: 2.8844 - val_accuracy: 0.1575 - val_precision_m: 0.1385 - val_recall_m: 0.0017 - val_f1_m: 0.0033\n",
      "Epoch 6/30\n",
      "610/611 [============================>.] - ETA: 0s - loss: 2.8296 - accuracy: 0.1662 - precision_m: 0.1406 - recall_m: 0.0013 - f1_m: 0.0026\n",
      "Epoch 6: val_loss improved from 2.88445 to 2.84410, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.1636 | Precision: 0.1923 | Recall: 0.0028 | F1: 0.0054\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.8296 - accuracy: 0.1662 - precision_m: 0.1403 - recall_m: 0.0013 - f1_m: 0.0026 - val_loss: 2.8441 - val_accuracy: 0.1636 - val_precision_m: 0.1923 - val_recall_m: 0.0028 - val_f1_m: 0.0054\n",
      "Epoch 7/30\n",
      "611/611 [==============================] - ETA: 0s - loss: 2.8123 - accuracy: 0.1682 - precision_m: 0.1987 - recall_m: 0.0019 - f1_m: 0.0038\n",
      "Epoch 7: val_loss improved from 2.84410 to 2.83359, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.1644 | Precision: 0.2923 | Recall: 0.0042 | F1: 0.0083\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.8123 - accuracy: 0.1682 - precision_m: 0.1987 - recall_m: 0.0019 - f1_m: 0.0038 - val_loss: 2.8336 - val_accuracy: 0.1644 - val_precision_m: 0.2923 - val_recall_m: 0.0042 - val_f1_m: 0.0083\n",
      "Epoch 8/30\n",
      "608/611 [============================>.] - ETA: 0s - loss: 2.7954 - accuracy: 0.1708 - precision_m: 0.2045 - recall_m: 0.0021 - f1_m: 0.0041\n",
      "Epoch 8: val_loss did not improve from 2.83359\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7951 - accuracy: 0.1709 - precision_m: 0.2059 - recall_m: 0.0021 - f1_m: 0.0041 - val_loss: 2.8417 - val_accuracy: 0.1621 - val_precision_m: 0.3248 - val_recall_m: 0.0050 - val_f1_m: 0.0099\n",
      "Epoch 9/30\n",
      "607/611 [============================>.] - ETA: 0s - loss: 2.7808 - accuracy: 0.1725 - precision_m: 0.2565 - recall_m: 0.0027 - f1_m: 0.0053\n",
      "Epoch 9: val_loss improved from 2.83359 to 2.80827, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.1699 | Precision: 0.2949 | Recall: 0.0044 | F1: 0.0087\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7811 - accuracy: 0.1725 - precision_m: 0.2548 - recall_m: 0.0027 - f1_m: 0.0053 - val_loss: 2.8083 - val_accuracy: 0.1699 - val_precision_m: 0.2949 - val_recall_m: 0.0044 - val_f1_m: 0.0087\n",
      "Epoch 10/30\n",
      "608/611 [============================>.] - ETA: 0s - loss: 2.7699 - accuracy: 0.1747 - precision_m: 0.2729 - recall_m: 0.0029 - f1_m: 0.0058\n",
      "Epoch 10: val_loss improved from 2.80827 to 2.79920, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.1727 | Precision: 0.3045 | Recall: 0.0047 | F1: 0.0092\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7702 - accuracy: 0.1746 - precision_m: 0.2715 - recall_m: 0.0029 - f1_m: 0.0057 - val_loss: 2.7992 - val_accuracy: 0.1727 - val_precision_m: 0.3045 - val_recall_m: 0.0047 - val_f1_m: 0.0092\n",
      "Epoch 11/30\n",
      "607/611 [============================>.] - ETA: 0s - loss: 2.7605 - accuracy: 0.1762 - precision_m: 0.3090 - recall_m: 0.0033 - f1_m: 0.0065\n",
      "Epoch 11: val_loss improved from 2.79920 to 2.79536, saving model to trained_models/model_1_fold_7_best.h5\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7613 - accuracy: 0.1761 - precision_m: 0.3070 - recall_m: 0.0033 - f1_m: 0.0064 - val_loss: 2.7954 - val_accuracy: 0.1675 - val_precision_m: 0.3154 - val_recall_m: 0.0042 - val_f1_m: 0.0083\n",
      "Epoch 12/30\n",
      "605/611 [============================>.] - ETA: 0s - loss: 2.7538 - accuracy: 0.1778 - precision_m: 0.3136 - recall_m: 0.0034 - f1_m: 0.0068\n",
      "Epoch 12: val_loss improved from 2.79536 to 2.78525, saving model to trained_models/model_1_fold_7_best.h5\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7538 - accuracy: 0.1777 - precision_m: 0.3106 - recall_m: 0.0034 - f1_m: 0.0067 - val_loss: 2.7853 - val_accuracy: 0.1716 - val_precision_m: 0.4197 - val_recall_m: 0.0069 - val_f1_m: 0.0134\n",
      "Epoch 13/30\n",
      "609/611 [============================>.] - ETA: 0s - loss: 2.7477 - accuracy: 0.1785 - precision_m: 0.3585 - recall_m: 0.0041 - f1_m: 0.0081\n",
      "Epoch 13: val_loss did not improve from 2.78525\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7476 - accuracy: 0.1786 - precision_m: 0.3573 - recall_m: 0.0041 - f1_m: 0.0081 - val_loss: 2.8008 - val_accuracy: 0.1651 - val_precision_m: 0.2692 - val_recall_m: 0.0040 - val_f1_m: 0.0078\n",
      "Epoch 14/30\n",
      "605/611 [============================>.] - ETA: 0s - loss: 2.7391 - accuracy: 0.1787 - precision_m: 0.3480 - recall_m: 0.0041 - f1_m: 0.0081\n",
      "Epoch 14: val_loss did not improve from 2.78525\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.1734 | Precision: 0.3887 | Recall: 0.0070 | F1: 0.0136\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7391 - accuracy: 0.1787 - precision_m: 0.3511 - recall_m: 0.0041 - f1_m: 0.0082 - val_loss: 2.7880 - val_accuracy: 0.1734 - val_precision_m: 0.3887 - val_recall_m: 0.0070 - val_f1_m: 0.0136\n",
      "Epoch 15/30\n",
      "609/611 [============================>.] - ETA: 0s - loss: 2.7356 - accuracy: 0.1782 - precision_m: 0.3436 - recall_m: 0.0040 - f1_m: 0.0080\n",
      "Epoch 15: val_loss improved from 2.78525 to 2.77617, saving model to trained_models/model_1_fold_7_best.h5\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7354 - accuracy: 0.1782 - precision_m: 0.3441 - recall_m: 0.0041 - f1_m: 0.0080 - val_loss: 2.7762 - val_accuracy: 0.1665 - val_precision_m: 0.4349 - val_recall_m: 0.0079 - val_f1_m: 0.0155\n",
      "Epoch 16/30\n",
      "609/611 [============================>.] - ETA: 0s - loss: 2.7332 - accuracy: 0.1799 - precision_m: 0.3963 - recall_m: 0.0048 - f1_m: 0.0094\n",
      "Epoch 16: val_loss improved from 2.77617 to 2.76553, saving model to trained_models/model_1_fold_7_best.h5\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7332 - accuracy: 0.1797 - precision_m: 0.3950 - recall_m: 0.0048 - f1_m: 0.0094 - val_loss: 2.7655 - val_accuracy: 0.1718 - val_precision_m: 0.3154 - val_recall_m: 0.0049 - val_f1_m: 0.0097\n",
      "Epoch 17/30\n",
      "605/611 [============================>.] - ETA: 0s - loss: 2.7248 - accuracy: 0.1804 - precision_m: 0.3655 - recall_m: 0.0046 - f1_m: 0.0091\n",
      "Epoch 17: val_loss improved from 2.76553 to 2.75756, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.1747 | Precision: 0.3977 | Recall: 0.0078 | F1: 0.0152\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7248 - accuracy: 0.1804 - precision_m: 0.3668 - recall_m: 0.0046 - f1_m: 0.0091 - val_loss: 2.7576 - val_accuracy: 0.1747 - val_precision_m: 0.3977 - val_recall_m: 0.0078 - val_f1_m: 0.0152\n",
      "Epoch 18/30\n",
      "607/611 [============================>.] - ETA: 0s - loss: 2.7235 - accuracy: 0.1809 - precision_m: 0.4037 - recall_m: 0.0051 - f1_m: 0.0100\n",
      "Epoch 18: val_loss did not improve from 2.75756\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.1779 | Precision: 0.3718 | Recall: 0.0063 | F1: 0.0122\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7236 - accuracy: 0.1808 - precision_m: 0.4060 - recall_m: 0.0051 - f1_m: 0.0101 - val_loss: 2.7679 - val_accuracy: 0.1779 - val_precision_m: 0.3718 - val_recall_m: 0.0063 - val_f1_m: 0.0122\n",
      "Epoch 19/30\n",
      "607/611 [============================>.] - ETA: 0s - loss: 2.7153 - accuracy: 0.1825 - precision_m: 0.4000 - recall_m: 0.0053 - f1_m: 0.0105\n",
      "Epoch 19: val_loss did not improve from 2.75756\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7155 - accuracy: 0.1826 - precision_m: 0.3974 - recall_m: 0.0053 - f1_m: 0.0104 - val_loss: 2.7753 - val_accuracy: 0.1724 - val_precision_m: 0.4295 - val_recall_m: 0.0085 - val_f1_m: 0.0166\n",
      "Epoch 20/30\n",
      "608/611 [============================>.] - ETA: 0s - loss: 2.7136 - accuracy: 0.1816 - precision_m: 0.4074 - recall_m: 0.0055 - f1_m: 0.0109\n",
      "Epoch 20: val_loss improved from 2.75756 to 2.75461, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 20\n",
      "Accuracy: 0.1797 | Precision: 0.4179 | Recall: 0.0087 | F1: 0.0168\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7136 - accuracy: 0.1815 - precision_m: 0.4087 - recall_m: 0.0055 - f1_m: 0.0109 - val_loss: 2.7546 - val_accuracy: 0.1797 - val_precision_m: 0.4179 - val_recall_m: 0.0087 - val_f1_m: 0.0168\n",
      "Epoch 21/30\n",
      "607/611 [============================>.] - ETA: 0s - loss: 2.7103 - accuracy: 0.1839 - precision_m: 0.4240 - recall_m: 0.0055 - f1_m: 0.0108\n",
      "Epoch 21: val_loss improved from 2.75461 to 2.74992, saving model to trained_models/model_1_fold_7_best.h5\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7102 - accuracy: 0.1839 - precision_m: 0.4262 - recall_m: 0.0056 - f1_m: 0.0109 - val_loss: 2.7499 - val_accuracy: 0.1717 - val_precision_m: 0.4205 - val_recall_m: 0.0078 - val_f1_m: 0.0152\n",
      "Epoch 22/30\n",
      "610/611 [============================>.] - ETA: 0s - loss: 2.7074 - accuracy: 0.1829 - precision_m: 0.4040 - recall_m: 0.0055 - f1_m: 0.0108\n",
      "Epoch 22: val_loss did not improve from 2.74992\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7074 - accuracy: 0.1829 - precision_m: 0.4033 - recall_m: 0.0055 - f1_m: 0.0108 - val_loss: 2.7622 - val_accuracy: 0.1723 - val_precision_m: 0.4231 - val_recall_m: 0.0073 - val_f1_m: 0.0143\n",
      "Epoch 23/30\n",
      "609/611 [============================>.] - ETA: 0s - loss: 2.7038 - accuracy: 0.1816 - precision_m: 0.4033 - recall_m: 0.0053 - f1_m: 0.0105\n",
      "Epoch 23: val_loss did not improve from 2.74992\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7041 - accuracy: 0.1815 - precision_m: 0.4036 - recall_m: 0.0054 - f1_m: 0.0105 - val_loss: 2.7792 - val_accuracy: 0.1730 - val_precision_m: 0.4246 - val_recall_m: 0.0087 - val_f1_m: 0.0168\n",
      "Epoch 24/30\n",
      "605/611 [============================>.] - ETA: 0s - loss: 2.7015 - accuracy: 0.1846 - precision_m: 0.4067 - recall_m: 0.0057 - f1_m: 0.0112\n",
      "Epoch 24: val_loss did not improve from 2.74992\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.7016 - accuracy: 0.1848 - precision_m: 0.4084 - recall_m: 0.0057 - f1_m: 0.0112 - val_loss: 2.7581 - val_accuracy: 0.1726 - val_precision_m: 0.4731 - val_recall_m: 0.0117 - val_f1_m: 0.0225\n",
      "Epoch 25/30\n",
      "605/611 [============================>.] - ETA: 0s - loss: 2.6985 - accuracy: 0.1860 - precision_m: 0.4235 - recall_m: 0.0060 - f1_m: 0.0118\n",
      "Epoch 25: val_loss did not improve from 2.74992\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.6986 - accuracy: 0.1861 - precision_m: 0.4237 - recall_m: 0.0060 - f1_m: 0.0119 - val_loss: 2.7511 - val_accuracy: 0.1787 - val_precision_m: 0.4983 - val_recall_m: 0.0117 - val_f1_m: 0.0225\n",
      "Epoch 26/30\n",
      "606/611 [============================>.] - ETA: 0s - loss: 2.6966 - accuracy: 0.1861 - precision_m: 0.4113 - recall_m: 0.0057 - f1_m: 0.0112\n",
      "Epoch 26: val_loss improved from 2.74992 to 2.73829, saving model to trained_models/model_1_fold_7_best.h5\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.6966 - accuracy: 0.1861 - precision_m: 0.4112 - recall_m: 0.0057 - f1_m: 0.0111 - val_loss: 2.7383 - val_accuracy: 0.1760 - val_precision_m: 0.3615 - val_recall_m: 0.0063 - val_f1_m: 0.0122\n",
      "Epoch 27/30\n",
      "609/611 [============================>.] - ETA: 0s - loss: 2.6905 - accuracy: 0.1862 - precision_m: 0.4184 - recall_m: 0.0058 - f1_m: 0.0115\n",
      "Epoch 27: val_loss improved from 2.73829 to 2.73669, saving model to trained_models/model_1_fold_7_best.h5\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.6909 - accuracy: 0.1861 - precision_m: 0.4179 - recall_m: 0.0058 - f1_m: 0.0115 - val_loss: 2.7367 - val_accuracy: 0.1768 - val_precision_m: 0.3921 - val_recall_m: 0.0087 - val_f1_m: 0.0168\n",
      "Epoch 28/30\n",
      "605/611 [============================>.] - ETA: 0s - loss: 2.6926 - accuracy: 0.1872 - precision_m: 0.4256 - recall_m: 0.0060 - f1_m: 0.0118\n",
      "Epoch 28: val_loss improved from 2.73669 to 2.73590, saving model to trained_models/model_1_fold_7_best.h5\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.6920 - accuracy: 0.1873 - precision_m: 0.4247 - recall_m: 0.0060 - f1_m: 0.0118 - val_loss: 2.7359 - val_accuracy: 0.1764 - val_precision_m: 0.3931 - val_recall_m: 0.0069 - val_f1_m: 0.0134\n",
      "Epoch 29/30\n",
      "609/611 [============================>.] - ETA: 0s - loss: 2.6858 - accuracy: 0.1870 - precision_m: 0.4290 - recall_m: 0.0062 - f1_m: 0.0122\n",
      "Epoch 29: val_loss improved from 2.73590 to 2.73532, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 29\n",
      "Accuracy: 0.1809 | Precision: 0.3987 | Recall: 0.0064 | F1: 0.0125\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.6859 - accuracy: 0.1870 - precision_m: 0.4284 - recall_m: 0.0062 - f1_m: 0.0122 - val_loss: 2.7353 - val_accuracy: 0.1809 - val_precision_m: 0.3987 - val_recall_m: 0.0064 - val_f1_m: 0.0125\n",
      "Epoch 30/30\n",
      "605/611 [============================>.] - ETA: 0s - loss: 2.6843 - accuracy: 0.1876 - precision_m: 0.4202 - recall_m: 0.0058 - f1_m: 0.0114\n",
      "Epoch 30: val_loss improved from 2.73532 to 2.73036, saving model to trained_models/model_1_fold_7_best.h5\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 2.6839 - accuracy: 0.1877 - precision_m: 0.4194 - recall_m: 0.0058 - f1_m: 0.0114 - val_loss: 2.7304 - val_accuracy: 0.1768 - val_precision_m: 0.4038 - val_recall_m: 0.0063 - val_f1_m: 0.0122\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 133.9 seconds (2.2 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 74.1%\n",
      "  Usage (max):  88.9%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 89.6%\n",
      "  Usage (max):  92.9%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  12.2%\n",
      "  Usage (max):   50.0%\n",
      "  Memory (mean): 587 MB\n",
      "  Memory (max):  613 MB\n",
      "  Power (mean):  24.8 W\n",
      "  Power (max):   41.8 W\n",
      "  Energy used:   0.923 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 RESULTS\n",
      "================================================================================\n",
      "Validation - Loss: 2.7304, Acc: 17.68%\n",
      "Test       - Loss: 2.7291, Acc: 18.65%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 8 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77895, Val=8304, Test=7432\n",
      "Epoch 1/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 2.8235 - accuracy: 0.2101 - precision_m: 0.4520 - recall_m: 0.0204 - f1_m: 0.0383\n",
      "Epoch 1: val_loss improved from inf to 2.43305, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.3024 | Precision: 0.7366 | Recall: 0.0546 | F1: 0.1003\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 5s 7ms/step - loss: 2.8229 - accuracy: 0.2102 - precision_m: 0.4531 - recall_m: 0.0205 - f1_m: 0.0386 - val_loss: 2.4330 - val_accuracy: 0.3024 - val_precision_m: 0.7366 - val_recall_m: 0.0546 - val_f1_m: 0.1003\n",
      "Epoch 2/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 2.2668 - accuracy: 0.3464 - precision_m: 0.7130 - recall_m: 0.0920 - f1_m: 0.1613\n",
      "Epoch 2: val_loss improved from 2.43305 to 2.21658, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3605 | Precision: 0.6869 | Recall: 0.1214 | F1: 0.2040\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.2660 - accuracy: 0.3466 - precision_m: 0.7132 - recall_m: 0.0922 - f1_m: 0.1616 - val_loss: 2.2166 - val_accuracy: 0.3605 - val_precision_m: 0.6869 - val_recall_m: 0.1214 - val_f1_m: 0.2040\n",
      "Epoch 3/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 2.0666 - accuracy: 0.4007 - precision_m: 0.7273 - recall_m: 0.1490 - f1_m: 0.2460\n",
      "Epoch 3: val_loss improved from 2.21658 to 2.08509, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3939 | Precision: 0.6831 | Recall: 0.1610 | F1: 0.2580\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.0666 - accuracy: 0.4008 - precision_m: 0.7272 - recall_m: 0.1490 - f1_m: 0.2461 - val_loss: 2.0851 - val_accuracy: 0.3939 - val_precision_m: 0.6831 - val_recall_m: 0.1610 - val_f1_m: 0.2580\n",
      "Epoch 4/30\n",
      "602/609 [============================>.] - ETA: 0s - loss: 1.9614 - accuracy: 0.4291 - precision_m: 0.7289 - recall_m: 0.1838 - f1_m: 0.2923\n",
      "Epoch 4: val_loss improved from 2.08509 to 1.99460, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.4203 | Precision: 0.6966 | Recall: 0.1796 | F1: 0.2835\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9605 - accuracy: 0.4293 - precision_m: 0.7286 - recall_m: 0.1840 - f1_m: 0.2926 - val_loss: 1.9946 - val_accuracy: 0.4203 - val_precision_m: 0.6966 - val_recall_m: 0.1796 - val_f1_m: 0.2835\n",
      "Epoch 5/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.8920 - accuracy: 0.4478 - precision_m: 0.7345 - recall_m: 0.2102 - f1_m: 0.3256\n",
      "Epoch 5: val_loss improved from 1.99460 to 1.92749, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.4382 | Precision: 0.7230 | Recall: 0.2051 | F1: 0.3171\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8920 - accuracy: 0.4478 - precision_m: 0.7345 - recall_m: 0.2102 - f1_m: 0.3256 - val_loss: 1.9275 - val_accuracy: 0.4382 - val_precision_m: 0.7230 - val_recall_m: 0.2051 - val_f1_m: 0.3171\n",
      "Epoch 6/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.8402 - accuracy: 0.4627 - precision_m: 0.7379 - recall_m: 0.2318 - f1_m: 0.3517\n",
      "Epoch 6: val_loss improved from 1.92749 to 1.90858, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.4422 | Precision: 0.7111 | Recall: 0.2213 | F1: 0.3352\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8402 - accuracy: 0.4627 - precision_m: 0.7379 - recall_m: 0.2318 - f1_m: 0.3517 - val_loss: 1.9086 - val_accuracy: 0.4422 - val_precision_m: 0.7111 - val_recall_m: 0.2213 - val_f1_m: 0.3352\n",
      "Epoch 7/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.8045 - accuracy: 0.4714 - precision_m: 0.7393 - recall_m: 0.2482 - f1_m: 0.3705\n",
      "Epoch 7: val_loss improved from 1.90858 to 1.90248, saving model to trained_models/model_1_fold_8_best.h5\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8050 - accuracy: 0.4712 - precision_m: 0.7391 - recall_m: 0.2480 - f1_m: 0.3702 - val_loss: 1.9025 - val_accuracy: 0.4376 - val_precision_m: 0.7038 - val_recall_m: 0.2363 - val_f1_m: 0.3518\n",
      "Epoch 8/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 1.7777 - accuracy: 0.4780 - precision_m: 0.7413 - recall_m: 0.2584 - f1_m: 0.3820\n",
      "Epoch 8: val_loss improved from 1.90248 to 1.85230, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.4499 | Precision: 0.7085 | Recall: 0.2396 | F1: 0.3560\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7779 - accuracy: 0.4779 - precision_m: 0.7413 - recall_m: 0.2583 - f1_m: 0.3820 - val_loss: 1.8523 - val_accuracy: 0.4499 - val_precision_m: 0.7085 - val_recall_m: 0.2396 - val_f1_m: 0.3560\n",
      "Epoch 9/30\n",
      "602/609 [============================>.] - ETA: 0s - loss: 1.7557 - accuracy: 0.4847 - precision_m: 0.7422 - recall_m: 0.2701 - f1_m: 0.3950\n",
      "Epoch 9: val_loss did not improve from 1.85230\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7552 - accuracy: 0.4849 - precision_m: 0.7426 - recall_m: 0.2702 - f1_m: 0.3952 - val_loss: 1.8646 - val_accuracy: 0.4497 - val_precision_m: 0.7008 - val_recall_m: 0.2390 - val_f1_m: 0.3546\n",
      "Epoch 10/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.7392 - accuracy: 0.4880 - precision_m: 0.7450 - recall_m: 0.2775 - f1_m: 0.4033\n",
      "Epoch 10: val_loss improved from 1.85230 to 1.82432, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.4597 | Precision: 0.7069 | Recall: 0.2537 | F1: 0.3711\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7392 - accuracy: 0.4880 - precision_m: 0.7450 - recall_m: 0.2775 - f1_m: 0.4033 - val_loss: 1.8243 - val_accuracy: 0.4597 - val_precision_m: 0.7069 - val_recall_m: 0.2537 - val_f1_m: 0.3711\n",
      "Epoch 11/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.7229 - accuracy: 0.4923 - precision_m: 0.7434 - recall_m: 0.2836 - f1_m: 0.4094\n",
      "Epoch 11: val_loss did not improve from 1.82432\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7229 - accuracy: 0.4923 - precision_m: 0.7434 - recall_m: 0.2836 - f1_m: 0.4094 - val_loss: 1.8457 - val_accuracy: 0.4445 - val_precision_m: 0.6799 - val_recall_m: 0.2617 - val_f1_m: 0.3763\n",
      "Epoch 12/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.7118 - accuracy: 0.4955 - precision_m: 0.7438 - recall_m: 0.2889 - f1_m: 0.4151\n",
      "Epoch 12: val_loss improved from 1.82432 to 1.80347, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.4669 | Precision: 0.7185 | Recall: 0.2685 | F1: 0.3891\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7110 - accuracy: 0.4956 - precision_m: 0.7440 - recall_m: 0.2890 - f1_m: 0.4152 - val_loss: 1.8035 - val_accuracy: 0.4669 - val_precision_m: 0.7185 - val_recall_m: 0.2685 - val_f1_m: 0.3891\n",
      "Epoch 13/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.6979 - accuracy: 0.4992 - precision_m: 0.7446 - recall_m: 0.2940 - f1_m: 0.4207\n",
      "Epoch 13: val_loss did not improve from 1.80347\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 13\n",
      "Accuracy: 0.4676 | Precision: 0.7002 | Recall: 0.2671 | F1: 0.3849\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6979 - accuracy: 0.4992 - precision_m: 0.7446 - recall_m: 0.2940 - f1_m: 0.4207 - val_loss: 1.8077 - val_accuracy: 0.4676 - val_precision_m: 0.7002 - val_recall_m: 0.2671 - val_f1_m: 0.3849\n",
      "Epoch 14/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.6904 - accuracy: 0.5019 - precision_m: 0.7464 - recall_m: 0.2995 - f1_m: 0.4264\n",
      "Epoch 14: val_loss improved from 1.80347 to 1.79974, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.4724 | Precision: 0.7056 | Recall: 0.2743 | F1: 0.3932\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6906 - accuracy: 0.5017 - precision_m: 0.7462 - recall_m: 0.2994 - f1_m: 0.4262 - val_loss: 1.7997 - val_accuracy: 0.4724 - val_precision_m: 0.7056 - val_recall_m: 0.2743 - val_f1_m: 0.3932\n",
      "Epoch 15/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.6806 - accuracy: 0.5039 - precision_m: 0.7500 - recall_m: 0.3023 - f1_m: 0.4299\n",
      "Epoch 15: val_loss improved from 1.79974 to 1.78826, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 15\n",
      "Accuracy: 0.4741 | Precision: 0.7126 | Recall: 0.2754 | F1: 0.3956\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6806 - accuracy: 0.5039 - precision_m: 0.7500 - recall_m: 0.3023 - f1_m: 0.4299 - val_loss: 1.7883 - val_accuracy: 0.4741 - val_precision_m: 0.7126 - val_recall_m: 0.2754 - val_f1_m: 0.3956\n",
      "Epoch 16/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.6780 - accuracy: 0.5048 - precision_m: 0.7468 - recall_m: 0.3052 - f1_m: 0.4323\n",
      "Epoch 16: val_loss did not improve from 1.78826\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.4772 | Precision: 0.7009 | Recall: 0.2848 | F1: 0.4034\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6778 - accuracy: 0.5049 - precision_m: 0.7469 - recall_m: 0.3054 - f1_m: 0.4325 - val_loss: 1.7886 - val_accuracy: 0.4772 - val_precision_m: 0.7009 - val_recall_m: 0.2848 - val_f1_m: 0.4034\n",
      "Epoch 17/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 1.6679 - accuracy: 0.5065 - precision_m: 0.7468 - recall_m: 0.3073 - f1_m: 0.4344\n",
      "Epoch 17: val_loss did not improve from 1.78826\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6676 - accuracy: 0.5065 - precision_m: 0.7469 - recall_m: 0.3076 - f1_m: 0.4347 - val_loss: 1.8075 - val_accuracy: 0.4698 - val_precision_m: 0.6981 - val_recall_m: 0.2765 - val_f1_m: 0.3944\n",
      "Epoch 18/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.6569 - accuracy: 0.5099 - precision_m: 0.7528 - recall_m: 0.3118 - f1_m: 0.4399\n",
      "Epoch 18: val_loss did not improve from 1.78826\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6569 - accuracy: 0.5099 - precision_m: 0.7525 - recall_m: 0.3117 - f1_m: 0.4397 - val_loss: 1.7999 - val_accuracy: 0.4712 - val_precision_m: 0.6938 - val_recall_m: 0.2958 - val_f1_m: 0.4127\n",
      "Epoch 19/30\n",
      "603/609 [============================>.] - ETA: 0s - loss: 1.6525 - accuracy: 0.5118 - precision_m: 0.7484 - recall_m: 0.3154 - f1_m: 0.4428\n",
      "Epoch 19: val_loss improved from 1.78826 to 1.78476, saving model to trained_models/model_1_fold_8_best.h5\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6527 - accuracy: 0.5119 - precision_m: 0.7485 - recall_m: 0.3154 - f1_m: 0.4428 - val_loss: 1.7848 - val_accuracy: 0.4718 - val_precision_m: 0.7061 - val_recall_m: 0.2846 - val_f1_m: 0.4036\n",
      "Epoch 20/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.6454 - accuracy: 0.5136 - precision_m: 0.7514 - recall_m: 0.3177 - f1_m: 0.4455\n",
      "Epoch 20: val_loss improved from 1.78476 to 1.77382, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 20\n",
      "Accuracy: 0.4815 | Precision: 0.7166 | Recall: 0.2967 | F1: 0.4175\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6452 - accuracy: 0.5136 - precision_m: 0.7513 - recall_m: 0.3177 - f1_m: 0.4455 - val_loss: 1.7738 - val_accuracy: 0.4815 - val_precision_m: 0.7166 - val_recall_m: 0.2967 - val_f1_m: 0.4175\n",
      "Epoch 21/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 1.6443 - accuracy: 0.5133 - precision_m: 0.7474 - recall_m: 0.3196 - f1_m: 0.4469\n",
      "Epoch 21: val_loss did not improve from 1.77382\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6446 - accuracy: 0.5131 - precision_m: 0.7473 - recall_m: 0.3198 - f1_m: 0.4470 - val_loss: 1.7882 - val_accuracy: 0.4712 - val_precision_m: 0.7026 - val_recall_m: 0.2964 - val_f1_m: 0.4151\n",
      "Epoch 22/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.6342 - accuracy: 0.5164 - precision_m: 0.7522 - recall_m: 0.3228 - f1_m: 0.4506\n",
      "Epoch 22: val_loss improved from 1.77382 to 1.76332, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 22\n",
      "Accuracy: 0.4824 | Precision: 0.7114 | Recall: 0.2955 | F1: 0.4156\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6342 - accuracy: 0.5165 - precision_m: 0.7522 - recall_m: 0.3228 - f1_m: 0.4507 - val_loss: 1.7633 - val_accuracy: 0.4824 - val_precision_m: 0.7114 - val_recall_m: 0.2955 - val_f1_m: 0.4156\n",
      "Epoch 23/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 1.6289 - accuracy: 0.5166 - precision_m: 0.7535 - recall_m: 0.3244 - f1_m: 0.4526\n",
      "Epoch 23: val_loss did not improve from 1.76332\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6288 - accuracy: 0.5167 - precision_m: 0.7535 - recall_m: 0.3243 - f1_m: 0.4524 - val_loss: 1.7748 - val_accuracy: 0.4746 - val_precision_m: 0.7026 - val_recall_m: 0.2958 - val_f1_m: 0.4145\n",
      "Epoch 24/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.6213 - accuracy: 0.5204 - precision_m: 0.7542 - recall_m: 0.3275 - f1_m: 0.4557\n",
      "Epoch 24: val_loss did not improve from 1.76332\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 24\n",
      "Accuracy: 0.4872 | Precision: 0.7147 | Recall: 0.3054 | F1: 0.4264\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6213 - accuracy: 0.5204 - precision_m: 0.7542 - recall_m: 0.3275 - f1_m: 0.4557 - val_loss: 1.7733 - val_accuracy: 0.4872 - val_precision_m: 0.7147 - val_recall_m: 0.3054 - val_f1_m: 0.4264\n",
      "Epoch 25/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.6216 - accuracy: 0.5203 - precision_m: 0.7539 - recall_m: 0.3278 - f1_m: 0.4559\n",
      "Epoch 25: val_loss improved from 1.76332 to 1.75022, saving model to trained_models/model_1_fold_8_best.h5\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6215 - accuracy: 0.5202 - precision_m: 0.7540 - recall_m: 0.3278 - f1_m: 0.4559 - val_loss: 1.7502 - val_accuracy: 0.4852 - val_precision_m: 0.7122 - val_recall_m: 0.3060 - val_f1_m: 0.4264\n",
      "Epoch 26/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.6141 - accuracy: 0.5211 - precision_m: 0.7555 - recall_m: 0.3313 - f1_m: 0.4595\n",
      "Epoch 26: val_loss did not improve from 1.75022\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 26\n",
      "Accuracy: 0.4881 | Precision: 0.7083 | Recall: 0.3025 | F1: 0.4223\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6139 - accuracy: 0.5210 - precision_m: 0.7555 - recall_m: 0.3313 - f1_m: 0.4596 - val_loss: 1.7563 - val_accuracy: 0.4881 - val_precision_m: 0.7083 - val_recall_m: 0.3025 - val_f1_m: 0.4223\n",
      "Epoch 27/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.6141 - accuracy: 0.5217 - precision_m: 0.7534 - recall_m: 0.3322 - f1_m: 0.4602\n",
      "Epoch 27: val_loss did not improve from 1.75022\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6141 - accuracy: 0.5217 - precision_m: 0.7534 - recall_m: 0.3322 - f1_m: 0.4602 - val_loss: 1.7789 - val_accuracy: 0.4769 - val_precision_m: 0.7036 - val_recall_m: 0.3013 - val_f1_m: 0.4202\n",
      "Epoch 28/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.6057 - accuracy: 0.5231 - precision_m: 0.7544 - recall_m: 0.3330 - f1_m: 0.4610\n",
      "Epoch 28: val_loss did not improve from 1.75022\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6060 - accuracy: 0.5230 - precision_m: 0.7542 - recall_m: 0.3328 - f1_m: 0.4608 - val_loss: 1.7732 - val_accuracy: 0.4841 - val_precision_m: 0.6973 - val_recall_m: 0.3019 - val_f1_m: 0.4199\n",
      "Epoch 29/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.6059 - accuracy: 0.5243 - precision_m: 0.7560 - recall_m: 0.3340 - f1_m: 0.4623\n",
      "Epoch 29: val_loss did not improve from 1.75022\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6060 - accuracy: 0.5243 - precision_m: 0.7560 - recall_m: 0.3340 - f1_m: 0.4624 - val_loss: 1.7790 - val_accuracy: 0.4747 - val_precision_m: 0.6993 - val_recall_m: 0.3027 - val_f1_m: 0.4207\n",
      "Epoch 30/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.6022 - accuracy: 0.5241 - precision_m: 0.7537 - recall_m: 0.3357 - f1_m: 0.4635\n",
      "Epoch 30: val_loss did not improve from 1.75022\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 30\n",
      "Accuracy: 0.4928 | Precision: 0.7108 | Recall: 0.3134 | F1: 0.4333\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6025 - accuracy: 0.5241 - precision_m: 0.7534 - recall_m: 0.3358 - f1_m: 0.4635 - val_loss: 1.7517 - val_accuracy: 0.4928 - val_precision_m: 0.7108 - val_recall_m: 0.3134 - val_f1_m: 0.4333\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 130.6 seconds (2.2 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 72.4%\n",
      "  Usage (max):  85.0%\n",
      "  Frequency:    3977 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 91.1%\n",
      "  Usage (max):  92.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  13.0%\n",
      "  Usage (max):   17.0%\n",
      "  Memory (mean): 584 MB\n",
      "  Memory (max):  584 MB\n",
      "  Power (mean):  16.3 W\n",
      "  Power (max):   17.8 W\n",
      "  Energy used:   0.591 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 RESULTS\n",
      "================================================================================\n",
      "Validation - Loss: 1.7502, Acc: 48.52%\n",
      "Test       - Loss: 1.7653, Acc: 48.60%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 9 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77896, Val=8304, Test=7446\n",
      "Epoch 1/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 2.9369 - accuracy: 0.1675 - precision_m: 0.3680 - recall_m: 0.0095 - f1_m: 0.0183\n",
      "Epoch 1: val_loss improved from inf to 2.57883, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2490 | Precision: 0.6663 | Recall: 0.0298 | F1: 0.0562\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 5s 7ms/step - loss: 2.9350 - accuracy: 0.1680 - precision_m: 0.3706 - recall_m: 0.0095 - f1_m: 0.0184 - val_loss: 2.5788 - val_accuracy: 0.2490 - val_precision_m: 0.6663 - val_recall_m: 0.0298 - val_f1_m: 0.0562\n",
      "Epoch 2/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 2.4340 - accuracy: 0.2905 - precision_m: 0.6697 - recall_m: 0.0509 - f1_m: 0.0936\n",
      "Epoch 2: val_loss improved from 2.57883 to 2.38851, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3082 | Precision: 0.6953 | Recall: 0.0815 | F1: 0.1443\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.4333 - accuracy: 0.2908 - precision_m: 0.6705 - recall_m: 0.0511 - f1_m: 0.0938 - val_loss: 2.3885 - val_accuracy: 0.3082 - val_precision_m: 0.6953 - val_recall_m: 0.0815 - val_f1_m: 0.1443\n",
      "Epoch 3/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 2.2669 - accuracy: 0.3383 - precision_m: 0.7056 - recall_m: 0.0965 - f1_m: 0.1688\n",
      "Epoch 3: val_loss improved from 2.38851 to 2.24729, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3546 | Precision: 0.6884 | Recall: 0.1149 | F1: 0.1953\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.2664 - accuracy: 0.3386 - precision_m: 0.7054 - recall_m: 0.0966 - f1_m: 0.1690 - val_loss: 2.2473 - val_accuracy: 0.3546 - val_precision_m: 0.6884 - val_recall_m: 0.1149 - val_f1_m: 0.1953\n",
      "Epoch 4/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 2.1758 - accuracy: 0.3653 - precision_m: 0.7112 - recall_m: 0.1222 - f1_m: 0.2075\n",
      "Epoch 4: val_loss improved from 2.24729 to 2.18947, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.3636 | Precision: 0.7010 | Recall: 0.1250 | F1: 0.2105\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.1760 - accuracy: 0.3653 - precision_m: 0.7111 - recall_m: 0.1223 - f1_m: 0.2077 - val_loss: 2.1895 - val_accuracy: 0.3636 - val_precision_m: 0.7010 - val_recall_m: 0.1250 - val_f1_m: 0.2105\n",
      "Epoch 5/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 2.1106 - accuracy: 0.3834 - precision_m: 0.7175 - recall_m: 0.1431 - f1_m: 0.2375\n",
      "Epoch 5: val_loss improved from 2.18947 to 2.13502, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.3772 | Precision: 0.6977 | Recall: 0.1451 | F1: 0.2384\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.1106 - accuracy: 0.3834 - precision_m: 0.7175 - recall_m: 0.1431 - f1_m: 0.2375 - val_loss: 2.1350 - val_accuracy: 0.3772 - val_precision_m: 0.6977 - val_recall_m: 0.1451 - val_f1_m: 0.2384\n",
      "Epoch 6/30\n",
      "602/609 [============================>.] - ETA: 0s - loss: 2.0411 - accuracy: 0.4023 - precision_m: 0.7227 - recall_m: 0.1647 - f1_m: 0.2671\n",
      "Epoch 6: val_loss improved from 2.13502 to 2.05538, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.3974 | Precision: 0.7172 | Recall: 0.1737 | F1: 0.2782\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 2.0407 - accuracy: 0.4026 - precision_m: 0.7224 - recall_m: 0.1649 - f1_m: 0.2673 - val_loss: 2.0554 - val_accuracy: 0.3974 - val_precision_m: 0.7172 - val_recall_m: 0.1737 - val_f1_m: 0.2782\n",
      "Epoch 7/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.9764 - accuracy: 0.4207 - precision_m: 0.7270 - recall_m: 0.1875 - f1_m: 0.2968\n",
      "Epoch 7: val_loss improved from 2.05538 to 2.01081, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.4146 | Precision: 0.7092 | Recall: 0.1967 | F1: 0.3061\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9764 - accuracy: 0.4207 - precision_m: 0.7268 - recall_m: 0.1875 - f1_m: 0.2968 - val_loss: 2.0108 - val_accuracy: 0.4146 - val_precision_m: 0.7092 - val_recall_m: 0.1967 - val_f1_m: 0.3061\n",
      "Epoch 8/30\n",
      "602/609 [============================>.] - ETA: 0s - loss: 1.9323 - accuracy: 0.4326 - precision_m: 0.7295 - recall_m: 0.2030 - f1_m: 0.3166\n",
      "Epoch 8: val_loss improved from 2.01081 to 1.98191, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.4204 | Precision: 0.6947 | Recall: 0.2064 | F1: 0.3166\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.9316 - accuracy: 0.4328 - precision_m: 0.7300 - recall_m: 0.2034 - f1_m: 0.3171 - val_loss: 1.9819 - val_accuracy: 0.4204 - val_precision_m: 0.6947 - val_recall_m: 0.2064 - val_f1_m: 0.3166\n",
      "Epoch 9/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.8979 - accuracy: 0.4411 - precision_m: 0.7303 - recall_m: 0.2148 - f1_m: 0.3308\n",
      "Epoch 9: val_loss improved from 1.98191 to 1.94979, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.4312 | Precision: 0.7118 | Recall: 0.2057 | F1: 0.3175\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8977 - accuracy: 0.4411 - precision_m: 0.7302 - recall_m: 0.2149 - f1_m: 0.3309 - val_loss: 1.9498 - val_accuracy: 0.4312 - val_precision_m: 0.7118 - val_recall_m: 0.2057 - val_f1_m: 0.3175\n",
      "Epoch 10/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.8766 - accuracy: 0.4492 - precision_m: 0.7312 - recall_m: 0.2225 - f1_m: 0.3400\n",
      "Epoch 10: val_loss did not improve from 1.94979\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8765 - accuracy: 0.4492 - precision_m: 0.7309 - recall_m: 0.2223 - f1_m: 0.3398 - val_loss: 1.9623 - val_accuracy: 0.4270 - val_precision_m: 0.6896 - val_recall_m: 0.2127 - val_f1_m: 0.3233\n",
      "Epoch 11/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.8531 - accuracy: 0.4568 - precision_m: 0.7315 - recall_m: 0.2304 - f1_m: 0.3492\n",
      "Epoch 11: val_loss improved from 1.94979 to 1.91636, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.4365 | Precision: 0.7026 | Recall: 0.2123 | F1: 0.3243\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8531 - accuracy: 0.4568 - precision_m: 0.7315 - recall_m: 0.2304 - f1_m: 0.3492 - val_loss: 1.9164 - val_accuracy: 0.4365 - val_precision_m: 0.7026 - val_recall_m: 0.2123 - val_f1_m: 0.3243\n",
      "Epoch 12/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.8361 - accuracy: 0.4598 - precision_m: 0.7300 - recall_m: 0.2376 - f1_m: 0.3575\n",
      "Epoch 12: val_loss improved from 1.91636 to 1.91088, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.4381 | Precision: 0.7046 | Recall: 0.2291 | F1: 0.3442\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8363 - accuracy: 0.4598 - precision_m: 0.7297 - recall_m: 0.2376 - f1_m: 0.3574 - val_loss: 1.9109 - val_accuracy: 0.4381 - val_precision_m: 0.7046 - val_recall_m: 0.2291 - val_f1_m: 0.3442\n",
      "Epoch 13/30\n",
      "603/609 [============================>.] - ETA: 0s - loss: 1.8183 - accuracy: 0.4657 - precision_m: 0.7320 - recall_m: 0.2433 - f1_m: 0.3641\n",
      "Epoch 13: val_loss improved from 1.91088 to 1.90922, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 13\n",
      "Accuracy: 0.4398 | Precision: 0.7025 | Recall: 0.2408 | F1: 0.3571\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8185 - accuracy: 0.4656 - precision_m: 0.7320 - recall_m: 0.2433 - f1_m: 0.3641 - val_loss: 1.9092 - val_accuracy: 0.4398 - val_precision_m: 0.7025 - val_recall_m: 0.2408 - val_f1_m: 0.3571\n",
      "Epoch 14/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 1.8088 - accuracy: 0.4677 - precision_m: 0.7339 - recall_m: 0.2484 - f1_m: 0.3700\n",
      "Epoch 14: val_loss improved from 1.90922 to 1.87826, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.4480 | Precision: 0.7028 | Recall: 0.2415 | F1: 0.3579\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.8085 - accuracy: 0.4677 - precision_m: 0.7338 - recall_m: 0.2485 - f1_m: 0.3702 - val_loss: 1.8783 - val_accuracy: 0.4480 - val_precision_m: 0.7028 - val_recall_m: 0.2415 - val_f1_m: 0.3579\n",
      "Epoch 15/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.7971 - accuracy: 0.4703 - precision_m: 0.7335 - recall_m: 0.2524 - f1_m: 0.3745\n",
      "Epoch 15: val_loss improved from 1.87826 to 1.87068, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 15\n",
      "Accuracy: 0.4500 | Precision: 0.6916 | Recall: 0.2375 | F1: 0.3520\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7971 - accuracy: 0.4703 - precision_m: 0.7335 - recall_m: 0.2524 - f1_m: 0.3745 - val_loss: 1.8707 - val_accuracy: 0.4500 - val_precision_m: 0.6916 - val_recall_m: 0.2375 - val_f1_m: 0.3520\n",
      "Epoch 16/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 1.7845 - accuracy: 0.4728 - precision_m: 0.7352 - recall_m: 0.2563 - f1_m: 0.3791\n",
      "Epoch 16: val_loss improved from 1.87068 to 1.85404, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.4611 | Precision: 0.7171 | Recall: 0.2529 | F1: 0.3721\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7846 - accuracy: 0.4729 - precision_m: 0.7351 - recall_m: 0.2562 - f1_m: 0.3789 - val_loss: 1.8540 - val_accuracy: 0.4611 - val_precision_m: 0.7171 - val_recall_m: 0.2529 - val_f1_m: 0.3721\n",
      "Epoch 17/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 1.7735 - accuracy: 0.4763 - precision_m: 0.7355 - recall_m: 0.2621 - f1_m: 0.3854\n",
      "Epoch 17: val_loss did not improve from 1.85404\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7734 - accuracy: 0.4764 - precision_m: 0.7357 - recall_m: 0.2622 - f1_m: 0.3856 - val_loss: 1.8867 - val_accuracy: 0.4473 - val_precision_m: 0.6876 - val_recall_m: 0.2537 - val_f1_m: 0.3694\n",
      "Epoch 18/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.7674 - accuracy: 0.4792 - precision_m: 0.7343 - recall_m: 0.2646 - f1_m: 0.3879\n",
      "Epoch 18: val_loss improved from 1.85404 to 1.85021, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.4636 | Precision: 0.7046 | Recall: 0.2540 | F1: 0.3718\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7676 - accuracy: 0.4792 - precision_m: 0.7341 - recall_m: 0.2645 - f1_m: 0.3878 - val_loss: 1.8502 - val_accuracy: 0.4636 - val_precision_m: 0.7046 - val_recall_m: 0.2540 - val_f1_m: 0.3718\n",
      "Epoch 19/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.7630 - accuracy: 0.4813 - precision_m: 0.7338 - recall_m: 0.2687 - f1_m: 0.3922\n",
      "Epoch 19: val_loss did not improve from 1.85021\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7626 - accuracy: 0.4813 - precision_m: 0.7341 - recall_m: 0.2689 - f1_m: 0.3924 - val_loss: 1.8719 - val_accuracy: 0.4534 - val_precision_m: 0.6825 - val_recall_m: 0.2524 - val_f1_m: 0.3670\n",
      "Epoch 20/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.7494 - accuracy: 0.4844 - precision_m: 0.7370 - recall_m: 0.2708 - f1_m: 0.3948\n",
      "Epoch 20: val_loss did not improve from 1.85021\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7492 - accuracy: 0.4844 - precision_m: 0.7370 - recall_m: 0.2709 - f1_m: 0.3949 - val_loss: 1.8586 - val_accuracy: 0.4591 - val_precision_m: 0.6832 - val_recall_m: 0.2592 - val_f1_m: 0.3745\n",
      "Epoch 21/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.7409 - accuracy: 0.4875 - precision_m: 0.7340 - recall_m: 0.2762 - f1_m: 0.4003\n",
      "Epoch 21: val_loss did not improve from 1.85021\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7409 - accuracy: 0.4875 - precision_m: 0.7340 - recall_m: 0.2762 - f1_m: 0.4003 - val_loss: 1.8520 - val_accuracy: 0.4635 - val_precision_m: 0.6970 - val_recall_m: 0.2654 - val_f1_m: 0.3828\n",
      "Epoch 22/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.7328 - accuracy: 0.4900 - precision_m: 0.7357 - recall_m: 0.2806 - f1_m: 0.4051\n",
      "Epoch 22: val_loss did not improve from 1.85021\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7330 - accuracy: 0.4901 - precision_m: 0.7359 - recall_m: 0.2805 - f1_m: 0.4050 - val_loss: 1.8861 - val_accuracy: 0.4486 - val_precision_m: 0.6881 - val_recall_m: 0.2458 - val_f1_m: 0.3608\n",
      "Epoch 23/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.7344 - accuracy: 0.4881 - precision_m: 0.7340 - recall_m: 0.2795 - f1_m: 0.4038\n",
      "Epoch 23: val_loss did not improve from 1.85021\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7346 - accuracy: 0.4880 - precision_m: 0.7338 - recall_m: 0.2796 - f1_m: 0.4038 - val_loss: 1.8539 - val_accuracy: 0.4610 - val_precision_m: 0.6945 - val_recall_m: 0.2715 - val_f1_m: 0.3890\n",
      "Epoch 24/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.7255 - accuracy: 0.4910 - precision_m: 0.7361 - recall_m: 0.2824 - f1_m: 0.4072\n",
      "Epoch 24: val_loss improved from 1.85021 to 1.81361, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 24\n",
      "Accuracy: 0.4712 | Precision: 0.7069 | Recall: 0.2641 | F1: 0.3832\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7255 - accuracy: 0.4910 - precision_m: 0.7361 - recall_m: 0.2824 - f1_m: 0.4072 - val_loss: 1.8136 - val_accuracy: 0.4712 - val_precision_m: 0.7069 - val_recall_m: 0.2641 - val_f1_m: 0.3832\n",
      "Epoch 25/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.7211 - accuracy: 0.4945 - precision_m: 0.7372 - recall_m: 0.2857 - f1_m: 0.4107\n",
      "Epoch 25: val_loss did not improve from 1.81361\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7209 - accuracy: 0.4945 - precision_m: 0.7371 - recall_m: 0.2856 - f1_m: 0.4106 - val_loss: 1.8261 - val_accuracy: 0.4635 - val_precision_m: 0.6983 - val_recall_m: 0.2715 - val_f1_m: 0.3899\n",
      "Epoch 26/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.7130 - accuracy: 0.4948 - precision_m: 0.7397 - recall_m: 0.2891 - f1_m: 0.4147\n",
      "Epoch 26: val_loss did not improve from 1.81361\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7131 - accuracy: 0.4948 - precision_m: 0.7396 - recall_m: 0.2890 - f1_m: 0.4147 - val_loss: 1.8270 - val_accuracy: 0.4659 - val_precision_m: 0.6946 - val_recall_m: 0.2717 - val_f1_m: 0.3892\n",
      "Epoch 27/30\n",
      "603/609 [============================>.] - ETA: 0s - loss: 1.7111 - accuracy: 0.4973 - precision_m: 0.7373 - recall_m: 0.2906 - f1_m: 0.4159\n",
      "Epoch 27: val_loss did not improve from 1.81361\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7116 - accuracy: 0.4972 - precision_m: 0.7369 - recall_m: 0.2903 - f1_m: 0.4156 - val_loss: 1.8227 - val_accuracy: 0.4669 - val_precision_m: 0.6993 - val_recall_m: 0.2592 - val_f1_m: 0.3770\n",
      "Epoch 28/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.7048 - accuracy: 0.4977 - precision_m: 0.7391 - recall_m: 0.2913 - f1_m: 0.4169\n",
      "Epoch 28: val_loss did not improve from 1.81361\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7048 - accuracy: 0.4977 - precision_m: 0.7391 - recall_m: 0.2913 - f1_m: 0.4169 - val_loss: 1.8232 - val_accuracy: 0.4700 - val_precision_m: 0.6944 - val_recall_m: 0.2789 - val_f1_m: 0.3971\n",
      "Epoch 29/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.7017 - accuracy: 0.4996 - precision_m: 0.7373 - recall_m: 0.2939 - f1_m: 0.4193\n",
      "Epoch 29: val_loss did not improve from 1.81361\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.7017 - accuracy: 0.4996 - precision_m: 0.7373 - recall_m: 0.2939 - f1_m: 0.4193 - val_loss: 1.8150 - val_accuracy: 0.4711 - val_precision_m: 0.6970 - val_recall_m: 0.2723 - val_f1_m: 0.3902\n",
      "Epoch 30/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.6977 - accuracy: 0.5005 - precision_m: 0.7379 - recall_m: 0.2951 - f1_m: 0.4206\n",
      "Epoch 30: val_loss improved from 1.81361 to 1.81010, saving model to trained_models/model_1_fold_9_best.h5\n",
      "609/609 [==============================] - 4s 7ms/step - loss: 1.6972 - accuracy: 0.5007 - precision_m: 0.7377 - recall_m: 0.2952 - f1_m: 0.4207 - val_loss: 1.8101 - val_accuracy: 0.4711 - val_precision_m: 0.7050 - val_recall_m: 0.2729 - val_f1_m: 0.3922\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 131.7 seconds (2.2 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 72.5%\n",
      "  Usage (max):  84.0%\n",
      "  Frequency:    3977 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 84.5%\n",
      "  Usage (max):  92.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  10.9%\n",
      "  Usage (max):   17.0%\n",
      "  Memory (mean): 580 MB\n",
      "  Memory (max):  611 MB\n",
      "  Power (mean):  16.1 W\n",
      "  Power (max):   17.2 W\n",
      "  Energy used:   0.590 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 RESULTS\n",
      "================================================================================\n",
      "Validation - Loss: 1.8101, Acc: 47.11%\n",
      "Test       - Loss: 1.8114, Acc: 47.37%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 10 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77991, Val=8318, Test=7389\n",
      "Epoch 1/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 2.9740 - accuracy: 0.1697 - precision_m: 0.2710 - recall_m: 0.0102 - f1_m: 0.0193\n",
      "Epoch 1: val_loss improved from inf to 2.45726, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2840 | Precision: 0.6326 | Recall: 0.0519 | F1: 0.0949\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 5s 7ms/step - loss: 2.9739 - accuracy: 0.1697 - precision_m: 0.2722 - recall_m: 0.0103 - f1_m: 0.0195 - val_loss: 2.4573 - val_accuracy: 0.2840 - val_precision_m: 0.6326 - val_recall_m: 0.0519 - val_f1_m: 0.0949\n",
      "Epoch 2/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 2.3304 - accuracy: 0.3188 - precision_m: 0.6769 - recall_m: 0.0766 - f1_m: 0.1364\n",
      "Epoch 2: val_loss improved from 2.45726 to 2.25733, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3454 | Precision: 0.7109 | Recall: 0.0913 | F1: 0.1605\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.3304 - accuracy: 0.3188 - precision_m: 0.6769 - recall_m: 0.0766 - f1_m: 0.1364 - val_loss: 2.2573 - val_accuracy: 0.3454 - val_precision_m: 0.7109 - val_recall_m: 0.0913 - val_f1_m: 0.1605\n",
      "Epoch 3/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 2.2136 - accuracy: 0.3544 - precision_m: 0.7009 - recall_m: 0.1101 - f1_m: 0.1891\n",
      "Epoch 3: val_loss improved from 2.25733 to 2.19973, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3627 | Precision: 0.7212 | Recall: 0.1115 | F1: 0.1915\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.2129 - accuracy: 0.3546 - precision_m: 0.7011 - recall_m: 0.1103 - f1_m: 0.1895 - val_loss: 2.1997 - val_accuracy: 0.3627 - val_precision_m: 0.7212 - val_recall_m: 0.1115 - val_f1_m: 0.1915\n",
      "Epoch 4/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.1395 - accuracy: 0.3753 - precision_m: 0.7111 - recall_m: 0.1296 - f1_m: 0.2182\n",
      "Epoch 4: val_loss improved from 2.19973 to 2.13807, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.3799 | Precision: 0.7006 | Recall: 0.1376 | F1: 0.2283\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.1393 - accuracy: 0.3754 - precision_m: 0.7118 - recall_m: 0.1297 - f1_m: 0.2184 - val_loss: 2.1381 - val_accuracy: 0.3799 - val_precision_m: 0.7006 - val_recall_m: 0.1376 - val_f1_m: 0.2283\n",
      "Epoch 5/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 2.0738 - accuracy: 0.3930 - precision_m: 0.7137 - recall_m: 0.1472 - f1_m: 0.2430\n",
      "Epoch 5: val_loss improved from 2.13807 to 2.07369, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.3910 | Precision: 0.7091 | Recall: 0.1478 | F1: 0.2424\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.0739 - accuracy: 0.3930 - precision_m: 0.7139 - recall_m: 0.1472 - f1_m: 0.2431 - val_loss: 2.0737 - val_accuracy: 0.3910 - val_precision_m: 0.7091 - val_recall_m: 0.1478 - val_f1_m: 0.2424\n",
      "Epoch 6/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.0191 - accuracy: 0.4094 - precision_m: 0.7166 - recall_m: 0.1622 - f1_m: 0.2634\n",
      "Epoch 6: val_loss improved from 2.07369 to 2.06080, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.4014 | Precision: 0.6960 | Recall: 0.1721 | F1: 0.2739\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 2.0181 - accuracy: 0.4096 - precision_m: 0.7169 - recall_m: 0.1626 - f1_m: 0.2640 - val_loss: 2.0608 - val_accuracy: 0.4014 - val_precision_m: 0.6960 - val_recall_m: 0.1721 - val_f1_m: 0.2739\n",
      "Epoch 7/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.9577 - accuracy: 0.4259 - precision_m: 0.7233 - recall_m: 0.1862 - f1_m: 0.2949\n",
      "Epoch 7: val_loss improved from 2.06080 to 1.98295, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.4233 | Precision: 0.7183 | Recall: 0.1913 | F1: 0.3003\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.9572 - accuracy: 0.4260 - precision_m: 0.7229 - recall_m: 0.1863 - f1_m: 0.2950 - val_loss: 1.9830 - val_accuracy: 0.4233 - val_precision_m: 0.7183 - val_recall_m: 0.1913 - val_f1_m: 0.3003\n",
      "Epoch 8/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.9046 - accuracy: 0.4396 - precision_m: 0.7242 - recall_m: 0.2038 - f1_m: 0.3168\n",
      "Epoch 8: val_loss improved from 1.98295 to 1.94747, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.4304 | Precision: 0.7161 | Recall: 0.2027 | F1: 0.3140\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.9046 - accuracy: 0.4396 - precision_m: 0.7243 - recall_m: 0.2039 - f1_m: 0.3169 - val_loss: 1.9475 - val_accuracy: 0.4304 - val_precision_m: 0.7161 - val_recall_m: 0.2027 - val_f1_m: 0.3140\n",
      "Epoch 9/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.8656 - accuracy: 0.4499 - precision_m: 0.7303 - recall_m: 0.2191 - f1_m: 0.3360\n",
      "Epoch 9: val_loss improved from 1.94747 to 1.92220, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.4363 | Precision: 0.7209 | Recall: 0.2133 | F1: 0.3273\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.8663 - accuracy: 0.4497 - precision_m: 0.7299 - recall_m: 0.2190 - f1_m: 0.3358 - val_loss: 1.9222 - val_accuracy: 0.4363 - val_precision_m: 0.7209 - val_recall_m: 0.2133 - val_f1_m: 0.3273\n",
      "Epoch 10/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 1.8446 - accuracy: 0.4540 - precision_m: 0.7276 - recall_m: 0.2264 - f1_m: 0.3442\n",
      "Epoch 10: val_loss improved from 1.92220 to 1.90960, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.4368 | Precision: 0.7100 | Recall: 0.2223 | F1: 0.3364\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.8446 - accuracy: 0.4540 - precision_m: 0.7271 - recall_m: 0.2263 - f1_m: 0.3440 - val_loss: 1.9096 - val_accuracy: 0.4368 - val_precision_m: 0.7100 - val_recall_m: 0.2223 - val_f1_m: 0.3364\n",
      "Epoch 11/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 1.8172 - accuracy: 0.4634 - precision_m: 0.7280 - recall_m: 0.2354 - f1_m: 0.3546\n",
      "Epoch 11: val_loss improved from 1.90960 to 1.90479, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.4422 | Precision: 0.7182 | Recall: 0.2292 | F1: 0.3455\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.8171 - accuracy: 0.4634 - precision_m: 0.7281 - recall_m: 0.2354 - f1_m: 0.3547 - val_loss: 1.9048 - val_accuracy: 0.4422 - val_precision_m: 0.7182 - val_recall_m: 0.2292 - val_f1_m: 0.3455\n",
      "Epoch 12/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.8048 - accuracy: 0.4665 - precision_m: 0.7280 - recall_m: 0.2431 - f1_m: 0.3634\n",
      "Epoch 12: val_loss improved from 1.90479 to 1.90290, saving model to trained_models/model_1_fold_10_best.h5\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.8045 - accuracy: 0.4666 - precision_m: 0.7282 - recall_m: 0.2433 - f1_m: 0.3637 - val_loss: 1.9029 - val_accuracy: 0.4383 - val_precision_m: 0.7046 - val_recall_m: 0.2312 - val_f1_m: 0.3464\n",
      "Epoch 13/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 1.7946 - accuracy: 0.4688 - precision_m: 0.7308 - recall_m: 0.2486 - f1_m: 0.3700\n",
      "Epoch 13: val_loss improved from 1.90290 to 1.87993, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 13\n",
      "Accuracy: 0.4482 | Precision: 0.7024 | Recall: 0.2431 | F1: 0.3593\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7954 - accuracy: 0.4686 - precision_m: 0.7304 - recall_m: 0.2483 - f1_m: 0.3696 - val_loss: 1.8799 - val_accuracy: 0.4482 - val_precision_m: 0.7024 - val_recall_m: 0.2431 - val_f1_m: 0.3593\n",
      "Epoch 14/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.7825 - accuracy: 0.4722 - precision_m: 0.7281 - recall_m: 0.2538 - f1_m: 0.3753\n",
      "Epoch 14: val_loss did not improve from 1.87993\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7832 - accuracy: 0.4722 - precision_m: 0.7277 - recall_m: 0.2537 - f1_m: 0.3751 - val_loss: 1.8805 - val_accuracy: 0.4472 - val_precision_m: 0.7176 - val_recall_m: 0.2306 - val_f1_m: 0.3472\n",
      "Epoch 15/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.7715 - accuracy: 0.4752 - precision_m: 0.7300 - recall_m: 0.2570 - f1_m: 0.3791\n",
      "Epoch 15: val_loss did not improve from 1.87993\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7714 - accuracy: 0.4752 - precision_m: 0.7301 - recall_m: 0.2570 - f1_m: 0.3792 - val_loss: 1.9142 - val_accuracy: 0.4388 - val_precision_m: 0.6918 - val_recall_m: 0.2359 - val_f1_m: 0.3501\n",
      "Epoch 16/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 1.7591 - accuracy: 0.4781 - precision_m: 0.7317 - recall_m: 0.2615 - f1_m: 0.3842\n",
      "Epoch 16: val_loss improved from 1.87993 to 1.85760, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.4543 | Precision: 0.7011 | Recall: 0.2539 | F1: 0.3713\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7594 - accuracy: 0.4781 - precision_m: 0.7319 - recall_m: 0.2616 - f1_m: 0.3844 - val_loss: 1.8576 - val_accuracy: 0.4543 - val_precision_m: 0.7011 - val_recall_m: 0.2539 - val_f1_m: 0.3713\n",
      "Epoch 17/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.7494 - accuracy: 0.4804 - precision_m: 0.7315 - recall_m: 0.2664 - f1_m: 0.3895\n",
      "Epoch 17: val_loss improved from 1.85760 to 1.85719, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.4546 | Precision: 0.7123 | Recall: 0.2508 | F1: 0.3689\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7505 - accuracy: 0.4802 - precision_m: 0.7312 - recall_m: 0.2662 - f1_m: 0.3892 - val_loss: 1.8572 - val_accuracy: 0.4546 - val_precision_m: 0.7123 - val_recall_m: 0.2508 - val_f1_m: 0.3689\n",
      "Epoch 18/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.7476 - accuracy: 0.4817 - precision_m: 0.7326 - recall_m: 0.2687 - f1_m: 0.3921\n",
      "Epoch 18: val_loss did not improve from 1.85719\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7469 - accuracy: 0.4817 - precision_m: 0.7328 - recall_m: 0.2687 - f1_m: 0.3922 - val_loss: 1.8623 - val_accuracy: 0.4528 - val_precision_m: 0.6907 - val_recall_m: 0.2531 - val_f1_m: 0.3686\n",
      "Epoch 19/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.7350 - accuracy: 0.4863 - precision_m: 0.7377 - recall_m: 0.2741 - f1_m: 0.3986\n",
      "Epoch 19: val_loss improved from 1.85719 to 1.84046, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 19\n",
      "Accuracy: 0.4635 | Precision: 0.6980 | Recall: 0.2604 | F1: 0.3776\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7349 - accuracy: 0.4863 - precision_m: 0.7377 - recall_m: 0.2741 - f1_m: 0.3986 - val_loss: 1.8405 - val_accuracy: 0.4635 - val_precision_m: 0.6980 - val_recall_m: 0.2604 - val_f1_m: 0.3776\n",
      "Epoch 20/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.7327 - accuracy: 0.4852 - precision_m: 0.7349 - recall_m: 0.2751 - f1_m: 0.3993\n",
      "Epoch 20: val_loss improved from 1.84046 to 1.82876, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 20\n",
      "Accuracy: 0.4649 | Precision: 0.7021 | Recall: 0.2605 | F1: 0.3784\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7329 - accuracy: 0.4851 - precision_m: 0.7352 - recall_m: 0.2752 - f1_m: 0.3995 - val_loss: 1.8288 - val_accuracy: 0.4649 - val_precision_m: 0.7021 - val_recall_m: 0.2605 - val_f1_m: 0.3784\n",
      "Epoch 21/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.7213 - accuracy: 0.4893 - precision_m: 0.7391 - recall_m: 0.2800 - f1_m: 0.4052\n",
      "Epoch 21: val_loss improved from 1.82876 to 1.82308, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 21\n",
      "Accuracy: 0.4661 | Precision: 0.6993 | Recall: 0.2619 | F1: 0.3790\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7211 - accuracy: 0.4896 - precision_m: 0.7388 - recall_m: 0.2799 - f1_m: 0.4050 - val_loss: 1.8231 - val_accuracy: 0.4661 - val_precision_m: 0.6993 - val_recall_m: 0.2619 - val_f1_m: 0.3790\n",
      "Epoch 22/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.7193 - accuracy: 0.4913 - precision_m: 0.7356 - recall_m: 0.2817 - f1_m: 0.4062\n",
      "Epoch 22: val_loss improved from 1.82308 to 1.81310, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 22\n",
      "Accuracy: 0.4731 | Precision: 0.6999 | Recall: 0.2690 | F1: 0.3866\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7194 - accuracy: 0.4912 - precision_m: 0.7356 - recall_m: 0.2817 - f1_m: 0.4062 - val_loss: 1.8131 - val_accuracy: 0.4731 - val_precision_m: 0.6999 - val_recall_m: 0.2690 - val_f1_m: 0.3866\n",
      "Epoch 23/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.7104 - accuracy: 0.4922 - precision_m: 0.7383 - recall_m: 0.2848 - f1_m: 0.4100\n",
      "Epoch 23: val_loss did not improve from 1.81310\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7105 - accuracy: 0.4922 - precision_m: 0.7380 - recall_m: 0.2846 - f1_m: 0.4097 - val_loss: 1.8178 - val_accuracy: 0.4648 - val_precision_m: 0.6979 - val_recall_m: 0.2688 - val_f1_m: 0.3864\n",
      "Epoch 24/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.7050 - accuracy: 0.4938 - precision_m: 0.7367 - recall_m: 0.2867 - f1_m: 0.4118\n",
      "Epoch 24: val_loss did not improve from 1.81310\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7052 - accuracy: 0.4937 - precision_m: 0.7366 - recall_m: 0.2866 - f1_m: 0.4116 - val_loss: 1.8211 - val_accuracy: 0.4649 - val_precision_m: 0.6948 - val_recall_m: 0.2714 - val_f1_m: 0.3886\n",
      "Epoch 25/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.6983 - accuracy: 0.4958 - precision_m: 0.7369 - recall_m: 0.2888 - f1_m: 0.4140\n",
      "Epoch 25: val_loss improved from 1.81310 to 1.80793, saving model to trained_models/model_1_fold_10_best.h5\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.6982 - accuracy: 0.4958 - precision_m: 0.7371 - recall_m: 0.2888 - f1_m: 0.4140 - val_loss: 1.8079 - val_accuracy: 0.4667 - val_precision_m: 0.6977 - val_recall_m: 0.2715 - val_f1_m: 0.3891\n",
      "Epoch 26/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.7001 - accuracy: 0.4954 - precision_m: 0.7348 - recall_m: 0.2911 - f1_m: 0.4159\n",
      "Epoch 26: val_loss did not improve from 1.80793\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.7008 - accuracy: 0.4951 - precision_m: 0.7344 - recall_m: 0.2908 - f1_m: 0.4155 - val_loss: 1.8558 - val_accuracy: 0.4564 - val_precision_m: 0.6888 - val_recall_m: 0.2639 - val_f1_m: 0.3799\n",
      "Epoch 27/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.6947 - accuracy: 0.4970 - precision_m: 0.7355 - recall_m: 0.2924 - f1_m: 0.4174\n",
      "Epoch 27: val_loss improved from 1.80793 to 1.79474, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 27\n",
      "Accuracy: 0.4733 | Precision: 0.7043 | Recall: 0.2848 | F1: 0.4040\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.6949 - accuracy: 0.4969 - precision_m: 0.7352 - recall_m: 0.2922 - f1_m: 0.4172 - val_loss: 1.7947 - val_accuracy: 0.4733 - val_precision_m: 0.7043 - val_recall_m: 0.2848 - val_f1_m: 0.4040\n",
      "Epoch 28/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.6808 - accuracy: 0.5006 - precision_m: 0.7388 - recall_m: 0.2949 - f1_m: 0.4206\n",
      "Epoch 28: val_loss did not improve from 1.79474\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.6809 - accuracy: 0.5006 - precision_m: 0.7386 - recall_m: 0.2949 - f1_m: 0.4205 - val_loss: 1.8118 - val_accuracy: 0.4692 - val_precision_m: 0.6899 - val_recall_m: 0.2847 - val_f1_m: 0.4011\n",
      "Epoch 29/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.6812 - accuracy: 0.4996 - precision_m: 0.7367 - recall_m: 0.2980 - f1_m: 0.4234\n",
      "Epoch 29: val_loss improved from 1.79474 to 1.78893, saving model to trained_models/model_1_fold_10_best.h5\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.6813 - accuracy: 0.4995 - precision_m: 0.7366 - recall_m: 0.2978 - f1_m: 0.4231 - val_loss: 1.7889 - val_accuracy: 0.4707 - val_precision_m: 0.7028 - val_recall_m: 0.2771 - val_f1_m: 0.3959\n",
      "Epoch 30/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.6746 - accuracy: 0.5045 - precision_m: 0.7395 - recall_m: 0.3009 - f1_m: 0.4267\n",
      "Epoch 30: val_loss did not improve from 1.78893\n",
      "610/610 [==============================] - 4s 7ms/step - loss: 1.6745 - accuracy: 0.5045 - precision_m: 0.7393 - recall_m: 0.3007 - f1_m: 0.4265 - val_loss: 1.8039 - val_accuracy: 0.4709 - val_precision_m: 0.6958 - val_recall_m: 0.2762 - val_f1_m: 0.3937\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 131.7 seconds (2.2 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 72.3%\n",
      "  Usage (max):  84.0%\n",
      "  Frequency:    3977 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 85.9%\n",
      "  Usage (max):  87.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  9.5%\n",
      "  Usage (max):   15.0%\n",
      "  Memory (mean): 579 MB\n",
      "  Memory (max):  579 MB\n",
      "  Power (mean):  16.1 W\n",
      "  Power (max):   16.7 W\n",
      "  Energy used:   0.590 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 RESULTS\n",
      "================================================================================\n",
      "Validation - Loss: 1.7889, Acc: 47.07%\n",
      "Test       - Loss: 1.8097, Acc: 46.84%\n",
      "================================================================================\n",
      "\n",
      "Results saved to: results/model_1_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "CROSS-VALIDATION SUMMARY: model_1\n",
      "################################################################################\n",
      "\n",
      "AVERAGE VALIDATION METRICS:\n",
      "  Accuracy:  43.53% ± 9.47%\n",
      "  Precision: 0.6705 ± 0.0922\n",
      "  Recall:    0.2446 ± 0.1010\n",
      "  F1 Score:  0.3479 ± 0.1325\n",
      "\n",
      "AVERAGE TEST METRICS:\n",
      "  Accuracy:  43.80% ± 9.36%\n",
      "  Precision: 0.6357 ± 0.1764\n",
      "  Recall:    0.2455 ± 0.1035\n",
      "  F1 Score:  0.3439 ± 0.1348\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE SUMMARY: model_1\n",
      "================================================================================\n",
      "\n",
      "Total training time: 1303.7 seconds (21.7 minutes)\n",
      "Average CPU usage: 72.5%\n",
      "Average RAM usage: 85.2%\n",
      "Average GPU usage: 10.8%\n",
      "Average GPU power: 19.2 W\n",
      "Total energy consumed: 6.988 Wh (0.006988 kWh)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_1 = train_model_with_metrics(build_model_1, 'model_1', early_stopping_patience=5, monitor_resources=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25128e30-68db-4409-856b-ba241ecb4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'resource_stats' in metrics_1:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESOURCE USAGE - MODEL 1\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_time = sum(s['duration_seconds'] for s in metrics_1['resource_stats']) / 60\n",
    "    print(f\"\\nTotal training time: {total_time:.1f} minutes\")\n",
    "    \n",
    "    if 'gpu_power_mean_w' in metrics_1['resource_stats'][0]:\n",
    "        total_energy = sum(s['gpu_energy_wh'] for s in metrics_1['resource_stats'])\n",
    "        avg_power = np.mean([s['gpu_power_mean_w'] for s in metrics_1['resource_stats']])\n",
    "        print(f\"Average GPU power: {avg_power:.1f} W\")\n",
    "        print(f\"Total energy consumed: {total_energy:.3f} Wh\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43057056-cf92-44e8-9521-1ce593d71abc",
   "metadata": {},
   "source": [
    "## Train Single Model (Memory-Constrained Approach)\n",
    "\n",
    "Train one model at a time to avoid RAM exhaustion. Change `model_to_train` to train different architectures:\n",
    "```python\n",
    "model_to_train = ('model_X', build_model_X)  # Replace X with 1-10\n",
    "```\n",
    "\n",
    "To train multiple models automatically Replace the single tuple with a loop:\n",
    "```python\n",
    "models_to_train = [\n",
    "    ('model_1', build_model_1),\n",
    "    ('model_2', build_model_2),\n",
    "    ('model_3', build_model_3)\n",
    "]\n",
    "\n",
    "for model_name, model_builder in models_to_train:\n",
    "    # Training code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f906a2e5-9734-4b73-8fc2-88117232e156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "STARTING TRAINING: model_1\n",
      "################################################################################\n",
      "\n",
      "\n",
      "################################################################################\n",
      "STARTING 10-FOLD CROSS-VALIDATION FOR model_1\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 1 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Permission denied for /sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj. Run with sudo or add permissions.\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77912, Val=8253, Test=7521\n",
      "Epoch 1/30\n",
      "599/609 [============================>.] - ETA: 0s - loss: 3.0667 - accuracy: 0.1250 - precision_m: 0.1609 - recall_m: 0.0026 - f1_m: 0.0050\n",
      "Epoch 1: val_loss improved from inf to 2.77132, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.1876 | Precision: 0.3392 | Recall: 0.0054 | F1: 0.0106\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 6s 4ms/step - loss: 3.0626 - accuracy: 0.1258 - precision_m: 0.1623 - recall_m: 0.0026 - f1_m: 0.0051 - val_loss: 2.7713 - val_accuracy: 0.1876 - val_precision_m: 0.3392 - val_recall_m: 0.0054 - val_f1_m: 0.0106\n",
      "Epoch 2/30\n",
      "603/609 [============================>.] - ETA: 0s - loss: 2.6729 - accuracy: 0.2043 - precision_m: 0.5002 - recall_m: 0.0083 - f1_m: 0.0163\n",
      "Epoch 2: val_loss improved from 2.77132 to 2.64797, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.2182 | Precision: 0.4047 | Recall: 0.0067 | F1: 0.0132\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.6730 - accuracy: 0.2043 - precision_m: 0.5002 - recall_m: 0.0084 - f1_m: 0.0164 - val_loss: 2.6480 - val_accuracy: 0.2182 - val_precision_m: 0.4047 - val_recall_m: 0.0067 - val_f1_m: 0.0132\n",
      "Epoch 3/30\n",
      "592/609 [============================>.] - ETA: 0s - loss: 2.5598 - accuracy: 0.2375 - precision_m: 0.5735 - recall_m: 0.0164 - f1_m: 0.0315\n",
      "Epoch 3: val_loss improved from 2.64797 to 2.53883, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.2600 | Precision: 0.6482 | Recall: 0.0416 | F1: 0.0772\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.5579 - accuracy: 0.2389 - precision_m: 0.5769 - recall_m: 0.0170 - f1_m: 0.0326 - val_loss: 2.5388 - val_accuracy: 0.2600 - val_precision_m: 0.6482 - val_recall_m: 0.0416 - val_f1_m: 0.0772\n",
      "Epoch 4/30\n",
      "603/609 [============================>.] - ETA: 0s - loss: 2.3910 - accuracy: 0.2959 - precision_m: 0.6829 - recall_m: 0.0479 - f1_m: 0.0889\n",
      "Epoch 4: val_loss improved from 2.53883 to 2.39180, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.3033 | Precision: 0.6745 | Recall: 0.0592 | F1: 0.1076\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.3899 - accuracy: 0.2963 - precision_m: 0.6835 - recall_m: 0.0480 - f1_m: 0.0890 - val_loss: 2.3918 - val_accuracy: 0.3033 - val_precision_m: 0.6745 - val_recall_m: 0.0592 - val_f1_m: 0.1076\n",
      "Epoch 5/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 2.2984 - accuracy: 0.3216 - precision_m: 0.6861 - recall_m: 0.0621 - f1_m: 0.1130\n",
      "Epoch 5: val_loss improved from 2.39180 to 2.34594, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.3115 | Precision: 0.6759 | Recall: 0.0744 | F1: 0.1325\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.2985 - accuracy: 0.3215 - precision_m: 0.6850 - recall_m: 0.0621 - f1_m: 0.1129 - val_loss: 2.3459 - val_accuracy: 0.3115 - val_precision_m: 0.6759 - val_recall_m: 0.0744 - val_f1_m: 0.1325\n",
      "Epoch 6/30\n",
      "598/609 [============================>.] - ETA: 0s - loss: 2.2335 - accuracy: 0.3417 - precision_m: 0.6772 - recall_m: 0.0743 - f1_m: 0.1331\n",
      "Epoch 6: val_loss improved from 2.34594 to 2.25703, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.3302 | Precision: 0.6662 | Recall: 0.0804 | F1: 0.1418\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.2323 - accuracy: 0.3419 - precision_m: 0.6770 - recall_m: 0.0746 - f1_m: 0.1335 - val_loss: 2.2570 - val_accuracy: 0.3302 - val_precision_m: 0.6662 - val_recall_m: 0.0804 - val_f1_m: 0.1418\n",
      "Epoch 7/30\n",
      "595/609 [============================>.] - ETA: 0s - loss: 2.1837 - accuracy: 0.3556 - precision_m: 0.6880 - recall_m: 0.0873 - f1_m: 0.1541\n",
      "Epoch 7: val_loss improved from 2.25703 to 2.22965, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.3412 | Precision: 0.6594 | Recall: 0.0854 | F1: 0.1499\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.1836 - accuracy: 0.3558 - precision_m: 0.6874 - recall_m: 0.0874 - f1_m: 0.1542 - val_loss: 2.2296 - val_accuracy: 0.3412 - val_precision_m: 0.6594 - val_recall_m: 0.0854 - val_f1_m: 0.1499\n",
      "Epoch 8/30\n",
      "598/609 [============================>.] - ETA: 0s - loss: 2.1430 - accuracy: 0.3673 - precision_m: 0.6937 - recall_m: 0.0999 - f1_m: 0.1738\n",
      "Epoch 8: val_loss improved from 2.22965 to 2.20774, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.3457 | Precision: 0.6656 | Recall: 0.0936 | F1: 0.1625\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.1430 - accuracy: 0.3672 - precision_m: 0.6944 - recall_m: 0.1000 - f1_m: 0.1739 - val_loss: 2.2077 - val_accuracy: 0.3457 - val_precision_m: 0.6656 - val_recall_m: 0.0936 - val_f1_m: 0.1625\n",
      "Epoch 9/30\n",
      "600/609 [============================>.] - ETA: 0s - loss: 2.1125 - accuracy: 0.3750 - precision_m: 0.6970 - recall_m: 0.1113 - f1_m: 0.1910\n",
      "Epoch 9: val_loss improved from 2.20774 to 2.15366, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.3591 | Precision: 0.6471 | Recall: 0.1067 | F1: 0.1816\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.1118 - accuracy: 0.3751 - precision_m: 0.6972 - recall_m: 0.1112 - f1_m: 0.1907 - val_loss: 2.1537 - val_accuracy: 0.3591 - val_precision_m: 0.6471 - val_recall_m: 0.1067 - val_f1_m: 0.1816\n",
      "Epoch 10/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 2.0889 - accuracy: 0.3786 - precision_m: 0.7006 - recall_m: 0.1190 - f1_m: 0.2025\n",
      "Epoch 10: val_loss improved from 2.15366 to 2.14648, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.3628 | Precision: 0.6656 | Recall: 0.1185 | F1: 0.1994\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0886 - accuracy: 0.3787 - precision_m: 0.7010 - recall_m: 0.1192 - f1_m: 0.2028 - val_loss: 2.1465 - val_accuracy: 0.3628 - val_precision_m: 0.6656 - val_recall_m: 0.1185 - val_f1_m: 0.1994\n",
      "Epoch 11/30\n",
      "592/609 [============================>.] - ETA: 0s - loss: 2.0726 - accuracy: 0.3841 - precision_m: 0.7042 - recall_m: 0.1272 - f1_m: 0.2144\n",
      "Epoch 11: val_loss improved from 2.14648 to 2.12233, saving model to trained_models/model_1_fold_1_best.h5\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0720 - accuracy: 0.3838 - precision_m: 0.7045 - recall_m: 0.1273 - f1_m: 0.2145 - val_loss: 2.1223 - val_accuracy: 0.3619 - val_precision_m: 0.6647 - val_recall_m: 0.1227 - val_f1_m: 0.2056\n",
      "Epoch 12/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 2.0540 - accuracy: 0.3883 - precision_m: 0.7019 - recall_m: 0.1316 - f1_m: 0.2206\n",
      "Epoch 12: val_loss improved from 2.12233 to 2.11714, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.3651 | Precision: 0.6782 | Recall: 0.1332 | F1: 0.2209\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0540 - accuracy: 0.3883 - precision_m: 0.7019 - recall_m: 0.1316 - f1_m: 0.2206 - val_loss: 2.1171 - val_accuracy: 0.3651 - val_precision_m: 0.6782 - val_recall_m: 0.1332 - val_f1_m: 0.2209\n",
      "Epoch 13/30\n",
      "602/609 [============================>.] - ETA: 0s - loss: 2.0433 - accuracy: 0.3908 - precision_m: 0.7056 - recall_m: 0.1372 - f1_m: 0.2287\n",
      "Epoch 13: val_loss improved from 2.11714 to 2.11175, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 13\n",
      "Accuracy: 0.3728 | Precision: 0.6570 | Recall: 0.1344 | F1: 0.2210\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 4ms/step - loss: 2.0426 - accuracy: 0.3910 - precision_m: 0.7058 - recall_m: 0.1372 - f1_m: 0.2287 - val_loss: 2.1118 - val_accuracy: 0.3728 - val_precision_m: 0.6570 - val_recall_m: 0.1344 - val_f1_m: 0.2210\n",
      "Epoch 14/30\n",
      "597/609 [============================>.] - ETA: 0s - loss: 2.0369 - accuracy: 0.3928 - precision_m: 0.7030 - recall_m: 0.1403 - f1_m: 0.2327\n",
      "Epoch 14: val_loss did not improve from 2.11175\n",
      "609/609 [==============================] - 2s 4ms/step - loss: 2.0374 - accuracy: 0.3926 - precision_m: 0.7023 - recall_m: 0.1401 - f1_m: 0.2325 - val_loss: 2.1443 - val_accuracy: 0.3593 - val_precision_m: 0.6200 - val_recall_m: 0.1367 - val_f1_m: 0.2219\n",
      "Epoch 15/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 2.0292 - accuracy: 0.3958 - precision_m: 0.7047 - recall_m: 0.1428 - f1_m: 0.2364\n",
      "Epoch 15: val_loss improved from 2.11175 to 2.09214, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 15\n",
      "Accuracy: 0.3802 | Precision: 0.6572 | Recall: 0.1433 | F1: 0.2329\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 4ms/step - loss: 2.0295 - accuracy: 0.3958 - precision_m: 0.7043 - recall_m: 0.1426 - f1_m: 0.2362 - val_loss: 2.0921 - val_accuracy: 0.3802 - val_precision_m: 0.6572 - val_recall_m: 0.1433 - val_f1_m: 0.2329\n",
      "Epoch 16/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 2.0251 - accuracy: 0.3954 - precision_m: 0.7012 - recall_m: 0.1449 - f1_m: 0.2392\n",
      "Epoch 16: val_loss did not improve from 2.09214\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.3858 | Precision: 0.6722 | Recall: 0.1402 | F1: 0.2298\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 4ms/step - loss: 2.0246 - accuracy: 0.3956 - precision_m: 0.7015 - recall_m: 0.1449 - f1_m: 0.2393 - val_loss: 2.0924 - val_accuracy: 0.3858 - val_precision_m: 0.6722 - val_recall_m: 0.1402 - val_f1_m: 0.2298\n",
      "Epoch 17/30\n",
      "594/609 [============================>.] - ETA: 0s - loss: 2.0183 - accuracy: 0.3985 - precision_m: 0.7036 - recall_m: 0.1476 - f1_m: 0.2429\n",
      "Epoch 17: val_loss did not improve from 2.09214\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0175 - accuracy: 0.3988 - precision_m: 0.7038 - recall_m: 0.1476 - f1_m: 0.2429 - val_loss: 2.0975 - val_accuracy: 0.3778 - val_precision_m: 0.6486 - val_recall_m: 0.1414 - val_f1_m: 0.2303\n",
      "Epoch 18/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 2.0118 - accuracy: 0.3991 - precision_m: 0.7041 - recall_m: 0.1481 - f1_m: 0.2435\n",
      "Epoch 18: val_loss did not improve from 2.09214\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0116 - accuracy: 0.3991 - precision_m: 0.7044 - recall_m: 0.1481 - f1_m: 0.2435 - val_loss: 2.0949 - val_accuracy: 0.3762 - val_precision_m: 0.6751 - val_recall_m: 0.1343 - val_f1_m: 0.2217\n",
      "Epoch 19/30\n",
      "594/609 [============================>.] - ETA: 0s - loss: 2.0059 - accuracy: 0.4015 - precision_m: 0.7048 - recall_m: 0.1509 - f1_m: 0.2474\n",
      "Epoch 19: val_loss improved from 2.09214 to 2.07298, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 19\n",
      "Accuracy: 0.3860 | Precision: 0.6580 | Recall: 0.1466 | F1: 0.2378\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0057 - accuracy: 0.4013 - precision_m: 0.7040 - recall_m: 0.1506 - f1_m: 0.2470 - val_loss: 2.0730 - val_accuracy: 0.3860 - val_precision_m: 0.6580 - val_recall_m: 0.1466 - val_f1_m: 0.2378\n",
      "Epoch 20/30\n",
      "592/609 [============================>.] - ETA: 0s - loss: 2.0038 - accuracy: 0.4014 - precision_m: 0.7026 - recall_m: 0.1526 - f1_m: 0.2496\n",
      "Epoch 20: val_loss did not improve from 2.07298\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0040 - accuracy: 0.4008 - precision_m: 0.7029 - recall_m: 0.1526 - f1_m: 0.2496 - val_loss: 2.0989 - val_accuracy: 0.3774 - val_precision_m: 0.6562 - val_recall_m: 0.1406 - val_f1_m: 0.2297\n",
      "Epoch 21/30\n",
      "598/609 [============================>.] - ETA: 0s - loss: 2.0013 - accuracy: 0.4030 - precision_m: 0.7052 - recall_m: 0.1529 - f1_m: 0.2502\n",
      "Epoch 21: val_loss did not improve from 2.07298\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0013 - accuracy: 0.4028 - precision_m: 0.7049 - recall_m: 0.1529 - f1_m: 0.2502 - val_loss: 2.0788 - val_accuracy: 0.3854 - val_precision_m: 0.6819 - val_recall_m: 0.1481 - val_f1_m: 0.2414\n",
      "Epoch 22/30\n",
      "600/609 [============================>.] - ETA: 0s - loss: 1.9991 - accuracy: 0.4034 - precision_m: 0.7004 - recall_m: 0.1539 - f1_m: 0.2513\n",
      "Epoch 22: val_loss did not improve from 2.07298\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9994 - accuracy: 0.4033 - precision_m: 0.6999 - recall_m: 0.1539 - f1_m: 0.2513 - val_loss: 2.0781 - val_accuracy: 0.3825 - val_precision_m: 0.6797 - val_recall_m: 0.1451 - val_f1_m: 0.2374\n",
      "Epoch 23/30\n",
      "591/609 [============================>.] - ETA: 0s - loss: 1.9954 - accuracy: 0.4053 - precision_m: 0.7016 - recall_m: 0.1550 - f1_m: 0.2528\n",
      "Epoch 23: val_loss did not improve from 2.07298\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9957 - accuracy: 0.4052 - precision_m: 0.7017 - recall_m: 0.1550 - f1_m: 0.2528 - val_loss: 2.1081 - val_accuracy: 0.3744 - val_precision_m: 0.6511 - val_recall_m: 0.1437 - val_f1_m: 0.2332\n",
      "Epoch 24/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.9918 - accuracy: 0.4045 - precision_m: 0.6991 - recall_m: 0.1561 - f1_m: 0.2540\n",
      "Epoch 24: val_loss improved from 2.07298 to 2.06406, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 24\n",
      "Accuracy: 0.3915 | Precision: 0.6664 | Recall: 0.1502 | F1: 0.2431\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9919 - accuracy: 0.4045 - precision_m: 0.6991 - recall_m: 0.1561 - f1_m: 0.2541 - val_loss: 2.0641 - val_accuracy: 0.3915 - val_precision_m: 0.6664 - val_recall_m: 0.1502 - val_f1_m: 0.2431\n",
      "Epoch 25/30\n",
      "597/609 [============================>.] - ETA: 0s - loss: 1.9871 - accuracy: 0.4072 - precision_m: 0.7015 - recall_m: 0.1576 - f1_m: 0.2563\n",
      "Epoch 25: val_loss did not improve from 2.06406\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9873 - accuracy: 0.4072 - precision_m: 0.7021 - recall_m: 0.1575 - f1_m: 0.2562 - val_loss: 2.0874 - val_accuracy: 0.3851 - val_precision_m: 0.6859 - val_recall_m: 0.1382 - val_f1_m: 0.2285\n",
      "Epoch 26/30\n",
      "600/609 [============================>.] - ETA: 0s - loss: 1.9883 - accuracy: 0.4061 - precision_m: 0.7000 - recall_m: 0.1571 - f1_m: 0.2556\n",
      "Epoch 26: val_loss did not improve from 2.06406\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9897 - accuracy: 0.4059 - precision_m: 0.6998 - recall_m: 0.1569 - f1_m: 0.2553 - val_loss: 2.0667 - val_accuracy: 0.3875 - val_precision_m: 0.6585 - val_recall_m: 0.1590 - val_f1_m: 0.2539\n",
      "Epoch 27/30\n",
      "596/609 [============================>.] - ETA: 0s - loss: 1.9878 - accuracy: 0.4063 - precision_m: 0.6989 - recall_m: 0.1580 - f1_m: 0.2567\n",
      "Epoch 27: val_loss improved from 2.06406 to 2.06190, saving model to trained_models/model_1_fold_1_best.h5\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9878 - accuracy: 0.4066 - precision_m: 0.6992 - recall_m: 0.1580 - f1_m: 0.2566 - val_loss: 2.0619 - val_accuracy: 0.3905 - val_precision_m: 0.6742 - val_recall_m: 0.1504 - val_f1_m: 0.2435\n",
      "Epoch 28/30\n",
      "592/609 [============================>.] - ETA: 0s - loss: 1.9862 - accuracy: 0.4072 - precision_m: 0.7020 - recall_m: 0.1587 - f1_m: 0.2577\n",
      "Epoch 28: val_loss did not improve from 2.06190\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 28\n",
      "Accuracy: 0.3945 | Precision: 0.6743 | Recall: 0.1484 | F1: 0.2411\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9857 - accuracy: 0.4070 - precision_m: 0.7013 - recall_m: 0.1588 - f1_m: 0.2578 - val_loss: 2.0766 - val_accuracy: 0.3945 - val_precision_m: 0.6743 - val_recall_m: 0.1484 - val_f1_m: 0.2411\n",
      "Epoch 29/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.9712 - accuracy: 0.4126 - precision_m: 0.7012 - recall_m: 0.1645 - f1_m: 0.2653\n",
      "Epoch 29: val_loss improved from 2.06190 to 2.04392, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 29\n",
      "Accuracy: 0.3951 | Precision: 0.6650 | Recall: 0.1643 | F1: 0.2617\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9707 - accuracy: 0.4127 - precision_m: 0.7017 - recall_m: 0.1645 - f1_m: 0.2654 - val_loss: 2.0439 - val_accuracy: 0.3951 - val_precision_m: 0.6650 - val_recall_m: 0.1643 - val_f1_m: 0.2617\n",
      "Epoch 30/30\n",
      "596/609 [============================>.] - ETA: 0s - loss: 1.9515 - accuracy: 0.4176 - precision_m: 0.7032 - recall_m: 0.1743 - f1_m: 0.2782\n",
      "Epoch 30: val_loss improved from 2.04392 to 2.02776, saving model to trained_models/model_1_fold_1_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 30\n",
      "Accuracy: 0.3962 | Precision: 0.6744 | Recall: 0.1719 | F1: 0.2718\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9505 - accuracy: 0.4182 - precision_m: 0.7043 - recall_m: 0.1748 - f1_m: 0.2790 - val_loss: 2.0278 - val_accuracy: 0.3962 - val_precision_m: 0.6744 - val_recall_m: 0.1719 - val_f1_m: 0.2718\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 64.6 seconds (1.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 33.8%\n",
      "  Usage (max):  72.7%\n",
      "  Frequency:    3987 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 36.8%\n",
      "  Usage (max):  40.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  28.9%\n",
      "  Usage (max):   37.0%\n",
      "  Memory (mean): 1590 MB\n",
      "  Memory (max):  1661 MB\n",
      "  Power (mean):  43.9 W\n",
      "  Power (max):   47.4 W\n",
      "  Energy used:   0.788451 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 RESULTS\n",
      "================================================================================\n",
      "Validation:\n",
      "  Loss:      2.0278\n",
      "  Accuracy:  39.62%\n",
      "  Precision: 0.6744\n",
      "  Recall:    0.1719\n",
      "  F1 Score:  0.2718\n",
      "\n",
      "Test:\n",
      "  Loss:      2.0446\n",
      "  Accuracy:  39.32%\n",
      "  Precision: 0.6476\n",
      "  Recall:    0.1658\n",
      "  F1 Score:  0.2584\n",
      "\n",
      "Resources:\n",
      "  Duration:     64.6s (1.1m)\n",
      "  GPU Power:    43.9W (max: 47.4W)\n",
      "  Energy Used:  0.788Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 2 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Permission denied for /sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj. Run with sudo or add permissions.\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77821, Val=8256, Test=7524\n",
      "Epoch 1/30\n",
      "598/608 [============================>.] - ETA: 0s - loss: 2.8849 - accuracy: 0.1915 - precision_m: 0.4405 - recall_m: 0.0176 - f1_m: 0.0334\n",
      "Epoch 1: val_loss improved from inf to 2.50768, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2816 | Precision: 0.6213 | Recall: 0.0495 | F1: 0.0905\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 3s 3ms/step - loss: 2.8779 - accuracy: 0.1931 - precision_m: 0.4456 - recall_m: 0.0180 - f1_m: 0.0340 - val_loss: 2.5077 - val_accuracy: 0.2816 - val_precision_m: 0.6213 - val_recall_m: 0.0495 - val_f1_m: 0.0905\n",
      "Epoch 2/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 2.3367 - accuracy: 0.3266 - precision_m: 0.6889 - recall_m: 0.0796 - f1_m: 0.1416\n",
      "Epoch 2: val_loss improved from 2.50768 to 2.29335, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3436 | Precision: 0.6969 | Recall: 0.1054 | F1: 0.1811\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3364 - accuracy: 0.3267 - precision_m: 0.6890 - recall_m: 0.0798 - f1_m: 0.1418 - val_loss: 2.2934 - val_accuracy: 0.3436 - val_precision_m: 0.6969 - val_recall_m: 0.1054 - val_f1_m: 0.1811\n",
      "Epoch 3/30\n",
      "604/608 [============================>.] - ETA: 0s - loss: 2.1906 - accuracy: 0.3682 - precision_m: 0.7072 - recall_m: 0.1212 - f1_m: 0.2059\n",
      "Epoch 3: val_loss improved from 2.29335 to 2.19906, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3779 | Precision: 0.6958 | Recall: 0.1227 | F1: 0.2071\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.1901 - accuracy: 0.3684 - precision_m: 0.7073 - recall_m: 0.1213 - f1_m: 0.2061 - val_loss: 2.1991 - val_accuracy: 0.3779 - val_precision_m: 0.6958 - val_recall_m: 0.1227 - val_f1_m: 0.2071\n",
      "Epoch 4/30\n",
      "601/608 [============================>.] - ETA: 0s - loss: 2.0723 - accuracy: 0.4006 - precision_m: 0.7235 - recall_m: 0.1595 - f1_m: 0.2601\n",
      "Epoch 4: val_loss improved from 2.19906 to 2.07878, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.4018 | Precision: 0.7161 | Recall: 0.1708 | F1: 0.2737\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.0721 - accuracy: 0.4010 - precision_m: 0.7240 - recall_m: 0.1597 - f1_m: 0.2605 - val_loss: 2.0788 - val_accuracy: 0.4018 - val_precision_m: 0.7161 - val_recall_m: 0.1708 - val_f1_m: 0.2737\n",
      "Epoch 5/30\n",
      "598/608 [============================>.] - ETA: 0s - loss: 1.9640 - accuracy: 0.4320 - precision_m: 0.7363 - recall_m: 0.1953 - f1_m: 0.3076\n",
      "Epoch 5: val_loss improved from 2.07878 to 2.00462, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.4174 | Precision: 0.7248 | Recall: 0.2031 | F1: 0.3156\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.9633 - accuracy: 0.4323 - precision_m: 0.7357 - recall_m: 0.1956 - f1_m: 0.3079 - val_loss: 2.0046 - val_accuracy: 0.4174 - val_precision_m: 0.7248 - val_recall_m: 0.2031 - val_f1_m: 0.3156\n",
      "Epoch 6/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.8736 - accuracy: 0.4547 - precision_m: 0.7397 - recall_m: 0.2246 - f1_m: 0.3433\n",
      "Epoch 6: val_loss improved from 2.00462 to 1.94726, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.4399 | Precision: 0.7231 | Recall: 0.2238 | F1: 0.3401\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.8737 - accuracy: 0.4546 - precision_m: 0.7396 - recall_m: 0.2246 - f1_m: 0.3433 - val_loss: 1.9473 - val_accuracy: 0.4399 - val_precision_m: 0.7231 - val_recall_m: 0.2238 - val_f1_m: 0.3401\n",
      "Epoch 7/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 1.8133 - accuracy: 0.4710 - precision_m: 0.7469 - recall_m: 0.2476 - f1_m: 0.3707\n",
      "Epoch 7: val_loss improved from 1.94726 to 1.89058, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.4554 | Precision: 0.7239 | Recall: 0.2440 | F1: 0.3631\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.8128 - accuracy: 0.4711 - precision_m: 0.7466 - recall_m: 0.2477 - f1_m: 0.3709 - val_loss: 1.8906 - val_accuracy: 0.4554 - val_precision_m: 0.7239 - val_recall_m: 0.2440 - val_f1_m: 0.3631\n",
      "Epoch 8/30\n",
      "595/608 [============================>.] - ETA: 0s - loss: 1.7661 - accuracy: 0.4838 - precision_m: 0.7477 - recall_m: 0.2660 - f1_m: 0.3912\n",
      "Epoch 8: val_loss improved from 1.89058 to 1.86086, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.4583 | Precision: 0.7432 | Recall: 0.2484 | F1: 0.3707\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.7673 - accuracy: 0.4836 - precision_m: 0.7475 - recall_m: 0.2660 - f1_m: 0.3913 - val_loss: 1.8609 - val_accuracy: 0.4583 - val_precision_m: 0.7432 - val_recall_m: 0.2484 - val_f1_m: 0.3707\n",
      "Epoch 9/30\n",
      "597/608 [============================>.] - ETA: 0s - loss: 1.7345 - accuracy: 0.4928 - precision_m: 0.7498 - recall_m: 0.2787 - f1_m: 0.4053\n",
      "Epoch 9: val_loss improved from 1.86086 to 1.82766, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.4707 | Precision: 0.7510 | Recall: 0.2555 | F1: 0.3794\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.7348 - accuracy: 0.4923 - precision_m: 0.7494 - recall_m: 0.2783 - f1_m: 0.4047 - val_loss: 1.8277 - val_accuracy: 0.4707 - val_precision_m: 0.7510 - val_recall_m: 0.2555 - val_f1_m: 0.3794\n",
      "Epoch 10/30\n",
      "590/608 [============================>.] - ETA: 0s - loss: 1.7095 - accuracy: 0.4988 - precision_m: 0.7504 - recall_m: 0.2905 - f1_m: 0.4179\n",
      "Epoch 10: val_loss did not improve from 1.82766\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.7090 - accuracy: 0.4990 - precision_m: 0.7504 - recall_m: 0.2908 - f1_m: 0.4181 - val_loss: 1.8539 - val_accuracy: 0.4662 - val_precision_m: 0.7151 - val_recall_m: 0.2743 - val_f1_m: 0.3948\n",
      "Epoch 11/30\n",
      "589/608 [============================>.] - ETA: 0s - loss: 1.6864 - accuracy: 0.5054 - precision_m: 0.7499 - recall_m: 0.2992 - f1_m: 0.4267\n",
      "Epoch 11: val_loss improved from 1.82766 to 1.79850, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.4811 | Precision: 0.7416 | Recall: 0.2792 | F1: 0.4040\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.6873 - accuracy: 0.5051 - precision_m: 0.7496 - recall_m: 0.2994 - f1_m: 0.4268 - val_loss: 1.7985 - val_accuracy: 0.4811 - val_precision_m: 0.7416 - val_recall_m: 0.2792 - val_f1_m: 0.4040\n",
      "Epoch 12/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 1.6686 - accuracy: 0.5083 - precision_m: 0.7515 - recall_m: 0.3073 - f1_m: 0.4352\n",
      "Epoch 12: val_loss did not improve from 1.79850\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.4832 | Precision: 0.7137 | Recall: 0.2897 | F1: 0.4108\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.6684 - accuracy: 0.5084 - precision_m: 0.7517 - recall_m: 0.3073 - f1_m: 0.4353 - val_loss: 1.8014 - val_accuracy: 0.4832 - val_precision_m: 0.7137 - val_recall_m: 0.2897 - val_f1_m: 0.4108\n",
      "Epoch 13/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 1.6530 - accuracy: 0.5129 - precision_m: 0.7518 - recall_m: 0.3135 - f1_m: 0.4415\n",
      "Epoch 13: val_loss improved from 1.79850 to 1.75835, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 13\n",
      "Accuracy: 0.4943 | Precision: 0.7350 | Recall: 0.2891 | F1: 0.4133\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.6530 - accuracy: 0.5129 - precision_m: 0.7518 - recall_m: 0.3135 - f1_m: 0.4415 - val_loss: 1.7584 - val_accuracy: 0.4943 - val_precision_m: 0.7350 - val_recall_m: 0.2891 - val_f1_m: 0.4133\n",
      "Epoch 14/30\n",
      "597/608 [============================>.] - ETA: 0s - loss: 1.6408 - accuracy: 0.5161 - precision_m: 0.7552 - recall_m: 0.3191 - f1_m: 0.4475\n",
      "Epoch 14: val_loss did not improve from 1.75835\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.6405 - accuracy: 0.5163 - precision_m: 0.7551 - recall_m: 0.3191 - f1_m: 0.4475 - val_loss: 1.7897 - val_accuracy: 0.4859 - val_precision_m: 0.7224 - val_recall_m: 0.3067 - val_f1_m: 0.4289\n",
      "Epoch 15/30\n",
      "598/608 [============================>.] - ETA: 0s - loss: 1.6309 - accuracy: 0.5171 - precision_m: 0.7521 - recall_m: 0.3253 - f1_m: 0.4530\n",
      "Epoch 15: val_loss did not improve from 1.75835\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.6300 - accuracy: 0.5174 - precision_m: 0.7522 - recall_m: 0.3258 - f1_m: 0.4535 - val_loss: 1.7626 - val_accuracy: 0.4925 - val_precision_m: 0.7211 - val_recall_m: 0.3019 - val_f1_m: 0.4243\n",
      "Epoch 16/30\n",
      "598/608 [============================>.] - ETA: 0s - loss: 1.6169 - accuracy: 0.5219 - precision_m: 0.7514 - recall_m: 0.3299 - f1_m: 0.4574\n",
      "Epoch 16: val_loss improved from 1.75835 to 1.75375, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.4971 | Precision: 0.7316 | Recall: 0.3111 | F1: 0.4354\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.6167 - accuracy: 0.5217 - precision_m: 0.7506 - recall_m: 0.3295 - f1_m: 0.4569 - val_loss: 1.7538 - val_accuracy: 0.4971 - val_precision_m: 0.7316 - val_recall_m: 0.3111 - val_f1_m: 0.4354\n",
      "Epoch 17/30\n",
      "597/608 [============================>.] - ETA: 0s - loss: 1.6086 - accuracy: 0.5234 - precision_m: 0.7566 - recall_m: 0.3346 - f1_m: 0.4630\n",
      "Epoch 17: val_loss improved from 1.75375 to 1.73457, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.5029 | Precision: 0.7362 | Recall: 0.3089 | F1: 0.4339\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.6079 - accuracy: 0.5237 - precision_m: 0.7569 - recall_m: 0.3347 - f1_m: 0.4632 - val_loss: 1.7346 - val_accuracy: 0.5029 - val_precision_m: 0.7362 - val_recall_m: 0.3089 - val_f1_m: 0.4339\n",
      "Epoch 18/30\n",
      "594/608 [============================>.] - ETA: 0s - loss: 1.6016 - accuracy: 0.5254 - precision_m: 0.7533 - recall_m: 0.3380 - f1_m: 0.4657\n",
      "Epoch 18: val_loss did not improve from 1.73457\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.6014 - accuracy: 0.5254 - precision_m: 0.7531 - recall_m: 0.3381 - f1_m: 0.4658 - val_loss: 1.7391 - val_accuracy: 0.5008 - val_precision_m: 0.7346 - val_recall_m: 0.3099 - val_f1_m: 0.4346\n",
      "Epoch 19/30\n",
      "590/608 [============================>.] - ETA: 0s - loss: 1.5887 - accuracy: 0.5300 - precision_m: 0.7566 - recall_m: 0.3419 - f1_m: 0.4700\n",
      "Epoch 19: val_loss improved from 1.73457 to 1.73111, saving model to trained_models/model_1_fold_2_best.h5\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5879 - accuracy: 0.5301 - precision_m: 0.7572 - recall_m: 0.3422 - f1_m: 0.4704 - val_loss: 1.7311 - val_accuracy: 0.5002 - val_precision_m: 0.7321 - val_recall_m: 0.3181 - val_f1_m: 0.4423\n",
      "Epoch 20/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 1.5854 - accuracy: 0.5289 - precision_m: 0.7528 - recall_m: 0.3454 - f1_m: 0.4727\n",
      "Epoch 20: val_loss improved from 1.73111 to 1.72873, saving model to trained_models/model_1_fold_2_best.h5\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5853 - accuracy: 0.5288 - precision_m: 0.7527 - recall_m: 0.3454 - f1_m: 0.4726 - val_loss: 1.7287 - val_accuracy: 0.5006 - val_precision_m: 0.7235 - val_recall_m: 0.3258 - val_f1_m: 0.4478\n",
      "Epoch 21/30\n",
      "605/608 [============================>.] - ETA: 0s - loss: 1.5796 - accuracy: 0.5308 - precision_m: 0.7553 - recall_m: 0.3466 - f1_m: 0.4742\n",
      "Epoch 21: val_loss did not improve from 1.72873\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5798 - accuracy: 0.5307 - precision_m: 0.7551 - recall_m: 0.3464 - f1_m: 0.4740 - val_loss: 1.7323 - val_accuracy: 0.5001 - val_precision_m: 0.7041 - val_recall_m: 0.3282 - val_f1_m: 0.4464\n",
      "Epoch 22/30\n",
      "601/608 [============================>.] - ETA: 0s - loss: 1.5714 - accuracy: 0.5325 - precision_m: 0.7554 - recall_m: 0.3499 - f1_m: 0.4773\n",
      "Epoch 22: val_loss improved from 1.72873 to 1.71816, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 22\n",
      "Accuracy: 0.5050 | Precision: 0.7258 | Recall: 0.3228 | F1: 0.4456\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5715 - accuracy: 0.5322 - precision_m: 0.7551 - recall_m: 0.3497 - f1_m: 0.4771 - val_loss: 1.7182 - val_accuracy: 0.5050 - val_precision_m: 0.7258 - val_recall_m: 0.3228 - val_f1_m: 0.4456\n",
      "Epoch 23/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 1.5683 - accuracy: 0.5338 - precision_m: 0.7540 - recall_m: 0.3517 - f1_m: 0.4787\n",
      "Epoch 23: val_loss did not improve from 1.71816\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 23\n",
      "Accuracy: 0.5074 | Precision: 0.7114 | Recall: 0.3302 | F1: 0.4497\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5685 - accuracy: 0.5337 - precision_m: 0.7539 - recall_m: 0.3516 - f1_m: 0.4786 - val_loss: 1.7217 - val_accuracy: 0.5074 - val_precision_m: 0.7114 - val_recall_m: 0.3302 - val_f1_m: 0.4497\n",
      "Epoch 24/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 1.5618 - accuracy: 0.5354 - precision_m: 0.7559 - recall_m: 0.3545 - f1_m: 0.4817\n",
      "Epoch 24: val_loss improved from 1.71816 to 1.70927, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 24\n",
      "Accuracy: 0.5101 | Precision: 0.7229 | Recall: 0.3292 | F1: 0.4512\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5612 - accuracy: 0.5356 - precision_m: 0.7560 - recall_m: 0.3546 - f1_m: 0.4818 - val_loss: 1.7093 - val_accuracy: 0.5101 - val_precision_m: 0.7229 - val_recall_m: 0.3292 - val_f1_m: 0.4512\n",
      "Epoch 25/30\n",
      "596/608 [============================>.] - ETA: 0s - loss: 1.5570 - accuracy: 0.5376 - precision_m: 0.7565 - recall_m: 0.3592 - f1_m: 0.4862\n",
      "Epoch 25: val_loss did not improve from 1.70927\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5566 - accuracy: 0.5376 - precision_m: 0.7569 - recall_m: 0.3593 - f1_m: 0.4864 - val_loss: 1.7182 - val_accuracy: 0.5101 - val_precision_m: 0.7169 - val_recall_m: 0.3355 - val_f1_m: 0.4555\n",
      "Epoch 26/30\n",
      "592/608 [============================>.] - ETA: 0s - loss: 1.5507 - accuracy: 0.5378 - precision_m: 0.7569 - recall_m: 0.3589 - f1_m: 0.4860\n",
      "Epoch 26: val_loss did not improve from 1.70927\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5507 - accuracy: 0.5378 - precision_m: 0.7562 - recall_m: 0.3586 - f1_m: 0.4856 - val_loss: 1.7104 - val_accuracy: 0.5057 - val_precision_m: 0.7186 - val_recall_m: 0.3379 - val_f1_m: 0.4582\n",
      "Epoch 27/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 1.5467 - accuracy: 0.5381 - precision_m: 0.7551 - recall_m: 0.3603 - f1_m: 0.4869\n",
      "Epoch 27: val_loss improved from 1.70927 to 1.67987, saving model to trained_models/model_1_fold_2_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 27\n",
      "Accuracy: 0.5197 | Precision: 0.7318 | Recall: 0.3482 | F1: 0.4707\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5467 - accuracy: 0.5381 - precision_m: 0.7551 - recall_m: 0.3603 - f1_m: 0.4869 - val_loss: 1.6799 - val_accuracy: 0.5197 - val_precision_m: 0.7318 - val_recall_m: 0.3482 - val_f1_m: 0.4707\n",
      "Epoch 28/30\n",
      "596/608 [============================>.] - ETA: 0s - loss: 1.5403 - accuracy: 0.5424 - precision_m: 0.7584 - recall_m: 0.3658 - f1_m: 0.4926\n",
      "Epoch 28: val_loss did not improve from 1.67987\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5404 - accuracy: 0.5424 - precision_m: 0.7583 - recall_m: 0.3658 - f1_m: 0.4926 - val_loss: 1.6818 - val_accuracy: 0.5147 - val_precision_m: 0.7240 - val_recall_m: 0.3475 - val_f1_m: 0.4684\n",
      "Epoch 29/30\n",
      "593/608 [============================>.] - ETA: 0s - loss: 1.5374 - accuracy: 0.5419 - precision_m: 0.7550 - recall_m: 0.3646 - f1_m: 0.4909\n",
      "Epoch 29: val_loss did not improve from 1.67987\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5376 - accuracy: 0.5418 - precision_m: 0.7549 - recall_m: 0.3646 - f1_m: 0.4908 - val_loss: 1.6913 - val_accuracy: 0.5128 - val_precision_m: 0.7221 - val_recall_m: 0.3368 - val_f1_m: 0.4579\n",
      "Epoch 30/30\n",
      "598/608 [============================>.] - ETA: 0s - loss: 1.5347 - accuracy: 0.5422 - precision_m: 0.7556 - recall_m: 0.3664 - f1_m: 0.4926\n",
      "Epoch 30: val_loss did not improve from 1.67987\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 1.5349 - accuracy: 0.5425 - precision_m: 0.7561 - recall_m: 0.3665 - f1_m: 0.4929 - val_loss: 1.7220 - val_accuracy: 0.5071 - val_precision_m: 0.7093 - val_recall_m: 0.3323 - val_f1_m: 0.4515\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 58.6 seconds (1.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 28.4%\n",
      "  Usage (max):  46.8%\n",
      "  Frequency:    3978 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 38.7%\n",
      "  Usage (max):  40.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  29.2%\n",
      "  Usage (max):   34.0%\n",
      "  Memory (mean): 1642 MB\n",
      "  Memory (max):  1647 MB\n",
      "  Power (mean):  44.8 W\n",
      "  Power (max):   46.6 W\n",
      "  Energy used:   0.729787 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 RESULTS\n",
      "================================================================================\n",
      "Validation:\n",
      "  Loss:      1.6799\n",
      "  Accuracy:  51.97%\n",
      "  Precision: 0.7318\n",
      "  Recall:    0.3482\n",
      "  F1 Score:  0.4707\n",
      "\n",
      "Test:\n",
      "  Loss:      1.6912\n",
      "  Accuracy:  51.56%\n",
      "  Precision: 0.7123\n",
      "  Recall:    0.3440\n",
      "  F1 Score:  0.4585\n",
      "\n",
      "Resources:\n",
      "  Duration:     58.6s (1.0m)\n",
      "  GPU Power:    44.8W (max: 46.6W)\n",
      "  Energy Used:  0.730Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 3 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Permission denied for /sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj. Run with sudo or add permissions.\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77973, Val=8263, Test=7405\n",
      "Epoch 1/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 2.7904 - accuracy: 0.2217 - precision_m: 0.4944 - recall_m: 0.0294 - f1_m: 0.0544\n",
      "Epoch 1: val_loss improved from inf to 2.44272, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2977 | Precision: 0.6026 | Recall: 0.0779 | F1: 0.1363\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 3s 3ms/step - loss: 2.7895 - accuracy: 0.2219 - precision_m: 0.4943 - recall_m: 0.0295 - f1_m: 0.0546 - val_loss: 2.4427 - val_accuracy: 0.2977 - val_precision_m: 0.6026 - val_recall_m: 0.0779 - val_f1_m: 0.1363\n",
      "Epoch 2/30\n",
      "599/610 [============================>.] - ETA: 0s - loss: 2.2201 - accuracy: 0.3594 - precision_m: 0.6997 - recall_m: 0.1103 - f1_m: 0.1891\n",
      "Epoch 2: val_loss improved from 2.44272 to 2.23140, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3620 | Precision: 0.6649 | Recall: 0.1401 | F1: 0.2293\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2181 - accuracy: 0.3598 - precision_m: 0.7001 - recall_m: 0.1110 - f1_m: 0.1901 - val_loss: 2.2314 - val_accuracy: 0.3620 - val_precision_m: 0.6649 - val_recall_m: 0.1401 - val_f1_m: 0.2293\n",
      "Epoch 3/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 2.0517 - accuracy: 0.4044 - precision_m: 0.7175 - recall_m: 0.1636 - f1_m: 0.2652\n",
      "Epoch 3: val_loss improved from 2.23140 to 2.07770, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.4047 | Precision: 0.7241 | Recall: 0.1706 | F1: 0.2739\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0521 - accuracy: 0.4044 - precision_m: 0.7177 - recall_m: 0.1641 - f1_m: 0.2659 - val_loss: 2.0777 - val_accuracy: 0.4047 - val_precision_m: 0.7241 - val_recall_m: 0.1706 - val_f1_m: 0.2739\n",
      "Epoch 4/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.9641 - accuracy: 0.4278 - precision_m: 0.7258 - recall_m: 0.1967 - f1_m: 0.3083\n",
      "Epoch 4: val_loss improved from 2.07770 to 2.02871, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.4146 | Precision: 0.7043 | Recall: 0.1865 | F1: 0.2931\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9639 - accuracy: 0.4279 - precision_m: 0.7260 - recall_m: 0.1968 - f1_m: 0.3084 - val_loss: 2.0287 - val_accuracy: 0.4146 - val_precision_m: 0.7043 - val_recall_m: 0.1865 - val_f1_m: 0.2931\n",
      "Epoch 5/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.9099 - accuracy: 0.4438 - precision_m: 0.7277 - recall_m: 0.2163 - f1_m: 0.3323\n",
      "Epoch 5: val_loss improved from 2.02871 to 1.96381, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.4383 | Precision: 0.7178 | Recall: 0.2149 | F1: 0.3288\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9100 - accuracy: 0.4437 - precision_m: 0.7279 - recall_m: 0.2163 - f1_m: 0.3323 - val_loss: 1.9638 - val_accuracy: 0.4383 - val_precision_m: 0.7178 - val_recall_m: 0.2149 - val_f1_m: 0.3288\n",
      "Epoch 6/30\n",
      "594/610 [============================>.] - ETA: 0s - loss: 1.8595 - accuracy: 0.4576 - precision_m: 0.7337 - recall_m: 0.2361 - f1_m: 0.3562\n",
      "Epoch 6: val_loss improved from 1.96381 to 1.92795, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.4445 | Precision: 0.7180 | Recall: 0.2253 | F1: 0.3406\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.8595 - accuracy: 0.4574 - precision_m: 0.7338 - recall_m: 0.2360 - f1_m: 0.3560 - val_loss: 1.9279 - val_accuracy: 0.4445 - val_precision_m: 0.7180 - val_recall_m: 0.2253 - val_f1_m: 0.3406\n",
      "Epoch 7/30\n",
      "597/610 [============================>.] - ETA: 0s - loss: 1.8233 - accuracy: 0.4685 - precision_m: 0.7407 - recall_m: 0.2498 - f1_m: 0.3724\n",
      "Epoch 7: val_loss improved from 1.92795 to 1.91386, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.4506 | Precision: 0.7204 | Recall: 0.2505 | F1: 0.3696\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.8241 - accuracy: 0.4687 - precision_m: 0.7403 - recall_m: 0.2504 - f1_m: 0.3729 - val_loss: 1.9139 - val_accuracy: 0.4506 - val_precision_m: 0.7204 - val_recall_m: 0.2505 - val_f1_m: 0.3696\n",
      "Epoch 8/30\n",
      "596/610 [============================>.] - ETA: 0s - loss: 1.7911 - accuracy: 0.4761 - precision_m: 0.7390 - recall_m: 0.2615 - f1_m: 0.3852\n",
      "Epoch 8: val_loss improved from 1.91386 to 1.89334, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.4572 | Precision: 0.7293 | Recall: 0.2517 | F1: 0.3721\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.7901 - accuracy: 0.4762 - precision_m: 0.7395 - recall_m: 0.2616 - f1_m: 0.3854 - val_loss: 1.8933 - val_accuracy: 0.4572 - val_precision_m: 0.7293 - val_recall_m: 0.2517 - val_f1_m: 0.3721\n",
      "Epoch 9/30\n",
      "596/610 [============================>.] - ETA: 0s - loss: 1.7605 - accuracy: 0.4835 - precision_m: 0.7411 - recall_m: 0.2731 - f1_m: 0.3981\n",
      "Epoch 9: val_loss improved from 1.89334 to 1.87998, saving model to trained_models/model_1_fold_3_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.7611 - accuracy: 0.4834 - precision_m: 0.7412 - recall_m: 0.2735 - f1_m: 0.3984 - val_loss: 1.8800 - val_accuracy: 0.4555 - val_precision_m: 0.7172 - val_recall_m: 0.2570 - val_f1_m: 0.3763\n",
      "Epoch 10/30\n",
      "592/610 [============================>.] - ETA: 0s - loss: 1.7370 - accuracy: 0.4895 - precision_m: 0.7426 - recall_m: 0.2824 - f1_m: 0.4080\n",
      "Epoch 10: val_loss improved from 1.87998 to 1.85133, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.4635 | Precision: 0.7034 | Recall: 0.2751 | F1: 0.3936\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.7390 - accuracy: 0.4888 - precision_m: 0.7429 - recall_m: 0.2819 - f1_m: 0.4075 - val_loss: 1.8513 - val_accuracy: 0.4635 - val_precision_m: 0.7034 - val_recall_m: 0.2751 - val_f1_m: 0.3936\n",
      "Epoch 11/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.7169 - accuracy: 0.4954 - precision_m: 0.7455 - recall_m: 0.2913 - f1_m: 0.4178\n",
      "Epoch 11: val_loss improved from 1.85133 to 1.81938, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.4745 | Precision: 0.7273 | Recall: 0.2727 | F1: 0.3946\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.7170 - accuracy: 0.4954 - precision_m: 0.7456 - recall_m: 0.2913 - f1_m: 0.4178 - val_loss: 1.8194 - val_accuracy: 0.4745 - val_precision_m: 0.7273 - val_recall_m: 0.2727 - val_f1_m: 0.3946\n",
      "Epoch 12/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 1.6969 - accuracy: 0.5023 - precision_m: 0.7457 - recall_m: 0.2995 - f1_m: 0.4263\n",
      "Epoch 12: val_loss improved from 1.81938 to 1.80464, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.4755 | Precision: 0.7344 | Recall: 0.2829 | F1: 0.4063\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.6969 - accuracy: 0.5023 - precision_m: 0.7459 - recall_m: 0.2994 - f1_m: 0.4263 - val_loss: 1.8046 - val_accuracy: 0.4755 - val_precision_m: 0.7344 - val_recall_m: 0.2829 - val_f1_m: 0.4063\n",
      "Epoch 13/30\n",
      "597/610 [============================>.] - ETA: 0s - loss: 1.6784 - accuracy: 0.5046 - precision_m: 0.7470 - recall_m: 0.3061 - f1_m: 0.4332\n",
      "Epoch 13: val_loss improved from 1.80464 to 1.79905, saving model to trained_models/model_1_fold_3_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.6783 - accuracy: 0.5044 - precision_m: 0.7461 - recall_m: 0.3058 - f1_m: 0.4328 - val_loss: 1.7990 - val_accuracy: 0.4733 - val_precision_m: 0.7307 - val_recall_m: 0.2877 - val_f1_m: 0.4107\n",
      "Epoch 14/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 1.6594 - accuracy: 0.5121 - precision_m: 0.7488 - recall_m: 0.3133 - f1_m: 0.4407\n",
      "Epoch 14: val_loss did not improve from 1.79905\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.4786 | Precision: 0.7313 | Recall: 0.2960 | F1: 0.4191\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.6598 - accuracy: 0.5119 - precision_m: 0.7484 - recall_m: 0.3131 - f1_m: 0.4404 - val_loss: 1.8051 - val_accuracy: 0.4786 - val_precision_m: 0.7313 - val_recall_m: 0.2960 - val_f1_m: 0.4191\n",
      "Epoch 15/30\n",
      "596/610 [============================>.] - ETA: 0s - loss: 1.6496 - accuracy: 0.5125 - precision_m: 0.7486 - recall_m: 0.3182 - f1_m: 0.4456\n",
      "Epoch 15: val_loss did not improve from 1.79905\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.6488 - accuracy: 0.5126 - precision_m: 0.7484 - recall_m: 0.3184 - f1_m: 0.4457 - val_loss: 1.8066 - val_accuracy: 0.4782 - val_precision_m: 0.7195 - val_recall_m: 0.2938 - val_f1_m: 0.4155\n",
      "Epoch 16/30\n",
      "601/610 [============================>.] - ETA: 0s - loss: 1.6327 - accuracy: 0.5187 - precision_m: 0.7505 - recall_m: 0.3240 - f1_m: 0.4517\n",
      "Epoch 16: val_loss improved from 1.79905 to 1.74693, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.4986 | Precision: 0.7292 | Recall: 0.3179 | F1: 0.4406\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.6327 - accuracy: 0.5189 - precision_m: 0.7499 - recall_m: 0.3239 - f1_m: 0.4515 - val_loss: 1.7469 - val_accuracy: 0.4986 - val_precision_m: 0.7292 - val_recall_m: 0.3179 - val_f1_m: 0.4406\n",
      "Epoch 17/30\n",
      "599/610 [============================>.] - ETA: 0s - loss: 1.6179 - accuracy: 0.5238 - precision_m: 0.7529 - recall_m: 0.3303 - f1_m: 0.4581\n",
      "Epoch 17: val_loss improved from 1.74693 to 1.73920, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.5005 | Precision: 0.7359 | Recall: 0.3118 | F1: 0.4360\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.6180 - accuracy: 0.5238 - precision_m: 0.7529 - recall_m: 0.3304 - f1_m: 0.4581 - val_loss: 1.7392 - val_accuracy: 0.5005 - val_precision_m: 0.7359 - val_recall_m: 0.3118 - val_f1_m: 0.4360\n",
      "Epoch 18/30\n",
      "601/610 [============================>.] - ETA: 0s - loss: 1.6099 - accuracy: 0.5266 - precision_m: 0.7532 - recall_m: 0.3362 - f1_m: 0.4639\n",
      "Epoch 18: val_loss did not improve from 1.73920\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.6095 - accuracy: 0.5265 - precision_m: 0.7531 - recall_m: 0.3355 - f1_m: 0.4631 - val_loss: 1.7874 - val_accuracy: 0.4812 - val_precision_m: 0.7106 - val_recall_m: 0.3137 - val_f1_m: 0.4334\n",
      "Epoch 19/30\n",
      "596/610 [============================>.] - ETA: 0s - loss: 1.5998 - accuracy: 0.5278 - precision_m: 0.7515 - recall_m: 0.3380 - f1_m: 0.4652\n",
      "Epoch 19: val_loss did not improve from 1.73920\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5990 - accuracy: 0.5282 - precision_m: 0.7517 - recall_m: 0.3384 - f1_m: 0.4657 - val_loss: 1.7405 - val_accuracy: 0.4985 - val_precision_m: 0.7313 - val_recall_m: 0.3237 - val_f1_m: 0.4468\n",
      "Epoch 20/30\n",
      "595/610 [============================>.] - ETA: 0s - loss: 1.5864 - accuracy: 0.5330 - precision_m: 0.7552 - recall_m: 0.3455 - f1_m: 0.4732\n",
      "Epoch 20: val_loss improved from 1.73920 to 1.71794, saving model to trained_models/model_1_fold_3_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5873 - accuracy: 0.5328 - precision_m: 0.7554 - recall_m: 0.3459 - f1_m: 0.4735 - val_loss: 1.7179 - val_accuracy: 0.4986 - val_precision_m: 0.7246 - val_recall_m: 0.3223 - val_f1_m: 0.4446\n",
      "Epoch 21/30\n",
      "599/610 [============================>.] - ETA: 0s - loss: 1.5727 - accuracy: 0.5362 - precision_m: 0.7559 - recall_m: 0.3506 - f1_m: 0.4781\n",
      "Epoch 21: val_loss did not improve from 1.71794\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5732 - accuracy: 0.5363 - precision_m: 0.7563 - recall_m: 0.3510 - f1_m: 0.4786 - val_loss: 1.7281 - val_accuracy: 0.4993 - val_precision_m: 0.7307 - val_recall_m: 0.3292 - val_f1_m: 0.4519\n",
      "Epoch 22/30\n",
      "592/610 [============================>.] - ETA: 0s - loss: 1.5613 - accuracy: 0.5381 - precision_m: 0.7586 - recall_m: 0.3570 - f1_m: 0.4845\n",
      "Epoch 22: val_loss improved from 1.71794 to 1.70490, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 22\n",
      "Accuracy: 0.5068 | Precision: 0.7365 | Recall: 0.3328 | F1: 0.4564\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5600 - accuracy: 0.5384 - precision_m: 0.7595 - recall_m: 0.3572 - f1_m: 0.4849 - val_loss: 1.7049 - val_accuracy: 0.5068 - val_precision_m: 0.7365 - val_recall_m: 0.3328 - val_f1_m: 0.4564\n",
      "Epoch 23/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 1.5510 - accuracy: 0.5426 - precision_m: 0.7598 - recall_m: 0.3592 - f1_m: 0.4869\n",
      "Epoch 23: val_loss did not improve from 1.70490\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5509 - accuracy: 0.5426 - precision_m: 0.7598 - recall_m: 0.3591 - f1_m: 0.4867 - val_loss: 1.7276 - val_accuracy: 0.4970 - val_precision_m: 0.7030 - val_recall_m: 0.3363 - val_f1_m: 0.4533\n",
      "Epoch 24/30\n",
      "593/610 [============================>.] - ETA: 0s - loss: 1.5426 - accuracy: 0.5450 - precision_m: 0.7576 - recall_m: 0.3644 - f1_m: 0.4911\n",
      "Epoch 24: val_loss improved from 1.70490 to 1.70094, saving model to trained_models/model_1_fold_3_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5428 - accuracy: 0.5448 - precision_m: 0.7579 - recall_m: 0.3644 - f1_m: 0.4911 - val_loss: 1.7009 - val_accuracy: 0.5044 - val_precision_m: 0.7239 - val_recall_m: 0.3286 - val_f1_m: 0.4500\n",
      "Epoch 25/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 1.5352 - accuracy: 0.5463 - precision_m: 0.7624 - recall_m: 0.3677 - f1_m: 0.4951\n",
      "Epoch 25: val_loss improved from 1.70094 to 1.66641, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.5170 | Precision: 0.7260 | Recall: 0.3516 | F1: 0.4723\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5348 - accuracy: 0.5464 - precision_m: 0.7624 - recall_m: 0.3675 - f1_m: 0.4949 - val_loss: 1.6664 - val_accuracy: 0.5170 - val_precision_m: 0.7260 - val_recall_m: 0.3516 - val_f1_m: 0.4723\n",
      "Epoch 26/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 1.5274 - accuracy: 0.5490 - precision_m: 0.7596 - recall_m: 0.3705 - f1_m: 0.4972\n",
      "Epoch 26: val_loss did not improve from 1.66641\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5269 - accuracy: 0.5493 - precision_m: 0.7597 - recall_m: 0.3708 - f1_m: 0.4975 - val_loss: 1.6992 - val_accuracy: 0.5043 - val_precision_m: 0.7074 - val_recall_m: 0.3488 - val_f1_m: 0.4657\n",
      "Epoch 27/30\n",
      "599/610 [============================>.] - ETA: 0s - loss: 1.5188 - accuracy: 0.5506 - precision_m: 0.7622 - recall_m: 0.3727 - f1_m: 0.4997\n",
      "Epoch 27: val_loss improved from 1.66641 to 1.65282, saving model to trained_models/model_1_fold_3_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 27\n",
      "Accuracy: 0.5183 | Precision: 0.7340 | Recall: 0.3550 | F1: 0.4766\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5200 - accuracy: 0.5504 - precision_m: 0.7618 - recall_m: 0.3725 - f1_m: 0.4995 - val_loss: 1.6528 - val_accuracy: 0.5183 - val_precision_m: 0.7340 - val_recall_m: 0.3550 - val_f1_m: 0.4766\n",
      "Epoch 28/30\n",
      "596/610 [============================>.] - ETA: 0s - loss: 1.5139 - accuracy: 0.5521 - precision_m: 0.7621 - recall_m: 0.3770 - f1_m: 0.5035\n",
      "Epoch 28: val_loss did not improve from 1.65282\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5137 - accuracy: 0.5522 - precision_m: 0.7619 - recall_m: 0.3767 - f1_m: 0.5032 - val_loss: 1.6765 - val_accuracy: 0.5152 - val_precision_m: 0.7354 - val_recall_m: 0.3470 - val_f1_m: 0.4698\n",
      "Epoch 29/30\n",
      "601/610 [============================>.] - ETA: 0s - loss: 1.5045 - accuracy: 0.5553 - precision_m: 0.7624 - recall_m: 0.3787 - f1_m: 0.5051\n",
      "Epoch 29: val_loss did not improve from 1.65282\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.5039 - accuracy: 0.5554 - precision_m: 0.7626 - recall_m: 0.3788 - f1_m: 0.5052 - val_loss: 1.6841 - val_accuracy: 0.5080 - val_precision_m: 0.7246 - val_recall_m: 0.3523 - val_f1_m: 0.4727\n",
      "Epoch 30/30\n",
      "595/610 [============================>.] - ETA: 0s - loss: 1.4950 - accuracy: 0.5569 - precision_m: 0.7661 - recall_m: 0.3827 - f1_m: 0.5095\n",
      "Epoch 30: val_loss did not improve from 1.65282\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.4960 - accuracy: 0.5567 - precision_m: 0.7660 - recall_m: 0.3831 - f1_m: 0.5099 - val_loss: 1.6584 - val_accuracy: 0.5168 - val_precision_m: 0.7244 - val_recall_m: 0.3565 - val_f1_m: 0.4765\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 58.6 seconds (1.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 29.3%\n",
      "  Usage (max):  51.9%\n",
      "  Frequency:    3978 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 38.6%\n",
      "  Usage (max):  39.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  28.1%\n",
      "  Usage (max):   33.0%\n",
      "  Memory (mean): 1644 MB\n",
      "  Memory (max):  1644 MB\n",
      "  Power (mean):  45.2 W\n",
      "  Power (max):   47.8 W\n",
      "  Energy used:   0.736842 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 RESULTS\n",
      "================================================================================\n",
      "Validation:\n",
      "  Loss:      1.6528\n",
      "  Accuracy:  51.83%\n",
      "  Precision: 0.7340\n",
      "  Recall:    0.3550\n",
      "  F1 Score:  0.4766\n",
      "\n",
      "Test:\n",
      "  Loss:      1.5981\n",
      "  Accuracy:  53.34%\n",
      "  Precision: 0.7420\n",
      "  Recall:    0.3656\n",
      "  F1 Score:  0.4848\n",
      "\n",
      "Resources:\n",
      "  Duration:     58.6s (1.0m)\n",
      "  GPU Power:    45.2W (max: 47.8W)\n",
      "  Energy Used:  0.737Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 4 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Permission denied for /sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj. Run with sudo or add permissions.\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77820, Val=8281, Test=7550\n",
      "Epoch 1/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 3.4092 - accuracy: 0.0633 - precision_m: 0.0016 - recall_m: 1.2871e-05 - f1_m: 2.5542e-05\n",
      "Epoch 1: val_loss improved from inf to 3.18128, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.1268 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 3s 3ms/step - loss: 3.4090 - accuracy: 0.0634 - precision_m: 0.0016 - recall_m: 1.2850e-05 - f1_m: 2.5500e-05 - val_loss: 3.1813 - val_accuracy: 0.1268 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "600/608 [============================>.] - ETA: 0s - loss: 2.8427 - accuracy: 0.1717 - precision_m: 0.2530 - recall_m: 0.0052 - f1_m: 0.0101\n",
      "Epoch 2: val_loss improved from 3.18128 to 2.65811, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.2107 | Precision: 0.5302 | Recall: 0.0170 | F1: 0.0327\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.8393 - accuracy: 0.1723 - precision_m: 0.2600 - recall_m: 0.0054 - f1_m: 0.0104 - val_loss: 2.6581 - val_accuracy: 0.2107 - val_precision_m: 0.5302 - val_recall_m: 0.0170 - val_f1_m: 0.0327\n",
      "Epoch 3/30\n",
      "608/608 [==============================] - ETA: 0s - loss: 2.5859 - accuracy: 0.2323 - precision_m: 0.6522 - recall_m: 0.0237 - f1_m: 0.0454\n",
      "Epoch 3: val_loss improved from 2.65811 to 2.58525, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.2263 | Precision: 0.5618 | Recall: 0.0261 | F1: 0.0493\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.5859 - accuracy: 0.2323 - precision_m: 0.6522 - recall_m: 0.0237 - f1_m: 0.0454 - val_loss: 2.5852 - val_accuracy: 0.2263 - val_precision_m: 0.5618 - val_recall_m: 0.0261 - val_f1_m: 0.0493\n",
      "Epoch 4/30\n",
      "596/608 [============================>.] - ETA: 0s - loss: 2.5359 - accuracy: 0.2471 - precision_m: 0.6704 - recall_m: 0.0273 - f1_m: 0.0521\n",
      "Epoch 4: val_loss did not improve from 2.58525\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.2313 | Precision: 0.5722 | Recall: 0.0332 | F1: 0.0619\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.5353 - accuracy: 0.2473 - precision_m: 0.6683 - recall_m: 0.0273 - f1_m: 0.0522 - val_loss: 2.6073 - val_accuracy: 0.2313 - val_precision_m: 0.5722 - val_recall_m: 0.0332 - val_f1_m: 0.0619\n",
      "Epoch 5/30\n",
      "604/608 [============================>.] - ETA: 0s - loss: 2.5037 - accuracy: 0.2540 - precision_m: 0.6633 - recall_m: 0.0303 - f1_m: 0.0575\n",
      "Epoch 5: val_loss improved from 2.58525 to 2.54679, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.2465 | Precision: 0.6225 | Recall: 0.0382 | F1: 0.0710\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.5035 - accuracy: 0.2541 - precision_m: 0.6640 - recall_m: 0.0305 - f1_m: 0.0579 - val_loss: 2.5468 - val_accuracy: 0.2465 - val_precision_m: 0.6225 - val_recall_m: 0.0382 - val_f1_m: 0.0710\n",
      "Epoch 6/30\n",
      "601/608 [============================>.] - ETA: 0s - loss: 2.4836 - accuracy: 0.2611 - precision_m: 0.6639 - recall_m: 0.0336 - f1_m: 0.0635\n",
      "Epoch 6: val_loss improved from 2.54679 to 2.52392, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.2536 | Precision: 0.6511 | Recall: 0.0351 | F1: 0.0657\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.4832 - accuracy: 0.2610 - precision_m: 0.6627 - recall_m: 0.0336 - f1_m: 0.0635 - val_loss: 2.5239 - val_accuracy: 0.2536 - val_precision_m: 0.6511 - val_recall_m: 0.0351 - val_f1_m: 0.0657\n",
      "Epoch 7/30\n",
      "607/608 [============================>.] - ETA: 0s - loss: 2.4645 - accuracy: 0.2690 - precision_m: 0.6655 - recall_m: 0.0353 - f1_m: 0.0665\n",
      "Epoch 7: val_loss did not improve from 2.52392\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.2553 | Precision: 0.5959 | Recall: 0.0428 | F1: 0.0787\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.4647 - accuracy: 0.2690 - precision_m: 0.6655 - recall_m: 0.0353 - f1_m: 0.0665 - val_loss: 2.5367 - val_accuracy: 0.2553 - val_precision_m: 0.5959 - val_recall_m: 0.0428 - val_f1_m: 0.0787\n",
      "Epoch 8/30\n",
      "592/608 [============================>.] - ETA: 0s - loss: 2.4515 - accuracy: 0.2740 - precision_m: 0.6743 - recall_m: 0.0377 - f1_m: 0.0708\n",
      "Epoch 8: val_loss improved from 2.52392 to 2.51584, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.4519 - accuracy: 0.2738 - precision_m: 0.6749 - recall_m: 0.0377 - f1_m: 0.0710 - val_loss: 2.5158 - val_accuracy: 0.2537 - val_precision_m: 0.6504 - val_recall_m: 0.0402 - val_f1_m: 0.0746\n",
      "Epoch 9/30\n",
      "599/608 [============================>.] - ETA: 0s - loss: 2.4381 - accuracy: 0.2778 - precision_m: 0.6670 - recall_m: 0.0392 - f1_m: 0.0734\n",
      "Epoch 9: val_loss improved from 2.51584 to 2.48588, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.2637 | Precision: 0.7018 | Recall: 0.0381 | F1: 0.0711\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.4378 - accuracy: 0.2777 - precision_m: 0.6675 - recall_m: 0.0391 - f1_m: 0.0733 - val_loss: 2.4859 - val_accuracy: 0.2637 - val_precision_m: 0.7018 - val_recall_m: 0.0381 - val_f1_m: 0.0711\n",
      "Epoch 10/30\n",
      "598/608 [============================>.] - ETA: 0s - loss: 2.4268 - accuracy: 0.2838 - precision_m: 0.6749 - recall_m: 0.0415 - f1_m: 0.0777\n",
      "Epoch 10: val_loss did not improve from 2.48588\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.2684 | Precision: 0.6248 | Recall: 0.0480 | F1: 0.0879\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.4265 - accuracy: 0.2837 - precision_m: 0.6753 - recall_m: 0.0416 - f1_m: 0.0779 - val_loss: 2.4890 - val_accuracy: 0.2684 - val_precision_m: 0.6248 - val_recall_m: 0.0480 - val_f1_m: 0.0879\n",
      "Epoch 11/30\n",
      "592/608 [============================>.] - ETA: 0s - loss: 2.4146 - accuracy: 0.2862 - precision_m: 0.6777 - recall_m: 0.0430 - f1_m: 0.0802\n",
      "Epoch 11: val_loss improved from 2.48588 to 2.48575, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.4147 - accuracy: 0.2861 - precision_m: 0.6785 - recall_m: 0.0430 - f1_m: 0.0803 - val_loss: 2.4858 - val_accuracy: 0.2636 - val_precision_m: 0.6919 - val_recall_m: 0.0449 - val_f1_m: 0.0833\n",
      "Epoch 12/30\n",
      "594/608 [============================>.] - ETA: 0s - loss: 2.4074 - accuracy: 0.2894 - precision_m: 0.6884 - recall_m: 0.0457 - f1_m: 0.0850\n",
      "Epoch 12: val_loss improved from 2.48575 to 2.48106, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.2712 | Precision: 0.6788 | Recall: 0.0452 | F1: 0.0837\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.4070 - accuracy: 0.2893 - precision_m: 0.6877 - recall_m: 0.0457 - f1_m: 0.0852 - val_loss: 2.4811 - val_accuracy: 0.2712 - val_precision_m: 0.6788 - val_recall_m: 0.0452 - val_f1_m: 0.0837\n",
      "Epoch 13/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 2.3960 - accuracy: 0.2930 - precision_m: 0.6947 - recall_m: 0.0476 - f1_m: 0.0884\n",
      "Epoch 13: val_loss improved from 2.48106 to 2.46214, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 13\n",
      "Accuracy: 0.2770 | Precision: 0.6857 | Recall: 0.0472 | F1: 0.0871\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3959 - accuracy: 0.2931 - precision_m: 0.6949 - recall_m: 0.0477 - f1_m: 0.0886 - val_loss: 2.4621 - val_accuracy: 0.2770 - val_precision_m: 0.6857 - val_recall_m: 0.0472 - val_f1_m: 0.0871\n",
      "Epoch 14/30\n",
      "597/608 [============================>.] - ETA: 0s - loss: 2.3873 - accuracy: 0.2953 - precision_m: 0.6912 - recall_m: 0.0493 - f1_m: 0.0915\n",
      "Epoch 14: val_loss did not improve from 2.46214\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3871 - accuracy: 0.2955 - precision_m: 0.6903 - recall_m: 0.0493 - f1_m: 0.0914 - val_loss: 2.4688 - val_accuracy: 0.2742 - val_precision_m: 0.6668 - val_recall_m: 0.0468 - val_f1_m: 0.0865\n",
      "Epoch 15/30\n",
      "598/608 [============================>.] - ETA: 0s - loss: 2.3799 - accuracy: 0.2982 - precision_m: 0.6970 - recall_m: 0.0512 - f1_m: 0.0947\n",
      "Epoch 15: val_loss improved from 2.46214 to 2.43353, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 15\n",
      "Accuracy: 0.2810 | Precision: 0.6684 | Recall: 0.0567 | F1: 0.1032\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3788 - accuracy: 0.2984 - precision_m: 0.6965 - recall_m: 0.0511 - f1_m: 0.0946 - val_loss: 2.4335 - val_accuracy: 0.2810 - val_precision_m: 0.6684 - val_recall_m: 0.0567 - val_f1_m: 0.1032\n",
      "Epoch 16/30\n",
      "598/608 [============================>.] - ETA: 0s - loss: 2.3671 - accuracy: 0.3006 - precision_m: 0.7005 - recall_m: 0.0518 - f1_m: 0.0957\n",
      "Epoch 16: val_loss improved from 2.43353 to 2.42983, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3672 - accuracy: 0.3009 - precision_m: 0.6993 - recall_m: 0.0518 - f1_m: 0.0957 - val_loss: 2.4298 - val_accuracy: 0.2790 - val_precision_m: 0.6516 - val_recall_m: 0.0566 - val_f1_m: 0.1030\n",
      "Epoch 17/30\n",
      "595/608 [============================>.] - ETA: 0s - loss: 2.3581 - accuracy: 0.3050 - precision_m: 0.6946 - recall_m: 0.0534 - f1_m: 0.0985\n",
      "Epoch 17: val_loss improved from 2.42983 to 2.42363, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.2855 | Precision: 0.6648 | Recall: 0.0594 | F1: 0.1078\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3567 - accuracy: 0.3053 - precision_m: 0.6941 - recall_m: 0.0535 - f1_m: 0.0987 - val_loss: 2.4236 - val_accuracy: 0.2855 - val_precision_m: 0.6648 - val_recall_m: 0.0594 - val_f1_m: 0.1078\n",
      "Epoch 18/30\n",
      "594/608 [============================>.] - ETA: 0s - loss: 2.3466 - accuracy: 0.3068 - precision_m: 0.6978 - recall_m: 0.0554 - f1_m: 0.1021\n",
      "Epoch 18: val_loss improved from 2.42363 to 2.41934, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.2944 | Precision: 0.6793 | Recall: 0.0549 | F1: 0.1005\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3469 - accuracy: 0.3063 - precision_m: 0.6946 - recall_m: 0.0551 - f1_m: 0.1015 - val_loss: 2.4193 - val_accuracy: 0.2944 - val_precision_m: 0.6793 - val_recall_m: 0.0549 - val_f1_m: 0.1005\n",
      "Epoch 19/30\n",
      "603/608 [============================>.] - ETA: 0s - loss: 2.3386 - accuracy: 0.3084 - precision_m: 0.7017 - recall_m: 0.0563 - f1_m: 0.1036\n",
      "Epoch 19: val_loss improved from 2.41934 to 2.40186, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3389 - accuracy: 0.3084 - precision_m: 0.7020 - recall_m: 0.0563 - f1_m: 0.1035 - val_loss: 2.4019 - val_accuracy: 0.2870 - val_precision_m: 0.7040 - val_recall_m: 0.0527 - val_f1_m: 0.0970\n",
      "Epoch 20/30\n",
      "600/608 [============================>.] - ETA: 0s - loss: 2.3309 - accuracy: 0.3119 - precision_m: 0.6969 - recall_m: 0.0582 - f1_m: 0.1068\n",
      "Epoch 20: val_loss improved from 2.40186 to 2.40135, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3305 - accuracy: 0.3118 - precision_m: 0.6987 - recall_m: 0.0583 - f1_m: 0.1069 - val_loss: 2.4014 - val_accuracy: 0.2895 - val_precision_m: 0.6901 - val_recall_m: 0.0572 - val_f1_m: 0.1044\n",
      "Epoch 21/30\n",
      "599/608 [============================>.] - ETA: 0s - loss: 2.3181 - accuracy: 0.3131 - precision_m: 0.7020 - recall_m: 0.0603 - f1_m: 0.1104\n",
      "Epoch 21: val_loss improved from 2.40135 to 2.38682, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3182 - accuracy: 0.3130 - precision_m: 0.7015 - recall_m: 0.0602 - f1_m: 0.1103 - val_loss: 2.3868 - val_accuracy: 0.2904 - val_precision_m: 0.7138 - val_recall_m: 0.0572 - val_f1_m: 0.1048\n",
      "Epoch 22/30\n",
      "600/608 [============================>.] - ETA: 0s - loss: 2.3084 - accuracy: 0.3153 - precision_m: 0.6966 - recall_m: 0.0606 - f1_m: 0.1108\n",
      "Epoch 22: val_loss improved from 2.38682 to 2.36660, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 22\n",
      "Accuracy: 0.2997 | Precision: 0.7265 | Recall: 0.0584 | F1: 0.1067\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.3083 - accuracy: 0.3153 - precision_m: 0.6971 - recall_m: 0.0605 - f1_m: 0.1106 - val_loss: 2.3666 - val_accuracy: 0.2997 - val_precision_m: 0.7265 - val_recall_m: 0.0584 - val_f1_m: 0.1067\n",
      "Epoch 23/30\n",
      "600/608 [============================>.] - ETA: 0s - loss: 2.2977 - accuracy: 0.3197 - precision_m: 0.7050 - recall_m: 0.0632 - f1_m: 0.1152\n",
      "Epoch 23: val_loss improved from 2.36660 to 2.35506, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 23\n",
      "Accuracy: 0.3072 | Precision: 0.6967 | Recall: 0.0714 | F1: 0.1278\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.2973 - accuracy: 0.3199 - precision_m: 0.7046 - recall_m: 0.0632 - f1_m: 0.1153 - val_loss: 2.3551 - val_accuracy: 0.3072 - val_precision_m: 0.6967 - val_recall_m: 0.0714 - val_f1_m: 0.1278\n",
      "Epoch 24/30\n",
      "602/608 [============================>.] - ETA: 0s - loss: 2.2909 - accuracy: 0.3205 - precision_m: 0.7001 - recall_m: 0.0648 - f1_m: 0.1179\n",
      "Epoch 24: val_loss improved from 2.35506 to 2.34459, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 24\n",
      "Accuracy: 0.3087 | Precision: 0.6854 | Recall: 0.0705 | F1: 0.1261\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.2911 - accuracy: 0.3202 - precision_m: 0.6997 - recall_m: 0.0649 - f1_m: 0.1180 - val_loss: 2.3446 - val_accuracy: 0.3087 - val_precision_m: 0.6854 - val_recall_m: 0.0705 - val_f1_m: 0.1261\n",
      "Epoch 25/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 2.2803 - accuracy: 0.3244 - precision_m: 0.7041 - recall_m: 0.0665 - f1_m: 0.1207\n",
      "Epoch 25: val_loss did not improve from 2.34459\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.2802 - accuracy: 0.3244 - precision_m: 0.7037 - recall_m: 0.0665 - f1_m: 0.1207 - val_loss: 2.3575 - val_accuracy: 0.3000 - val_precision_m: 0.6941 - val_recall_m: 0.0601 - val_f1_m: 0.1093\n",
      "Epoch 26/30\n",
      "598/608 [============================>.] - ETA: 0s - loss: 2.2704 - accuracy: 0.3262 - precision_m: 0.6971 - recall_m: 0.0673 - f1_m: 0.1220\n",
      "Epoch 26: val_loss improved from 2.34459 to 2.33595, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.2707 - accuracy: 0.3262 - precision_m: 0.6962 - recall_m: 0.0673 - f1_m: 0.1219 - val_loss: 2.3360 - val_accuracy: 0.3085 - val_precision_m: 0.6841 - val_recall_m: 0.0711 - val_f1_m: 0.1271\n",
      "Epoch 27/30\n",
      "597/608 [============================>.] - ETA: 0s - loss: 2.2641 - accuracy: 0.3278 - precision_m: 0.7011 - recall_m: 0.0689 - f1_m: 0.1247\n",
      "Epoch 27: val_loss improved from 2.33595 to 2.32774, saving model to trained_models/model_1_fold_4_best.h5\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.2634 - accuracy: 0.3279 - precision_m: 0.7012 - recall_m: 0.0690 - f1_m: 0.1248 - val_loss: 2.3277 - val_accuracy: 0.3061 - val_precision_m: 0.7135 - val_recall_m: 0.0641 - val_f1_m: 0.1159\n",
      "Epoch 28/30\n",
      "601/608 [============================>.] - ETA: 0s - loss: 2.2561 - accuracy: 0.3288 - precision_m: 0.7022 - recall_m: 0.0708 - f1_m: 0.1277\n",
      "Epoch 28: val_loss did not improve from 2.32774\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 28\n",
      "Accuracy: 0.3097 | Precision: 0.7138 | Recall: 0.0650 | F1: 0.1177\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.2556 - accuracy: 0.3289 - precision_m: 0.7025 - recall_m: 0.0708 - f1_m: 0.1278 - val_loss: 2.3345 - val_accuracy: 0.3097 - val_precision_m: 0.7138 - val_recall_m: 0.0650 - val_f1_m: 0.1177\n",
      "Epoch 29/30\n",
      "606/608 [============================>.] - ETA: 0s - loss: 2.2464 - accuracy: 0.3323 - precision_m: 0.6997 - recall_m: 0.0714 - f1_m: 0.1288\n",
      "Epoch 29: val_loss improved from 2.32774 to 2.31274, saving model to trained_models/model_1_fold_4_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 29\n",
      "Accuracy: 0.3116 | Precision: 0.6829 | Recall: 0.0767 | F1: 0.1360\n",
      "================================================================================\n",
      "\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.2464 - accuracy: 0.3321 - precision_m: 0.6998 - recall_m: 0.0714 - f1_m: 0.1288 - val_loss: 2.3127 - val_accuracy: 0.3116 - val_precision_m: 0.6829 - val_recall_m: 0.0767 - val_f1_m: 0.1360\n",
      "Epoch 30/30\n",
      "592/608 [============================>.] - ETA: 0s - loss: 2.2400 - accuracy: 0.3325 - precision_m: 0.7032 - recall_m: 0.0731 - f1_m: 0.1316\n",
      "Epoch 30: val_loss did not improve from 2.31274\n",
      "608/608 [==============================] - 2s 3ms/step - loss: 2.2394 - accuracy: 0.3329 - precision_m: 0.7036 - recall_m: 0.0735 - f1_m: 0.1322 - val_loss: 2.3130 - val_accuracy: 0.3113 - val_precision_m: 0.7152 - val_recall_m: 0.0744 - val_f1_m: 0.1329\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 58.6 seconds (1.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 29.0%\n",
      "  Usage (max):  44.4%\n",
      "  Frequency:    3979 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 38.8%\n",
      "  Usage (max):  39.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  28.3%\n",
      "  Usage (max):   33.0%\n",
      "  Memory (mean): 1643 MB\n",
      "  Memory (max):  1644 MB\n",
      "  Power (mean):  45.3 W\n",
      "  Power (max):   47.7 W\n",
      "  Energy used:   0.737262 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 RESULTS\n",
      "================================================================================\n",
      "Validation:\n",
      "  Loss:      2.3127\n",
      "  Accuracy:  31.16%\n",
      "  Precision: 0.6829\n",
      "  Recall:    0.0767\n",
      "  F1 Score:  0.1360\n",
      "\n",
      "Test:\n",
      "  Loss:      2.2914\n",
      "  Accuracy:  33.27%\n",
      "  Precision: 0.6231\n",
      "  Recall:    0.0686\n",
      "  F1 Score:  0.1204\n",
      "\n",
      "Resources:\n",
      "  Duration:     58.6s (1.0m)\n",
      "  GPU Power:    45.3W (max: 47.7W)\n",
      "  Energy Used:  0.737Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 5 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Permission denied for /sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj. Run with sudo or add permissions.\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=78003, Val=8252, Test=7409\n",
      "Epoch 1/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 3.0836 - accuracy: 0.1399 - precision_m: 0.2188 - recall_m: 0.0030 - f1_m: 0.0060\n",
      "Epoch 1: val_loss improved from inf to 2.68383, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2066 | Precision: 0.5947 | Recall: 0.0152 | F1: 0.0293\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 3s 3ms/step - loss: 3.0819 - accuracy: 0.1402 - precision_m: 0.2210 - recall_m: 0.0031 - f1_m: 0.0061 - val_loss: 2.6838 - val_accuracy: 0.2066 - val_precision_m: 0.5947 - val_recall_m: 0.0152 - val_f1_m: 0.0293\n",
      "Epoch 2/30\n",
      "601/610 [============================>.] - ETA: 0s - loss: 2.5370 - accuracy: 0.2498 - precision_m: 0.5955 - recall_m: 0.0198 - f1_m: 0.0379\n",
      "Epoch 2: val_loss improved from 2.68383 to 2.50726, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.2524 | Precision: 0.6107 | Recall: 0.0379 | F1: 0.0708\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.5355 - accuracy: 0.2502 - precision_m: 0.5963 - recall_m: 0.0199 - f1_m: 0.0382 - val_loss: 2.5073 - val_accuracy: 0.2524 - val_precision_m: 0.6107 - val_recall_m: 0.0379 - val_f1_m: 0.0708\n",
      "Epoch 3/30\n",
      "601/610 [============================>.] - ETA: 0s - loss: 2.4162 - accuracy: 0.2817 - precision_m: 0.5992 - recall_m: 0.0367 - f1_m: 0.0686\n",
      "Epoch 3: val_loss improved from 2.50726 to 2.42827, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.2750 | Precision: 0.6091 | Recall: 0.0522 | F1: 0.0953\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.4151 - accuracy: 0.2818 - precision_m: 0.5991 - recall_m: 0.0368 - f1_m: 0.0687 - val_loss: 2.4283 - val_accuracy: 0.2750 - val_precision_m: 0.6091 - val_recall_m: 0.0522 - val_f1_m: 0.0953\n",
      "Epoch 4/30\n",
      "600/610 [============================>.] - ETA: 0s - loss: 2.3466 - accuracy: 0.3007 - precision_m: 0.6213 - recall_m: 0.0506 - f1_m: 0.0929\n",
      "Epoch 4: val_loss did not improve from 2.42827\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.2754 | Precision: 0.6051 | Recall: 0.0584 | F1: 0.1054\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.3462 - accuracy: 0.3011 - precision_m: 0.6200 - recall_m: 0.0507 - f1_m: 0.0930 - val_loss: 2.4306 - val_accuracy: 0.2754 - val_precision_m: 0.6051 - val_recall_m: 0.0584 - val_f1_m: 0.1054\n",
      "Epoch 5/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 2.2958 - accuracy: 0.3159 - precision_m: 0.6369 - recall_m: 0.0621 - f1_m: 0.1124\n",
      "Epoch 5: val_loss improved from 2.42827 to 2.33872, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.3027 | Precision: 0.6029 | Recall: 0.0610 | F1: 0.1098\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2955 - accuracy: 0.3161 - precision_m: 0.6353 - recall_m: 0.0619 - f1_m: 0.1121 - val_loss: 2.3387 - val_accuracy: 0.3027 - val_precision_m: 0.6029 - val_recall_m: 0.0610 - val_f1_m: 0.1098\n",
      "Epoch 6/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 2.2519 - accuracy: 0.3284 - precision_m: 0.6452 - recall_m: 0.0723 - f1_m: 0.1292\n",
      "Epoch 6: val_loss improved from 2.33872 to 2.31799, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.3060 | Precision: 0.6170 | Recall: 0.0776 | F1: 0.1367\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2516 - accuracy: 0.3284 - precision_m: 0.6448 - recall_m: 0.0724 - f1_m: 0.1293 - val_loss: 2.3180 - val_accuracy: 0.3060 - val_precision_m: 0.6170 - val_recall_m: 0.0776 - val_f1_m: 0.1367\n",
      "Epoch 7/30\n",
      "597/610 [============================>.] - ETA: 0s - loss: 2.2137 - accuracy: 0.3397 - precision_m: 0.6600 - recall_m: 0.0849 - f1_m: 0.1495\n",
      "Epoch 7: val_loss improved from 2.31799 to 2.30147, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.3134 | Precision: 0.6041 | Recall: 0.0827 | F1: 0.1439\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2143 - accuracy: 0.3397 - precision_m: 0.6610 - recall_m: 0.0850 - f1_m: 0.1497 - val_loss: 2.3015 - val_accuracy: 0.3134 - val_precision_m: 0.6041 - val_recall_m: 0.0827 - val_f1_m: 0.1439\n",
      "Epoch 8/30\n",
      "596/610 [============================>.] - ETA: 0s - loss: 2.1809 - accuracy: 0.3494 - precision_m: 0.6702 - recall_m: 0.0938 - f1_m: 0.1637\n",
      "Epoch 8: val_loss improved from 2.30147 to 2.27912, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.3181 | Precision: 0.6067 | Recall: 0.0902 | F1: 0.1555\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1807 - accuracy: 0.3495 - precision_m: 0.6701 - recall_m: 0.0938 - f1_m: 0.1636 - val_loss: 2.2791 - val_accuracy: 0.3181 - val_precision_m: 0.6067 - val_recall_m: 0.0902 - val_f1_m: 0.1555\n",
      "Epoch 9/30\n",
      "596/610 [============================>.] - ETA: 0s - loss: 2.1578 - accuracy: 0.3537 - precision_m: 0.6694 - recall_m: 0.0998 - f1_m: 0.1728\n",
      "Epoch 9: val_loss improved from 2.27912 to 2.21859, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.3358 | Precision: 0.6108 | Recall: 0.0977 | F1: 0.1668\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1586 - accuracy: 0.3535 - precision_m: 0.6690 - recall_m: 0.0999 - f1_m: 0.1729 - val_loss: 2.2186 - val_accuracy: 0.3358 - val_precision_m: 0.6108 - val_recall_m: 0.0977 - val_f1_m: 0.1668\n",
      "Epoch 10/30\n",
      "599/610 [============================>.] - ETA: 0s - loss: 2.1387 - accuracy: 0.3594 - precision_m: 0.6748 - recall_m: 0.1061 - f1_m: 0.1825\n",
      "Epoch 10: val_loss improved from 2.21859 to 2.20429, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.3432 | Precision: 0.6434 | Recall: 0.0985 | F1: 0.1692\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1382 - accuracy: 0.3597 - precision_m: 0.6753 - recall_m: 0.1061 - f1_m: 0.1825 - val_loss: 2.2043 - val_accuracy: 0.3432 - val_precision_m: 0.6434 - val_recall_m: 0.0985 - val_f1_m: 0.1692\n",
      "Epoch 11/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.1230 - accuracy: 0.3627 - precision_m: 0.6804 - recall_m: 0.1099 - f1_m: 0.1882\n",
      "Epoch 11: val_loss did not improve from 2.20429\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1231 - accuracy: 0.3628 - precision_m: 0.6803 - recall_m: 0.1100 - f1_m: 0.1884 - val_loss: 2.2428 - val_accuracy: 0.3311 - val_precision_m: 0.5887 - val_recall_m: 0.1109 - val_f1_m: 0.1853\n",
      "Epoch 12/30\n",
      "599/610 [============================>.] - ETA: 0s - loss: 2.1069 - accuracy: 0.3667 - precision_m: 0.6772 - recall_m: 0.1145 - f1_m: 0.1950\n",
      "Epoch 12: val_loss improved from 2.20429 to 2.16834, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.3576 | Precision: 0.6300 | Recall: 0.1030 | F1: 0.1756\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1075 - accuracy: 0.3665 - precision_m: 0.6769 - recall_m: 0.1144 - f1_m: 0.1949 - val_loss: 2.1683 - val_accuracy: 0.3576 - val_precision_m: 0.6300 - val_recall_m: 0.1030 - val_f1_m: 0.1756\n",
      "Epoch 13/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.0949 - accuracy: 0.3704 - precision_m: 0.6827 - recall_m: 0.1157 - f1_m: 0.1969\n",
      "Epoch 13: val_loss did not improve from 2.16834\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0957 - accuracy: 0.3703 - precision_m: 0.6821 - recall_m: 0.1156 - f1_m: 0.1968 - val_loss: 2.2027 - val_accuracy: 0.3393 - val_precision_m: 0.6063 - val_recall_m: 0.0970 - val_f1_m: 0.1659\n",
      "Epoch 14/30\n",
      "599/610 [============================>.] - ETA: 0s - loss: 2.0866 - accuracy: 0.3728 - precision_m: 0.6805 - recall_m: 0.1195 - f1_m: 0.2022\n",
      "Epoch 14: val_loss improved from 2.16834 to 2.14668, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.3623 | Precision: 0.6308 | Recall: 0.1085 | F1: 0.1836\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0872 - accuracy: 0.3727 - precision_m: 0.6803 - recall_m: 0.1196 - f1_m: 0.2024 - val_loss: 2.1467 - val_accuracy: 0.3623 - val_precision_m: 0.6308 - val_recall_m: 0.1085 - val_f1_m: 0.1836\n",
      "Epoch 15/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 2.0754 - accuracy: 0.3744 - precision_m: 0.6812 - recall_m: 0.1214 - f1_m: 0.2051\n",
      "Epoch 15: val_loss did not improve from 2.14668\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0752 - accuracy: 0.3745 - precision_m: 0.6808 - recall_m: 0.1215 - f1_m: 0.2052 - val_loss: 2.1869 - val_accuracy: 0.3482 - val_precision_m: 0.6122 - val_recall_m: 0.1098 - val_f1_m: 0.1847\n",
      "Epoch 16/30\n",
      "596/610 [============================>.] - ETA: 0s - loss: 2.0678 - accuracy: 0.3760 - precision_m: 0.6792 - recall_m: 0.1244 - f1_m: 0.2093\n",
      "Epoch 16: val_loss did not improve from 2.14668\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0683 - accuracy: 0.3760 - precision_m: 0.6785 - recall_m: 0.1244 - f1_m: 0.2093 - val_loss: 2.1625 - val_accuracy: 0.3589 - val_precision_m: 0.6157 - val_recall_m: 0.1078 - val_f1_m: 0.1819\n",
      "Epoch 17/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.0644 - accuracy: 0.3782 - precision_m: 0.6824 - recall_m: 0.1271 - f1_m: 0.2133\n",
      "Epoch 17: val_loss improved from 2.14668 to 2.13066, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.3629 | Precision: 0.6269 | Recall: 0.1131 | F1: 0.1900\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0649 - accuracy: 0.3783 - precision_m: 0.6829 - recall_m: 0.1270 - f1_m: 0.2133 - val_loss: 2.1307 - val_accuracy: 0.3629 - val_precision_m: 0.6269 - val_recall_m: 0.1131 - val_f1_m: 0.1900\n",
      "Epoch 18/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.0553 - accuracy: 0.3800 - precision_m: 0.6817 - recall_m: 0.1264 - f1_m: 0.2123\n",
      "Epoch 18: val_loss did not improve from 2.13066\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0556 - accuracy: 0.3799 - precision_m: 0.6815 - recall_m: 0.1264 - f1_m: 0.2122 - val_loss: 2.2042 - val_accuracy: 0.3446 - val_precision_m: 0.6233 - val_recall_m: 0.1089 - val_f1_m: 0.1838\n",
      "Epoch 19/30\n",
      "598/610 [============================>.] - ETA: 0s - loss: 2.0490 - accuracy: 0.3800 - precision_m: 0.6803 - recall_m: 0.1297 - f1_m: 0.2168\n",
      "Epoch 19: val_loss did not improve from 2.13066\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 19\n",
      "Accuracy: 0.3644 | Precision: 0.6261 | Recall: 0.1091 | F1: 0.1841\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0496 - accuracy: 0.3798 - precision_m: 0.6791 - recall_m: 0.1292 - f1_m: 0.2160 - val_loss: 2.1466 - val_accuracy: 0.3644 - val_precision_m: 0.6261 - val_recall_m: 0.1091 - val_f1_m: 0.1841\n",
      "Epoch 20/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.0461 - accuracy: 0.3836 - precision_m: 0.6815 - recall_m: 0.1314 - f1_m: 0.2192\n",
      "Epoch 20: val_loss did not improve from 2.13066\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0459 - accuracy: 0.3836 - precision_m: 0.6814 - recall_m: 0.1314 - f1_m: 0.2192 - val_loss: 2.1838 - val_accuracy: 0.3513 - val_precision_m: 0.6240 - val_recall_m: 0.1067 - val_f1_m: 0.1806\n",
      "Epoch 21/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.0407 - accuracy: 0.3830 - precision_m: 0.6818 - recall_m: 0.1312 - f1_m: 0.2191\n",
      "Epoch 21: val_loss improved from 2.13066 to 2.12122, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 21\n",
      "Accuracy: 0.3686 | Precision: 0.6324 | Recall: 0.1166 | F1: 0.1952\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0405 - accuracy: 0.3830 - precision_m: 0.6824 - recall_m: 0.1315 - f1_m: 0.2195 - val_loss: 2.1212 - val_accuracy: 0.3686 - val_precision_m: 0.6324 - val_recall_m: 0.1166 - val_f1_m: 0.1952\n",
      "Epoch 22/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.0347 - accuracy: 0.3834 - precision_m: 0.6877 - recall_m: 0.1350 - f1_m: 0.2248\n",
      "Epoch 22: val_loss did not improve from 2.12122\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0349 - accuracy: 0.3834 - precision_m: 0.6874 - recall_m: 0.1348 - f1_m: 0.2246 - val_loss: 2.1683 - val_accuracy: 0.3602 - val_precision_m: 0.6069 - val_recall_m: 0.1142 - val_f1_m: 0.1909\n",
      "Epoch 23/30\n",
      "601/610 [============================>.] - ETA: 0s - loss: 2.0256 - accuracy: 0.3889 - precision_m: 0.6899 - recall_m: 0.1363 - f1_m: 0.2266\n",
      "Epoch 23: val_loss improved from 2.12122 to 2.12027, saving model to trained_models/model_1_fold_5_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0257 - accuracy: 0.3887 - precision_m: 0.6890 - recall_m: 0.1362 - f1_m: 0.2263 - val_loss: 2.1203 - val_accuracy: 0.3680 - val_precision_m: 0.6233 - val_recall_m: 0.1375 - val_f1_m: 0.2236\n",
      "Epoch 24/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.0283 - accuracy: 0.3872 - precision_m: 0.6867 - recall_m: 0.1377 - f1_m: 0.2283\n",
      "Epoch 24: val_loss did not improve from 2.12027\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0286 - accuracy: 0.3870 - precision_m: 0.6856 - recall_m: 0.1375 - f1_m: 0.2280 - val_loss: 2.1645 - val_accuracy: 0.3588 - val_precision_m: 0.6189 - val_recall_m: 0.1332 - val_f1_m: 0.2176\n",
      "Epoch 25/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 2.0184 - accuracy: 0.3913 - precision_m: 0.6908 - recall_m: 0.1405 - f1_m: 0.2325\n",
      "Epoch 25: val_loss improved from 2.12027 to 2.10712, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.3709 | Precision: 0.6359 | Recall: 0.1325 | F1: 0.2177\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0175 - accuracy: 0.3912 - precision_m: 0.6912 - recall_m: 0.1408 - f1_m: 0.2329 - val_loss: 2.1071 - val_accuracy: 0.3709 - val_precision_m: 0.6359 - val_recall_m: 0.1325 - val_f1_m: 0.2177\n",
      "Epoch 26/30\n",
      "595/610 [============================>.] - ETA: 0s - loss: 2.0144 - accuracy: 0.3929 - precision_m: 0.6906 - recall_m: 0.1415 - f1_m: 0.2339\n",
      "Epoch 26: val_loss did not improve from 2.10712\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0141 - accuracy: 0.3925 - precision_m: 0.6907 - recall_m: 0.1414 - f1_m: 0.2337 - val_loss: 2.1222 - val_accuracy: 0.3659 - val_precision_m: 0.6237 - val_recall_m: 0.1274 - val_f1_m: 0.2101\n",
      "Epoch 27/30\n",
      "600/610 [============================>.] - ETA: 0s - loss: 2.0107 - accuracy: 0.3924 - precision_m: 0.6940 - recall_m: 0.1434 - f1_m: 0.2366\n",
      "Epoch 27: val_loss improved from 2.10712 to 2.10595, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 27\n",
      "Accuracy: 0.3723 | Precision: 0.6283 | Recall: 0.1363 | F1: 0.2224\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0110 - accuracy: 0.3924 - precision_m: 0.6934 - recall_m: 0.1435 - f1_m: 0.2367 - val_loss: 2.1060 - val_accuracy: 0.3723 - val_precision_m: 0.6283 - val_recall_m: 0.1363 - val_f1_m: 0.2224\n",
      "Epoch 28/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.0063 - accuracy: 0.3941 - precision_m: 0.6951 - recall_m: 0.1457 - f1_m: 0.2398\n",
      "Epoch 28: val_loss improved from 2.10595 to 2.09758, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 28\n",
      "Accuracy: 0.3737 | Precision: 0.6406 | Recall: 0.1388 | F1: 0.2263\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0065 - accuracy: 0.3940 - precision_m: 0.6951 - recall_m: 0.1458 - f1_m: 0.2399 - val_loss: 2.0976 - val_accuracy: 0.3737 - val_precision_m: 0.6406 - val_recall_m: 0.1388 - val_f1_m: 0.2263\n",
      "Epoch 29/30\n",
      "599/610 [============================>.] - ETA: 0s - loss: 2.0004 - accuracy: 0.3973 - precision_m: 0.6970 - recall_m: 0.1475 - f1_m: 0.2424\n",
      "Epoch 29: val_loss did not improve from 2.09758\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 29\n",
      "Accuracy: 0.3762 | Precision: 0.6217 | Recall: 0.1370 | F1: 0.2228\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0008 - accuracy: 0.3974 - precision_m: 0.6975 - recall_m: 0.1476 - f1_m: 0.2425 - val_loss: 2.1136 - val_accuracy: 0.3762 - val_precision_m: 0.6217 - val_recall_m: 0.1370 - val_f1_m: 0.2228\n",
      "Epoch 30/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 1.9989 - accuracy: 0.3970 - precision_m: 0.6970 - recall_m: 0.1487 - f1_m: 0.2440\n",
      "Epoch 30: val_loss improved from 2.09758 to 2.07804, saving model to trained_models/model_1_fold_5_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 30\n",
      "Accuracy: 0.3820 | Precision: 0.6575 | Recall: 0.1400 | F1: 0.2291\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9987 - accuracy: 0.3970 - precision_m: 0.6975 - recall_m: 0.1489 - f1_m: 0.2443 - val_loss: 2.0780 - val_accuracy: 0.3820 - val_precision_m: 0.6575 - val_recall_m: 0.1400 - val_f1_m: 0.2291\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 58.6 seconds (1.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 30.0%\n",
      "  Usage (max):  55.7%\n",
      "  Frequency:    3993 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.1%\n",
      "  Usage (max):  39.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  27.7%\n",
      "  Usage (max):   32.0%\n",
      "  Memory (mean): 1643 MB\n",
      "  Memory (max):  1643 MB\n",
      "  Power (mean):  45.4 W\n",
      "  Power (max):   47.6 W\n",
      "  Energy used:   0.738891 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 RESULTS\n",
      "================================================================================\n",
      "Validation:\n",
      "  Loss:      2.0780\n",
      "  Accuracy:  38.20%\n",
      "  Precision: 0.6575\n",
      "  Recall:    0.1400\n",
      "  F1 Score:  0.2291\n",
      "\n",
      "Test:\n",
      "  Loss:      2.0703\n",
      "  Accuracy:  37.14%\n",
      "  Precision: 0.6508\n",
      "  Recall:    0.1349\n",
      "  F1 Score:  0.2184\n",
      "\n",
      "Resources:\n",
      "  Duration:     58.6s (1.0m)\n",
      "  GPU Power:    45.4W (max: 47.6W)\n",
      "  Energy Used:  0.739Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 6 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Permission denied for /sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj. Run with sudo or add permissions.\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77987, Val=8298, Test=7371\n",
      "Epoch 1/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 3.1040 - accuracy: 0.1353 - precision_m: 0.1758 - recall_m: 0.0033 - f1_m: 0.0064\n",
      "Epoch 1: val_loss improved from inf to 2.64794, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2297 | Precision: 0.5171 | Recall: 0.0111 | F1: 0.0215\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 3s 3ms/step - loss: 3.1038 - accuracy: 0.1353 - precision_m: 0.1755 - recall_m: 0.0033 - f1_m: 0.0064 - val_loss: 2.6479 - val_accuracy: 0.2297 - val_precision_m: 0.5171 - val_recall_m: 0.0111 - val_f1_m: 0.0215\n",
      "Epoch 2/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 2.4658 - accuracy: 0.2845 - precision_m: 0.6761 - recall_m: 0.0438 - f1_m: 0.0811\n",
      "Epoch 2: val_loss improved from 2.64794 to 2.36041, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3238 | Precision: 0.7187 | Recall: 0.0754 | F1: 0.1350\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.4658 - accuracy: 0.2845 - precision_m: 0.6761 - recall_m: 0.0438 - f1_m: 0.0811 - val_loss: 2.3604 - val_accuracy: 0.3238 - val_precision_m: 0.7187 - val_recall_m: 0.0754 - val_f1_m: 0.1350\n",
      "Epoch 3/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.3053 - accuracy: 0.3307 - precision_m: 0.6913 - recall_m: 0.0840 - f1_m: 0.1490\n",
      "Epoch 3: val_loss improved from 2.36041 to 2.28421, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3376 | Precision: 0.6982 | Recall: 0.0948 | F1: 0.1652\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.3052 - accuracy: 0.3306 - precision_m: 0.6909 - recall_m: 0.0841 - f1_m: 0.1491 - val_loss: 2.2842 - val_accuracy: 0.3376 - val_precision_m: 0.6982 - val_recall_m: 0.0948 - val_f1_m: 0.1652\n",
      "Epoch 4/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 2.2254 - accuracy: 0.3533 - precision_m: 0.7025 - recall_m: 0.1036 - f1_m: 0.1795\n",
      "Epoch 4: val_loss improved from 2.28421 to 2.25117, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.3492 | Precision: 0.6505 | Recall: 0.1082 | F1: 0.1835\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2251 - accuracy: 0.3535 - precision_m: 0.7031 - recall_m: 0.1035 - f1_m: 0.1795 - val_loss: 2.2512 - val_accuracy: 0.3492 - val_precision_m: 0.6505 - val_recall_m: 0.1082 - val_f1_m: 0.1835\n",
      "Epoch 5/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 2.1722 - accuracy: 0.3700 - precision_m: 0.7036 - recall_m: 0.1162 - f1_m: 0.1984\n",
      "Epoch 5: val_loss improved from 2.25117 to 2.19583, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.3632 | Precision: 0.6770 | Recall: 0.1264 | F1: 0.2113\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1727 - accuracy: 0.3699 - precision_m: 0.7036 - recall_m: 0.1162 - f1_m: 0.1984 - val_loss: 2.1958 - val_accuracy: 0.3632 - val_precision_m: 0.6770 - val_recall_m: 0.1264 - val_f1_m: 0.2113\n",
      "Epoch 6/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.1318 - accuracy: 0.3793 - precision_m: 0.7088 - recall_m: 0.1282 - f1_m: 0.2160\n",
      "Epoch 6: val_loss improved from 2.19583 to 2.15158, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.3708 | Precision: 0.6815 | Recall: 0.1369 | F1: 0.2261\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1311 - accuracy: 0.3795 - precision_m: 0.7092 - recall_m: 0.1283 - f1_m: 0.2162 - val_loss: 2.1516 - val_accuracy: 0.3708 - val_precision_m: 0.6815 - val_recall_m: 0.1369 - val_f1_m: 0.2261\n",
      "Epoch 7/30\n",
      "600/610 [============================>.] - ETA: 0s - loss: 2.0979 - accuracy: 0.3882 - precision_m: 0.7080 - recall_m: 0.1364 - f1_m: 0.2278\n",
      "Epoch 7: val_loss improved from 2.15158 to 2.12763, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.3772 | Precision: 0.6818 | Recall: 0.1344 | F1: 0.2225\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0986 - accuracy: 0.3882 - precision_m: 0.7078 - recall_m: 0.1365 - f1_m: 0.2279 - val_loss: 2.1276 - val_accuracy: 0.3772 - val_precision_m: 0.6818 - val_recall_m: 0.1344 - val_f1_m: 0.2225\n",
      "Epoch 8/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.0702 - accuracy: 0.3952 - precision_m: 0.7144 - recall_m: 0.1439 - f1_m: 0.2385\n",
      "Epoch 8: val_loss improved from 2.12763 to 2.09880, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.3883 | Precision: 0.6894 | Recall: 0.1485 | F1: 0.2425\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0703 - accuracy: 0.3953 - precision_m: 0.7143 - recall_m: 0.1440 - f1_m: 0.2385 - val_loss: 2.0988 - val_accuracy: 0.3883 - val_precision_m: 0.6894 - val_recall_m: 0.1485 - val_f1_m: 0.2425\n",
      "Epoch 9/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 2.0483 - accuracy: 0.4012 - precision_m: 0.7129 - recall_m: 0.1524 - f1_m: 0.2500\n",
      "Epoch 9: val_loss improved from 2.09880 to 2.08527, saving model to trained_models/model_1_fold_6_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0484 - accuracy: 0.4012 - precision_m: 0.7124 - recall_m: 0.1522 - f1_m: 0.2497 - val_loss: 2.0853 - val_accuracy: 0.3860 - val_precision_m: 0.7019 - val_recall_m: 0.1446 - val_f1_m: 0.2372\n",
      "Epoch 10/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 2.0310 - accuracy: 0.4038 - precision_m: 0.7147 - recall_m: 0.1574 - f1_m: 0.2568\n",
      "Epoch 10: val_loss improved from 2.08527 to 2.07250, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.3891 | Precision: 0.6748 | Recall: 0.1561 | F1: 0.2514\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0310 - accuracy: 0.4038 - precision_m: 0.7147 - recall_m: 0.1574 - f1_m: 0.2568 - val_loss: 2.0725 - val_accuracy: 0.3891 - val_precision_m: 0.6748 - val_recall_m: 0.1561 - val_f1_m: 0.2514\n",
      "Epoch 11/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 2.0086 - accuracy: 0.4091 - precision_m: 0.7161 - recall_m: 0.1624 - f1_m: 0.2637\n",
      "Epoch 11: val_loss improved from 2.07250 to 2.04842, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.4008 | Precision: 0.6973 | Recall: 0.1574 | F1: 0.2547\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.0086 - accuracy: 0.4091 - precision_m: 0.7161 - recall_m: 0.1624 - f1_m: 0.2637 - val_loss: 2.0484 - val_accuracy: 0.4008 - val_precision_m: 0.6973 - val_recall_m: 0.1574 - val_f1_m: 0.2547\n",
      "Epoch 12/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.9937 - accuracy: 0.4140 - precision_m: 0.7161 - recall_m: 0.1687 - f1_m: 0.2721\n",
      "Epoch 12: val_loss improved from 2.04842 to 2.03486, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.4044 | Precision: 0.6868 | Recall: 0.1643 | F1: 0.2632\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9937 - accuracy: 0.4139 - precision_m: 0.7162 - recall_m: 0.1688 - f1_m: 0.2722 - val_loss: 2.0349 - val_accuracy: 0.4044 - val_precision_m: 0.6868 - val_recall_m: 0.1643 - val_f1_m: 0.2632\n",
      "Epoch 13/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 1.9790 - accuracy: 0.4173 - precision_m: 0.7133 - recall_m: 0.1714 - f1_m: 0.2752\n",
      "Epoch 13: val_loss did not improve from 2.03486\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9792 - accuracy: 0.4173 - precision_m: 0.7134 - recall_m: 0.1715 - f1_m: 0.2752 - val_loss: 2.0388 - val_accuracy: 0.4002 - val_precision_m: 0.6699 - val_recall_m: 0.1691 - val_f1_m: 0.2680\n",
      "Epoch 14/30\n",
      "597/610 [============================>.] - ETA: 0s - loss: 1.9733 - accuracy: 0.4185 - precision_m: 0.7107 - recall_m: 0.1756 - f1_m: 0.2804\n",
      "Epoch 14: val_loss did not improve from 2.03486\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9720 - accuracy: 0.4183 - precision_m: 0.7109 - recall_m: 0.1754 - f1_m: 0.2802 - val_loss: 2.0429 - val_accuracy: 0.3902 - val_precision_m: 0.6752 - val_recall_m: 0.1601 - val_f1_m: 0.2571\n",
      "Epoch 15/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 1.9593 - accuracy: 0.4227 - precision_m: 0.7139 - recall_m: 0.1775 - f1_m: 0.2833\n",
      "Epoch 15: val_loss improved from 2.03486 to 2.01137, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 15\n",
      "Accuracy: 0.4113 | Precision: 0.6881 | Recall: 0.1776 | F1: 0.2802\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9593 - accuracy: 0.4227 - precision_m: 0.7139 - recall_m: 0.1775 - f1_m: 0.2833 - val_loss: 2.0114 - val_accuracy: 0.4113 - val_precision_m: 0.6881 - val_recall_m: 0.1776 - val_f1_m: 0.2802\n",
      "Epoch 16/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.9521 - accuracy: 0.4234 - precision_m: 0.7069 - recall_m: 0.1824 - f1_m: 0.2889\n",
      "Epoch 16: val_loss improved from 2.01137 to 2.01077, saving model to trained_models/model_1_fold_6_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9519 - accuracy: 0.4234 - precision_m: 0.7066 - recall_m: 0.1823 - f1_m: 0.2887 - val_loss: 2.0108 - val_accuracy: 0.4044 - val_precision_m: 0.6776 - val_recall_m: 0.1711 - val_f1_m: 0.2712\n",
      "Epoch 17/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.9415 - accuracy: 0.4270 - precision_m: 0.7136 - recall_m: 0.1849 - f1_m: 0.2926\n",
      "Epoch 17: val_loss did not improve from 2.01077\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9423 - accuracy: 0.4268 - precision_m: 0.7134 - recall_m: 0.1850 - f1_m: 0.2927 - val_loss: 2.0139 - val_accuracy: 0.4066 - val_precision_m: 0.6902 - val_recall_m: 0.1774 - val_f1_m: 0.2805\n",
      "Epoch 18/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 1.9341 - accuracy: 0.4297 - precision_m: 0.7155 - recall_m: 0.1870 - f1_m: 0.2955\n",
      "Epoch 18: val_loss did not improve from 2.01077\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9345 - accuracy: 0.4297 - precision_m: 0.7154 - recall_m: 0.1872 - f1_m: 0.2957 - val_loss: 2.0115 - val_accuracy: 0.4031 - val_precision_m: 0.6767 - val_recall_m: 0.1766 - val_f1_m: 0.2778\n",
      "Epoch 19/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 1.9277 - accuracy: 0.4310 - precision_m: 0.7140 - recall_m: 0.1898 - f1_m: 0.2987\n",
      "Epoch 19: val_loss improved from 2.01077 to 1.99057, saving model to trained_models/model_1_fold_6_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9280 - accuracy: 0.4309 - precision_m: 0.7137 - recall_m: 0.1898 - f1_m: 0.2987 - val_loss: 1.9906 - val_accuracy: 0.4090 - val_precision_m: 0.6878 - val_recall_m: 0.1858 - val_f1_m: 0.2905\n",
      "Epoch 20/30\n",
      "597/610 [============================>.] - ETA: 0s - loss: 1.9202 - accuracy: 0.4335 - precision_m: 0.7149 - recall_m: 0.1900 - f1_m: 0.2990\n",
      "Epoch 20: val_loss did not improve from 1.99057\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9202 - accuracy: 0.4335 - precision_m: 0.7151 - recall_m: 0.1902 - f1_m: 0.2993 - val_loss: 2.0303 - val_accuracy: 0.4013 - val_precision_m: 0.6675 - val_recall_m: 0.1843 - val_f1_m: 0.2865\n",
      "Epoch 21/30\n",
      "600/610 [============================>.] - ETA: 0s - loss: 1.9190 - accuracy: 0.4329 - precision_m: 0.7106 - recall_m: 0.1932 - f1_m: 0.3028\n",
      "Epoch 21: val_loss did not improve from 1.99057\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 21\n",
      "Accuracy: 0.4155 | Precision: 0.6869 | Recall: 0.1891 | F1: 0.2942\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9192 - accuracy: 0.4327 - precision_m: 0.7100 - recall_m: 0.1930 - f1_m: 0.3024 - val_loss: 1.9931 - val_accuracy: 0.4155 - val_precision_m: 0.6869 - val_recall_m: 0.1891 - val_f1_m: 0.2942\n",
      "Epoch 22/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.9106 - accuracy: 0.4356 - precision_m: 0.7117 - recall_m: 0.1940 - f1_m: 0.3038\n",
      "Epoch 22: val_loss improved from 1.99057 to 1.98304, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 22\n",
      "Accuracy: 0.4172 | Precision: 0.6849 | Recall: 0.1856 | F1: 0.2896\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9106 - accuracy: 0.4356 - precision_m: 0.7119 - recall_m: 0.1942 - f1_m: 0.3041 - val_loss: 1.9830 - val_accuracy: 0.4172 - val_precision_m: 0.6849 - val_recall_m: 0.1856 - val_f1_m: 0.2896\n",
      "Epoch 23/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.9062 - accuracy: 0.4367 - precision_m: 0.7138 - recall_m: 0.1973 - f1_m: 0.3080\n",
      "Epoch 23: val_loss did not improve from 1.98304\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9060 - accuracy: 0.4367 - precision_m: 0.7136 - recall_m: 0.1975 - f1_m: 0.3082 - val_loss: 2.0109 - val_accuracy: 0.4047 - val_precision_m: 0.6857 - val_recall_m: 0.1773 - val_f1_m: 0.2797\n",
      "Epoch 24/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 1.9071 - accuracy: 0.4350 - precision_m: 0.7132 - recall_m: 0.1968 - f1_m: 0.3074\n",
      "Epoch 24: val_loss improved from 1.98304 to 1.97683, saving model to trained_models/model_1_fold_6_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.9071 - accuracy: 0.4351 - precision_m: 0.7131 - recall_m: 0.1969 - f1_m: 0.3075 - val_loss: 1.9768 - val_accuracy: 0.4148 - val_precision_m: 0.6816 - val_recall_m: 0.1836 - val_f1_m: 0.2868\n",
      "Epoch 25/30\n",
      "598/610 [============================>.] - ETA: 0s - loss: 1.8954 - accuracy: 0.4368 - precision_m: 0.7151 - recall_m: 0.1992 - f1_m: 0.3105\n",
      "Epoch 25: val_loss improved from 1.97683 to 1.95958, saving model to trained_models/model_1_fold_6_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.4207 | Precision: 0.6938 | Recall: 0.1851 | F1: 0.2899\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.8951 - accuracy: 0.4370 - precision_m: 0.7154 - recall_m: 0.1993 - f1_m: 0.3106 - val_loss: 1.9596 - val_accuracy: 0.4207 - val_precision_m: 0.6938 - val_recall_m: 0.1851 - val_f1_m: 0.2899\n",
      "Epoch 26/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 1.8951 - accuracy: 0.4412 - precision_m: 0.7134 - recall_m: 0.2009 - f1_m: 0.3124\n",
      "Epoch 26: val_loss did not improve from 1.95958\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.8949 - accuracy: 0.4411 - precision_m: 0.7134 - recall_m: 0.2010 - f1_m: 0.3125 - val_loss: 1.9849 - val_accuracy: 0.4140 - val_precision_m: 0.6737 - val_recall_m: 0.1981 - val_f1_m: 0.3037\n",
      "Epoch 27/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 1.8887 - accuracy: 0.4403 - precision_m: 0.7146 - recall_m: 0.2042 - f1_m: 0.3165\n",
      "Epoch 27: val_loss did not improve from 1.95958\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.8885 - accuracy: 0.4402 - precision_m: 0.7139 - recall_m: 0.2041 - f1_m: 0.3163 - val_loss: 1.9811 - val_accuracy: 0.4162 - val_precision_m: 0.6809 - val_recall_m: 0.1991 - val_f1_m: 0.3056\n",
      "Epoch 28/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 1.8868 - accuracy: 0.4417 - precision_m: 0.7143 - recall_m: 0.2037 - f1_m: 0.3158\n",
      "Epoch 28: val_loss did not improve from 1.95958\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.8868 - accuracy: 0.4417 - precision_m: 0.7143 - recall_m: 0.2037 - f1_m: 0.3158 - val_loss: 2.0053 - val_accuracy: 0.4081 - val_precision_m: 0.6783 - val_recall_m: 0.1909 - val_f1_m: 0.2956\n",
      "Epoch 29/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 1.8825 - accuracy: 0.4415 - precision_m: 0.7139 - recall_m: 0.2052 - f1_m: 0.3177\n",
      "Epoch 29: val_loss did not improve from 1.95958\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.8836 - accuracy: 0.4413 - precision_m: 0.7137 - recall_m: 0.2048 - f1_m: 0.3172 - val_loss: 1.9632 - val_accuracy: 0.4200 - val_precision_m: 0.6709 - val_recall_m: 0.1929 - val_f1_m: 0.2976\n",
      "Epoch 30/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 1.8776 - accuracy: 0.4440 - precision_m: 0.7154 - recall_m: 0.2057 - f1_m: 0.3182\n",
      "Epoch 30: val_loss did not improve from 1.95958\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 1.8777 - accuracy: 0.4439 - precision_m: 0.7157 - recall_m: 0.2057 - f1_m: 0.3184 - val_loss: 2.0007 - val_accuracy: 0.4087 - val_precision_m: 0.6657 - val_recall_m: 0.2035 - val_f1_m: 0.3094\n",
      "Epoch 30: early stopping\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 58.6 seconds (1.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 29.9%\n",
      "  Usage (max):  43.7%\n",
      "  Frequency:    3970 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.1%\n",
      "  Usage (max):  40.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  27.8%\n",
      "  Usage (max):   32.0%\n",
      "  Memory (mean): 1642 MB\n",
      "  Memory (max):  1643 MB\n",
      "  Power (mean):  45.3 W\n",
      "  Power (max):   48.1 W\n",
      "  Energy used:   0.737607 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 RESULTS\n",
      "================================================================================\n",
      "Validation:\n",
      "  Loss:      1.9596\n",
      "  Accuracy:  42.07%\n",
      "  Precision: 0.6938\n",
      "  Recall:    0.1851\n",
      "  F1 Score:  0.2899\n",
      "\n",
      "Test:\n",
      "  Loss:      1.9847\n",
      "  Accuracy:  42.12%\n",
      "  Precision: 0.6777\n",
      "  Recall:    0.1828\n",
      "  F1 Score:  0.2812\n",
      "\n",
      "Resources:\n",
      "  Duration:     58.6s (1.0m)\n",
      "  GPU Power:    45.3W (max: 48.1W)\n",
      "  Energy Used:  0.738Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 7 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Permission denied for /sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj. Run with sudo or add permissions.\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=78139, Val=8252, Test=7309\n",
      "Epoch 1/30\n",
      "610/611 [============================>.] - ETA: 0s - loss: 3.0625 - accuracy: 0.1405 - precision_m: 0.2487 - recall_m: 0.0048 - f1_m: 0.0093\n",
      "Epoch 1: val_loss improved from inf to 2.63728, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2256 | Precision: 0.4913 | Recall: 0.0197 | F1: 0.0376\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 3s 3ms/step - loss: 3.0621 - accuracy: 0.1405 - precision_m: 0.2491 - recall_m: 0.0048 - f1_m: 0.0093 - val_loss: 2.6373 - val_accuracy: 0.2256 - val_precision_m: 0.4913 - val_recall_m: 0.0197 - val_f1_m: 0.0376\n",
      "Epoch 2/30\n",
      "607/611 [============================>.] - ETA: 0s - loss: 2.4575 - accuracy: 0.2721 - precision_m: 0.6391 - recall_m: 0.0309 - f1_m: 0.0583\n",
      "Epoch 2: val_loss improved from 2.63728 to 2.39761, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.2939 | Precision: 0.6181 | Recall: 0.0516 | F1: 0.0944\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 2.4569 - accuracy: 0.2722 - precision_m: 0.6390 - recall_m: 0.0310 - f1_m: 0.0586 - val_loss: 2.3976 - val_accuracy: 0.2939 - val_precision_m: 0.6181 - val_recall_m: 0.0516 - val_f1_m: 0.0944\n",
      "Epoch 3/30\n",
      "598/611 [============================>.] - ETA: 0s - loss: 2.3056 - accuracy: 0.3138 - precision_m: 0.6617 - recall_m: 0.0580 - f1_m: 0.1059\n",
      "Epoch 3: val_loss improved from 2.39761 to 2.28757, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3285 | Precision: 0.6497 | Recall: 0.0628 | F1: 0.1131\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 2.3048 - accuracy: 0.3141 - precision_m: 0.6627 - recall_m: 0.0583 - f1_m: 0.1065 - val_loss: 2.2876 - val_accuracy: 0.3285 - val_precision_m: 0.6497 - val_recall_m: 0.0628 - val_f1_m: 0.1131\n",
      "Epoch 4/30\n",
      "609/611 [============================>.] - ETA: 0s - loss: 2.2143 - accuracy: 0.3411 - precision_m: 0.6736 - recall_m: 0.0788 - f1_m: 0.1401\n",
      "Epoch 4: val_loss improved from 2.28757 to 2.23766, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.3445 | Precision: 0.6463 | Recall: 0.0787 | F1: 0.1384\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 2.2141 - accuracy: 0.3411 - precision_m: 0.6741 - recall_m: 0.0788 - f1_m: 0.1402 - val_loss: 2.2377 - val_accuracy: 0.3445 - val_precision_m: 0.6463 - val_recall_m: 0.0787 - val_f1_m: 0.1384\n",
      "Epoch 5/30\n",
      "608/611 [============================>.] - ETA: 0s - loss: 2.1440 - accuracy: 0.3600 - precision_m: 0.6806 - recall_m: 0.0974 - f1_m: 0.1694\n",
      "Epoch 5: val_loss improved from 2.23766 to 2.19713, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.3531 | Precision: 0.6263 | Recall: 0.0986 | F1: 0.1684\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 2.1442 - accuracy: 0.3599 - precision_m: 0.6801 - recall_m: 0.0972 - f1_m: 0.1692 - val_loss: 2.1971 - val_accuracy: 0.3531 - val_precision_m: 0.6263 - val_recall_m: 0.0986 - val_f1_m: 0.1684\n",
      "Epoch 6/30\n",
      "603/611 [============================>.] - ETA: 0s - loss: 2.0975 - accuracy: 0.3727 - precision_m: 0.6779 - recall_m: 0.1136 - f1_m: 0.1936\n",
      "Epoch 6: val_loss improved from 2.19713 to 2.14469, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.3640 | Precision: 0.6518 | Recall: 0.1092 | F1: 0.1853\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 2.0972 - accuracy: 0.3727 - precision_m: 0.6779 - recall_m: 0.1137 - f1_m: 0.1937 - val_loss: 2.1447 - val_accuracy: 0.3640 - val_precision_m: 0.6518 - val_recall_m: 0.1092 - val_f1_m: 0.1853\n",
      "Epoch 7/30\n",
      "604/611 [============================>.] - ETA: 0s - loss: 2.0620 - accuracy: 0.3841 - precision_m: 0.6817 - recall_m: 0.1259 - f1_m: 0.2116\n",
      "Epoch 7: val_loss improved from 2.14469 to 2.12874, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.3667 | Precision: 0.6475 | Recall: 0.1155 | F1: 0.1944\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 2.0620 - accuracy: 0.3839 - precision_m: 0.6815 - recall_m: 0.1258 - f1_m: 0.2115 - val_loss: 2.1287 - val_accuracy: 0.3667 - val_precision_m: 0.6475 - val_recall_m: 0.1155 - val_f1_m: 0.1944\n",
      "Epoch 8/30\n",
      "605/611 [============================>.] - ETA: 0s - loss: 2.0350 - accuracy: 0.3909 - precision_m: 0.6818 - recall_m: 0.1342 - f1_m: 0.2233\n",
      "Epoch 8: val_loss improved from 2.12874 to 2.10074, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.3754 | Precision: 0.6380 | Recall: 0.1343 | F1: 0.2201\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 2.0350 - accuracy: 0.3910 - precision_m: 0.6823 - recall_m: 0.1343 - f1_m: 0.2234 - val_loss: 2.1007 - val_accuracy: 0.3754 - val_precision_m: 0.6380 - val_recall_m: 0.1343 - val_f1_m: 0.2201\n",
      "Epoch 9/30\n",
      "596/611 [============================>.] - ETA: 0s - loss: 2.0142 - accuracy: 0.3953 - precision_m: 0.6885 - recall_m: 0.1441 - f1_m: 0.2372\n",
      "Epoch 9: val_loss did not improve from 2.10074\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 2.0144 - accuracy: 0.3954 - precision_m: 0.6883 - recall_m: 0.1438 - f1_m: 0.2367 - val_loss: 2.1212 - val_accuracy: 0.3728 - val_precision_m: 0.6323 - val_recall_m: 0.1267 - val_f1_m: 0.2096\n",
      "Epoch 10/30\n",
      "602/611 [============================>.] - ETA: 0s - loss: 2.0007 - accuracy: 0.3995 - precision_m: 0.6862 - recall_m: 0.1494 - f1_m: 0.2443\n",
      "Epoch 10: val_loss improved from 2.10074 to 2.08237, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.3792 | Precision: 0.6363 | Recall: 0.1471 | F1: 0.2373\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 2.0003 - accuracy: 0.3999 - precision_m: 0.6867 - recall_m: 0.1496 - f1_m: 0.2446 - val_loss: 2.0824 - val_accuracy: 0.3792 - val_precision_m: 0.6363 - val_recall_m: 0.1471 - val_f1_m: 0.2373\n",
      "Epoch 11/30\n",
      "593/611 [============================>.] - ETA: 0s - loss: 1.9874 - accuracy: 0.4062 - precision_m: 0.6918 - recall_m: 0.1566 - f1_m: 0.2544\n",
      "Epoch 11: val_loss improved from 2.08237 to 2.07167, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.3865 | Precision: 0.6395 | Recall: 0.1507 | F1: 0.2422\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9874 - accuracy: 0.4058 - precision_m: 0.6915 - recall_m: 0.1563 - f1_m: 0.2540 - val_loss: 2.0717 - val_accuracy: 0.3865 - val_precision_m: 0.6395 - val_recall_m: 0.1507 - val_f1_m: 0.2422\n",
      "Epoch 12/30\n",
      "603/611 [============================>.] - ETA: 0s - loss: 1.9731 - accuracy: 0.4078 - precision_m: 0.6902 - recall_m: 0.1613 - f1_m: 0.2605\n",
      "Epoch 12: val_loss improved from 2.07167 to 2.07138, saving model to trained_models/model_1_fold_7_best.h5\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9743 - accuracy: 0.4076 - precision_m: 0.6895 - recall_m: 0.1612 - f1_m: 0.2602 - val_loss: 2.0714 - val_accuracy: 0.3850 - val_precision_m: 0.6478 - val_recall_m: 0.1303 - val_f1_m: 0.2153\n",
      "Epoch 13/30\n",
      "605/611 [============================>.] - ETA: 0s - loss: 1.9633 - accuracy: 0.4118 - precision_m: 0.7001 - recall_m: 0.1659 - f1_m: 0.2672\n",
      "Epoch 13: val_loss improved from 2.07138 to 2.07075, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 13\n",
      "Accuracy: 0.3897 | Precision: 0.6612 | Recall: 0.1428 | F1: 0.2334\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9637 - accuracy: 0.4116 - precision_m: 0.7003 - recall_m: 0.1659 - f1_m: 0.2672 - val_loss: 2.0707 - val_accuracy: 0.3897 - val_precision_m: 0.6612 - val_recall_m: 0.1428 - val_f1_m: 0.2334\n",
      "Epoch 14/30\n",
      "608/611 [============================>.] - ETA: 0s - loss: 1.9546 - accuracy: 0.4146 - precision_m: 0.7011 - recall_m: 0.1709 - f1_m: 0.2736\n",
      "Epoch 14: val_loss improved from 2.07075 to 2.04120, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.3905 | Precision: 0.6555 | Recall: 0.1619 | F1: 0.2578\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9548 - accuracy: 0.4147 - precision_m: 0.7012 - recall_m: 0.1708 - f1_m: 0.2736 - val_loss: 2.0412 - val_accuracy: 0.3905 - val_precision_m: 0.6555 - val_recall_m: 0.1619 - val_f1_m: 0.2578\n",
      "Epoch 15/30\n",
      "606/611 [============================>.] - ETA: 0s - loss: 1.9458 - accuracy: 0.4163 - precision_m: 0.6997 - recall_m: 0.1725 - f1_m: 0.2757\n",
      "Epoch 15: val_loss did not improve from 2.04120\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9459 - accuracy: 0.4164 - precision_m: 0.6998 - recall_m: 0.1726 - f1_m: 0.2757 - val_loss: 2.0898 - val_accuracy: 0.3793 - val_precision_m: 0.6218 - val_recall_m: 0.1630 - val_f1_m: 0.2565\n",
      "Epoch 16/30\n",
      "611/611 [==============================] - ETA: 0s - loss: 1.9348 - accuracy: 0.4206 - precision_m: 0.7021 - recall_m: 0.1778 - f1_m: 0.2826\n",
      "Epoch 16: val_loss did not improve from 2.04120\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.3946 | Precision: 0.6471 | Recall: 0.1691 | F1: 0.2663\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9348 - accuracy: 0.4206 - precision_m: 0.7021 - recall_m: 0.1778 - f1_m: 0.2826 - val_loss: 2.0576 - val_accuracy: 0.3946 - val_precision_m: 0.6471 - val_recall_m: 0.1691 - val_f1_m: 0.2663\n",
      "Epoch 17/30\n",
      "606/611 [============================>.] - ETA: 0s - loss: 1.9328 - accuracy: 0.4231 - precision_m: 0.7029 - recall_m: 0.1802 - f1_m: 0.2859\n",
      "Epoch 17: val_loss improved from 2.04120 to 2.02691, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.3997 | Precision: 0.6577 | Recall: 0.1563 | F1: 0.2511\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9325 - accuracy: 0.4231 - precision_m: 0.7031 - recall_m: 0.1803 - f1_m: 0.2860 - val_loss: 2.0269 - val_accuracy: 0.3997 - val_precision_m: 0.6577 - val_recall_m: 0.1563 - val_f1_m: 0.2511\n",
      "Epoch 18/30\n",
      "606/611 [============================>.] - ETA: 0s - loss: 1.9228 - accuracy: 0.4260 - precision_m: 0.7034 - recall_m: 0.1847 - f1_m: 0.2915\n",
      "Epoch 18: val_loss improved from 2.02691 to 2.02365, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.4044 | Precision: 0.6634 | Recall: 0.1651 | F1: 0.2628\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9235 - accuracy: 0.4257 - precision_m: 0.7030 - recall_m: 0.1846 - f1_m: 0.2913 - val_loss: 2.0236 - val_accuracy: 0.4044 - val_precision_m: 0.6634 - val_recall_m: 0.1651 - val_f1_m: 0.2628\n",
      "Epoch 19/30\n",
      "608/611 [============================>.] - ETA: 0s - loss: 1.9151 - accuracy: 0.4276 - precision_m: 0.7059 - recall_m: 0.1862 - f1_m: 0.2936\n",
      "Epoch 19: val_loss did not improve from 2.02365\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9150 - accuracy: 0.4275 - precision_m: 0.7060 - recall_m: 0.1863 - f1_m: 0.2938 - val_loss: 2.0253 - val_accuracy: 0.4016 - val_precision_m: 0.6410 - val_recall_m: 0.1763 - val_f1_m: 0.2750\n",
      "Epoch 20/30\n",
      "611/611 [==============================] - ETA: 0s - loss: 1.9114 - accuracy: 0.4301 - precision_m: 0.7073 - recall_m: 0.1893 - f1_m: 0.2976\n",
      "Epoch 20: val_loss did not improve from 2.02365\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9114 - accuracy: 0.4301 - precision_m: 0.7073 - recall_m: 0.1893 - f1_m: 0.2976 - val_loss: 2.0355 - val_accuracy: 0.3958 - val_precision_m: 0.6396 - val_recall_m: 0.1775 - val_f1_m: 0.2764\n",
      "Epoch 21/30\n",
      "609/611 [============================>.] - ETA: 0s - loss: 1.9057 - accuracy: 0.4318 - precision_m: 0.7069 - recall_m: 0.1916 - f1_m: 0.3004\n",
      "Epoch 21: val_loss improved from 2.02365 to 1.99001, saving model to trained_models/model_1_fold_7_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 21\n",
      "Accuracy: 0.4124 | Precision: 0.6736 | Recall: 0.1752 | F1: 0.2764\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.9058 - accuracy: 0.4318 - precision_m: 0.7066 - recall_m: 0.1916 - f1_m: 0.3003 - val_loss: 1.9900 - val_accuracy: 0.4124 - val_precision_m: 0.6736 - val_recall_m: 0.1752 - val_f1_m: 0.2764\n",
      "Epoch 22/30\n",
      "605/611 [============================>.] - ETA: 0s - loss: 1.8996 - accuracy: 0.4337 - precision_m: 0.7098 - recall_m: 0.1951 - f1_m: 0.3049\n",
      "Epoch 22: val_loss did not improve from 1.99001\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.8994 - accuracy: 0.4338 - precision_m: 0.7095 - recall_m: 0.1951 - f1_m: 0.3049 - val_loss: 2.0265 - val_accuracy: 0.3992 - val_precision_m: 0.6527 - val_recall_m: 0.1756 - val_f1_m: 0.2751\n",
      "Epoch 23/30\n",
      "594/611 [============================>.] - ETA: 0s - loss: 1.8927 - accuracy: 0.4333 - precision_m: 0.7089 - recall_m: 0.1968 - f1_m: 0.3070\n",
      "Epoch 23: val_loss did not improve from 1.99001\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.8924 - accuracy: 0.4337 - precision_m: 0.7091 - recall_m: 0.1971 - f1_m: 0.3074 - val_loss: 2.0094 - val_accuracy: 0.4101 - val_precision_m: 0.6579 - val_recall_m: 0.1943 - val_f1_m: 0.2983\n",
      "Epoch 24/30\n",
      "602/611 [============================>.] - ETA: 0s - loss: 1.8932 - accuracy: 0.4360 - precision_m: 0.7102 - recall_m: 0.1976 - f1_m: 0.3081\n",
      "Epoch 24: val_loss did not improve from 1.99001\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 24\n",
      "Accuracy: 0.4187 | Precision: 0.6721 | Recall: 0.1838 | F1: 0.2870\n",
      "================================================================================\n",
      "\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.8927 - accuracy: 0.4363 - precision_m: 0.7106 - recall_m: 0.1981 - f1_m: 0.3087 - val_loss: 1.9938 - val_accuracy: 0.4187 - val_precision_m: 0.6721 - val_recall_m: 0.1838 - val_f1_m: 0.2870\n",
      "Epoch 25/30\n",
      "603/611 [============================>.] - ETA: 0s - loss: 1.8881 - accuracy: 0.4369 - precision_m: 0.7103 - recall_m: 0.2004 - f1_m: 0.3115\n",
      "Epoch 25: val_loss did not improve from 1.99001\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.8888 - accuracy: 0.4368 - precision_m: 0.7099 - recall_m: 0.2003 - f1_m: 0.3114 - val_loss: 2.0025 - val_accuracy: 0.4111 - val_precision_m: 0.6667 - val_recall_m: 0.1738 - val_f1_m: 0.2741\n",
      "Epoch 26/30\n",
      "596/611 [============================>.] - ETA: 0s - loss: 1.8815 - accuracy: 0.4378 - precision_m: 0.7110 - recall_m: 0.2024 - f1_m: 0.3140\n",
      "Epoch 26: val_loss did not improve from 1.99001\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "611/611 [==============================] - 2s 3ms/step - loss: 1.8811 - accuracy: 0.4380 - precision_m: 0.7112 - recall_m: 0.2022 - f1_m: 0.3137 - val_loss: 2.0045 - val_accuracy: 0.4177 - val_precision_m: 0.6626 - val_recall_m: 0.1896 - val_f1_m: 0.2932\n",
      "Epoch 26: early stopping\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 50.9 seconds (0.8 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 30.7%\n",
      "  Usage (max):  38.0%\n",
      "  Frequency:    3983 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.6%\n",
      "  Usage (max):  40.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  27.2%\n",
      "  Usage (max):   32.0%\n",
      "  Memory (mean): 1641 MB\n",
      "  Memory (max):  1641 MB\n",
      "  Power (mean):  45.4 W\n",
      "  Power (max):   47.2 W\n",
      "  Energy used:   0.641216 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 RESULTS\n",
      "================================================================================\n",
      "Validation:\n",
      "  Loss:      1.9900\n",
      "  Accuracy:  41.24%\n",
      "  Precision: 0.6721\n",
      "  Recall:    0.1838\n",
      "  F1 Score:  0.2870\n",
      "\n",
      "Test:\n",
      "  Loss:      1.9964\n",
      "  Accuracy:  41.40%\n",
      "  Precision: 0.6888\n",
      "  Recall:    0.1850\n",
      "  F1 Score:  0.2862\n",
      "\n",
      "Resources:\n",
      "  Duration:     50.9s (0.8m)\n",
      "  GPU Power:    45.4W (max: 47.2W)\n",
      "  Energy Used:  0.641Wh\n",
      "\n",
      "  Early stopping triggered at epoch 26/30\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 8 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Permission denied for /sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj. Run with sudo or add permissions.\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77895, Val=8304, Test=7432\n",
      "Epoch 1/30\n",
      "597/609 [============================>.] - ETA: 0s - loss: 2.9798 - accuracy: 0.1738 - precision_m: 0.3408 - recall_m: 0.0095 - f1_m: 0.0183\n",
      "Epoch 1: val_loss improved from inf to 2.56558, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2643 | Precision: 0.6222 | Recall: 0.0395 | F1: 0.0733\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 3s 3ms/step - loss: 2.9707 - accuracy: 0.1755 - precision_m: 0.3475 - recall_m: 0.0100 - f1_m: 0.0193 - val_loss: 2.5656 - val_accuracy: 0.2643 - val_precision_m: 0.6222 - val_recall_m: 0.0395 - val_f1_m: 0.0733\n",
      "Epoch 2/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 2.4305 - accuracy: 0.2909 - precision_m: 0.6705 - recall_m: 0.0505 - f1_m: 0.0930\n",
      "Epoch 2: val_loss improved from 2.56558 to 2.35816, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3170 | Precision: 0.6543 | Recall: 0.0688 | F1: 0.1234\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.4305 - accuracy: 0.2908 - precision_m: 0.6705 - recall_m: 0.0506 - f1_m: 0.0932 - val_loss: 2.3582 - val_accuracy: 0.3170 - val_precision_m: 0.6543 - val_recall_m: 0.0688 - val_f1_m: 0.1234\n",
      "Epoch 3/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 2.2667 - accuracy: 0.3376 - precision_m: 0.6911 - recall_m: 0.0901 - f1_m: 0.1585\n",
      "Epoch 3: val_loss improved from 2.35816 to 2.32581, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3312 | Precision: 0.6752 | Recall: 0.0964 | F1: 0.1672\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.2662 - accuracy: 0.3377 - precision_m: 0.6912 - recall_m: 0.0902 - f1_m: 0.1585 - val_loss: 2.3258 - val_accuracy: 0.3312 - val_precision_m: 0.6752 - val_recall_m: 0.0964 - val_f1_m: 0.1672\n",
      "Epoch 4/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 2.1930 - accuracy: 0.3573 - precision_m: 0.6983 - recall_m: 0.1100 - f1_m: 0.1890\n",
      "Epoch 4: val_loss improved from 2.32581 to 2.23881, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.3433 | Precision: 0.6771 | Recall: 0.1179 | F1: 0.1992\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.1931 - accuracy: 0.3572 - precision_m: 0.6983 - recall_m: 0.1101 - f1_m: 0.1892 - val_loss: 2.2388 - val_accuracy: 0.3433 - val_precision_m: 0.6771 - val_recall_m: 0.1179 - val_f1_m: 0.1992\n",
      "Epoch 5/30\n",
      "603/609 [============================>.] - ETA: 0s - loss: 2.1471 - accuracy: 0.3690 - precision_m: 0.7031 - recall_m: 0.1246 - f1_m: 0.2106\n",
      "Epoch 5: val_loss improved from 2.23881 to 2.18963, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.3537 | Precision: 0.6791 | Recall: 0.1090 | F1: 0.1863\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.1471 - accuracy: 0.3690 - precision_m: 0.7027 - recall_m: 0.1245 - f1_m: 0.2104 - val_loss: 2.1896 - val_accuracy: 0.3537 - val_precision_m: 0.6791 - val_recall_m: 0.1090 - val_f1_m: 0.1863\n",
      "Epoch 6/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 2.1076 - accuracy: 0.3796 - precision_m: 0.7112 - recall_m: 0.1357 - f1_m: 0.2269\n",
      "Epoch 6: val_loss improved from 2.18963 to 2.14352, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.3681 | Precision: 0.6960 | Recall: 0.1367 | F1: 0.2263\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.1079 - accuracy: 0.3795 - precision_m: 0.7112 - recall_m: 0.1357 - f1_m: 0.2268 - val_loss: 2.1435 - val_accuracy: 0.3681 - val_precision_m: 0.6960 - val_recall_m: 0.1367 - val_f1_m: 0.2263\n",
      "Epoch 7/30\n",
      "600/609 [============================>.] - ETA: 0s - loss: 2.0702 - accuracy: 0.3913 - precision_m: 0.7189 - recall_m: 0.1472 - f1_m: 0.2433\n",
      "Epoch 7: val_loss did not improve from 2.14352\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0701 - accuracy: 0.3913 - precision_m: 0.7188 - recall_m: 0.1474 - f1_m: 0.2435 - val_loss: 2.1436 - val_accuracy: 0.3664 - val_precision_m: 0.6692 - val_recall_m: 0.1434 - val_f1_m: 0.2343\n",
      "Epoch 8/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 2.0436 - accuracy: 0.3965 - precision_m: 0.7212 - recall_m: 0.1573 - f1_m: 0.2572\n",
      "Epoch 8: val_loss improved from 2.14352 to 2.08674, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 8\n",
      "Accuracy: 0.3885 | Precision: 0.6795 | Recall: 0.1587 | F1: 0.2555\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0436 - accuracy: 0.3965 - precision_m: 0.7211 - recall_m: 0.1573 - f1_m: 0.2572 - val_loss: 2.0867 - val_accuracy: 0.3885 - val_precision_m: 0.6795 - val_recall_m: 0.1587 - val_f1_m: 0.2555\n",
      "Epoch 9/30\n",
      "596/609 [============================>.] - ETA: 0s - loss: 2.0166 - accuracy: 0.4037 - precision_m: 0.7199 - recall_m: 0.1666 - f1_m: 0.2695\n",
      "Epoch 9: val_loss did not improve from 2.08674\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0152 - accuracy: 0.4039 - precision_m: 0.7201 - recall_m: 0.1669 - f1_m: 0.2698 - val_loss: 2.0879 - val_accuracy: 0.3884 - val_precision_m: 0.6765 - val_recall_m: 0.1678 - val_f1_m: 0.2668\n",
      "Epoch 10/30\n",
      "601/609 [============================>.] - ETA: 0s - loss: 1.9969 - accuracy: 0.4101 - precision_m: 0.7216 - recall_m: 0.1754 - f1_m: 0.2810\n",
      "Epoch 10: val_loss improved from 2.08674 to 2.05513, saving model to trained_models/model_1_fold_8_best.h5\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9967 - accuracy: 0.4102 - precision_m: 0.7218 - recall_m: 0.1756 - f1_m: 0.2813 - val_loss: 2.0551 - val_accuracy: 0.3881 - val_precision_m: 0.6921 - val_recall_m: 0.1685 - val_f1_m: 0.2692\n",
      "Epoch 11/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.9736 - accuracy: 0.4154 - precision_m: 0.7277 - recall_m: 0.1838 - f1_m: 0.2923\n",
      "Epoch 11: val_loss improved from 2.05513 to 2.03631, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.3934 | Precision: 0.7009 | Recall: 0.1708 | F1: 0.2726\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9743 - accuracy: 0.4153 - precision_m: 0.7281 - recall_m: 0.1838 - f1_m: 0.2924 - val_loss: 2.0363 - val_accuracy: 0.3934 - val_precision_m: 0.7009 - val_recall_m: 0.1708 - val_f1_m: 0.2726\n",
      "Epoch 12/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.9634 - accuracy: 0.4179 - precision_m: 0.7260 - recall_m: 0.1882 - f1_m: 0.2978\n",
      "Epoch 12: val_loss did not improve from 2.03631\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9632 - accuracy: 0.4179 - precision_m: 0.7264 - recall_m: 0.1883 - f1_m: 0.2979 - val_loss: 2.0382 - val_accuracy: 0.3932 - val_precision_m: 0.6784 - val_recall_m: 0.1692 - val_f1_m: 0.2686\n",
      "Epoch 13/30\n",
      "594/609 [============================>.] - ETA: 0s - loss: 1.9443 - accuracy: 0.4249 - precision_m: 0.7307 - recall_m: 0.1938 - f1_m: 0.3051\n",
      "Epoch 13: val_loss improved from 2.03631 to 2.02947, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 13\n",
      "Accuracy: 0.3972 | Precision: 0.6841 | Recall: 0.1891 | F1: 0.2940\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9448 - accuracy: 0.4252 - precision_m: 0.7311 - recall_m: 0.1943 - f1_m: 0.3057 - val_loss: 2.0295 - val_accuracy: 0.3972 - val_precision_m: 0.6841 - val_recall_m: 0.1891 - val_f1_m: 0.2940\n",
      "Epoch 14/30\n",
      "594/609 [============================>.] - ETA: 0s - loss: 1.9400 - accuracy: 0.4241 - precision_m: 0.7231 - recall_m: 0.1980 - f1_m: 0.3097\n",
      "Epoch 14: val_loss improved from 2.02947 to 2.01279, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.4038 | Precision: 0.6887 | Recall: 0.1925 | F1: 0.2989\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9397 - accuracy: 0.4242 - precision_m: 0.7236 - recall_m: 0.1977 - f1_m: 0.3094 - val_loss: 2.0128 - val_accuracy: 0.4038 - val_precision_m: 0.6887 - val_recall_m: 0.1925 - val_f1_m: 0.2989\n",
      "Epoch 15/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 1.9249 - accuracy: 0.4302 - precision_m: 0.7277 - recall_m: 0.2034 - f1_m: 0.3168\n",
      "Epoch 15: val_loss improved from 2.01279 to 2.00188, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 15\n",
      "Accuracy: 0.4069 | Precision: 0.7043 | Recall: 0.1892 | F1: 0.2963\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9252 - accuracy: 0.4301 - precision_m: 0.7275 - recall_m: 0.2033 - f1_m: 0.3166 - val_loss: 2.0019 - val_accuracy: 0.4069 - val_precision_m: 0.7043 - val_recall_m: 0.1892 - val_f1_m: 0.2963\n",
      "Epoch 16/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.9194 - accuracy: 0.4304 - precision_m: 0.7279 - recall_m: 0.2056 - f1_m: 0.3195\n",
      "Epoch 16: val_loss did not improve from 2.00188\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.4078 | Precision: 0.6829 | Recall: 0.1979 | F1: 0.3050\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9194 - accuracy: 0.4304 - precision_m: 0.7278 - recall_m: 0.2057 - f1_m: 0.3196 - val_loss: 2.0097 - val_accuracy: 0.4078 - val_precision_m: 0.6829 - val_recall_m: 0.1979 - val_f1_m: 0.3050\n",
      "Epoch 17/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 1.9099 - accuracy: 0.4338 - precision_m: 0.7275 - recall_m: 0.2088 - f1_m: 0.3233\n",
      "Epoch 17: val_loss did not improve from 2.00188\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9105 - accuracy: 0.4337 - precision_m: 0.7276 - recall_m: 0.2089 - f1_m: 0.3235 - val_loss: 2.0042 - val_accuracy: 0.4056 - val_precision_m: 0.6831 - val_recall_m: 0.1980 - val_f1_m: 0.3049\n",
      "Epoch 18/30\n",
      "599/609 [============================>.] - ETA: 0s - loss: 1.9044 - accuracy: 0.4364 - precision_m: 0.7290 - recall_m: 0.2111 - f1_m: 0.3263\n",
      "Epoch 18: val_loss improved from 2.00188 to 1.98591, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.4085 | Precision: 0.6862 | Recall: 0.2060 | F1: 0.3147\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9053 - accuracy: 0.4363 - precision_m: 0.7294 - recall_m: 0.2112 - f1_m: 0.3265 - val_loss: 1.9859 - val_accuracy: 0.4085 - val_precision_m: 0.6862 - val_recall_m: 0.2060 - val_f1_m: 0.3147\n",
      "Epoch 19/30\n",
      "600/609 [============================>.] - ETA: 0s - loss: 1.8972 - accuracy: 0.4378 - precision_m: 0.7274 - recall_m: 0.2139 - f1_m: 0.3294\n",
      "Epoch 19: val_loss did not improve from 1.98591\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8981 - accuracy: 0.4374 - precision_m: 0.7270 - recall_m: 0.2137 - f1_m: 0.3292 - val_loss: 2.0219 - val_accuracy: 0.3994 - val_precision_m: 0.6678 - val_recall_m: 0.1995 - val_f1_m: 0.3056\n",
      "Epoch 20/30\n",
      "601/609 [============================>.] - ETA: 0s - loss: 1.8922 - accuracy: 0.4381 - precision_m: 0.7286 - recall_m: 0.2163 - f1_m: 0.3323\n",
      "Epoch 20: val_loss did not improve from 1.98591\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8919 - accuracy: 0.4381 - precision_m: 0.7287 - recall_m: 0.2161 - f1_m: 0.3321 - val_loss: 2.0060 - val_accuracy: 0.4056 - val_precision_m: 0.6705 - val_recall_m: 0.1957 - val_f1_m: 0.3014\n",
      "Epoch 21/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.8838 - accuracy: 0.4414 - precision_m: 0.7324 - recall_m: 0.2210 - f1_m: 0.3385\n",
      "Epoch 21: val_loss improved from 1.98591 to 1.98212, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 21\n",
      "Accuracy: 0.4139 | Precision: 0.6877 | Recall: 0.2125 | F1: 0.3225\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8839 - accuracy: 0.4413 - precision_m: 0.7319 - recall_m: 0.2209 - f1_m: 0.3383 - val_loss: 1.9821 - val_accuracy: 0.4139 - val_precision_m: 0.6877 - val_recall_m: 0.2125 - val_f1_m: 0.3225\n",
      "Epoch 22/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.8817 - accuracy: 0.4412 - precision_m: 0.7280 - recall_m: 0.2201 - f1_m: 0.3368\n",
      "Epoch 22: val_loss did not improve from 1.98212\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8813 - accuracy: 0.4414 - precision_m: 0.7280 - recall_m: 0.2202 - f1_m: 0.3369 - val_loss: 1.9998 - val_accuracy: 0.4098 - val_precision_m: 0.6725 - val_recall_m: 0.2040 - val_f1_m: 0.3110\n",
      "Epoch 23/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.8761 - accuracy: 0.4433 - precision_m: 0.7307 - recall_m: 0.2231 - f1_m: 0.3407\n",
      "Epoch 23: val_loss improved from 1.98212 to 1.97905, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 23\n",
      "Accuracy: 0.4157 | Precision: 0.6818 | Recall: 0.2132 | F1: 0.3228\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8763 - accuracy: 0.4432 - precision_m: 0.7307 - recall_m: 0.2231 - f1_m: 0.3407 - val_loss: 1.9791 - val_accuracy: 0.4157 - val_precision_m: 0.6818 - val_recall_m: 0.2132 - val_f1_m: 0.3228\n",
      "Epoch 24/30\n",
      "600/609 [============================>.] - ETA: 0s - loss: 1.8706 - accuracy: 0.4448 - precision_m: 0.7313 - recall_m: 0.2259 - f1_m: 0.3441\n",
      "Epoch 24: val_loss did not improve from 1.97905\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8714 - accuracy: 0.4445 - precision_m: 0.7306 - recall_m: 0.2254 - f1_m: 0.3434 - val_loss: 1.9864 - val_accuracy: 0.4100 - val_precision_m: 0.6804 - val_recall_m: 0.2121 - val_f1_m: 0.3219\n",
      "Epoch 25/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.8646 - accuracy: 0.4455 - precision_m: 0.7320 - recall_m: 0.2269 - f1_m: 0.3453\n",
      "Epoch 25: val_loss improved from 1.97905 to 1.96182, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.4221 | Precision: 0.6809 | Recall: 0.2103 | F1: 0.3196\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8646 - accuracy: 0.4455 - precision_m: 0.7320 - recall_m: 0.2268 - f1_m: 0.3453 - val_loss: 1.9618 - val_accuracy: 0.4221 - val_precision_m: 0.6809 - val_recall_m: 0.2103 - val_f1_m: 0.3196\n",
      "Epoch 26/30\n",
      "609/609 [==============================] - ETA: 0s - loss: 1.8605 - accuracy: 0.4477 - precision_m: 0.7326 - recall_m: 0.2294 - f1_m: 0.3483\n",
      "Epoch 26: val_loss did not improve from 1.96182\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8605 - accuracy: 0.4477 - precision_m: 0.7326 - recall_m: 0.2294 - f1_m: 0.3483 - val_loss: 1.9772 - val_accuracy: 0.4220 - val_precision_m: 0.6846 - val_recall_m: 0.2047 - val_f1_m: 0.3134\n",
      "Epoch 27/30\n",
      "593/609 [============================>.] - ETA: 0s - loss: 1.8552 - accuracy: 0.4491 - precision_m: 0.7331 - recall_m: 0.2297 - f1_m: 0.3487\n",
      "Epoch 27: val_loss improved from 1.96182 to 1.94023, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 27\n",
      "Accuracy: 0.4268 | Precision: 0.6940 | Recall: 0.2180 | F1: 0.3295\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8555 - accuracy: 0.4491 - precision_m: 0.7332 - recall_m: 0.2298 - f1_m: 0.3489 - val_loss: 1.9402 - val_accuracy: 0.4268 - val_precision_m: 0.6940 - val_recall_m: 0.2180 - val_f1_m: 0.3295\n",
      "Epoch 28/30\n",
      "601/609 [============================>.] - ETA: 0s - loss: 1.8505 - accuracy: 0.4509 - precision_m: 0.7334 - recall_m: 0.2319 - f1_m: 0.3513\n",
      "Epoch 28: val_loss did not improve from 1.94023\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8515 - accuracy: 0.4506 - precision_m: 0.7327 - recall_m: 0.2315 - f1_m: 0.3508 - val_loss: 1.9591 - val_accuracy: 0.4227 - val_precision_m: 0.6906 - val_recall_m: 0.2170 - val_f1_m: 0.3281\n",
      "Epoch 29/30\n",
      "600/609 [============================>.] - ETA: 0s - loss: 1.8416 - accuracy: 0.4513 - precision_m: 0.7359 - recall_m: 0.2341 - f1_m: 0.3541\n",
      "Epoch 29: val_loss improved from 1.94023 to 1.92996, saving model to trained_models/model_1_fold_8_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 29\n",
      "Accuracy: 0.4299 | Precision: 0.6980 | Recall: 0.2233 | F1: 0.3366\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8417 - accuracy: 0.4515 - precision_m: 0.7359 - recall_m: 0.2342 - f1_m: 0.3542 - val_loss: 1.9300 - val_accuracy: 0.4299 - val_precision_m: 0.6980 - val_recall_m: 0.2233 - val_f1_m: 0.3366\n",
      "Epoch 30/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.8388 - accuracy: 0.4530 - precision_m: 0.7316 - recall_m: 0.2358 - f1_m: 0.3556\n",
      "Epoch 30: val_loss did not improve from 1.92996\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8388 - accuracy: 0.4531 - precision_m: 0.7317 - recall_m: 0.2360 - f1_m: 0.3558 - val_loss: 1.9739 - val_accuracy: 0.4157 - val_precision_m: 0.6756 - val_recall_m: 0.2237 - val_f1_m: 0.3347\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 57.5 seconds (1.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 31.6%\n",
      "  Usage (max):  48.1%\n",
      "  Frequency:    3970 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.7%\n",
      "  Usage (max):  40.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  26.8%\n",
      "  Usage (max):   32.0%\n",
      "  Memory (mean): 1641 MB\n",
      "  Memory (max):  1641 MB\n",
      "  Power (mean):  45.3 W\n",
      "  Power (max):   47.8 W\n",
      "  Energy used:   0.723980 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 RESULTS\n",
      "================================================================================\n",
      "Validation:\n",
      "  Loss:      1.9300\n",
      "  Accuracy:  42.99%\n",
      "  Precision: 0.6980\n",
      "  Recall:    0.2233\n",
      "  F1 Score:  0.3366\n",
      "\n",
      "Test:\n",
      "  Loss:      1.9812\n",
      "  Accuracy:  42.14%\n",
      "  Precision: 0.6731\n",
      "  Recall:    0.2134\n",
      "  F1 Score:  0.3175\n",
      "\n",
      "Resources:\n",
      "  Duration:     57.5s (1.0m)\n",
      "  GPU Power:    45.3W (max: 47.8W)\n",
      "  Energy Used:  0.724Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 9 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Permission denied for /sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj. Run with sudo or add permissions.\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77896, Val=8304, Test=7446\n",
      "Epoch 1/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 2.8342 - accuracy: 0.1949 - precision_m: 0.3811 - recall_m: 0.0126 - f1_m: 0.0241\n",
      "Epoch 1: val_loss improved from inf to 2.46859, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.2814 | Precision: 0.6043 | Recall: 0.0305 | F1: 0.0575\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 3s 3ms/step - loss: 2.8332 - accuracy: 0.1952 - precision_m: 0.3814 - recall_m: 0.0126 - f1_m: 0.0242 - val_loss: 2.4686 - val_accuracy: 0.2814 - val_precision_m: 0.6043 - val_recall_m: 0.0305 - val_f1_m: 0.0575\n",
      "Epoch 2/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 2.3505 - accuracy: 0.3192 - precision_m: 0.6721 - recall_m: 0.0657 - f1_m: 0.1185\n",
      "Epoch 2: val_loss improved from 2.46859 to 2.28586, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.3509 | Precision: 0.6504 | Recall: 0.0857 | F1: 0.1497\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.3505 - accuracy: 0.3192 - precision_m: 0.6720 - recall_m: 0.0657 - f1_m: 0.1185 - val_loss: 2.2859 - val_accuracy: 0.3509 - val_precision_m: 0.6504 - val_recall_m: 0.0857 - val_f1_m: 0.1497\n",
      "Epoch 3/30\n",
      "596/609 [============================>.] - ETA: 0s - loss: 2.2028 - accuracy: 0.3625 - precision_m: 0.7014 - recall_m: 0.1103 - f1_m: 0.1895\n",
      "Epoch 3: val_loss improved from 2.28586 to 2.21166, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.3572 | Precision: 0.6928 | Recall: 0.1189 | F1: 0.2012\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.2010 - accuracy: 0.3630 - precision_m: 0.7020 - recall_m: 0.1108 - f1_m: 0.1903 - val_loss: 2.2117 - val_accuracy: 0.3572 - val_precision_m: 0.6928 - val_recall_m: 0.1189 - val_f1_m: 0.2012\n",
      "Epoch 4/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 2.1194 - accuracy: 0.3860 - precision_m: 0.7258 - recall_m: 0.1407 - f1_m: 0.2345\n",
      "Epoch 4: val_loss improved from 2.21166 to 2.14818, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.3807 | Precision: 0.7041 | Recall: 0.1413 | F1: 0.2334\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.1194 - accuracy: 0.3859 - precision_m: 0.7256 - recall_m: 0.1408 - f1_m: 0.2347 - val_loss: 2.1482 - val_accuracy: 0.3807 - val_precision_m: 0.7041 - val_recall_m: 0.1413 - val_f1_m: 0.2334\n",
      "Epoch 5/30\n",
      "604/609 [============================>.] - ETA: 0s - loss: 2.0572 - accuracy: 0.4027 - precision_m: 0.7289 - recall_m: 0.1613 - f1_m: 0.2629\n",
      "Epoch 5: val_loss improved from 2.14818 to 2.08342, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.3975 | Precision: 0.7117 | Recall: 0.1617 | F1: 0.2615\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0574 - accuracy: 0.4027 - precision_m: 0.7292 - recall_m: 0.1615 - f1_m: 0.2632 - val_loss: 2.0834 - val_accuracy: 0.3975 - val_precision_m: 0.7117 - val_recall_m: 0.1617 - val_f1_m: 0.2615\n",
      "Epoch 6/30\n",
      "602/609 [============================>.] - ETA: 0s - loss: 2.0060 - accuracy: 0.4161 - precision_m: 0.7339 - recall_m: 0.1780 - f1_m: 0.2852\n",
      "Epoch 6: val_loss improved from 2.08342 to 2.06855, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.3981 | Precision: 0.7097 | Recall: 0.1759 | F1: 0.2801\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 2.0065 - accuracy: 0.4157 - precision_m: 0.7335 - recall_m: 0.1779 - f1_m: 0.2851 - val_loss: 2.0685 - val_accuracy: 0.3981 - val_precision_m: 0.7097 - val_recall_m: 0.1759 - val_f1_m: 0.2801\n",
      "Epoch 7/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.9609 - accuracy: 0.4291 - precision_m: 0.7418 - recall_m: 0.1941 - f1_m: 0.3064\n",
      "Epoch 7: val_loss improved from 2.06855 to 2.00982, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.4121 | Precision: 0.7091 | Recall: 0.1877 | F1: 0.2950\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9606 - accuracy: 0.4292 - precision_m: 0.7418 - recall_m: 0.1941 - f1_m: 0.3066 - val_loss: 2.0098 - val_accuracy: 0.4121 - val_precision_m: 0.7091 - val_recall_m: 0.1877 - val_f1_m: 0.2950\n",
      "Epoch 8/30\n",
      "595/609 [============================>.] - ETA: 0s - loss: 1.9289 - accuracy: 0.4370 - precision_m: 0.7391 - recall_m: 0.2071 - f1_m: 0.3224\n",
      "Epoch 8: val_loss did not improve from 2.00982\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9289 - accuracy: 0.4371 - precision_m: 0.7393 - recall_m: 0.2072 - f1_m: 0.3226 - val_loss: 2.0167 - val_accuracy: 0.4110 - val_precision_m: 0.6844 - val_recall_m: 0.1994 - val_f1_m: 0.3068\n",
      "Epoch 9/30\n",
      "595/609 [============================>.] - ETA: 0s - loss: 1.9013 - accuracy: 0.4429 - precision_m: 0.7382 - recall_m: 0.2151 - f1_m: 0.3320\n",
      "Epoch 9: val_loss improved from 2.00982 to 1.99031, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.4171 | Precision: 0.6919 | Recall: 0.2093 | F1: 0.3192\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.9018 - accuracy: 0.4429 - precision_m: 0.7386 - recall_m: 0.2152 - f1_m: 0.3321 - val_loss: 1.9903 - val_accuracy: 0.4171 - val_precision_m: 0.6919 - val_recall_m: 0.2093 - val_f1_m: 0.3192\n",
      "Epoch 10/30\n",
      "597/609 [============================>.] - ETA: 0s - loss: 1.8696 - accuracy: 0.4504 - precision_m: 0.7383 - recall_m: 0.2248 - f1_m: 0.3435\n",
      "Epoch 10: val_loss improved from 1.99031 to 1.98018, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 10\n",
      "Accuracy: 0.4205 | Precision: 0.6951 | Recall: 0.2171 | F1: 0.3289\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8698 - accuracy: 0.4503 - precision_m: 0.7384 - recall_m: 0.2252 - f1_m: 0.3440 - val_loss: 1.9802 - val_accuracy: 0.4205 - val_precision_m: 0.6951 - val_recall_m: 0.2171 - val_f1_m: 0.3289\n",
      "Epoch 11/30\n",
      "594/609 [============================>.] - ETA: 0s - loss: 1.8467 - accuracy: 0.4594 - precision_m: 0.7394 - recall_m: 0.2340 - f1_m: 0.3545\n",
      "Epoch 11: val_loss improved from 1.98018 to 1.95555, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.4302 | Precision: 0.7075 | Recall: 0.2196 | F1: 0.3332\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8476 - accuracy: 0.4592 - precision_m: 0.7389 - recall_m: 0.2341 - f1_m: 0.3544 - val_loss: 1.9555 - val_accuracy: 0.4302 - val_precision_m: 0.7075 - val_recall_m: 0.2196 - val_f1_m: 0.3332\n",
      "Epoch 12/30\n",
      "607/609 [============================>.] - ETA: 0s - loss: 1.8247 - accuracy: 0.4635 - precision_m: 0.7414 - recall_m: 0.2442 - f1_m: 0.3662\n",
      "Epoch 12: val_loss improved from 1.95555 to 1.91476, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.4392 | Precision: 0.7154 | Recall: 0.2245 | F1: 0.3397\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8251 - accuracy: 0.4634 - precision_m: 0.7411 - recall_m: 0.2441 - f1_m: 0.3661 - val_loss: 1.9148 - val_accuracy: 0.4392 - val_precision_m: 0.7154 - val_recall_m: 0.2245 - val_f1_m: 0.3397\n",
      "Epoch 13/30\n",
      "597/609 [============================>.] - ETA: 0s - loss: 1.8057 - accuracy: 0.4685 - precision_m: 0.7415 - recall_m: 0.2499 - f1_m: 0.3726\n",
      "Epoch 13: val_loss did not improve from 1.91476\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.8064 - accuracy: 0.4682 - precision_m: 0.7411 - recall_m: 0.2497 - f1_m: 0.3723 - val_loss: 1.9352 - val_accuracy: 0.4349 - val_precision_m: 0.7020 - val_recall_m: 0.2346 - val_f1_m: 0.3494\n",
      "Epoch 14/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.7907 - accuracy: 0.4716 - precision_m: 0.7385 - recall_m: 0.2566 - f1_m: 0.3797\n",
      "Epoch 14: val_loss improved from 1.91476 to 1.90570, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.4468 | Precision: 0.6911 | Recall: 0.2467 | F1: 0.3617\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.7905 - accuracy: 0.4717 - precision_m: 0.7388 - recall_m: 0.2567 - f1_m: 0.3799 - val_loss: 1.9057 - val_accuracy: 0.4468 - val_precision_m: 0.6911 - val_recall_m: 0.2467 - val_f1_m: 0.3617\n",
      "Epoch 15/30\n",
      "600/609 [============================>.] - ETA: 0s - loss: 1.7761 - accuracy: 0.4776 - precision_m: 0.7446 - recall_m: 0.2630 - f1_m: 0.3876\n",
      "Epoch 15: val_loss improved from 1.90570 to 1.88295, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 15\n",
      "Accuracy: 0.4486 | Precision: 0.6965 | Recall: 0.2492 | F1: 0.3653\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.7765 - accuracy: 0.4773 - precision_m: 0.7439 - recall_m: 0.2629 - f1_m: 0.3874 - val_loss: 1.8829 - val_accuracy: 0.4486 - val_precision_m: 0.6965 - val_recall_m: 0.2492 - val_f1_m: 0.3653\n",
      "Epoch 16/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.7641 - accuracy: 0.4788 - precision_m: 0.7404 - recall_m: 0.2678 - f1_m: 0.3922\n",
      "Epoch 16: val_loss improved from 1.88295 to 1.86724, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.4560 | Precision: 0.6993 | Recall: 0.2572 | F1: 0.3741\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.7642 - accuracy: 0.4786 - precision_m: 0.7401 - recall_m: 0.2675 - f1_m: 0.3919 - val_loss: 1.8672 - val_accuracy: 0.4560 - val_precision_m: 0.6993 - val_recall_m: 0.2572 - val_f1_m: 0.3741\n",
      "Epoch 17/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.7523 - accuracy: 0.4840 - precision_m: 0.7423 - recall_m: 0.2740 - f1_m: 0.3991\n",
      "Epoch 17: val_loss did not improve from 1.86724\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 17\n",
      "Accuracy: 0.4562 | Precision: 0.6823 | Recall: 0.2579 | F1: 0.3722\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.7526 - accuracy: 0.4839 - precision_m: 0.7423 - recall_m: 0.2740 - f1_m: 0.3991 - val_loss: 1.8825 - val_accuracy: 0.4562 - val_precision_m: 0.6823 - val_recall_m: 0.2579 - val_f1_m: 0.3722\n",
      "Epoch 18/30\n",
      "602/609 [============================>.] - ETA: 0s - loss: 1.7418 - accuracy: 0.4857 - precision_m: 0.7408 - recall_m: 0.2780 - f1_m: 0.4031\n",
      "Epoch 18: val_loss improved from 1.86724 to 1.84674, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.4689 | Precision: 0.7018 | Recall: 0.2706 | F1: 0.3888\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.7408 - accuracy: 0.4860 - precision_m: 0.7414 - recall_m: 0.2780 - f1_m: 0.4032 - val_loss: 1.8467 - val_accuracy: 0.4689 - val_precision_m: 0.7018 - val_recall_m: 0.2706 - val_f1_m: 0.3888\n",
      "Epoch 19/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.7315 - accuracy: 0.4885 - precision_m: 0.7405 - recall_m: 0.2819 - f1_m: 0.4073\n",
      "Epoch 19: val_loss did not improve from 1.84674\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.7317 - accuracy: 0.4886 - precision_m: 0.7406 - recall_m: 0.2822 - f1_m: 0.4075 - val_loss: 1.8930 - val_accuracy: 0.4454 - val_precision_m: 0.6789 - val_recall_m: 0.2555 - val_f1_m: 0.3695\n",
      "Epoch 20/30\n",
      "601/609 [============================>.] - ETA: 0s - loss: 1.7203 - accuracy: 0.4927 - precision_m: 0.7445 - recall_m: 0.2885 - f1_m: 0.4148\n",
      "Epoch 20: val_loss did not improve from 1.84674\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.7205 - accuracy: 0.4927 - precision_m: 0.7437 - recall_m: 0.2882 - f1_m: 0.4143 - val_loss: 1.8505 - val_accuracy: 0.4616 - val_precision_m: 0.7069 - val_recall_m: 0.2680 - val_f1_m: 0.3870\n",
      "Epoch 21/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.7128 - accuracy: 0.4944 - precision_m: 0.7417 - recall_m: 0.2891 - f1_m: 0.4150\n",
      "Epoch 21: val_loss improved from 1.84674 to 1.82426, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 21\n",
      "Accuracy: 0.4692 | Precision: 0.7089 | Recall: 0.2743 | F1: 0.3938\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.7128 - accuracy: 0.4943 - precision_m: 0.7416 - recall_m: 0.2893 - f1_m: 0.4152 - val_loss: 1.8243 - val_accuracy: 0.4692 - val_precision_m: 0.7089 - val_recall_m: 0.2743 - val_f1_m: 0.3938\n",
      "Epoch 22/30\n",
      "608/609 [============================>.] - ETA: 0s - loss: 1.7061 - accuracy: 0.4968 - precision_m: 0.7421 - recall_m: 0.2941 - f1_m: 0.4202\n",
      "Epoch 22: val_loss improved from 1.82426 to 1.82364, saving model to trained_models/model_1_fold_9_best.h5\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.7059 - accuracy: 0.4969 - precision_m: 0.7421 - recall_m: 0.2942 - f1_m: 0.4203 - val_loss: 1.8236 - val_accuracy: 0.4675 - val_precision_m: 0.7116 - val_recall_m: 0.2764 - val_f1_m: 0.3961\n",
      "Epoch 23/30\n",
      "596/609 [============================>.] - ETA: 0s - loss: 1.6978 - accuracy: 0.4971 - precision_m: 0.7415 - recall_m: 0.2970 - f1_m: 0.4231\n",
      "Epoch 23: val_loss improved from 1.82364 to 1.82087, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 23\n",
      "Accuracy: 0.4751 | Precision: 0.7091 | Recall: 0.2723 | F1: 0.3917\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.6979 - accuracy: 0.4972 - precision_m: 0.7420 - recall_m: 0.2972 - f1_m: 0.4233 - val_loss: 1.8209 - val_accuracy: 0.4751 - val_precision_m: 0.7091 - val_recall_m: 0.2723 - val_f1_m: 0.3917\n",
      "Epoch 24/30\n",
      "591/609 [============================>.] - ETA: 0s - loss: 1.6934 - accuracy: 0.5015 - precision_m: 0.7408 - recall_m: 0.2987 - f1_m: 0.4247\n",
      "Epoch 24: val_loss did not improve from 1.82087\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.6941 - accuracy: 0.5011 - precision_m: 0.7403 - recall_m: 0.2985 - f1_m: 0.4245 - val_loss: 1.8421 - val_accuracy: 0.4699 - val_precision_m: 0.6959 - val_recall_m: 0.2774 - val_f1_m: 0.3948\n",
      "Epoch 25/30\n",
      "599/609 [============================>.] - ETA: 0s - loss: 1.6838 - accuracy: 0.5021 - precision_m: 0.7421 - recall_m: 0.3025 - f1_m: 0.4288\n",
      "Epoch 25: val_loss improved from 1.82087 to 1.79507, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.4793 | Precision: 0.7046 | Recall: 0.2832 | F1: 0.4024\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.6843 - accuracy: 0.5021 - precision_m: 0.7425 - recall_m: 0.3026 - f1_m: 0.4290 - val_loss: 1.7951 - val_accuracy: 0.4793 - val_precision_m: 0.7046 - val_recall_m: 0.2832 - val_f1_m: 0.4024\n",
      "Epoch 26/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.6754 - accuracy: 0.5047 - precision_m: 0.7426 - recall_m: 0.3056 - f1_m: 0.4320\n",
      "Epoch 26: val_loss did not improve from 1.79507\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 26\n",
      "Accuracy: 0.4836 | Precision: 0.7146 | Recall: 0.2842 | F1: 0.4050\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.6750 - accuracy: 0.5047 - precision_m: 0.7424 - recall_m: 0.3057 - f1_m: 0.4320 - val_loss: 1.7960 - val_accuracy: 0.4836 - val_precision_m: 0.7146 - val_recall_m: 0.2842 - val_f1_m: 0.4050\n",
      "Epoch 27/30\n",
      "606/609 [============================>.] - ETA: 0s - loss: 1.6729 - accuracy: 0.5046 - precision_m: 0.7430 - recall_m: 0.3075 - f1_m: 0.4339\n",
      "Epoch 27: val_loss improved from 1.79507 to 1.77804, saving model to trained_models/model_1_fold_9_best.h5\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.6732 - accuracy: 0.5047 - precision_m: 0.7433 - recall_m: 0.3076 - f1_m: 0.4341 - val_loss: 1.7780 - val_accuracy: 0.4833 - val_precision_m: 0.7122 - val_recall_m: 0.2845 - val_f1_m: 0.4048\n",
      "Epoch 28/30\n",
      "597/609 [============================>.] - ETA: 0s - loss: 1.6666 - accuracy: 0.5082 - precision_m: 0.7418 - recall_m: 0.3100 - f1_m: 0.4362\n",
      "Epoch 28: val_loss did not improve from 1.77804\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.6677 - accuracy: 0.5078 - precision_m: 0.7411 - recall_m: 0.3097 - f1_m: 0.4357 - val_loss: 1.8117 - val_accuracy: 0.4816 - val_precision_m: 0.6970 - val_recall_m: 0.2802 - val_f1_m: 0.3981\n",
      "Epoch 29/30\n",
      "602/609 [============================>.] - ETA: 0s - loss: 1.6622 - accuracy: 0.5082 - precision_m: 0.7421 - recall_m: 0.3107 - f1_m: 0.4370\n",
      "Epoch 29: val_loss improved from 1.77804 to 1.77007, saving model to trained_models/model_1_fold_9_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 29\n",
      "Accuracy: 0.4908 | Precision: 0.7124 | Recall: 0.2946 | F1: 0.4153\n",
      "================================================================================\n",
      "\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.6615 - accuracy: 0.5082 - precision_m: 0.7422 - recall_m: 0.3109 - f1_m: 0.4373 - val_loss: 1.7701 - val_accuracy: 0.4908 - val_precision_m: 0.7124 - val_recall_m: 0.2946 - val_f1_m: 0.4153\n",
      "Epoch 30/30\n",
      "605/609 [============================>.] - ETA: 0s - loss: 1.6586 - accuracy: 0.5100 - precision_m: 0.7422 - recall_m: 0.3142 - f1_m: 0.4405\n",
      "Epoch 30: val_loss did not improve from 1.77007\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 1.6590 - accuracy: 0.5099 - precision_m: 0.7421 - recall_m: 0.3142 - f1_m: 0.4405 - val_loss: 1.8042 - val_accuracy: 0.4777 - val_precision_m: 0.6986 - val_recall_m: 0.2951 - val_f1_m: 0.4133\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 58.6 seconds (1.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 33.2%\n",
      "  Usage (max):  72.2%\n",
      "  Frequency:    3963 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.9%\n",
      "  Usage (max):  41.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  27.0%\n",
      "  Usage (max):   33.0%\n",
      "  Memory (mean): 1640 MB\n",
      "  Memory (max):  1641 MB\n",
      "  Power (mean):  45.2 W\n",
      "  Power (max):   47.0 W\n",
      "  Energy used:   0.735304 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 RESULTS\n",
      "================================================================================\n",
      "Validation:\n",
      "  Loss:      1.7701\n",
      "  Accuracy:  49.08%\n",
      "  Precision: 0.7124\n",
      "  Recall:    0.2946\n",
      "  F1 Score:  0.4153\n",
      "\n",
      "Test:\n",
      "  Loss:      1.7815\n",
      "  Accuracy:  47.97%\n",
      "  Precision: 0.7092\n",
      "  Recall:    0.2995\n",
      "  F1 Score:  0.4151\n",
      "\n",
      "Resources:\n",
      "  Duration:     58.6s (1.0m)\n",
      "  GPU Power:    45.2W (max: 47.0W)\n",
      "  Energy Used:  0.735Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING FOLD 10 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Permission denied for /sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj. Run with sudo or add permissions.\n",
      "Resource monitoring started\n",
      "Loaded fold: Train=77991, Val=8318, Test=7389\n",
      "Epoch 1/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 3.1095 - accuracy: 0.1235 - precision_m: 0.1421 - recall_m: 0.0017 - f1_m: 0.0033\n",
      "Epoch 1: val_loss improved from inf to 2.72541, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 1\n",
      "Accuracy: 0.1901 | Precision: 0.2808 | Recall: 0.0049 | F1: 0.0096\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 4s 4ms/step - loss: 3.1086 - accuracy: 0.1236 - precision_m: 0.1433 - recall_m: 0.0017 - f1_m: 0.0033 - val_loss: 2.7254 - val_accuracy: 0.1901 - val_precision_m: 0.2808 - val_recall_m: 0.0049 - val_f1_m: 0.0096\n",
      "Epoch 2/30\n",
      "604/610 [============================>.] - ETA: 0s - loss: 2.6318 - accuracy: 0.2144 - precision_m: 0.5594 - recall_m: 0.0102 - f1_m: 0.0200\n",
      "Epoch 2: val_loss improved from 2.72541 to 2.62991, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 2\n",
      "Accuracy: 0.2275 | Precision: 0.5171 | Recall: 0.0112 | F1: 0.0217\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.6316 - accuracy: 0.2146 - precision_m: 0.5572 - recall_m: 0.0102 - f1_m: 0.0200 - val_loss: 2.6299 - val_accuracy: 0.2275 - val_precision_m: 0.5171 - val_recall_m: 0.0112 - val_f1_m: 0.0217\n",
      "Epoch 3/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 2.5581 - accuracy: 0.2369 - precision_m: 0.6366 - recall_m: 0.0175 - f1_m: 0.0338\n",
      "Epoch 3: val_loss improved from 2.62991 to 2.57422, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 3\n",
      "Accuracy: 0.2397 | Precision: 0.5864 | Recall: 0.0171 | F1: 0.0328\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.5579 - accuracy: 0.2370 - precision_m: 0.6361 - recall_m: 0.0175 - f1_m: 0.0338 - val_loss: 2.5742 - val_accuracy: 0.2397 - val_precision_m: 0.5864 - val_recall_m: 0.0171 - val_f1_m: 0.0328\n",
      "Epoch 4/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.5140 - accuracy: 0.2480 - precision_m: 0.6632 - recall_m: 0.0227 - f1_m: 0.0435\n",
      "Epoch 4: val_loss improved from 2.57422 to 2.53289, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 4\n",
      "Accuracy: 0.2497 | Precision: 0.5924 | Recall: 0.0277 | F1: 0.0522\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.5141 - accuracy: 0.2480 - precision_m: 0.6621 - recall_m: 0.0226 - f1_m: 0.0435 - val_loss: 2.5329 - val_accuracy: 0.2497 - val_precision_m: 0.5924 - val_recall_m: 0.0277 - val_f1_m: 0.0522\n",
      "Epoch 5/30\n",
      "601/610 [============================>.] - ETA: 0s - loss: 2.4818 - accuracy: 0.2565 - precision_m: 0.6618 - recall_m: 0.0258 - f1_m: 0.0493\n",
      "Epoch 5: val_loss improved from 2.53289 to 2.50395, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 5\n",
      "Accuracy: 0.2604 | Precision: 0.6388 | Recall: 0.0305 | F1: 0.0577\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.4810 - accuracy: 0.2567 - precision_m: 0.6615 - recall_m: 0.0259 - f1_m: 0.0495 - val_loss: 2.5040 - val_accuracy: 0.2604 - val_precision_m: 0.6388 - val_recall_m: 0.0305 - val_f1_m: 0.0577\n",
      "Epoch 6/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.4511 - accuracy: 0.2650 - precision_m: 0.6848 - recall_m: 0.0310 - f1_m: 0.0588\n",
      "Epoch 6: val_loss improved from 2.50395 to 2.47943, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 6\n",
      "Accuracy: 0.2621 | Precision: 0.6373 | Recall: 0.0382 | F1: 0.0713\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.4507 - accuracy: 0.2652 - precision_m: 0.6847 - recall_m: 0.0310 - f1_m: 0.0589 - val_loss: 2.4794 - val_accuracy: 0.2621 - val_precision_m: 0.6373 - val_recall_m: 0.0382 - val_f1_m: 0.0713\n",
      "Epoch 7/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 2.4250 - accuracy: 0.2754 - precision_m: 0.6848 - recall_m: 0.0355 - f1_m: 0.0670\n",
      "Epoch 7: val_loss improved from 2.47943 to 2.46512, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 7\n",
      "Accuracy: 0.2763 | Precision: 0.7101 | Recall: 0.0429 | F1: 0.0800\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.4244 - accuracy: 0.2754 - precision_m: 0.6861 - recall_m: 0.0355 - f1_m: 0.0670 - val_loss: 2.4651 - val_accuracy: 0.2763 - val_precision_m: 0.7101 - val_recall_m: 0.0429 - val_f1_m: 0.0800\n",
      "Epoch 8/30\n",
      "593/610 [============================>.] - ETA: 0s - loss: 2.3987 - accuracy: 0.2845 - precision_m: 0.6901 - recall_m: 0.0396 - f1_m: 0.0743\n",
      "Epoch 8: val_loss improved from 2.46512 to 2.44555, saving model to trained_models/model_1_fold_10_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.3989 - accuracy: 0.2844 - precision_m: 0.6910 - recall_m: 0.0399 - f1_m: 0.0749 - val_loss: 2.4456 - val_accuracy: 0.2754 - val_precision_m: 0.6868 - val_recall_m: 0.0512 - val_f1_m: 0.0942\n",
      "Epoch 9/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.3782 - accuracy: 0.2912 - precision_m: 0.7056 - recall_m: 0.0441 - f1_m: 0.0823\n",
      "Epoch 9: val_loss improved from 2.44555 to 2.42244, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 9\n",
      "Accuracy: 0.2866 | Precision: 0.6986 | Recall: 0.0418 | F1: 0.0782\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.3788 - accuracy: 0.2910 - precision_m: 0.7053 - recall_m: 0.0441 - f1_m: 0.0823 - val_loss: 2.4224 - val_accuracy: 0.2866 - val_precision_m: 0.6986 - val_recall_m: 0.0418 - val_f1_m: 0.0782\n",
      "Epoch 10/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.3597 - accuracy: 0.2965 - precision_m: 0.7018 - recall_m: 0.0469 - f1_m: 0.0873\n",
      "Epoch 10: val_loss improved from 2.42244 to 2.41200, saving model to trained_models/model_1_fold_10_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.3596 - accuracy: 0.2966 - precision_m: 0.7023 - recall_m: 0.0469 - f1_m: 0.0873 - val_loss: 2.4120 - val_accuracy: 0.2832 - val_precision_m: 0.6667 - val_recall_m: 0.0532 - val_f1_m: 0.0974\n",
      "Epoch 11/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 2.3459 - accuracy: 0.3001 - precision_m: 0.6990 - recall_m: 0.0522 - f1_m: 0.0966\n",
      "Epoch 11: val_loss improved from 2.41200 to 2.40846, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 11\n",
      "Accuracy: 0.2884 | Precision: 0.6969 | Recall: 0.0545 | F1: 0.0999\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.3459 - accuracy: 0.3001 - precision_m: 0.6986 - recall_m: 0.0522 - f1_m: 0.0966 - val_loss: 2.4085 - val_accuracy: 0.2884 - val_precision_m: 0.6969 - val_recall_m: 0.0545 - val_f1_m: 0.0999\n",
      "Epoch 12/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.3346 - accuracy: 0.3037 - precision_m: 0.7073 - recall_m: 0.0557 - f1_m: 0.1027\n",
      "Epoch 12: val_loss improved from 2.40846 to 2.39265, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 12\n",
      "Accuracy: 0.2933 | Precision: 0.6725 | Recall: 0.0612 | F1: 0.1110\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.3342 - accuracy: 0.3038 - precision_m: 0.7080 - recall_m: 0.0559 - f1_m: 0.1030 - val_loss: 2.3927 - val_accuracy: 0.2933 - val_precision_m: 0.6725 - val_recall_m: 0.0612 - val_f1_m: 0.1110\n",
      "Epoch 13/30\n",
      "602/610 [============================>.] - ETA: 0s - loss: 2.3151 - accuracy: 0.3096 - precision_m: 0.7083 - recall_m: 0.0596 - f1_m: 0.1092\n",
      "Epoch 13: val_loss improved from 2.39265 to 2.36070, saving model to trained_models/model_1_fold_10_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.3156 - accuracy: 0.3095 - precision_m: 0.7083 - recall_m: 0.0595 - f1_m: 0.1091 - val_loss: 2.3607 - val_accuracy: 0.2906 - val_precision_m: 0.6840 - val_recall_m: 0.0598 - val_f1_m: 0.1089\n",
      "Epoch 14/30\n",
      "606/610 [============================>.] - ETA: 0s - loss: 2.3041 - accuracy: 0.3126 - precision_m: 0.7179 - recall_m: 0.0643 - f1_m: 0.1172\n",
      "Epoch 14: val_loss improved from 2.36070 to 2.34725, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 14\n",
      "Accuracy: 0.3043 | Precision: 0.6877 | Recall: 0.0667 | F1: 0.1206\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.3041 - accuracy: 0.3125 - precision_m: 0.7187 - recall_m: 0.0643 - f1_m: 0.1173 - val_loss: 2.3472 - val_accuracy: 0.3043 - val_precision_m: 0.6877 - val_recall_m: 0.0667 - val_f1_m: 0.1206\n",
      "Epoch 15/30\n",
      "609/610 [============================>.] - ETA: 0s - loss: 2.2910 - accuracy: 0.3164 - precision_m: 0.7120 - recall_m: 0.0669 - f1_m: 0.1216\n",
      "Epoch 15: val_loss did not improve from 2.34725\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2909 - accuracy: 0.3164 - precision_m: 0.7125 - recall_m: 0.0670 - f1_m: 0.1217 - val_loss: 2.3595 - val_accuracy: 0.3003 - val_precision_m: 0.6894 - val_recall_m: 0.0653 - val_f1_m: 0.1180\n",
      "Epoch 16/30\n",
      "593/610 [============================>.] - ETA: 0s - loss: 2.2781 - accuracy: 0.3196 - precision_m: 0.7155 - recall_m: 0.0703 - f1_m: 0.1273\n",
      "Epoch 16: val_loss improved from 2.34725 to 2.32483, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 16\n",
      "Accuracy: 0.3105 | Precision: 0.6953 | Recall: 0.0719 | F1: 0.1289\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2777 - accuracy: 0.3199 - precision_m: 0.7171 - recall_m: 0.0707 - f1_m: 0.1279 - val_loss: 2.3248 - val_accuracy: 0.3105 - val_precision_m: 0.6953 - val_recall_m: 0.0719 - val_f1_m: 0.1289\n",
      "Epoch 17/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 2.2645 - accuracy: 0.3239 - precision_m: 0.7211 - recall_m: 0.0743 - f1_m: 0.1340\n",
      "Epoch 17: val_loss improved from 2.32483 to 2.31314, saving model to trained_models/model_1_fold_10_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2644 - accuracy: 0.3237 - precision_m: 0.7194 - recall_m: 0.0741 - f1_m: 0.1335 - val_loss: 2.3131 - val_accuracy: 0.3091 - val_precision_m: 0.7057 - val_recall_m: 0.0718 - val_f1_m: 0.1289\n",
      "Epoch 18/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 2.2475 - accuracy: 0.3267 - precision_m: 0.7167 - recall_m: 0.0779 - f1_m: 0.1397\n",
      "Epoch 18: val_loss improved from 2.31314 to 2.30034, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 18\n",
      "Accuracy: 0.3162 | Precision: 0.7389 | Recall: 0.0700 | F1: 0.1265\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2477 - accuracy: 0.3266 - precision_m: 0.7160 - recall_m: 0.0778 - f1_m: 0.1395 - val_loss: 2.3003 - val_accuracy: 0.3162 - val_precision_m: 0.7389 - val_recall_m: 0.0700 - val_f1_m: 0.1265\n",
      "Epoch 19/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 2.2359 - accuracy: 0.3291 - precision_m: 0.7201 - recall_m: 0.0798 - f1_m: 0.1428\n",
      "Epoch 19: val_loss improved from 2.30034 to 2.27628, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 19\n",
      "Accuracy: 0.3187 | Precision: 0.6951 | Recall: 0.0802 | F1: 0.1423\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2361 - accuracy: 0.3291 - precision_m: 0.7201 - recall_m: 0.0799 - f1_m: 0.1430 - val_loss: 2.2763 - val_accuracy: 0.3187 - val_precision_m: 0.6951 - val_recall_m: 0.0802 - val_f1_m: 0.1423\n",
      "Epoch 20/30\n",
      "597/610 [============================>.] - ETA: 0s - loss: 2.2202 - accuracy: 0.3341 - precision_m: 0.7226 - recall_m: 0.0829 - f1_m: 0.1479\n",
      "Epoch 20: val_loss improved from 2.27628 to 2.27037, saving model to trained_models/model_1_fold_10_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2210 - accuracy: 0.3338 - precision_m: 0.7209 - recall_m: 0.0826 - f1_m: 0.1475 - val_loss: 2.2704 - val_accuracy: 0.3181 - val_precision_m: 0.7115 - val_recall_m: 0.0768 - val_f1_m: 0.1372\n",
      "Epoch 21/30\n",
      "595/610 [============================>.] - ETA: 0s - loss: 2.2140 - accuracy: 0.3355 - precision_m: 0.7224 - recall_m: 0.0847 - f1_m: 0.1507\n",
      "Epoch 21: val_loss improved from 2.27037 to 2.25369, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 21\n",
      "Accuracy: 0.3201 | Precision: 0.7220 | Recall: 0.0795 | F1: 0.1416\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.2143 - accuracy: 0.3353 - precision_m: 0.7221 - recall_m: 0.0846 - f1_m: 0.1504 - val_loss: 2.2537 - val_accuracy: 0.3201 - val_precision_m: 0.7220 - val_recall_m: 0.0795 - val_f1_m: 0.1416\n",
      "Epoch 22/30\n",
      "603/610 [============================>.] - ETA: 0s - loss: 2.1988 - accuracy: 0.3387 - precision_m: 0.7210 - recall_m: 0.0870 - f1_m: 0.1543\n",
      "Epoch 22: val_loss improved from 2.25369 to 2.25209, saving model to trained_models/model_1_fold_10_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1983 - accuracy: 0.3388 - precision_m: 0.7214 - recall_m: 0.0870 - f1_m: 0.1543 - val_loss: 2.2521 - val_accuracy: 0.3167 - val_precision_m: 0.6710 - val_recall_m: 0.0874 - val_f1_m: 0.1532\n",
      "Epoch 23/30\n",
      "608/610 [============================>.] - ETA: 0s - loss: 2.1857 - accuracy: 0.3401 - precision_m: 0.7189 - recall_m: 0.0889 - f1_m: 0.1572\n",
      "Epoch 23: val_loss improved from 2.25209 to 2.23437, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 23\n",
      "Accuracy: 0.3228 | Precision: 0.6915 | Recall: 0.0856 | F1: 0.1508\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1854 - accuracy: 0.3402 - precision_m: 0.7193 - recall_m: 0.0889 - f1_m: 0.1574 - val_loss: 2.2344 - val_accuracy: 0.3228 - val_precision_m: 0.6915 - val_recall_m: 0.0856 - val_f1_m: 0.1508\n",
      "Epoch 24/30\n",
      "597/610 [============================>.] - ETA: 0s - loss: 2.1744 - accuracy: 0.3424 - precision_m: 0.7184 - recall_m: 0.0904 - f1_m: 0.1596\n",
      "Epoch 24: val_loss improved from 2.23437 to 2.22933, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 24\n",
      "Accuracy: 0.3307 | Precision: 0.6766 | Recall: 0.0816 | F1: 0.1442\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1750 - accuracy: 0.3421 - precision_m: 0.7173 - recall_m: 0.0902 - f1_m: 0.1593 - val_loss: 2.2293 - val_accuracy: 0.3307 - val_precision_m: 0.6766 - val_recall_m: 0.0816 - val_f1_m: 0.1442\n",
      "Epoch 25/30\n",
      "600/610 [============================>.] - ETA: 0s - loss: 2.1667 - accuracy: 0.3438 - precision_m: 0.7192 - recall_m: 0.0908 - f1_m: 0.1603\n",
      "Epoch 25: val_loss improved from 2.22933 to 2.21190, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 25\n",
      "Accuracy: 0.3388 | Precision: 0.7114 | Recall: 0.0874 | F1: 0.1539\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1673 - accuracy: 0.3437 - precision_m: 0.7180 - recall_m: 0.0907 - f1_m: 0.1601 - val_loss: 2.2119 - val_accuracy: 0.3388 - val_precision_m: 0.7114 - val_recall_m: 0.0874 - val_f1_m: 0.1539\n",
      "Epoch 26/30\n",
      "597/610 [============================>.] - ETA: 0s - loss: 2.1571 - accuracy: 0.3476 - precision_m: 0.7134 - recall_m: 0.0908 - f1_m: 0.1603\n",
      "Epoch 26: val_loss improved from 2.21190 to 2.18750, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 26\n",
      "Accuracy: 0.3424 | Precision: 0.6799 | Recall: 0.0899 | F1: 0.1570\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1573 - accuracy: 0.3476 - precision_m: 0.7139 - recall_m: 0.0910 - f1_m: 0.1606 - val_loss: 2.1875 - val_accuracy: 0.3424 - val_precision_m: 0.6799 - val_recall_m: 0.0899 - val_f1_m: 0.1570\n",
      "Epoch 27/30\n",
      "607/610 [============================>.] - ETA: 0s - loss: 2.1474 - accuracy: 0.3490 - precision_m: 0.7120 - recall_m: 0.0917 - f1_m: 0.1615\n",
      "Epoch 27: val_loss did not improve from 2.18750\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1471 - accuracy: 0.3491 - precision_m: 0.7121 - recall_m: 0.0917 - f1_m: 0.1615 - val_loss: 2.1923 - val_accuracy: 0.3401 - val_precision_m: 0.6600 - val_recall_m: 0.0932 - val_f1_m: 0.1613\n",
      "Epoch 28/30\n",
      "605/610 [============================>.] - ETA: 0s - loss: 2.1380 - accuracy: 0.3506 - precision_m: 0.7123 - recall_m: 0.0936 - f1_m: 0.1646\n",
      "Epoch 28: val_loss did not improve from 2.18750\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1382 - accuracy: 0.3506 - precision_m: 0.7120 - recall_m: 0.0937 - f1_m: 0.1646 - val_loss: 2.1989 - val_accuracy: 0.3330 - val_precision_m: 0.6499 - val_recall_m: 0.0886 - val_f1_m: 0.1540\n",
      "Epoch 29/30\n",
      "610/610 [==============================] - ETA: 0s - loss: 2.1304 - accuracy: 0.3538 - precision_m: 0.7088 - recall_m: 0.0941 - f1_m: 0.1653\n",
      "Epoch 29: val_loss improved from 2.18750 to 2.17801, saving model to trained_models/model_1_fold_10_best.h5\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1304 - accuracy: 0.3538 - precision_m: 0.7088 - recall_m: 0.0941 - f1_m: 0.1653 - val_loss: 2.1780 - val_accuracy: 0.3401 - val_precision_m: 0.6350 - val_recall_m: 0.0929 - val_f1_m: 0.1605\n",
      "Epoch 30/30\n",
      "595/610 [============================>.] - ETA: 0s - loss: 2.1258 - accuracy: 0.3529 - precision_m: 0.7069 - recall_m: 0.0934 - f1_m: 0.1640\n",
      "Epoch 30: val_loss improved from 2.17801 to 2.16788, saving model to trained_models/model_1_fold_10_best.h5\n",
      "\n",
      "================================================================================\n",
      "NEW BEST METRICS at Epoch 30\n",
      "Accuracy: 0.3464 | Precision: 0.6701 | Recall: 0.0911 | F1: 0.1587\n",
      "================================================================================\n",
      "\n",
      "610/610 [==============================] - 2s 3ms/step - loss: 2.1252 - accuracy: 0.3531 - precision_m: 0.7077 - recall_m: 0.0934 - f1_m: 0.1640 - val_loss: 2.1679 - val_accuracy: 0.3464 - val_precision_m: 0.6701 - val_recall_m: 0.0911 - val_f1_m: 0.1587\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 60.9 seconds (1.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 38.8%\n",
      "  Usage (max):  65.4%\n",
      "  Frequency:    3993 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.1%\n",
      "  Usage (max):  45.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  26.0%\n",
      "  Usage (max):   34.0%\n",
      "  Memory (mean): 1628 MB\n",
      "  Memory (max):  1656 MB\n",
      "  Power (mean):  45.1 W\n",
      "  Power (max):   47.9 W\n",
      "  Energy used:   0.763146 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 RESULTS\n",
      "================================================================================\n",
      "Validation:\n",
      "  Loss:      2.1679\n",
      "  Accuracy:  34.64%\n",
      "  Precision: 0.6701\n",
      "  Recall:    0.0911\n",
      "  F1 Score:  0.1587\n",
      "\n",
      "Test:\n",
      "  Loss:      2.1860\n",
      "  Accuracy:  34.40%\n",
      "  Precision: 0.6662\n",
      "  Recall:    0.0948\n",
      "  F1 Score:  0.1608\n",
      "\n",
      "Resources:\n",
      "  Duration:     60.9s (1.0m)\n",
      "  GPU Power:    45.1W (max: 47.9W)\n",
      "  Energy Used:  0.763Wh\n",
      "================================================================================\n",
      "\n",
      "Results saved to: results/model_1_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "CROSS-VALIDATION SUMMARY: model_1\n",
      "################################################################################\n",
      "\n",
      "AVERAGE VALIDATION METRICS:\n",
      "  Accuracy:  42.28% ± 6.63%\n",
      "  Precision: 0.6927 ± 0.0250\n",
      "  Recall:    0.2070 ± 0.0932\n",
      "  F1 Score:  0.3072 ± 0.1129\n",
      "\n",
      "AVERAGE TEST METRICS:\n",
      "  Accuracy:  42.27% ± 6.48%\n",
      "  Precision: 0.6791 ± 0.0335\n",
      "  Recall:    0.2054 ± 0.0960\n",
      "  F1 Score:  0.3001 ± 0.1155\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE SUMMARY: model_1\n",
      "================================================================================\n",
      "\n",
      "Total training time: 585.7 seconds (9.8 minutes)\n",
      "Average CPU usage: 31.5%\n",
      "Average RAM usage: 39.4%\n",
      "Average GPU usage: 27.7%\n",
      "Average GPU power: 45.1 W\n",
      "Total energy consumed: 7.332 Wh (0.007332 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Saved model_1 metrics to saved_metrics/model_1_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "model_to_train = ('model_1', build_model_1)\n",
    "\n",
    "model_name, model_builder = model_to_train\n",
    "\n",
    "print(f\"\\n{'#'*80}\")\n",
    "print(f\"STARTING TRAINING: {model_name}\")\n",
    "print(f\"{'#'*80}\\n\")\n",
    "\n",
    "try:\n",
    "    metrics = train_model_with_metrics(model_builder, model_name, \n",
    "                                      early_stopping_patience=5, \n",
    "                                      monitor_resources=True)\n",
    "    \n",
    "    # Save immediately\n",
    "    os.makedirs('saved_metrics', exist_ok=True)\n",
    "    with open(f'saved_metrics/{model_name}_metrics.pkl', 'wb') as f:\n",
    "        pickle.dump(metrics, f)\n",
    "    print(f\"\\nSaved {model_name} metrics to saved_metrics/{model_name}_metrics.pkl\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error training {model_name}: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ba647eb-004f-4f8b-88f6-351cc317c929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in metrics:\n",
      "[{'model_name': 'model_1',\n",
      "  'resource_stats': [{'cpu_freq_mean': 3987.050444915254,\n",
      "                      'cpu_usage_max': 72.7,\n",
      "                      'cpu_usage_mean': 33.76101694915254,\n",
      "                      'duration_seconds': 64.58969044685364,\n",
      "                      'gpu_energy_wh': 0.7884506694278888,\n",
      "                      'gpu_memory_max_mb': 1661.4375,\n",
      "                      'gpu_memory_mean_mb': 1589.6694915254238,\n",
      "                      'gpu_power_max_w': 47.398,\n",
      "                      'gpu_power_mean_w': 43.94544067796609,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 28.89830508474576,\n",
      "                      'ram_usage_max': 40.0,\n",
      "                      'ram_usage_mean': 36.777966101694915},\n",
      "                     {'cpu_freq_mean': 3977.981664351853,\n",
      "                      'cpu_usage_max': 46.8,\n",
      "                      'cpu_usage_mean': 28.44814814814814,\n",
      "                      'duration_seconds': 58.64923596382141,\n",
      "                      'gpu_energy_wh': 0.7297865623583397,\n",
      "                      'gpu_memory_max_mb': 1647.3125,\n",
      "                      'gpu_memory_mean_mb': 1641.6226851851852,\n",
      "                      'gpu_power_max_w': 46.631,\n",
      "                      'gpu_power_mean_w': 44.795666666666676,\n",
      "                      'gpu_usage_max': 34.0,\n",
      "                      'gpu_usage_mean': 29.185185185185187,\n",
      "                      'ram_usage_max': 40.3,\n",
      "                      'ram_usage_mean': 38.69814814814816},\n",
      "                     {'cpu_freq_mean': 3977.8110370370373,\n",
      "                      'cpu_usage_max': 51.9,\n",
      "                      'cpu_usage_mean': 29.266666666666666,\n",
      "                      'duration_seconds': 58.63819885253906,\n",
      "                      'gpu_energy_wh': 0.736842056663419,\n",
      "                      'gpu_memory_max_mb': 1643.5625,\n",
      "                      'gpu_memory_mean_mb': 1643.5625,\n",
      "                      'gpu_power_max_w': 47.771,\n",
      "                      'gpu_power_mean_w': 45.237259259259254,\n",
      "                      'gpu_usage_max': 33.0,\n",
      "                      'gpu_usage_mean': 28.074074074074073,\n",
      "                      'ram_usage_max': 39.5,\n",
      "                      'ram_usage_mean': 38.5537037037037},\n",
      "                     {'cpu_freq_mean': 3978.798064814814,\n",
      "                      'cpu_usage_max': 44.4,\n",
      "                      'cpu_usage_mean': 29.01481481481481,\n",
      "                      'duration_seconds': 58.644920349121094,\n",
      "                      'gpu_energy_wh': 0.7372619769511591,\n",
      "                      'gpu_memory_max_mb': 1643.5625,\n",
      "                      'gpu_memory_mean_mb': 1643.3819444444443,\n",
      "                      'gpu_power_max_w': 47.672,\n",
      "                      'gpu_power_mean_w': 45.25785185185183,\n",
      "                      'gpu_usage_max': 33.0,\n",
      "                      'gpu_usage_mean': 28.27777777777778,\n",
      "                      'ram_usage_max': 39.6,\n",
      "                      'ram_usage_mean': 38.83518518518519},\n",
      "                     {'cpu_freq_mean': 3992.694238425926,\n",
      "                      'cpu_usage_max': 55.7,\n",
      "                      'cpu_usage_mean': 30.03148148148148,\n",
      "                      'duration_seconds': 58.623122692108154,\n",
      "                      'gpu_energy_wh': 0.7388907839834101,\n",
      "                      'gpu_memory_max_mb': 1643.3125,\n",
      "                      'gpu_memory_mean_mb': 1643.3125,\n",
      "                      'gpu_power_max_w': 47.573,\n",
      "                      'gpu_power_mean_w': 45.3747037037037,\n",
      "                      'gpu_usage_max': 32.0,\n",
      "                      'gpu_usage_mean': 27.72222222222222,\n",
      "                      'ram_usage_max': 39.8,\n",
      "                      'ram_usage_mean': 39.144444444444446},\n",
      "                     {'cpu_freq_mean': 3970.378539351852,\n",
      "                      'cpu_usage_max': 43.7,\n",
      "                      'cpu_usage_mean': 29.937037037037037,\n",
      "                      'duration_seconds': 58.63872289657593,\n",
      "                      'gpu_energy_wh': 0.7376066618676416,\n",
      "                      'gpu_memory_max_mb': 1643.3125,\n",
      "                      'gpu_memory_mean_mb': 1642.0162037037037,\n",
      "                      'gpu_power_max_w': 48.061,\n",
      "                      'gpu_power_mean_w': 45.283796296296295,\n",
      "                      'gpu_usage_max': 32.0,\n",
      "                      'gpu_usage_mean': 27.814814814814813,\n",
      "                      'ram_usage_max': 40.0,\n",
      "                      'ram_usage_mean': 39.109259259259254},\n",
      "                     {'cpu_freq_mean': 3983.0213590425537,\n",
      "                      'cpu_usage_max': 38.0,\n",
      "                      'cpu_usage_mean': 30.689361702127663,\n",
      "                      'duration_seconds': 50.86537837982178,\n",
      "                      'gpu_energy_wh': 0.6412161146787605,\n",
      "                      'gpu_memory_max_mb': 1641.3125,\n",
      "                      'gpu_memory_mean_mb': 1641.3125,\n",
      "                      'gpu_power_max_w': 47.179,\n",
      "                      'gpu_power_mean_w': 45.38210638297872,\n",
      "                      'gpu_usage_max': 32.0,\n",
      "                      'gpu_usage_mean': 27.19148936170213,\n",
      "                      'ram_usage_max': 40.4,\n",
      "                      'ram_usage_mean': 39.612765957446804},\n",
      "                     {'cpu_freq_mean': 3969.8597287735843,\n",
      "                      'cpu_usage_max': 48.1,\n",
      "                      'cpu_usage_mean': 31.575471698113198,\n",
      "                      'duration_seconds': 57.525681495666504,\n",
      "                      'gpu_energy_wh': 0.7239796959517586,\n",
      "                      'gpu_memory_max_mb': 1641.3125,\n",
      "                      'gpu_memory_mean_mb': 1641.3125,\n",
      "                      'gpu_power_max_w': 47.751,\n",
      "                      'gpu_power_mean_w': 45.30718867924528,\n",
      "                      'gpu_usage_max': 32.0,\n",
      "                      'gpu_usage_mean': 26.77358490566038,\n",
      "                      'ram_usage_max': 40.8,\n",
      "                      'ram_usage_mean': 39.74905660377358},\n",
      "                     {'cpu_freq_mean': 3963.0195324074075,\n",
      "                      'cpu_usage_max': 72.2,\n",
      "                      'cpu_usage_mean': 33.2462962962963,\n",
      "                      'duration_seconds': 58.61679482460022,\n",
      "                      'gpu_energy_wh': 0.7353042712265916,\n",
      "                      'gpu_memory_max_mb': 1641.3125,\n",
      "                      'gpu_memory_mean_mb': 1640.423611111111,\n",
      "                      'gpu_power_max_w': 47.021,\n",
      "                      'gpu_power_mean_w': 45.159333333333336,\n",
      "                      'gpu_usage_max': 33.0,\n",
      "                      'gpu_usage_mean': 27.0,\n",
      "                      'ram_usage_max': 41.1,\n",
      "                      'ram_usage_mean': 39.88518518518518},\n",
      "                     {'cpu_freq_mean': 3993.3131696428572,\n",
      "                      'cpu_usage_max': 65.4,\n",
      "                      'cpu_usage_mean': 38.81964285714286,\n",
      "                      'duration_seconds': 60.87736463546753,\n",
      "                      'gpu_energy_wh': 0.7631463830453985,\n",
      "                      'gpu_memory_max_mb': 1656.5,\n",
      "                      'gpu_memory_mean_mb': 1628.431919642857,\n",
      "                      'gpu_power_max_w': 47.862,\n",
      "                      'gpu_power_mean_w': 45.128875,\n",
      "                      'gpu_usage_max': 34.0,\n",
      "                      'gpu_usage_mean': 26.035714285714285,\n",
      "                      'ram_usage_max': 45.1,\n",
      "                      'ram_usage_mean': 43.14821428571428}],\n",
      "  'stopped_epochs': [30, 30, 30, 30, 30, 30, 26, 30, 30, 30],\n",
      "  'test_acc': [39.316579699516296,\n",
      "               51.555025577545166,\n",
      "               53.34233641624451,\n",
      "               33.271524310112,\n",
      "               37.14401423931122,\n",
      "               42.124542593955994,\n",
      "               41.40101373195648,\n",
      "               42.14208722114563,\n",
      "               47.97206521034241,\n",
      "               34.40248966217041],\n",
      "  'test_f1': [0.25843068957328796,\n",
      "              0.4584636390209198,\n",
      "              0.48478543758392334,\n",
      "              0.12038042396306992,\n",
      "              0.21842257678508759,\n",
      "              0.2811669111251831,\n",
      "              0.286175936460495,\n",
      "              0.31752610206604004,\n",
      "              0.4151246249675751,\n",
      "              0.16076110303401947],\n",
      "  'test_loss': [2.0446324348449707,\n",
      "                1.6911598443984985,\n",
      "                1.5980674028396606,\n",
      "                2.2914061546325684,\n",
      "                2.0703089237213135,\n",
      "                1.9847261905670166,\n",
      "                1.996355414390564,\n",
      "                1.9811879396438599,\n",
      "                1.7815061807632446,\n",
      "                2.185992956161499],\n",
      "  'test_precision': [0.6476064324378967,\n",
      "                     0.7123236656188965,\n",
      "                     0.7420092821121216,\n",
      "                     0.6230847835540771,\n",
      "                     0.6508221626281738,\n",
      "                     0.6776507496833801,\n",
      "                     0.6888103485107422,\n",
      "                     0.6731170415878296,\n",
      "                     0.7092356085777283,\n",
      "                     0.6662230491638184],\n",
      "  'test_recall': [0.16578389704227448,\n",
      "                  0.34401482343673706,\n",
      "                  0.36556077003479004,\n",
      "                  0.06859992444515228,\n",
      "                  0.13493597507476807,\n",
      "                  0.18282665312290192,\n",
      "                  0.18504366278648376,\n",
      "                  0.2133851945400238,\n",
      "                  0.29946595430374146,\n",
      "                  0.09483224898576736],\n",
      "  'val_acc': [39.621955156326294,\n",
      "              51.97432041168213,\n",
      "              51.83347463607788,\n",
      "              31.15565776824951,\n",
      "              38.19680213928223,\n",
      "              42.070379853248596,\n",
      "              41.238486766815186,\n",
      "              42.99132823944092,\n",
      "              49.08477962017059,\n",
      "              34.63572859764099],\n",
      "  'val_f1': [0.2718130648136139,\n",
      "             0.4706762731075287,\n",
      "             0.4765740633010864,\n",
      "             0.13597875833511353,\n",
      "             0.2291477918624878,\n",
      "             0.28994128108024597,\n",
      "             0.28704506158828735,\n",
      "             0.33659791946411133,\n",
      "             0.41526833176612854,\n",
      "             0.15867379307746887],\n",
      "  'val_loss': [2.0277609825134277,\n",
      "               1.6798732280731201,\n",
      "               1.6528164148330688,\n",
      "               2.312744617462158,\n",
      "               2.078036308288574,\n",
      "               1.9595849514007568,\n",
      "               1.9900116920471191,\n",
      "               1.9299582242965698,\n",
      "               1.7700695991516113,\n",
      "               2.1678833961486816],\n",
      "  'val_precision': [0.6744260191917419,\n",
      "                    0.7318173050880432,\n",
      "                    0.733955979347229,\n",
      "                    0.6828932762145996,\n",
      "                    0.6575222015380859,\n",
      "                    0.6937742233276367,\n",
      "                    0.6720571517944336,\n",
      "                    0.6979617476463318,\n",
      "                    0.712415337562561,\n",
      "                    0.6701046228408813],\n",
      "  'val_recall': [0.17190849781036377,\n",
      "                 0.3481971025466919,\n",
      "                 0.3549634516239166,\n",
      "                 0.07667594403028488,\n",
      "                 0.14003205299377441,\n",
      "                 0.18505306541919708,\n",
      "                 0.18375802040100098,\n",
      "                 0.22326579689979553,\n",
      "                 0.2946256697177887,\n",
      "                 0.09114201366901398]},\n",
      " {'model_name': 'model_2',\n",
      "  'resource_stats': [{'cpu_freq_mean': 3919.9764287974676,\n",
      "                      'cpu_usage_max': 41.8,\n",
      "                      'cpu_usage_mean': 26.684810126582278,\n",
      "                      'duration_seconds': 86.40419673919678,\n",
      "                      'gpu_energy_wh': 1.0944999457791151,\n",
      "                      'gpu_memory_max_mb': 1510.875,\n",
      "                      'gpu_memory_mean_mb': 1490.2294303797469,\n",
      "                      'gpu_power_max_w': 48.152,\n",
      "                      'gpu_power_mean_w': 45.601949367088615,\n",
      "                      'gpu_usage_max': 35.0,\n",
      "                      'gpu_usage_mean': 30.11392405063291,\n",
      "                      'ram_usage_max': 39.0,\n",
      "                      'ram_usage_mean': 37.81392405063292},\n",
      "                     {'cpu_freq_mean': 3975.0756718750004,\n",
      "                      'cpu_usage_max': 50.0,\n",
      "                      'cpu_usage_mean': 27.108749999999997,\n",
      "                      'duration_seconds': 87.38786911964417,\n",
      "                      'gpu_energy_wh': 1.111969368053721,\n",
      "                      'gpu_memory_max_mb': 1504.875,\n",
      "                      'gpu_memory_mean_mb': 1504.875,\n",
      "                      'gpu_power_max_w': 47.909,\n",
      "                      'gpu_power_mean_w': 45.808299999999996,\n",
      "                      'gpu_usage_max': 35.0,\n",
      "                      'gpu_usage_mean': 30.225,\n",
      "                      'ram_usage_max': 39.9,\n",
      "                      'ram_usage_mean': 38.65625},\n",
      "                     {'cpu_freq_mean': 3969.2876971153846,\n",
      "                      'cpu_usage_max': 44.2,\n",
      "                      'cpu_usage_mean': 27.024358974358968,\n",
      "                      'duration_seconds': 85.16726064682007,\n",
      "                      'gpu_energy_wh': 1.0859122968635635,\n",
      "                      'gpu_memory_max_mb': 1504.875,\n",
      "                      'gpu_memory_mean_mb': 1504.875,\n",
      "                      'gpu_power_max_w': 47.946,\n",
      "                      'gpu_power_mean_w': 45.90125641025641,\n",
      "                      'gpu_usage_max': 35.0,\n",
      "                      'gpu_usage_mean': 29.53846153846154,\n",
      "                      'ram_usage_max': 40.3,\n",
      "                      'ram_usage_mean': 39.09615384615384},\n",
      "                     {'cpu_freq_mean': 3984.3193316831675,\n",
      "                      'cpu_usage_max': 41.5,\n",
      "                      'cpu_usage_mean': 27.785148514851493,\n",
      "                      'duration_seconds': 110.62537884712219,\n",
      "                      'gpu_energy_wh': 1.4055413800354317,\n",
      "                      'gpu_memory_max_mb': 1504.875,\n",
      "                      'gpu_memory_mean_mb': 1476.0309405940593,\n",
      "                      'gpu_power_max_w': 48.057,\n",
      "                      'gpu_power_mean_w': 45.739495049504946,\n",
      "                      'gpu_usage_max': 35.0,\n",
      "                      'gpu_usage_mean': 29.73267326732673,\n",
      "                      'ram_usage_max': 40.5,\n",
      "                      'ram_usage_mean': 39.521782178217826},\n",
      "                     {'cpu_freq_mean': 3984.3408056930684,\n",
      "                      'cpu_usage_max': 50.6,\n",
      "                      'cpu_usage_mean': 28.96336633663367,\n",
      "                      'duration_seconds': 110.62802743911743,\n",
      "                      'gpu_energy_wh': 1.401989661102438,\n",
      "                      'gpu_memory_max_mb': 1428.4375,\n",
      "                      'gpu_memory_mean_mb': 1428.4375,\n",
      "                      'gpu_power_max_w': 47.648,\n",
      "                      'gpu_power_mean_w': 45.62282178217822,\n",
      "                      'gpu_usage_max': 35.0,\n",
      "                      'gpu_usage_mean': 29.712871287128714,\n",
      "                      'ram_usage_max': 42.1,\n",
      "                      'ram_usage_mean': 40.024752475247524},\n",
      "                     {'cpu_freq_mean': 3941.311636764705,\n",
      "                      'cpu_usage_max': 46.2,\n",
      "                      'cpu_usage_mean': 29.023529411764713,\n",
      "                      'duration_seconds': 92.93550968170166,\n",
      "                      'gpu_energy_wh': 1.1756660871092008,\n",
      "                      'gpu_memory_max_mb': 1428.4375,\n",
      "                      'gpu_memory_mean_mb': 1428.4375,\n",
      "                      'gpu_power_max_w': 48.156,\n",
      "                      'gpu_power_mean_w': 45.54123529411764,\n",
      "                      'gpu_usage_max': 35.0,\n",
      "                      'gpu_usage_mean': 29.423529411764704,\n",
      "                      'ram_usage_max': 41.8,\n",
      "                      'ram_usage_mean': 40.22117647058824},\n",
      "                     {'cpu_freq_mean': 3973.2608366477275,\n",
      "                      'cpu_usage_max': 39.7,\n",
      "                      'cpu_usage_mean': 29.919318181818188,\n",
      "                      'duration_seconds': 96.24813675880432,\n",
      "                      'gpu_energy_wh': 1.2186183795882182,\n",
      "                      'gpu_memory_max_mb': 1428.4375,\n",
      "                      'gpu_memory_mean_mb': 1426.6647727272727,\n",
      "                      'gpu_power_max_w': 48.041,\n",
      "                      'gpu_power_mean_w': 45.580375000000004,\n",
      "                      'gpu_usage_max': 34.0,\n",
      "                      'gpu_usage_mean': 29.65909090909091,\n",
      "                      'ram_usage_max': 41.7,\n",
      "                      'ram_usage_mean': 40.7659090909091},\n",
      "                     {'cpu_freq_mean': 3954.0610649038467,\n",
      "                      'cpu_usage_max': 40.5,\n",
      "                      'cpu_usage_mean': 30.190384615384616,\n",
      "                      'duration_seconds': 56.42031931877136,\n",
      "                      'gpu_energy_wh': 0.7146377876491182,\n",
      "                      'gpu_memory_max_mb': 1428.4375,\n",
      "                      'gpu_memory_mean_mb': 1427.7451923076924,\n",
      "                      'gpu_power_max_w': 47.958,\n",
      "                      'gpu_power_mean_w': 45.598749999999995,\n",
      "                      'gpu_usage_max': 33.0,\n",
      "                      'gpu_usage_mean': 28.5,\n",
      "                      'ram_usage_max': 41.8,\n",
      "                      'ram_usage_mean': 40.925},\n",
      "                     {'cpu_freq_mean': 3979.6475459183675,\n",
      "                      'cpu_usage_max': 47.6,\n",
      "                      'cpu_usage_mean': 30.851020408163265,\n",
      "                      'duration_seconds': 107.30214715003967,\n",
      "                      'gpu_energy_wh': 1.3572699689269065,\n",
      "                      'gpu_memory_max_mb': 1428.4375,\n",
      "                      'gpu_memory_mean_mb': 1428.4375,\n",
      "                      'gpu_power_max_w': 47.648,\n",
      "                      'gpu_power_mean_w': 45.53657142857143,\n",
      "                      'gpu_usage_max': 33.0,\n",
      "                      'gpu_usage_mean': 29.06122448979592,\n",
      "                      'ram_usage_max': 42.5,\n",
      "                      'ram_usage_mean': 41.28061224489796},\n",
      "                     {'cpu_freq_mean': 3980.8448425925926,\n",
      "                      'cpu_usage_max': 40.0,\n",
      "                      'cpu_usage_mean': 31.411111111111108,\n",
      "                      'duration_seconds': 88.50718021392822,\n",
      "                      'gpu_energy_wh': 1.1216005637645559,\n",
      "                      'gpu_memory_max_mb': 1430.4375,\n",
      "                      'gpu_memory_mean_mb': 1430.3881172839506,\n",
      "                      'gpu_power_max_w': 48.215,\n",
      "                      'gpu_power_mean_w': 45.620728395061725,\n",
      "                      'gpu_usage_max': 34.0,\n",
      "                      'gpu_usage_mean': 28.679012345679013,\n",
      "                      'ram_usage_max': 42.6,\n",
      "                      'ram_usage_mean': 41.70617283950617}],\n",
      "  'stopped_epochs': [23, 24, 23, 30, 30, 25, 26, 15, 29, 24],\n",
      "  'test_acc': [64.2068862915039,\n",
      "               53.641682863235474,\n",
      "               54.15260195732117,\n",
      "               41.74834489822388,\n",
      "               53.86691689491272,\n",
      "               60.9008252620697,\n",
      "               47.85880446434021,\n",
      "               62.40581274032593,\n",
      "               60.596293210983276,\n",
      "               59.23670530319214],\n",
      "  'test_f1': [0.646221399307251,\n",
      "              0.49181225895881653,\n",
      "              0.49859485030174255,\n",
      "              0.287466824054718,\n",
      "              0.4966266453266144,\n",
      "              0.5941590070724487,\n",
      "              0.3948690891265869,\n",
      "              0.618281900882721,\n",
      "              0.6023643612861633,\n",
      "              0.5812996029853821],\n",
      "  'test_loss': [1.286696195602417,\n",
      "                1.6177268028259277,\n",
      "                1.5612900257110596,\n",
      "                1.9619386196136475,\n",
      "                1.604347586631775,\n",
      "                1.3967293500900269,\n",
      "                1.773937702178955,\n",
      "                1.3241831064224243,\n",
      "                1.3837467432022095,\n",
      "                1.4207677841186523],\n",
      "  'test_precision': [0.7600510120391846,\n",
      "                     0.7281197905540466,\n",
      "                     0.7319200038909912,\n",
      "                     0.6687319278717041,\n",
      "                     0.7194798588752747,\n",
      "                     0.7372875809669495,\n",
      "                     0.702256441116333,\n",
      "                     0.7614996433258057,\n",
      "                     0.7566819787025452,\n",
      "                     0.7390094995498657],\n",
      "  'test_recall': [0.5659428238868713,\n",
      "                  0.3764565587043762,\n",
      "                  0.3834756314754486,\n",
      "                  0.18780015408992767,\n",
      "                  0.38431796431541443,\n",
      "                  0.501684844493866,\n",
      "                  0.281438946723938,\n",
      "                  0.5240074992179871,\n",
      "                  0.5045844912528992,\n",
      "                  0.4830571711063385],\n",
      "  'val_acc': [64.71586227416992,\n",
      "              52.77373790740967,\n",
      "              52.88636088371277,\n",
      "              42.10844039916992,\n",
      "              53.69607210159302,\n",
      "              60.94239354133606,\n",
      "              48.23073148727417,\n",
      "              63.52360248565674,\n",
      "              60.05539298057556,\n",
      "              60.976195335388184],\n",
      "  'val_f1': [0.6486438512802124,\n",
      "             0.49294647574424744,\n",
      "             0.5000045299530029,\n",
      "             0.28085780143737793,\n",
      "             0.4964251220226288,\n",
      "             0.601593554019928,\n",
      "             0.39951181411743164,\n",
      "             0.6381775736808777,\n",
      "             0.6030941009521484,\n",
      "             0.6075432300567627],\n",
      "  'val_loss': [1.2519558668136597,\n",
      "               1.6242262125015259,\n",
      "               1.6241570711135864,\n",
      "               1.929674744606018,\n",
      "               1.6131776571273804,\n",
      "               1.397290587425232,\n",
      "               1.7611578702926636,\n",
      "               1.2760266065597534,\n",
      "               1.3956594467163086,\n",
      "               1.3940435647964478],\n",
      "  'val_precision': [0.7690216302871704,\n",
      "                    0.7115864753723145,\n",
      "                    0.7128808498382568,\n",
      "                    0.6689829230308533,\n",
      "                    0.7116274237632751,\n",
      "                    0.7509951591491699,\n",
      "                    0.71102374792099,\n",
      "                    0.767073392868042,\n",
      "                    0.7439173460006714,\n",
      "                    0.75304114818573],\n",
      "  'val_recall': [0.562956690788269,\n",
      "                 0.3798449635505676,\n",
      "                 0.38782623410224915,\n",
      "                 0.1814134567975998,\n",
      "                 0.3843992352485657,\n",
      "                 0.5038518905639648,\n",
      "                 0.2806766629219055,\n",
      "                 0.5485175848007202,\n",
      "                 0.5090544819831848,\n",
      "                 0.5112089514732361]},\n",
      " {'model_name': 'model_3',\n",
      "  'resource_stats': [{'cpu_freq_mean': 4000.063292613637,\n",
      "                      'cpu_usage_max': 43.0,\n",
      "                      'cpu_usage_mean': 25.775,\n",
      "                      'duration_seconds': 96.23422598838806,\n",
      "                      'gpu_energy_wh': 1.2538004323690592,\n",
      "                      'gpu_memory_max_mb': 1458.4375,\n",
      "                      'gpu_memory_mean_mb': 1449.7102272727273,\n",
      "                      'gpu_power_max_w': 49.972,\n",
      "                      'gpu_power_mean_w': 46.90307954545454,\n",
      "                      'gpu_usage_max': 38.0,\n",
      "                      'gpu_usage_mean': 32.98863636363637,\n",
      "                      'ram_usage_max': 42.6,\n",
      "                      'ram_usage_mean': 41.86590909090909},\n",
      "                     {'cpu_freq_mean': 3969.6499171195655,\n",
      "                      'cpu_usage_max': 43.2,\n",
      "                      'cpu_usage_mean': 25.92282608695652,\n",
      "                      'duration_seconds': 100.64058589935303,\n",
      "                      'gpu_energy_wh': 1.3341699434663794,\n",
      "                      'gpu_memory_max_mb': 1448.4375,\n",
      "                      'gpu_memory_mean_mb': 1446.4375,\n",
      "                      'gpu_power_max_w': 50.262,\n",
      "                      'gpu_power_mean_w': 47.72440217391304,\n",
      "                      'gpu_usage_max': 39.0,\n",
      "                      'gpu_usage_mean': 33.21739130434783,\n",
      "                      'ram_usage_max': 43.1,\n",
      "                      'ram_usage_mean': 42.27717391304348},\n",
      "                     {'cpu_freq_mean': 3973.1128412921353,\n",
      "                      'cpu_usage_max': 46.2,\n",
      "                      'cpu_usage_mean': 27.785393258426968,\n",
      "                      'duration_seconds': 97.33755874633789,\n",
      "                      'gpu_energy_wh': 1.2990353422960006,\n",
      "                      'gpu_memory_max_mb': 1448.4375,\n",
      "                      'gpu_memory_mean_mb': 1447.8532303370787,\n",
      "                      'gpu_power_max_w': 50.912,\n",
      "                      'gpu_power_mean_w': 48.04442696629214,\n",
      "                      'gpu_usage_max': 38.0,\n",
      "                      'gpu_usage_mean': 32.98876404494382,\n",
      "                      'ram_usage_max': 43.2,\n",
      "                      'ram_usage_mean': 42.81348314606742},\n",
      "                     {'cpu_freq_mean': 3975.3834305555556,\n",
      "                      'cpu_usage_max': 40.7,\n",
      "                      'cpu_usage_mean': 27.849382716049384,\n",
      "                      'duration_seconds': 88.4851484298706,\n",
      "                      'gpu_energy_wh': 1.1868161567259718,\n",
      "                      'gpu_memory_max_mb': 1448.4375,\n",
      "                      'gpu_memory_mean_mb': 1448.4375,\n",
      "                      'gpu_power_max_w': 51.38,\n",
      "                      'gpu_power_mean_w': 48.28537037037037,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 32.641975308641975,\n",
      "                      'ram_usage_max': 43.8,\n",
      "                      'ram_usage_mean': 43.016049382716055},\n",
      "                     {'cpu_freq_mean': 3971.469214285713,\n",
      "                      'cpu_usage_max': 39.2,\n",
      "                      'cpu_usage_mean': 28.330000000000002,\n",
      "                      'duration_seconds': 76.32907772064209,\n",
      "                      'gpu_energy_wh': 1.0126557538675998,\n",
      "                      'gpu_memory_max_mb': 1448.4375,\n",
      "                      'gpu_memory_mean_mb': 1445.6946428571428,\n",
      "                      'gpu_power_max_w': 50.12,\n",
      "                      'gpu_power_mean_w': 47.7611,\n",
      "                      'gpu_usage_max': 38.0,\n",
      "                      'gpu_usage_mean': 32.457142857142856,\n",
      "                      'ram_usage_max': 44.5,\n",
      "                      'ram_usage_mean': 43.49285714285713},\n",
      "                     {'cpu_freq_mean': 3973.0795575842703,\n",
      "                      'cpu_usage_max': 41.8,\n",
      "                      'cpu_usage_mean': 28.604494382022473,\n",
      "                      'duration_seconds': 97.34120607376099,\n",
      "                      'gpu_energy_wh': 1.2878126115186832,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1436.4375,\n",
      "                      'gpu_power_max_w': 50.241,\n",
      "                      'gpu_power_mean_w': 47.62757303370787,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 32.449438202247194,\n",
      "                      'ram_usage_max': 44.6,\n",
      "                      'ram_usage_mean': 43.688764044943824},\n",
      "                     {'cpu_freq_mean': 3973.919,\n",
      "                      'cpu_usage_max': 39.2,\n",
      "                      'cpu_usage_mean': 29.111428571428576,\n",
      "                      'duration_seconds': 115.04628252983093,\n",
      "                      'gpu_energy_wh': 1.5242819806699015,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1436.4375,\n",
      "                      'gpu_power_max_w': 50.249,\n",
      "                      'gpu_power_mean_w': 47.69745714285715,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 32.628571428571426,\n",
      "                      'ram_usage_max': 45.0,\n",
      "                      'ram_usage_mean': 44.15142857142857},\n",
      "                     {'cpu_freq_mean': 3984.0863175000004,\n",
      "                      'cpu_usage_max': 50.0,\n",
      "                      'cpu_usage_mean': 30.020000000000003,\n",
      "                      'duration_seconds': 109.50204467773438,\n",
      "                      'gpu_energy_wh': 1.453531053569285,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1434.8775,\n",
      "                      'gpu_power_max_w': 50.423,\n",
      "                      'gpu_power_mean_w': 47.78642999999999,\n",
      "                      'gpu_usage_max': 38.0,\n",
      "                      'gpu_usage_mean': 32.48,\n",
      "                      'ram_usage_max': 45.2,\n",
      "                      'ram_usage_mean': 44.506},\n",
      "                     {'cpu_freq_mean': 3979.423288659794,\n",
      "                      'cpu_usage_max': 47.6,\n",
      "                      'cpu_usage_mean': 31.170103092783506,\n",
      "                      'duration_seconds': 106.18391680717468,\n",
      "                      'gpu_energy_wh': 1.4122387956717248,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1435.6127577319587,\n",
      "                      'gpu_power_max_w': 51.09,\n",
      "                      'gpu_power_mean_w': 47.87975257731958,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 32.381443298969074,\n",
      "                      'ram_usage_max': 45.4,\n",
      "                      'ram_usage_mean': 44.47525773195877},\n",
      "                     {'cpu_freq_mean': 3988.6364467821786,\n",
      "                      'cpu_usage_max': 38.8,\n",
      "                      'cpu_usage_mean': 31.260396039603968,\n",
      "                      'duration_seconds': 110.61484479904175,\n",
      "                      'gpu_energy_wh': 1.4670305960322723,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1436.4375,\n",
      "                      'gpu_power_max_w': 50.579,\n",
      "                      'gpu_power_mean_w': 47.745039603960386,\n",
      "                      'gpu_usage_max': 36.0,\n",
      "                      'gpu_usage_mean': 31.861386138613863,\n",
      "                      'ram_usage_max': 45.6,\n",
      "                      'ram_usage_mean': 44.637623762376236}],\n",
      "  'stopped_epochs': [22, 23, 22, 20, 17, 22, 26, 25, 24, 25],\n",
      "  'test_acc': [80.40153980255127,\n",
      "               81.00744485855103,\n",
      "               81.89061284065247,\n",
      "               80.60927391052246,\n",
      "               80.41570782661438,\n",
      "               82.03771710395813,\n",
      "               81.3380777835846,\n",
      "               79.83046174049377,\n",
      "               81.93660974502563,\n",
      "               81.54012560844421],\n",
      "  'test_f1': [0.8162059187889099,\n",
      "              0.8143453001976013,\n",
      "              0.8286104798316956,\n",
      "              0.8153938055038452,\n",
      "              0.8124980330467224,\n",
      "              0.8297846913337708,\n",
      "              0.8212760090827942,\n",
      "              0.8027656078338623,\n",
      "              0.8280354738235474,\n",
      "              0.8273259997367859],\n",
      "  'test_loss': [0.6846176385879517,\n",
      "                0.6753498315811157,\n",
      "                0.6233575940132141,\n",
      "                0.6690928936004639,\n",
      "                0.662858784198761,\n",
      "                0.6268210411071777,\n",
      "                0.6744645833969116,\n",
      "                0.7303102612495422,\n",
      "                0.6398298740386963,\n",
      "                0.6554320454597473],\n",
      "  'test_precision': [0.8778471350669861,\n",
      "                     0.8687154650688171,\n",
      "                     0.8850764632225037,\n",
      "                     0.8700651526451111,\n",
      "                     0.8820882439613342,\n",
      "                     0.8803873658180237,\n",
      "                     0.8726902008056641,\n",
      "                     0.8553572297096252,\n",
      "                     0.8808360695838928,\n",
      "                     0.8741235733032227],\n",
      "  'test_recall': [0.7648305296897888,\n",
      "                  0.7682732939720154,\n",
      "                  0.7810634970664978,\n",
      "                  0.7692267298698425,\n",
      "                  0.7556890249252319,\n",
      "                  0.7863907217979431,\n",
      "                  0.7773030996322632,\n",
      "                  0.7581813335418701,\n",
      "                  0.7833592891693115,\n",
      "                  0.7866845726966858],\n",
      "  'val_acc': [81.0371994972229,\n",
      "              81.62548542022705,\n",
      "              80.99963665008545,\n",
      "              81.43944144248962,\n",
      "              79.6776533126831,\n",
      "              81.70643448829651,\n",
      "              81.41056895256042,\n",
      "              81.47880434989929,\n",
      "              82.44219422340393,\n",
      "              82.21928477287292],\n",
      "  'val_f1': [0.8210753202438354,\n",
      "             0.8230018615722656,\n",
      "             0.8190158009529114,\n",
      "             0.8211835622787476,\n",
      "             0.8136784434318542,\n",
      "             0.8297998309135437,\n",
      "             0.8228397965431213,\n",
      "             0.826126217842102,\n",
      "             0.8340725302696228,\n",
      "             0.830852210521698],\n",
      "  'val_loss': [0.6430071592330933,\n",
      "               0.6519001722335815,\n",
      "               0.6530267596244812,\n",
      "               0.6635506749153137,\n",
      "               0.6791452169418335,\n",
      "               0.6330882906913757,\n",
      "               0.65585857629776,\n",
      "               0.6466890573501587,\n",
      "               0.630734920501709,\n",
      "               0.638058066368103],\n",
      "  'val_precision': [0.868129551410675,\n",
      "                    0.8777122497558594,\n",
      "                    0.8703895211219788,\n",
      "                    0.878476083278656,\n",
      "                    0.8699646592140198,\n",
      "                    0.8810459971427917,\n",
      "                    0.8705434799194336,\n",
      "                    0.8740469813346863,\n",
      "                    0.882622480392456,\n",
      "                    0.8761716485023499],\n",
      "  'val_recall': [0.7798699736595154,\n",
      "                 0.7757993936538696,\n",
      "                 0.7743474841117859,\n",
      "                 0.77228844165802,\n",
      "                 0.7656654119491577,\n",
      "                 0.7852048873901367,\n",
      "                 0.7811692953109741,\n",
      "                 0.784254789352417,\n",
      "                 0.7915865182876587,\n",
      "                 0.7910747528076172]},\n",
      " {'model_name': 'model_4',\n",
      "  'resource_stats': [{'cpu_freq_mean': 3931.3758038793103,\n",
      "                      'cpu_usage_max': 41.8,\n",
      "                      'cpu_usage_mean': 27.2551724137931,\n",
      "                      'duration_seconds': 63.206685066223145,\n",
      "                      'gpu_energy_wh': 1.1204874280912025,\n",
      "                      'gpu_memory_max_mb': 1484.4375,\n",
      "                      'gpu_memory_mean_mb': 1454.2478448275863,\n",
      "                      'gpu_power_max_w': 71.565,\n",
      "                      'gpu_power_mean_w': 63.81848275862068,\n",
      "                      'gpu_usage_max': 41.0,\n",
      "                      'gpu_usage_mean': 33.91379310344828,\n",
      "                      'ram_usage_max': 39.4,\n",
      "                      'ram_usage_mean': 38.463793103448275},\n",
      "                     {'cpu_freq_mean': 3965.324771739131,\n",
      "                      'cpu_usage_max': 43.2,\n",
      "                      'cpu_usage_mean': 26.53623188405797,\n",
      "                      'duration_seconds': 75.22318458557129,\n",
      "                      'gpu_energy_wh': 1.3827850425197155,\n",
      "                      'gpu_memory_max_mb': 1512.3125,\n",
      "                      'gpu_memory_mean_mb': 1506.6005434782608,\n",
      "                      'gpu_power_max_w': 71.179,\n",
      "                      'gpu_power_mean_w': 66.17675362318842,\n",
      "                      'gpu_usage_max': 39.0,\n",
      "                      'gpu_usage_mean': 34.10144927536232,\n",
      "                      'ram_usage_max': 40.3,\n",
      "                      'ram_usage_mean': 39.24927536231885},\n",
      "                     {'cpu_freq_mean': 3937.3504160714288,\n",
      "                      'cpu_usage_max': 37.5,\n",
      "                      'cpu_usage_mean': 26.47,\n",
      "                      'duration_seconds': 76.31735467910767,\n",
      "                      'gpu_energy_wh': 1.3766160778614904,\n",
      "                      'gpu_memory_max_mb': 1504.3125,\n",
      "                      'gpu_memory_mean_mb': 1504.3125,\n",
      "                      'gpu_power_max_w': 69.729,\n",
      "                      'gpu_power_mean_w': 64.93697142857141,\n",
      "                      'gpu_usage_max': 40.0,\n",
      "                      'gpu_usage_mean': 34.34285714285714,\n",
      "                      'ram_usage_max': 41.0,\n",
      "                      'ram_usage_mean': 39.682857142857145},\n",
      "                     {'cpu_freq_mean': 3958.0055131578947,\n",
      "                      'cpu_usage_max': 50.6,\n",
      "                      'cpu_usage_mean': 27.626315789473686,\n",
      "                      'duration_seconds': 61.94287657737732,\n",
      "                      'gpu_energy_wh': 1.0945617213068939,\n",
      "                      'gpu_memory_max_mb': 1504.3125,\n",
      "                      'gpu_memory_mean_mb': 1504.3125,\n",
      "                      'gpu_power_max_w': 70.157,\n",
      "                      'gpu_power_mean_w': 63.613807017543856,\n",
      "                      'gpu_usage_max': 39.0,\n",
      "                      'gpu_usage_mean': 33.96491228070175,\n",
      "                      'ram_usage_max': 40.7,\n",
      "                      'ram_usage_mean': 39.85438596491228},\n",
      "                     {'cpu_freq_mean': 3953.4695916666674,\n",
      "                      'cpu_usage_max': 45.6,\n",
      "                      'cpu_usage_mean': 27.88666666666667,\n",
      "                      'duration_seconds': 65.28297328948975,\n",
      "                      'gpu_energy_wh': 1.1258937317575612,\n",
      "                      'gpu_memory_max_mb': 1504.3125,\n",
      "                      'gpu_memory_mean_mb': 1504.3125,\n",
      "                      'gpu_power_max_w': 68.893,\n",
      "                      'gpu_power_mean_w': 62.0869,\n",
      "                      'gpu_usage_max': 40.0,\n",
      "                      'gpu_usage_mean': 34.13333333333333,\n",
      "                      'ram_usage_max': 41.4,\n",
      "                      'ram_usage_mean': 40.26333333333332},\n",
      "                     {'cpu_freq_mean': 3970.2096156716416,\n",
      "                      'cpu_usage_max': 41.6,\n",
      "                      'cpu_usage_mean': 28.119402985074622,\n",
      "                      'duration_seconds': 73.00595116615295,\n",
      "                      'gpu_energy_wh': 1.2292534420198877,\n",
      "                      'gpu_memory_max_mb': 1504.3125,\n",
      "                      'gpu_memory_mean_mb': 1504.3125,\n",
      "                      'gpu_power_max_w': 65.075,\n",
      "                      'gpu_power_mean_w': 60.615776119402994,\n",
      "                      'gpu_usage_max': 40.0,\n",
      "                      'gpu_usage_mean': 34.67164179104478,\n",
      "                      'ram_usage_max': 41.6,\n",
      "                      'ram_usage_mean': 40.5731343283582},\n",
      "                     {'cpu_freq_mean': 3952.090015,\n",
      "                      'cpu_usage_max': 42.5,\n",
      "                      'cpu_usage_mean': 28.217999999999993,\n",
      "                      'duration_seconds': 54.21151661872864,\n",
      "                      'gpu_energy_wh': 0.8843780704841679,\n",
      "                      'gpu_memory_max_mb': 1504.3125,\n",
      "                      'gpu_memory_mean_mb': 1504.3125,\n",
      "                      'gpu_power_max_w': 64.493,\n",
      "                      'gpu_power_mean_w': 58.7285,\n",
      "                      'gpu_usage_max': 39.0,\n",
      "                      'gpu_usage_mean': 33.32,\n",
      "                      'ram_usage_max': 41.5,\n",
      "                      'ram_usage_mean': 40.72800000000001},\n",
      "                     {'cpu_freq_mean': 3949.1007175925924,\n",
      "                      'cpu_usage_max': 38.5,\n",
      "                      'cpu_usage_mean': 28.792592592592595,\n",
      "                      'duration_seconds': 58.640095949172974,\n",
      "                      'gpu_energy_wh': 0.9341113901572611,\n",
      "                      'gpu_memory_max_mb': 1504.3125,\n",
      "                      'gpu_memory_mean_mb': 1504.3125,\n",
      "                      'gpu_power_max_w': 61.783,\n",
      "                      'gpu_power_mean_w': 57.34644444444445,\n",
      "                      'gpu_usage_max': 40.0,\n",
      "                      'gpu_usage_mean': 33.888888888888886,\n",
      "                      'ram_usage_max': 42.0,\n",
      "                      'ram_usage_mean': 40.90185185185185},\n",
      "                     {'cpu_freq_mean': 3960.44299,\n",
      "                      'cpu_usage_max': 44.3,\n",
      "                      'cpu_usage_mean': 29.448,\n",
      "                      'duration_seconds': 54.22077918052673,\n",
      "                      'gpu_energy_wh': 0.8952353691045138,\n",
      "                      'gpu_memory_max_mb': 1506.3125,\n",
      "                      'gpu_memory_mean_mb': 1488.41,\n",
      "                      'gpu_power_max_w': 63.885,\n",
      "                      'gpu_power_mean_w': 59.43934,\n",
      "                      'gpu_usage_max': 40.0,\n",
      "                      'gpu_usage_mean': 33.56,\n",
      "                      'ram_usage_max': 42.2,\n",
      "                      'ram_usage_mean': 41.21},\n",
      "                     {'cpu_freq_mean': 3962.57319140625,\n",
      "                      'cpu_usage_max': 43.8,\n",
      "                      'cpu_usage_mean': 30.012499999999996,\n",
      "                      'duration_seconds': 69.69172596931458,\n",
      "                      'gpu_energy_wh': 1.1126341522476482,\n",
      "                      'gpu_memory_max_mb': 1456.4375,\n",
      "                      'gpu_memory_mean_mb': 1456.4375,\n",
      "                      'gpu_power_max_w': 60.54,\n",
      "                      'gpu_power_mean_w': 57.474296875,\n",
      "                      'gpu_usage_max': 42.0,\n",
      "                      'gpu_usage_mean': 34.765625,\n",
      "                      'ram_usage_max': 42.5,\n",
      "                      'ram_usage_mean': 41.55}],\n",
      "  'stopped_epochs': [16, 20, 20, 16, 17, 19, 14, 15, 14, 18],\n",
      "  'test_acc': [63.64845037460327,\n",
      "               63.330674171447754,\n",
      "               64.52397108078003,\n",
      "               66.86092615127563,\n",
      "               66.10878705978394,\n",
      "               66.68023467063904,\n",
      "               63.52441906929016,\n",
      "               64.1953706741333,\n",
      "               64.7596001625061,\n",
      "               60.91487407684326],\n",
      "  'test_f1': [0.6410478353500366,\n",
      "              0.6370581388473511,\n",
      "              0.6450775861740112,\n",
      "              0.6771419048309326,\n",
      "              0.6656209826469421,\n",
      "              0.6716916561126709,\n",
      "              0.6337358951568604,\n",
      "              0.6459304690361023,\n",
      "              0.6552687287330627,\n",
      "              0.5982211828231812],\n",
      "  'test_loss': [1.273637056350708,\n",
      "                1.3439936637878418,\n",
      "                1.2396461963653564,\n",
      "                1.173840045928955,\n",
      "                1.2132333517074585,\n",
      "                1.2344979047775269,\n",
      "                1.281023621559143,\n",
      "                1.274652123451233,\n",
      "                1.2415237426757812,\n",
      "                1.363387107849121],\n",
      "  'test_precision': [0.7639558911323547,\n",
      "                     0.7535420656204224,\n",
      "                     0.7611289620399475,\n",
      "                     0.7720454335212708,\n",
      "                     0.773002028465271,\n",
      "                     0.7685158848762512,\n",
      "                     0.7639734148979187,\n",
      "                     0.7655409574508667,\n",
      "                     0.7750749588012695,\n",
      "                     0.7503856420516968],\n",
      "  'test_recall': [0.5560116767883301,\n",
      "                  0.5548199415206909,\n",
      "                  0.5634117722511292,\n",
      "                  0.6060734987258911,\n",
      "                  0.5878391265869141,\n",
      "                  0.5992227792739868,\n",
      "                  0.5452846884727478,\n",
      "                  0.5623658895492554,\n",
      "                  0.5717542767524719,\n",
      "                  0.50118488073349],\n",
      "  'val_acc': [64.54622745513916,\n",
      "              64.92248177528381,\n",
      "              64.44390416145325,\n",
      "              67.81789660453796,\n",
      "              66.04459285736084,\n",
      "              66.8353796005249,\n",
      "              63.936012983322144,\n",
      "              65.64306616783142,\n",
      "              65.96820950508118,\n",
      "              61.91391944885254],\n",
      "  'val_f1': [0.6565923094749451,\n",
      "             0.6524055004119873,\n",
      "             0.6448922753334045,\n",
      "             0.6874053478240967,\n",
      "             0.6658961176872253,\n",
      "             0.6861421465873718,\n",
      "             0.6555217504501343,\n",
      "             0.6644161939620972,\n",
      "             0.6685304641723633,\n",
      "             0.6093759536743164],\n",
      "  'val_loss': [1.2488255500793457,\n",
      "               1.2771925926208496,\n",
      "               1.2868068218231201,\n",
      "               1.1733051538467407,\n",
      "               1.2451610565185547,\n",
      "               1.2119555473327637,\n",
      "               1.2754313945770264,\n",
      "               1.2186115980148315,\n",
      "               1.2027281522750854,\n",
      "               1.351929783821106],\n",
      "  'val_precision': [0.7620696425437927,\n",
      "                    0.7668566703796387,\n",
      "                    0.7604122161865234,\n",
      "                    0.7598468661308289,\n",
      "                    0.7703210711479187,\n",
      "                    0.7655419707298279,\n",
      "                    0.7644233703613281,\n",
      "                    0.7703174948692322,\n",
      "                    0.7805362939834595,\n",
      "                    0.7646486759185791],\n",
      "  'val_recall': [0.5785022974014282,\n",
      "                 0.5694040656089783,\n",
      "                 0.5614869594573975,\n",
      "                 0.6286970973014832,\n",
      "                 0.5883640050888062,\n",
      "                 0.623054027557373,\n",
      "                 0.5753068327903748,\n",
      "                 0.5856971144676208,\n",
      "                 0.5864983797073364,\n",
      "                 0.5092974901199341]},\n",
      " {'model_name': 'model_5',\n",
      "  'resource_stats': [{'cpu_freq_mean': 3926.966936538461,\n",
      "                      'cpu_usage_max': 46.2,\n",
      "                      'cpu_usage_mean': 26.75846153846154,\n",
      "                      'duration_seconds': 70.93301367759705,\n",
      "                      'gpu_energy_wh': 0.9324368965997575,\n",
      "                      'gpu_memory_max_mb': 1495.125,\n",
      "                      'gpu_memory_mean_mb': 1461.325,\n",
      "                      'gpu_power_max_w': 49.702,\n",
      "                      'gpu_power_mean_w': 47.32313846153846,\n",
      "                      'gpu_usage_max': 38.0,\n",
      "                      'gpu_usage_mean': 31.661538461538463,\n",
      "                      'ram_usage_max': 39.1,\n",
      "                      'ram_usage_mean': 38.18},\n",
      "                     {'cpu_freq_mean': 3959.4186197916665,\n",
      "                      'cpu_usage_max': 38.7,\n",
      "                      'cpu_usage_mean': 27.118749999999995,\n",
      "                      'duration_seconds': 51.985142946243286,\n",
      "                      'gpu_energy_wh': 0.6883157833226025,\n",
      "                      'gpu_memory_max_mb': 1473.125,\n",
      "                      'gpu_memory_mean_mb': 1473.125,\n",
      "                      'gpu_power_max_w': 50.088,\n",
      "                      'gpu_power_mean_w': 47.66624999999999,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 31.645833333333332,\n",
      "                      'ram_usage_max': 39.7,\n",
      "                      'ram_usage_mean': 38.922916666666666},\n",
      "                     {'cpu_freq_mean': 2979.5708814935065,\n",
      "                      'cpu_usage_max': 41.8,\n",
      "                      'cpu_usage_mean': 18.442857142857143,\n",
      "                      'duration_seconds': 84.15209674835205,\n",
      "                      'gpu_energy_wh': 0.9804730189228367,\n",
      "                      'gpu_memory_max_mb': 1473.125,\n",
      "                      'gpu_memory_mean_mb': 1473.125,\n",
      "                      'gpu_power_max_w': 52.124,\n",
      "                      'gpu_power_mean_w': 41.94432467532467,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 20.272727272727273,\n",
      "                      'ram_usage_max': 40.9,\n",
      "                      'ram_usage_mean': 39.70649350649351},\n",
      "                     {'cpu_freq_mean': 3967.1459604166666,\n",
      "                      'cpu_usage_max': 46.2,\n",
      "                      'cpu_usage_mean': 27.615000000000002,\n",
      "                      'duration_seconds': 65.26356077194214,\n",
      "                      'gpu_energy_wh': 0.8736409875979335,\n",
      "                      'gpu_memory_max_mb': 1473.125,\n",
      "                      'gpu_memory_mean_mb': 1473.125,\n",
      "                      'gpu_power_max_w': 50.465,\n",
      "                      'gpu_power_mean_w': 48.190866666666665,\n",
      "                      'gpu_usage_max': 36.0,\n",
      "                      'gpu_usage_mean': 31.466666666666665,\n",
      "                      'ram_usage_max': 40.1,\n",
      "                      'ram_usage_mean': 39.461666666666666},\n",
      "                     {'cpu_freq_mean': 3959.2621913265302,\n",
      "                      'cpu_usage_max': 45.6,\n",
      "                      'cpu_usage_mean': 27.920408163265307,\n",
      "                      'duration_seconds': 53.08563566207886,\n",
      "                      'gpu_energy_wh': 0.7126424582927974,\n",
      "                      'gpu_memory_max_mb': 1473.125,\n",
      "                      'gpu_memory_mean_mb': 1473.125,\n",
      "                      'gpu_power_max_w': 50.249,\n",
      "                      'gpu_power_mean_w': 48.327816326530616,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 31.244897959183675,\n",
      "                      'ram_usage_max': 40.3,\n",
      "                      'ram_usage_mean': 39.76326530612245},\n",
      "                     {'cpu_freq_mean': 3957.91109868421,\n",
      "                      'cpu_usage_max': 38.0,\n",
      "                      'cpu_usage_mean': 28.361403508771932,\n",
      "                      'duration_seconds': 61.945088148117065,\n",
      "                      'gpu_energy_wh': 0.824624967742991,\n",
      "                      'gpu_memory_max_mb': 1473.125,\n",
      "                      'gpu_memory_mean_mb': 1473.125,\n",
      "                      'gpu_power_max_w': 49.615,\n",
      "                      'gpu_power_mean_w': 47.9238947368421,\n",
      "                      'gpu_usage_max': 36.0,\n",
      "                      'gpu_usage_mean': 31.12280701754386,\n",
      "                      'ram_usage_max': 40.5,\n",
      "                      'ram_usage_mean': 39.796491228070174},\n",
      "                     {'cpu_freq_mean': 3967.3315143442614,\n",
      "                      'cpu_usage_max': 37.0,\n",
      "                      'cpu_usage_mean': 29.157377049180333,\n",
      "                      'duration_seconds': 66.38011860847473,\n",
      "                      'gpu_energy_wh': 0.8868453369895866,\n",
      "                      'gpu_memory_max_mb': 1473.125,\n",
      "                      'gpu_memory_mean_mb': 1465.3811475409836,\n",
      "                      'gpu_power_max_w': 49.793,\n",
      "                      'gpu_power_mean_w': 48.09637704918032,\n",
      "                      'gpu_usage_max': 36.0,\n",
      "                      'gpu_usage_mean': 31.491803278688526,\n",
      "                      'ram_usage_max': 40.9,\n",
      "                      'ram_usage_mean': 40.17704918032786},\n",
      "                     {'cpu_freq_mean': 3904.6643725000004,\n",
      "                      'cpu_usage_max': 40.7,\n",
      "                      'cpu_usage_mean': 28.701999999999998,\n",
      "                      'duration_seconds': 54.19651937484741,\n",
      "                      'gpu_energy_wh': 0.7219623728044431,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1436.3575,\n",
      "                      'gpu_power_max_w': 50.054,\n",
      "                      'gpu_power_mean_w': 47.9563,\n",
      "                      'gpu_usage_max': 36.0,\n",
      "                      'gpu_usage_mean': 30.62,\n",
      "                      'ram_usage_max': 41.8,\n",
      "                      'ram_usage_mean': 40.552},\n",
      "                     {'cpu_freq_mean': 3992.505257075472,\n",
      "                      'cpu_usage_max': 38.5,\n",
      "                      'cpu_usage_mean': 29.466037735849063,\n",
      "                      'duration_seconds': 57.522998094558716,\n",
      "                      'gpu_energy_wh': 0.7688132600101073,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1436.4375,\n",
      "                      'gpu_power_max_w': 49.76,\n",
      "                      'gpu_power_mean_w': 48.11515094339623,\n",
      "                      'gpu_usage_max': 36.0,\n",
      "                      'gpu_usage_mean': 31.20754716981132,\n",
      "                      'ram_usage_max': 41.5,\n",
      "                      'ram_usage_mean': 40.788679245283014},\n",
      "                     {'cpu_freq_mean': 3941.0544200819672,\n",
      "                      'cpu_usage_max': 38.8,\n",
      "                      'cpu_usage_mean': 29.640983606557377,\n",
      "                      'duration_seconds': 66.38086700439453,\n",
      "                      'gpu_energy_wh': 0.8807677023013868,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1436.4375,\n",
      "                      'gpu_power_max_w': 49.607,\n",
      "                      'gpu_power_mean_w': 47.76622950819672,\n",
      "                      'gpu_usage_max': 36.0,\n",
      "                      'gpu_usage_mean': 30.770491803278688,\n",
      "                      'ram_usage_max': 42.1,\n",
      "                      'ram_usage_mean': 41.04590163934426}],\n",
      "  'stopped_epochs': [16, 12, 12, 15, 12, 14, 15, 12, 13, 15],\n",
      "  'test_acc': [78.85919213294983,\n",
      "               78.09675931930542,\n",
      "               78.12288999557495,\n",
      "               78.8476824760437,\n",
      "               78.08071374893188,\n",
      "               78.25261354446411,\n",
      "               78.38281393051147,\n",
      "               76.0360598564148,\n",
      "               78.98200154304504,\n",
      "               79.36121225357056],\n",
      "  'test_f1': [0.7991612553596497,\n",
      "              0.7836476564407349,\n",
      "              0.7935402989387512,\n",
      "              0.7947750687599182,\n",
      "              0.789522647857666,\n",
      "              0.7919145226478577,\n",
      "              0.7894721031188965,\n",
      "              0.7658020257949829,\n",
      "              0.7988405823707581,\n",
      "              0.803053081035614],\n",
      "  'test_loss': [0.7644521594047546,\n",
      "                0.7831308841705322,\n",
      "                0.7549455761909485,\n",
      "                0.7903650999069214,\n",
      "                0.7727659344673157,\n",
      "                0.7784739136695862,\n",
      "                0.8059980869293213,\n",
      "                0.8668837547302246,\n",
      "                0.7456684112548828,\n",
      "                0.7603257298469543],\n",
      "  'test_precision': [0.8390712141990662,\n",
      "                     0.8431696891784668,\n",
      "                     0.8478139638900757,\n",
      "                     0.840621292591095,\n",
      "                     0.8477718234062195,\n",
      "                     0.8456300497055054,\n",
      "                     0.8328896760940552,\n",
      "                     0.816638171672821,\n",
      "                     0.8516057133674622,\n",
      "                     0.8520129323005676],\n",
      "  'test_recall': [0.7643008232116699,\n",
      "                  0.734375,\n",
      "                  0.7476583123207092,\n",
      "                  0.7553231120109558,\n",
      "                  0.7407692074775696,\n",
      "                  0.7463597059249878,\n",
      "                  0.7517845630645752,\n",
      "                  0.7226395010948181,\n",
      "                  0.7539870142936707,\n",
      "                  0.7611443996429443],\n",
      "  'val_acc': [79.35296297073364,\n",
      "              77.48304009437561,\n",
      "              78.38557362556458,\n",
      "              78.95181775093079,\n",
      "              78.04168462753296,\n",
      "              78.94673347473145,\n",
      "              78.92631888389587,\n",
      "              77.7697503566742,\n",
      "              78.80539298057556,\n",
      "              78.925222158432],\n",
      "  'val_f1': [0.8011910319328308,\n",
      "             0.7957528233528137,\n",
      "             0.7917296290397644,\n",
      "             0.7958166003227234,\n",
      "             0.7942514419555664,\n",
      "             0.8039624094963074,\n",
      "             0.7985783219337463,\n",
      "             0.7952882647514343,\n",
      "             0.7957823276519775,\n",
      "             0.799362063407898],\n",
      "  'val_loss': [0.7543188333511353,\n",
      "               0.7821545600891113,\n",
      "               0.7771856188774109,\n",
      "               0.7791702151298523,\n",
      "               0.7823643684387207,\n",
      "               0.7635564208030701,\n",
      "               0.7833630442619324,\n",
      "               0.7731678485870361,\n",
      "               0.7568409442901611,\n",
      "               0.7589342594146729],\n",
      "  'val_precision': [0.8444647789001465,\n",
      "                    0.8353160619735718,\n",
      "                    0.8308535218238831,\n",
      "                    0.8336769342422485,\n",
      "                    0.8356466293334961,\n",
      "                    0.8407275080680847,\n",
      "                    0.838584303855896,\n",
      "                    0.8315503001213074,\n",
      "                    0.8492920398712158,\n",
      "                    0.831928551197052],\n",
      "  'val_recall': [0.7630277872085571,\n",
      "                 0.7605378031730652,\n",
      "                 0.7569368481636047,\n",
      "                 0.7619374990463257,\n",
      "                 0.7576469779014587,\n",
      "                 0.7710279226303101,\n",
      "                 0.763008713722229,\n",
      "                 0.7627003192901611,\n",
      "                 0.7496394515037537,\n",
      "                 0.769773542881012]},\n",
      " {'model_name': 'model_6',\n",
      "  'resource_stats': [{'cpu_freq_mean': 3972.170398529413,\n",
      "                      'cpu_usage_max': 43.8,\n",
      "                      'cpu_usage_mean': 27.05176470588236,\n",
      "                      'duration_seconds': 93.01991510391235,\n",
      "                      'gpu_energy_wh': 1.2626267927418504,\n",
      "                      'gpu_memory_max_mb': 1493.125,\n",
      "                      'gpu_memory_mean_mb': 1462.210294117647,\n",
      "                      'gpu_power_max_w': 53.671,\n",
      "                      'gpu_power_mean_w': 48.86541176470589,\n",
      "                      'gpu_usage_max': 39.0,\n",
      "                      'gpu_usage_mean': 32.31764705882353,\n",
      "                      'ram_usage_max': 40.4,\n",
      "                      'ram_usage_mean': 38.97176470588234},\n",
      "                     {'cpu_freq_mean': 3973.7807927631566,\n",
      "                      'cpu_usage_max': 52.5,\n",
      "                      'cpu_usage_mean': 26.69736842105263,\n",
      "                      'duration_seconds': 82.94907069206238,\n",
      "                      'gpu_energy_wh': 1.0997154952856953,\n",
      "                      'gpu_memory_max_mb': 1473.125,\n",
      "                      'gpu_memory_mean_mb': 1473.125,\n",
      "                      'gpu_power_max_w': 50.34,\n",
      "                      'gpu_power_mean_w': 47.72778947368422,\n",
      "                      'gpu_usage_max': 38.0,\n",
      "                      'gpu_usage_mean': 33.18421052631579,\n",
      "                      'ram_usage_max': 40.2,\n",
      "                      'ram_usage_mean': 39.623684210526314},\n",
      "                     {'cpu_freq_mean': 3978.1813321917807,\n",
      "                      'cpu_usage_max': 46.3,\n",
      "                      'cpu_usage_mean': 27.60684931506849,\n",
      "                      'duration_seconds': 79.64217185974121,\n",
      "                      'gpu_energy_wh': 1.0576834994286708,\n",
      "                      'gpu_memory_max_mb': 1473.125,\n",
      "                      'gpu_memory_mean_mb': 1473.125,\n",
      "                      'gpu_power_max_w': 50.133,\n",
      "                      'gpu_power_mean_w': 47.80960273972603,\n",
      "                      'gpu_usage_max': 39.0,\n",
      "                      'gpu_usage_mean': 32.87671232876713,\n",
      "                      'ram_usage_max': 40.4,\n",
      "                      'ram_usage_mean': 39.76301369863014},\n",
      "                     {'cpu_freq_mean': 3968.839083806818,\n",
      "                      'cpu_usage_max': 46.9,\n",
      "                      'cpu_usage_mean': 28.223863636363635,\n",
      "                      'duration_seconds': 96.2133526802063,\n",
      "                      'gpu_energy_wh': 1.2786851756404145,\n",
      "                      'gpu_memory_max_mb': 1473.125,\n",
      "                      'gpu_memory_mean_mb': 1473.125,\n",
      "                      'gpu_power_max_w': 50.423,\n",
      "                      'gpu_power_mean_w': 47.84436363636364,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 32.79545454545455,\n",
      "                      'ram_usage_max': 40.5,\n",
      "                      'ram_usage_mean': 39.86590909090909},\n",
      "                     {'cpu_freq_mean': 3992.3678569711537,\n",
      "                      'cpu_usage_max': 42.3,\n",
      "                      'cpu_usage_mean': 28.63461538461539,\n",
      "                      'duration_seconds': 113.92295575141907,\n",
      "                      'gpu_energy_wh': 1.5160120853408727,\n",
      "                      'gpu_memory_max_mb': 1473.125,\n",
      "                      'gpu_memory_mean_mb': 1466.1460336538462,\n",
      "                      'gpu_power_max_w': 50.137,\n",
      "                      'gpu_power_mean_w': 47.90644230769231,\n",
      "                      'gpu_usage_max': 38.0,\n",
      "                      'gpu_usage_mean': 32.94230769230769,\n",
      "                      'ram_usage_max': 40.9,\n",
      "                      'ram_usage_mean': 40.00865384615384},\n",
      "                     {'cpu_freq_mean': 3976.4981161764713,\n",
      "                      'cpu_usage_max': 50.0,\n",
      "                      'cpu_usage_mean': 29.557647058823527,\n",
      "                      'duration_seconds': 92.9318516254425,\n",
      "                      'gpu_energy_wh': 1.2299424268025783,\n",
      "                      'gpu_memory_max_mb': 1434.4375,\n",
      "                      'gpu_memory_mean_mb': 1432.366911764706,\n",
      "                      'gpu_power_max_w': 50.8,\n",
      "                      'gpu_power_mean_w': 47.64558823529412,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 32.49411764705882,\n",
      "                      'ram_usage_max': 41.5,\n",
      "                      'ram_usage_mean': 40.46235294117647},\n",
      "                     {'cpu_freq_mean': 3976.30971039604,\n",
      "                      'cpu_usage_max': 41.8,\n",
      "                      'cpu_usage_mean': 29.87524752475247,\n",
      "                      'duration_seconds': 110.61249542236328,\n",
      "                      'gpu_energy_wh': 1.4745174973524993,\n",
      "                      'gpu_memory_max_mb': 1434.4375,\n",
      "                      'gpu_memory_mean_mb': 1434.4375,\n",
      "                      'gpu_power_max_w': 50.431,\n",
      "                      'gpu_power_mean_w': 47.989722772277226,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 32.48514851485149,\n",
      "                      'ram_usage_max': 42.2,\n",
      "                      'ram_usage_mean': 40.997029702970295},\n",
      "                     {'cpu_freq_mean': 3964.142008012822,\n",
      "                      'cpu_usage_max': 42.9,\n",
      "                      'cpu_usage_mean': 30.580769230769228,\n",
      "                      'duration_seconds': 85.16974830627441,\n",
      "                      'gpu_energy_wh': 1.1259880527140205,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1436.386217948718,\n",
      "                      'gpu_power_max_w': 50.406,\n",
      "                      'gpu_power_mean_w': 47.59385897435898,\n",
      "                      'gpu_usage_max': 37.0,\n",
      "                      'gpu_usage_mean': 32.32051282051282,\n",
      "                      'ram_usage_max': 43.2,\n",
      "                      'ram_usage_mean': 41.282051282051285},\n",
      "                     {'cpu_freq_mean': 3978.5652755376336,\n",
      "                      'cpu_usage_max': 46.8,\n",
      "                      'cpu_usage_mean': 31.278494623655916,\n",
      "                      'duration_seconds': 101.74329042434692,\n",
      "                      'gpu_energy_wh': 1.3520054432292141,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1436.4375,\n",
      "                      'gpu_power_max_w': 50.194,\n",
      "                      'gpu_power_mean_w': 47.838236559139794,\n",
      "                      'gpu_usage_max': 36.0,\n",
      "                      'gpu_usage_mean': 32.086021505376344,\n",
      "                      'ram_usage_max': 43.1,\n",
      "                      'ram_usage_mean': 42.00430107526882},\n",
      "                     {'cpu_freq_mean': 3976.3008081683165,\n",
      "                      'cpu_usage_max': 45.8,\n",
      "                      'cpu_usage_mean': 31.92079207920792,\n",
      "                      'duration_seconds': 110.62812280654907,\n",
      "                      'gpu_energy_wh': 1.4674893512151974,\n",
      "                      'gpu_memory_max_mb': 1436.4375,\n",
      "                      'gpu_memory_mean_mb': 1436.4375,\n",
      "                      'gpu_power_max_w': 50.8,\n",
      "                      'gpu_power_mean_w': 47.75423762376238,\n",
      "                      'gpu_usage_max': 36.0,\n",
      "                      'gpu_usage_mean': 32.16831683168317,\n",
      "                      'ram_usage_max': 43.4,\n",
      "                      'ram_usage_mean': 42.30792079207921}],\n",
      "  'stopped_epochs': [21, 19, 18, 22, 26, 21, 25, 19, 23, 25],\n",
      "  'test_acc': [80.5743932723999,\n",
      "               80.9011161327362,\n",
      "               80.94530701637268,\n",
      "               80.96688985824585,\n",
      "               81.42799139022827,\n",
      "               80.97951412200928,\n",
      "               80.77712655067444,\n",
      "               79.41334843635559,\n",
      "               81.0368001461029,\n",
      "               81.77019953727722],\n",
      "  'test_f1': [0.8112823963165283,\n",
      "              0.811473548412323,\n",
      "              0.8154730200767517,\n",
      "              0.8170340657234192,\n",
      "              0.8219252824783325,\n",
      "              0.8173386454582214,\n",
      "              0.8160006403923035,\n",
      "              0.802419900894165,\n",
      "              0.822918713092804,\n",
      "              0.8257600665092468],\n",
      "  'test_loss': [0.6831607222557068,\n",
      "                0.6672706007957458,\n",
      "                0.6520832777023315,\n",
      "                0.6610023379325867,\n",
      "                0.6419233679771423,\n",
      "                0.6480634808540344,\n",
      "                0.7010612487792969,\n",
      "                0.6983738541603088,\n",
      "                0.6464235186576843,\n",
      "                0.668137788772583],\n",
      "  'test_precision': [0.8772695660591125,\n",
      "                     0.8761072158813477,\n",
      "                     0.874031662940979,\n",
      "                     0.8745366930961609,\n",
      "                     0.8714515566825867,\n",
      "                     0.8842082023620605,\n",
      "                     0.8678616285324097,\n",
      "                     0.8635233044624329,\n",
      "                     0.882640540599823,\n",
      "                     0.870513916015625],\n",
      "  'test_recall': [0.7568855881690979,\n",
      "                  0.758209764957428,\n",
      "                  0.766319215297699,\n",
      "                  0.7688471078872681,\n",
      "                  0.779411792755127,\n",
      "                  0.7620892524719238,\n",
      "                  0.771991491317749,\n",
      "                  0.7516094446182251,\n",
      "                  0.7728979587554932,\n",
      "                  0.7869691252708435],\n",
      "  'val_acc': [80.4555892944336,\n",
      "              80.51114082336426,\n",
      "              80.20089268684387,\n",
      "              81.16169571876526,\n",
      "              81.26514554023743,\n",
      "              81.20028972625732,\n",
      "              80.97431063652039,\n",
      "              80.96098303794861,\n",
      "              80.84055781364441,\n",
      "              81.71435594558716],\n",
      "  'val_f1': [0.8208761215209961,\n",
      "             0.8182622790336609,\n",
      "             0.81526780128479,\n",
      "             0.8233867287635803,\n",
      "             0.8244453072547913,\n",
      "             0.8308637738227844,\n",
      "             0.8182528614997864,\n",
      "             0.8229122161865234,\n",
      "             0.8143298625946045,\n",
      "             0.8277023434638977],\n",
      "  'val_loss': [0.6601449251174927,\n",
      "               0.6715484857559204,\n",
      "               0.6885426044464111,\n",
      "               0.6401910781860352,\n",
      "               0.6504738926887512,\n",
      "               0.6321370005607605,\n",
      "               0.6752878427505493,\n",
      "               0.6398123502731323,\n",
      "               0.6552727222442627,\n",
      "               0.647377610206604],\n",
      "  'val_precision': [0.8709828853607178,\n",
      "                    0.8763756155967712,\n",
      "                    0.8637227416038513,\n",
      "                    0.869257926940918,\n",
      "                    0.8766244649887085,\n",
      "                    0.8758775591850281,\n",
      "                    0.8731549978256226,\n",
      "                    0.8697731494903564,\n",
      "                    0.8776591420173645,\n",
      "                    0.8689095377922058],\n",
      "  'val_recall': [0.77756267786026,\n",
      "                 0.768410861492157,\n",
      "                 0.7728022336959839,\n",
      "                 0.7830384373664856,\n",
      "                 0.7794654369354248,\n",
      "                 0.7911515235900879,\n",
      "                 0.771124005317688,\n",
      "                 0.7819310426712036,\n",
      "                 0.7608574032783508,\n",
      "                 0.7911755442619324]},\n",
      " {'model_name': 'model_7',\n",
      "  'resource_stats': [{'cpu_freq_mean': 3912.176381355932,\n",
      "                      'cpu_usage_max': 39.5,\n",
      "                      'cpu_usage_mean': 24.628813559322033,\n",
      "                      'duration_seconds': 64.28643202781677,\n",
      "                      'gpu_energy_wh': 1.4181017891719563,\n",
      "                      'gpu_memory_max_mb': 1499.125,\n",
      "                      'gpu_memory_mean_mb': 1467.4809322033898,\n",
      "                      'gpu_power_max_w': 91.272,\n",
      "                      'gpu_power_mean_w': 79.41281355932203,\n",
      "                      'gpu_usage_max': 53.0,\n",
      "                      'gpu_usage_mean': 45.71186440677966,\n",
      "                      'ram_usage_max': 39.6,\n",
      "                      'ram_usage_mean': 38.63728813559322},\n",
      "                     {'cpu_freq_mean': 3984.034869791667,\n",
      "                      'cpu_usage_max': 33.8,\n",
      "                      'cpu_usage_mean': 24.904166666666665,\n",
      "                      'duration_seconds': 51.9861478805542,\n",
      "                      'gpu_energy_wh': 1.1816553700809456,\n",
      "                      'gpu_memory_max_mb': 1485.125,\n",
      "                      'gpu_memory_mean_mb': 1485.125,\n",
      "                      'gpu_power_max_w': 89.25,\n",
      "                      'gpu_power_mean_w': 81.82870833333334,\n",
      "                      'gpu_usage_max': 53.0,\n",
      "                      'gpu_usage_mean': 46.0625,\n",
      "                      'ram_usage_max': 40.0,\n",
      "                      'ram_usage_mean': 39.12291666666667},\n",
      "                     {'cpu_freq_mean': 3987.896853448276,\n",
      "                      'cpu_usage_max': 41.8,\n",
      "                      'cpu_usage_mean': 24.874137931034483,\n",
      "                      'duration_seconds': 63.02345681190491,\n",
      "                      'gpu_energy_wh': 1.448181242518384,\n",
      "                      'gpu_memory_max_mb': 1485.125,\n",
      "                      'gpu_memory_mean_mb': 1485.125,\n",
      "                      'gpu_power_max_w': 90.469,\n",
      "                      'gpu_power_mean_w': 82.72241379310346,\n",
      "                      'gpu_usage_max': 53.0,\n",
      "                      'gpu_usage_mean': 45.87931034482759,\n",
      "                      'ram_usage_max': 40.5,\n",
      "                      'ram_usage_mean': 39.51379310344828},\n",
      "                     {'cpu_freq_mean': 3965.595625,\n",
      "                      'cpu_usage_max': 38.2,\n",
      "                      'cpu_usage_mean': 25.656896551724138,\n",
      "                      'duration_seconds': 63.031434297561646,\n",
      "                      'gpu_energy_wh': 1.4759139384181075,\n",
      "                      'gpu_memory_max_mb': 1485.125,\n",
      "                      'gpu_memory_mean_mb': 1485.125,\n",
      "                      'gpu_power_max_w': 91.565,\n",
      "                      'gpu_power_mean_w': 84.29587931034483,\n",
      "                      'gpu_usage_max': 53.0,\n",
      "                      'gpu_usage_mean': 46.06896551724138,\n",
      "                      'ram_usage_max': 40.7,\n",
      "                      'ram_usage_mean': 39.898275862068964},\n",
      "                     {'cpu_freq_mean': 3969.893334905661,\n",
      "                      'cpu_usage_max': 40.5,\n",
      "                      'cpu_usage_mean': 26.52641509433962,\n",
      "                      'duration_seconds': 57.50781464576721,\n",
      "                      'gpu_energy_wh': 1.3431218359759156,\n",
      "                      'gpu_memory_max_mb': 1485.125,\n",
      "                      'gpu_memory_mean_mb': 1485.125,\n",
      "                      'gpu_power_max_w': 91.635,\n",
      "                      'gpu_power_mean_w': 84.07967924528302,\n",
      "                      'gpu_usage_max': 51.0,\n",
      "                      'gpu_usage_mean': 45.75471698113208,\n",
      "                      'ram_usage_max': 41.5,\n",
      "                      'ram_usage_mean': 40.01509433962264},\n",
      "                     {'cpu_freq_mean': 3962.3064481132074,\n",
      "                      'cpu_usage_max': 38.3,\n",
      "                      'cpu_usage_mean': 27.09622641509434,\n",
      "                      'duration_seconds': 57.519235610961914,\n",
      "                      'gpu_energy_wh': 1.3422164878612795,\n",
      "                      'gpu_memory_max_mb': 1487.125,\n",
      "                      'gpu_memory_mean_mb': 1487.0495283018868,\n",
      "                      'gpu_power_max_w': 91.834,\n",
      "                      'gpu_power_mean_w': 84.00632075471698,\n",
      "                      'gpu_usage_max': 53.0,\n",
      "                      'gpu_usage_mean': 45.924528301886795,\n",
      "                      'ram_usage_max': 40.8,\n",
      "                      'ram_usage_mean': 39.84905660377358},\n",
      "                     {'cpu_freq_mean': 3951.7995625000003,\n",
      "                      'cpu_usage_max': 34.6,\n",
      "                      'cpu_usage_mean': 27.005172413793108,\n",
      "                      'duration_seconds': 63.05787682533264,\n",
      "                      'gpu_energy_wh': 1.4667437310341334,\n",
      "                      'gpu_memory_max_mb': 1487.125,\n",
      "                      'gpu_memory_mean_mb': 1487.125,\n",
      "                      'gpu_power_max_w': 91.919,\n",
      "                      'gpu_power_mean_w': 83.73700000000002,\n",
      "                      'gpu_usage_max': 51.0,\n",
      "                      'gpu_usage_mean': 44.94827586206897,\n",
      "                      'ram_usage_max': 40.8,\n",
      "                      'ram_usage_mean': 40.04655172413793},\n",
      "                     {'cpu_freq_mean': 3976.3534197761187,\n",
      "                      'cpu_usage_max': 46.8,\n",
      "                      'cpu_usage_mean': 28.15223880597015,\n",
      "                      'duration_seconds': 73.00355386734009,\n",
      "                      'gpu_energy_wh': 1.7101603082614512,\n",
      "                      'gpu_memory_max_mb': 1487.125,\n",
      "                      'gpu_memory_mean_mb': 1466.097947761194,\n",
      "                      'gpu_power_max_w': 92.014,\n",
      "                      'gpu_power_mean_w': 84.3325671641791,\n",
      "                      'gpu_usage_max': 51.0,\n",
      "                      'gpu_usage_mean': 46.76119402985075,\n",
      "                      'ram_usage_max': 41.1,\n",
      "                      'ram_usage_mean': 40.341791044776116},\n",
      "                     {'cpu_freq_mean': 3962.763472222223,\n",
      "                      'cpu_usage_max': 50.0,\n",
      "                      'cpu_usage_mean': 28.07142857142857,\n",
      "                      'duration_seconds': 68.56348204612732,\n",
      "                      'gpu_energy_wh': 1.6054332798298725,\n",
      "                      'gpu_memory_max_mb': 1448.4375,\n",
      "                      'gpu_memory_mean_mb': 1446.6597222222222,\n",
      "                      'gpu_power_max_w': 91.177,\n",
      "                      'gpu_power_mean_w': 84.29501587301587,\n",
      "                      'gpu_usage_max': 52.0,\n",
      "                      'gpu_usage_mean': 44.58730158730159,\n",
      "                      'ram_usage_max': 42.0,\n",
      "                      'ram_usage_mean': 41.32063492063492},\n",
      "                     {'cpu_freq_mean': 3962.5330966981132,\n",
      "                      'cpu_usage_max': 50.0,\n",
      "                      'cpu_usage_mean': 29.12641509433962,\n",
      "                      'duration_seconds': 57.51420736312866,\n",
      "                      'gpu_energy_wh': 1.3388424263300014,\n",
      "                      'gpu_memory_max_mb': 1448.4375,\n",
      "                      'gpu_memory_mean_mb': 1448.4375,\n",
      "                      'gpu_power_max_w': 91.438,\n",
      "                      'gpu_power_mean_w': 83.80247169811322,\n",
      "                      'gpu_usage_max': 50.0,\n",
      "                      'gpu_usage_mean': 45.339622641509436,\n",
      "                      'ram_usage_max': 41.8,\n",
      "                      'ram_usage_mean': 41.13018867924528}],\n",
      "  'stopped_epochs': [12, 10, 12, 12, 11, 11, 12, 14, 13, 11],\n",
      "  'test_acc': [88.76479268074036,\n",
      "               88.55661749839783,\n",
      "               89.10195827484131,\n",
      "               88.67549896240234,\n",
      "               88.94587755203247,\n",
      "               88.5632872581482,\n",
      "               88.57572674751282,\n",
      "               87.87674903869629,\n",
      "               88.58447670936584,\n",
      "               88.4964108467102],\n",
      "  'test_f1': [0.8965796828269958,\n",
      "              0.8945358395576477,\n",
      "              0.8966010808944702,\n",
      "              0.8954921364784241,\n",
      "              0.8968970775604248,\n",
      "              0.8903177976608276,\n",
      "              0.8917878866195679,\n",
      "              0.8845812678337097,\n",
      "              0.8948045372962952,\n",
      "              0.893341064453125],\n",
      "  'test_loss': [0.4231874942779541,\n",
      "                0.4026367664337158,\n",
      "                0.4018611013889313,\n",
      "                0.41480857133865356,\n",
      "                0.4002240300178528,\n",
      "                0.4193603992462158,\n",
      "                0.43630290031433105,\n",
      "                0.47455301880836487,\n",
      "                0.4052892029285431,\n",
      "                0.4114445447921753],\n",
      "  'test_precision': [0.92679363489151,\n",
      "                     0.9238868951797485,\n",
      "                     0.9237265586853027,\n",
      "                     0.9210999608039856,\n",
      "                     0.9251316785812378,\n",
      "                     0.919612467288971,\n",
      "                     0.9202343821525574,\n",
      "                     0.906065821647644,\n",
      "                     0.9196016192436218,\n",
      "                     0.9192736744880676],\n",
      "  'test_recall': [0.8693061470985413,\n",
      "                  0.8679819703102112,\n",
      "                  0.8721194863319397,\n",
      "                  0.8723164200782776,\n",
      "                  0.8715137243270874,\n",
      "                  0.863919198513031,\n",
      "                  0.8662034273147583,\n",
      "                  0.8650751113891602,\n",
      "                  0.8720737099647522,\n",
      "                  0.8699246644973755],\n",
      "  'val_acc': [89.25239443778992,\n",
      "              89.03827667236328,\n",
      "              88.82972002029419,\n",
      "              88.78154754638672,\n",
      "              88.70576620101929,\n",
      "              88.59966397285461,\n",
      "              89.02084231376648,\n",
      "              89.51107859611511,\n",
      "              89.27023410797119,\n",
      "              88.31449747085571],\n",
      "  'val_f1': [0.8996150493621826,\n",
      "             0.9010926485061646,\n",
      "             0.8997054100036621,\n",
      "             0.9034949541091919,\n",
      "             0.8959711790084839,\n",
      "             0.9015427231788635,\n",
      "             0.8990909457206726,\n",
      "             0.9034295082092285,\n",
      "             0.8995268940925598,\n",
      "             0.8949882984161377],\n",
      "  'val_loss': [0.3971261978149414,\n",
      "               0.3885515630245209,\n",
      "               0.40728142857551575,\n",
      "               0.41795098781585693,\n",
      "               0.40609341859817505,\n",
      "               0.40901240706443787,\n",
      "               0.4281235933303833,\n",
      "               0.4172804653644562,\n",
      "               0.4091823697090149,\n",
      "               0.4204317629337311],\n",
      "  'val_precision': [0.9168452620506287,\n",
      "                    0.9184466004371643,\n",
      "                    0.915829062461853,\n",
      "                    0.9187085032463074,\n",
      "                    0.9180946350097656,\n",
      "                    0.9195080995559692,\n",
      "                    0.9134435057640076,\n",
      "                    0.9178788065910339,\n",
      "                    0.9232445955276489,\n",
      "                    0.915144145488739],\n",
      "  'val_recall': [0.8834488987922668,\n",
      "                 0.8846899271011353,\n",
      "                 0.8844608664512634,\n",
      "                 0.8891826868057251,\n",
      "                 0.8754279613494873,\n",
      "                 0.8845524191856384,\n",
      "                 0.8854973912239075,\n",
      "                 0.8897435665130615,\n",
      "                 0.8776442408561707,\n",
      "                 0.8760507106781006]},\n",
      " {'model_name': 'model_8',\n",
      "  'resource_stats': [{'cpu_freq_mean': 3953.286723880597,\n",
      "                      'cpu_usage_max': 45.0,\n",
      "                      'cpu_usage_mean': 24.002985074626867,\n",
      "                      'duration_seconds': 73.03511023521423,\n",
      "                      'gpu_energy_wh': 1.8315927835361576,\n",
      "                      'gpu_memory_max_mb': 1506.4375,\n",
      "                      'gpu_memory_mean_mb': 1473.7360074626865,\n",
      "                      'gpu_power_max_w': 103.411,\n",
      "                      'gpu_power_mean_w': 90.28170149253731,\n",
      "                      'gpu_usage_max': 59.0,\n",
      "                      'gpu_usage_mean': 51.28358208955224,\n",
      "                      'ram_usage_max': 39.6,\n",
      "                      'ram_usage_mean': 38.71492537313432},\n",
      "                     {'cpu_freq_mean': 3971.5078625,\n",
      "                      'cpu_usage_max': 41.0,\n",
      "                      'cpu_usage_mean': 24.347142857142856,\n",
      "                      'duration_seconds': 76.29281115531921,\n",
      "                      'gpu_energy_wh': 2.026281963921666,\n",
      "                      'gpu_memory_max_mb': 1494.4375,\n",
      "                      'gpu_memory_mean_mb': 1493.2375,\n",
      "                      'gpu_power_max_w': 106.57,\n",
      "                      'gpu_power_mean_w': 95.6134,\n",
      "                      'gpu_usage_max': 59.0,\n",
      "                      'gpu_usage_mean': 52.614285714285714,\n",
      "                      'ram_usage_max': 40.1,\n",
      "                      'ram_usage_mean': 39.325714285714284},\n",
      "                     {'cpu_freq_mean': 3970.84549695122,\n",
      "                      'cpu_usage_max': 38.5,\n",
      "                      'cpu_usage_mean': 24.652439024390247,\n",
      "                      'duration_seconds': 89.56051325798035,\n",
      "                      'gpu_energy_wh': 2.3295074802776834,\n",
      "                      'gpu_memory_max_mb': 1494.4375,\n",
      "                      'gpu_memory_mean_mb': 1492.5838414634147,\n",
      "                      'gpu_power_max_w': 104.808,\n",
      "                      'gpu_power_mean_w': 93.6375487804878,\n",
      "                      'gpu_usage_max': 58.0,\n",
      "                      'gpu_usage_mean': 52.26829268292683,\n",
      "                      'ram_usage_max': 40.5,\n",
      "                      'ram_usage_mean': 39.87073170731708},\n",
      "                     {'cpu_freq_mean': 3984.7530995145635,\n",
      "                      'cpu_usage_max': 37.5,\n",
      "                      'cpu_usage_mean': 25.377669902912622,\n",
      "                      'duration_seconds': 112.78190612792969,\n",
      "                      'gpu_energy_wh': 2.9531160432708563,\n",
      "                      'gpu_memory_max_mb': 1494.4375,\n",
      "                      'gpu_memory_mean_mb': 1494.4375,\n",
      "                      'gpu_power_max_w': 108.754,\n",
      "                      'gpu_power_mean_w': 94.26350485436893,\n",
      "                      'gpu_usage_max': 59.0,\n",
      "                      'gpu_usage_mean': 52.689320388349515,\n",
      "                      'ram_usage_max': 40.8,\n",
      "                      'ram_usage_mean': 40.099999999999994},\n",
      "                     {'cpu_freq_mean': 3953.904551948051,\n",
      "                      'cpu_usage_max': 42.5,\n",
      "                      'cpu_usage_mean': 25.551948051948056,\n",
      "                      'duration_seconds': 84.04745101928711,\n",
      "                      'gpu_energy_wh': 2.2346564777947435,\n",
      "                      'gpu_memory_max_mb': 1494.4375,\n",
      "                      'gpu_memory_mean_mb': 1489.7102272727273,\n",
      "                      'gpu_power_max_w': 107.347,\n",
      "                      'gpu_power_mean_w': 95.71692207792208,\n",
      "                      'gpu_usage_max': 58.0,\n",
      "                      'gpu_usage_mean': 52.09090909090909,\n",
      "                      'ram_usage_max': 41.3,\n",
      "                      'ram_usage_mean': 40.58701298701298},\n",
      "                     {'cpu_freq_mean': 3946.4966387195122,\n",
      "                      'cpu_usage_max': 40.0,\n",
      "                      'cpu_usage_mean': 25.937804878048787,\n",
      "                      'duration_seconds': 89.56732392311096,\n",
      "                      'gpu_energy_wh': 2.392617506745191,\n",
      "                      'gpu_memory_max_mb': 1466.4375,\n",
      "                      'gpu_memory_mean_mb': 1466.4375,\n",
      "                      'gpu_power_max_w': 106.341,\n",
      "                      'gpu_power_mean_w': 96.16702439024391,\n",
      "                      'gpu_usage_max': 58.0,\n",
      "                      'gpu_usage_mean': 52.292682926829265,\n",
      "                      'ram_usage_max': 41.7,\n",
      "                      'ram_usage_mean': 41.23658536585366},\n",
      "                     {'cpu_freq_mean': 3978.415256793478,\n",
      "                      'cpu_usage_max': 45.0,\n",
      "                      'cpu_usage_mean': 27.116304347826084,\n",
      "                      'duration_seconds': 100.6218318939209,\n",
      "                      'gpu_energy_wh': 2.6822289607410665,\n",
      "                      'gpu_memory_max_mb': 1468.4375,\n",
      "                      'gpu_memory_mean_mb': 1468.3940217391305,\n",
      "                      'gpu_power_max_w': 106.843,\n",
      "                      'gpu_power_mean_w': 95.9635108695652,\n",
      "                      'gpu_usage_max': 59.0,\n",
      "                      'gpu_usage_mean': 52.5,\n",
      "                      'ram_usage_max': 42.6,\n",
      "                      'ram_usage_mean': 41.34239130434783},\n",
      "                     {'cpu_freq_mean': 3965.805936728395,\n",
      "                      'cpu_usage_max': 43.8,\n",
      "                      'cpu_usage_mean': 27.25802469135803,\n",
      "                      'duration_seconds': 88.47293257713318,\n",
      "                      'gpu_energy_wh': 2.3829167982503585,\n",
      "                      'gpu_memory_max_mb': 1468.4375,\n",
      "                      'gpu_memory_mean_mb': 1468.4375,\n",
      "                      'gpu_power_max_w': 106.937,\n",
      "                      'gpu_power_mean_w': 96.96186419753087,\n",
      "                      'gpu_usage_max': 57.0,\n",
      "                      'gpu_usage_mean': 52.65432098765432,\n",
      "                      'ram_usage_max': 42.5,\n",
      "                      'ram_usage_mean': 41.51481481481482},\n",
      "                     {'cpu_freq_mean': 3978.973664473684,\n",
      "                      'cpu_usage_max': 53.2,\n",
      "                      'cpu_usage_mean': 28.359210526315792,\n",
      "                      'duration_seconds': 82.93353796005249,\n",
      "                      'gpu_energy_wh': 2.234343485634578,\n",
      "                      'gpu_memory_max_mb': 1468.4375,\n",
      "                      'gpu_memory_mean_mb': 1465.3848684210527,\n",
      "                      'gpu_power_max_w': 106.12,\n",
      "                      'gpu_power_mean_w': 96.98894736842105,\n",
      "                      'gpu_usage_max': 59.0,\n",
      "                      'gpu_usage_mean': 51.973684210526315,\n",
      "                      'ram_usage_max': 42.5,\n",
      "                      'ram_usage_mean': 41.93815789473683},\n",
      "                     {'cpu_freq_mean': 3913.414162337662,\n",
      "                      'cpu_usage_max': 43.6,\n",
      "                      'cpu_usage_mean': 27.49090909090908,\n",
      "                      'duration_seconds': 84.03460097312927,\n",
      "                      'gpu_energy_wh': 2.2394338977921806,\n",
      "                      'gpu_memory_max_mb': 1468.4375,\n",
      "                      'gpu_memory_mean_mb': 1468.4375,\n",
      "                      'gpu_power_max_w': 108.388,\n",
      "                      'gpu_power_mean_w': 95.93622077922078,\n",
      "                      'gpu_usage_max': 58.0,\n",
      "                      'gpu_usage_mean': 51.83116883116883,\n",
      "                      'ram_usage_max': 43.1,\n",
      "                      'ram_usage_mean': 42.23116883116883}],\n",
      "  'stopped_epochs': [12, 13, 15, 19, 14, 15, 17, 15, 14, 14],\n",
      "  'test_acc': [83.53942036628723,\n",
      "               84.56937670707703,\n",
      "               85.42876243591309,\n",
      "               85.31125783920288,\n",
      "               85.22067666053772,\n",
      "               85.14448404312134,\n",
      "               85.19633412361145,\n",
      "               84.87620949745178,\n",
      "               83.93768668174744,\n",
      "               84.73406434059143],\n",
      "  'test_f1': [0.8426506519317627,\n",
      "              0.8555241227149963,\n",
      "              0.863273024559021,\n",
      "              0.8623908758163452,\n",
      "              0.8608986139297485,\n",
      "              0.8606901168823242,\n",
      "              0.8594262599945068,\n",
      "              0.8553858995437622,\n",
      "              0.849528431892395,\n",
      "              0.8566984534263611],\n",
      "  'test_loss': [0.566460907459259,\n",
      "                0.5227665305137634,\n",
      "                0.5180081725120544,\n",
      "                0.5413236021995544,\n",
      "                0.5270490050315857,\n",
      "                0.5379819869995117,\n",
      "                0.5359211564064026,\n",
      "                0.5559383630752563,\n",
      "                0.5378150343894958,\n",
      "                0.5573291778564453],\n",
      "  'test_precision': [0.8972765207290649,\n",
      "                     0.9029344320297241,\n",
      "                     0.8984834551811218,\n",
      "                     0.8931535482406616,\n",
      "                     0.895373523235321,\n",
      "                     0.8994240760803223,\n",
      "                     0.8946061730384827,\n",
      "                     0.8868004679679871,\n",
      "                     0.8929013609886169,\n",
      "                     0.8982173204421997],\n",
      "  'test_recall': [0.796477735042572,\n",
      "                  0.8147510886192322,\n",
      "                  0.8321245312690735,\n",
      "                  0.8346928358078003,\n",
      "                  0.8303436040878296,\n",
      "                  0.8264339566230774,\n",
      "                  0.8284031748771667,\n",
      "                  0.8273873329162598,\n",
      "                  0.811585545539856,\n",
      "                  0.8199778199195862],\n",
      "  'val_acc': [83.72712731361389,\n",
      "              84.94428396224976,\n",
      "              84.6907913684845,\n",
      "              85.71428656578064,\n",
      "              84.86427664756775,\n",
      "              84.93613004684448,\n",
      "              85.22782325744629,\n",
      "              85.74181199073792,\n",
      "              84.51348543167114,\n",
      "              85.3330135345459],\n",
      "  'val_f1': [0.8522690534591675,\n",
      "             0.8662545680999756,\n",
      "             0.863156259059906,\n",
      "             0.8654903769493103,\n",
      "             0.8643947839736938,\n",
      "             0.8652739524841309,\n",
      "             0.8637348413467407,\n",
      "             0.8674255013465881,\n",
      "             0.8563616871833801,\n",
      "             0.8649470210075378],\n",
      "  'val_loss': [0.5449251532554626,\n",
      "               0.515157163143158,\n",
      "               0.5419379472732544,\n",
      "               0.527433454990387,\n",
      "               0.5349621772766113,\n",
      "               0.5211556553840637,\n",
      "               0.5330923199653625,\n",
      "               0.5147784352302551,\n",
      "               0.5345754027366638,\n",
      "               0.5012049674987793],\n",
      "  'val_precision': [0.8884037137031555,\n",
      "                    0.8999946713447571,\n",
      "                    0.8932316303253174,\n",
      "                    0.8955805897712708,\n",
      "                    0.8920912742614746,\n",
      "                    0.8968743681907654,\n",
      "                    0.89253830909729,\n",
      "                    0.8908634185791016,\n",
      "                    0.8893159627914429,\n",
      "                    0.8908364176750183],\n",
      "  'val_recall': [0.8197197914123535,\n",
      "                 0.8357558250427246,\n",
      "                 0.8356627821922302,\n",
      "                 0.8381538391113281,\n",
      "                 0.8391069173812866,\n",
      "                 0.8363552689552307,\n",
      "                 0.8373950123786926,\n",
      "                 0.8457531929016113,\n",
      "                 0.8265224099159241,\n",
      "                 0.8409584760665894]},\n",
      " {'model_name': 'model_9',\n",
      "  'resource_stats': [{'cpu_freq_mean': 3913.398607638889,\n",
      "                      'cpu_usage_max': 44.3,\n",
      "                      'cpu_usage_mean': 22.118055555555557,\n",
      "                      'duration_seconds': 78.55888938903809,\n",
      "                      'gpu_energy_wh': 2.229761931496991,\n",
      "                      'gpu_memory_max_mb': 2124.4375,\n",
      "                      'gpu_memory_mean_mb': 2052.2291666666665,\n",
      "                      'gpu_power_max_w': 116.082,\n",
      "                      'gpu_power_mean_w': 102.17994444444444,\n",
      "                      'gpu_usage_max': 70.0,\n",
      "                      'gpu_usage_mean': 60.638888888888886,\n",
      "                      'ram_usage_max': 39.9,\n",
      "                      'ram_usage_mean': 38.99583333333333},\n",
      "                     {'cpu_freq_mean': 3949.642902777777,\n",
      "                      'cpu_usage_max': 36.7,\n",
      "                      'cpu_usage_mean': 22.303174603174604,\n",
      "                      'duration_seconds': 68.56284856796265,\n",
      "                      'gpu_energy_wh': 1.981803998666371,\n",
      "                      'gpu_memory_max_mb': 2106.4375,\n",
      "                      'gpu_memory_mean_mb': 2104.532738095238,\n",
      "                      'gpu_power_max_w': 116.048,\n",
      "                      'gpu_power_mean_w': 104.05773015873015,\n",
      "                      'gpu_usage_max': 70.0,\n",
      "                      'gpu_usage_mean': 63.111111111111114,\n",
      "                      'ram_usage_max': 40.5,\n",
      "                      'ram_usage_mean': 40.00317460317461},\n",
      "                     {'cpu_freq_mean': 3949.352698412699,\n",
      "                      'cpu_usage_max': 40.7,\n",
      "                      'cpu_usage_mean': 23.060317460317464,\n",
      "                      'duration_seconds': 68.56320452690125,\n",
      "                      'gpu_energy_wh': 1.9800745114332847,\n",
      "                      'gpu_memory_max_mb': 2106.4375,\n",
      "                      'gpu_memory_mean_mb': 2104.59623015873,\n",
      "                      'gpu_power_max_w': 118.288,\n",
      "                      'gpu_power_mean_w': 103.96638095238096,\n",
      "                      'gpu_usage_max': 69.0,\n",
      "                      'gpu_usage_mean': 62.19047619047619,\n",
      "                      'ram_usage_max': 41.0,\n",
      "                      'ram_usage_mean': 40.50476190476191},\n",
      "                     {'cpu_freq_mean': 3977.7591500000003,\n",
      "                      'cpu_usage_max': 38.7,\n",
      "                      'cpu_usage_mean': 23.07294117647059,\n",
      "                      'duration_seconds': 92.89163756370544,\n",
      "                      'gpu_energy_wh': 2.7017903137684214,\n",
      "                      'gpu_memory_max_mb': 2106.4375,\n",
      "                      'gpu_memory_mean_mb': 2106.4375,\n",
      "                      'gpu_power_max_w': 115.935,\n",
      "                      'gpu_power_mean_w': 104.70743529411766,\n",
      "                      'gpu_usage_max': 69.0,\n",
      "                      'gpu_usage_mean': 63.61176470588235,\n",
      "                      'ram_usage_max': 41.2,\n",
      "                      'ram_usage_mean': 40.75411764705883},\n",
      "                     {'cpu_freq_mean': 3925.2424119718307,\n",
      "                      'cpu_usage_max': 39.5,\n",
      "                      'cpu_usage_mean': 23.21971830985916,\n",
      "                      'duration_seconds': 77.38571262359619,\n",
      "                      'gpu_energy_wh': 2.2534162435743847,\n",
      "                      'gpu_memory_max_mb': 2106.4375,\n",
      "                      'gpu_memory_mean_mb': 2106.4375,\n",
      "                      'gpu_power_max_w': 120.793,\n",
      "                      'gpu_power_mean_w': 104.82940845070424,\n",
      "                      'gpu_usage_max': 69.0,\n",
      "                      'gpu_usage_mean': 62.95774647887324,\n",
      "                      'ram_usage_max': 41.5,\n",
      "                      'ram_usage_mean': 40.942253521126744},\n",
      "                     {'cpu_freq_mean': 3950.8212588028173,\n",
      "                      'cpu_usage_max': 41.8,\n",
      "                      'cpu_usage_mean': 23.664788732394367,\n",
      "                      'duration_seconds': 77.40578293800354,\n",
      "                      'gpu_energy_wh': 2.2470777651091884,\n",
      "                      'gpu_memory_max_mb': 2108.4375,\n",
      "                      'gpu_memory_mean_mb': 2088.662852112676,\n",
      "                      'gpu_power_max_w': 114.048,\n",
      "                      'gpu_power_mean_w': 104.50743661971832,\n",
      "                      'gpu_usage_max': 69.0,\n",
      "                      'gpu_usage_mean': 62.521126760563384,\n",
      "                      'ram_usage_max': 43.0,\n",
      "                      'ram_usage_mean': 41.076056338028174},\n",
      "                     {'cpu_freq_mean': 3943.7238521126746,\n",
      "                      'cpu_usage_max': 37.5,\n",
      "                      'cpu_usage_mean': 23.825352112676057,\n",
      "                      'duration_seconds': 77.40522789955139,\n",
      "                      'gpu_energy_wh': 2.245108654328358,\n",
      "                      'gpu_memory_max_mb': 2080.4375,\n",
      "                      'gpu_memory_mean_mb': 2080.4375,\n",
      "                      'gpu_power_max_w': 115.551,\n",
      "                      'gpu_power_mean_w': 104.41660563380282,\n",
      "                      'gpu_usage_max': 69.0,\n",
      "                      'gpu_usage_mean': 63.225352112676056,\n",
      "                      'ram_usage_max': 42.0,\n",
      "                      'ram_usage_mean': 41.421126760563375},\n",
      "                     {'cpu_freq_mean': 3940.791154761905,\n",
      "                      'cpu_usage_max': 32.5,\n",
      "                      'cpu_usage_mean': 24.406349206349205,\n",
      "                      'duration_seconds': 68.54085898399353,\n",
      "                      'gpu_energy_wh': 2.003483759856646,\n",
      "                      'gpu_memory_max_mb': 2080.4375,\n",
      "                      'gpu_memory_mean_mb': 2080.4375,\n",
      "                      'gpu_power_max_w': 114.688,\n",
      "                      'gpu_power_mean_w': 105.22980952380951,\n",
      "                      'gpu_usage_max': 69.0,\n",
      "                      'gpu_usage_mean': 62.42857142857143,\n",
      "                      'ram_usage_max': 41.9,\n",
      "                      'ram_usage_mean': 41.48253968253967},\n",
      "                     {'cpu_freq_mean': 3955.743140873016,\n",
      "                      'cpu_usage_max': 39.2,\n",
      "                      'cpu_usage_mean': 24.966666666666665,\n",
      "                      'duration_seconds': 68.549569606781,\n",
      "                      'gpu_energy_wh': 1.9868059066539339,\n",
      "                      'gpu_memory_max_mb': 2080.4375,\n",
      "                      'gpu_memory_mean_mb': 2080.4375,\n",
      "                      'gpu_power_max_w': 115.549,\n",
      "                      'gpu_power_mean_w': 104.34057142857142,\n",
      "                      'gpu_usage_max': 68.0,\n",
      "                      'gpu_usage_mean': 62.55555555555556,\n",
      "                      'ram_usage_max': 42.1,\n",
      "                      'ram_usage_mean': 41.56031746031746},\n",
      "                     {'cpu_freq_mean': 3955.202088141026,\n",
      "                      'cpu_usage_max': 38.0,\n",
      "                      'cpu_usage_mean': 25.346153846153843,\n",
      "                      'duration_seconds': 85.1438262462616,\n",
      "                      'gpu_energy_wh': 2.505320701045714,\n",
      "                      'gpu_memory_max_mb': 2080.4375,\n",
      "                      'gpu_memory_mean_mb': 2077.668269230769,\n",
      "                      'gpu_power_max_w': 116.356,\n",
      "                      'gpu_power_mean_w': 105.92846153846152,\n",
      "                      'gpu_usage_max': 68.0,\n",
      "                      'gpu_usage_mean': 62.93589743589744,\n",
      "                      'ram_usage_max': 42.4,\n",
      "                      'ram_usage_mean': 41.725641025641025}],\n",
      "  'stopped_epochs': [9, 8, 8, 11, 9, 9, 9, 8, 8, 10],\n",
      "  'test_acc': [89.12378549575806,\n",
      "               87.67942786216736,\n",
      "               88.48075866699219,\n",
      "               89.0860915184021,\n",
      "               89.01336193084717,\n",
      "               88.48189115524292,\n",
      "               87.91900277137756,\n",
      "               87.17707395553589,\n",
      "               87.51007318496704,\n",
      "               88.88888955116272],\n",
      "  'test_f1': [0.89350825548172,\n",
      "              0.8837814331054688,\n",
      "              0.8911348581314087,\n",
      "              0.8976086974143982,\n",
      "              0.8971980810165405,\n",
      "              0.8910984992980957,\n",
      "              0.8864326477050781,\n",
      "              0.8754094243049622,\n",
      "              0.8829138278961182,\n",
      "              0.8961833119392395],\n",
      "  'test_loss': [0.4081706404685974,\n",
      "                0.41934430599212646,\n",
      "                0.38948798179626465,\n",
      "                0.4415135383605957,\n",
      "                0.395255446434021,\n",
      "                0.41217029094696045,\n",
      "                0.43439391255378723,\n",
      "                0.4400828778743744,\n",
      "                0.4223175644874573,\n",
      "                0.42951148748397827],\n",
      "  'test_precision': [0.9176985621452332,\n",
      "                     0.9244480729103088,\n",
      "                     0.9272939562797546,\n",
      "                     0.9151880145072937,\n",
      "                     0.9233825206756592,\n",
      "                     0.9155719876289368,\n",
      "                     0.9145854711532593,\n",
      "                     0.9104171395301819,\n",
      "                     0.9256026148796082,\n",
      "                     0.918079137802124],\n",
      "  'test_recall': [0.8712923526763916,\n",
      "                  0.8482521176338196,\n",
      "                  0.8591884970664978,\n",
      "                  0.8814530372619629,\n",
      "                  0.8734153509140015,\n",
      "                  0.8688139915466309,\n",
      "                  0.8610807657241821,\n",
      "                  0.8445547223091125,\n",
      "                  0.8455301523208618,\n",
      "                  0.8760402202606201],\n",
      "  'val_acc': [89.49472904205322,\n",
      "              88.1177306175232,\n",
      "              88.20041418075562,\n",
      "              89.4819438457489,\n",
      "              88.35433721542358,\n",
      "              89.08170461654663,\n",
      "              88.36645483970642,\n",
      "              88.12620639801025,\n",
      "              87.71676421165466,\n",
      "              89.44457769393921],\n",
      "  'val_f1': [0.9016570448875427,\n",
      "             0.8974339962005615,\n",
      "             0.9037358164787292,\n",
      "             0.9018718600273132,\n",
      "             0.9018260836601257,\n",
      "             0.9008830785751343,\n",
      "             0.8985973596572876,\n",
      "             0.8991155028343201,\n",
      "             0.9001970291137695,\n",
      "             0.902009904384613],\n",
      "  'val_loss': [0.3843865692615509,\n",
      "               0.3960724174976349,\n",
      "               0.40725651383399963,\n",
      "               0.4194580614566803,\n",
      "               0.3963654637336731,\n",
      "               0.3947356343269348,\n",
      "               0.4160362482070923,\n",
      "               0.4106416702270508,\n",
      "               0.4053202271461487,\n",
      "               0.40168946981430054],\n",
      "  'val_precision': [0.913303017616272,\n",
      "                    0.9152090549468994,\n",
      "                    0.9181235432624817,\n",
      "                    0.9192706346511841,\n",
      "                    0.913622260093689,\n",
      "                    0.9145113229751587,\n",
      "                    0.9144402742385864,\n",
      "                    0.9162226915359497,\n",
      "                    0.9162213802337646,\n",
      "                    0.922254204750061],\n",
      "  'val_recall': [0.8904860019683838,\n",
      "                 0.8806928396224976,\n",
      "                 0.8901270627975464,\n",
      "                 0.8854567408561707,\n",
      "                 0.8905684351921082,\n",
      "                 0.8879120945930481,\n",
      "                 0.8835755586624146,\n",
      "                 0.8830528855323792,\n",
      "                 0.8850560784339905,\n",
      "                 0.8830257654190063]},\n",
      " {'model_name': 'model_10',\n",
      "  'resource_stats': [{'cpu_freq_mean': 3876.7375894097227,\n",
      "                      'cpu_usage_max': 51.9,\n",
      "                      'cpu_usage_mean': 25.891666666666666,\n",
      "                      'duration_seconds': 158.16527223587036,\n",
      "                      'gpu_energy_wh': 5.280723805301066,\n",
      "                      'gpu_memory_max_mb': 3135.9375,\n",
      "                      'gpu_memory_mean_mb': 3017.582465277778,\n",
      "                      'gpu_power_max_w': 150.785,\n",
      "                      'gpu_power_mean_w': 120.1945625,\n",
      "                      'gpu_usage_max': 88.0,\n",
      "                      'gpu_usage_mean': 79.125,\n",
      "                      'ram_usage_max': 44.0,\n",
      "                      'ram_usage_mean': 41.62777777777777},\n",
      "                     {'cpu_freq_mean': 3892.196435509555,\n",
      "                      'cpu_usage_max': 52.5,\n",
      "                      'cpu_usage_mean': 22.846496815286628,\n",
      "                      'duration_seconds': 172.42411947250366,\n",
      "                      'gpu_energy_wh': 5.8783772248698805,\n",
      "                      'gpu_memory_max_mb': 3138.0,\n",
      "                      'gpu_memory_mean_mb': 3116.7611464968154,\n",
      "                      'gpu_power_max_w': 139.203,\n",
      "                      'gpu_power_mean_w': 122.73316560509554,\n",
      "                      'gpu_usage_max': 87.0,\n",
      "                      'gpu_usage_mean': 80.43312101910828,\n",
      "                      'ram_usage_max': 42.5,\n",
      "                      'ram_usage_mean': 41.59745222929936},\n",
      "                     {'cpu_freq_mean': 3791.1752131294957,\n",
      "                      'cpu_usage_max': 36.3,\n",
      "                      'cpu_usage_mean': 19.117266187050358,\n",
      "                      'duration_seconds': 152.57665467262268,\n",
      "                      'gpu_energy_wh': 5.232778888698116,\n",
      "                      'gpu_memory_max_mb': 3119.125,\n",
      "                      'gpu_memory_mean_mb': 3119.0062949640287,\n",
      "                      'gpu_power_max_w': 134.022,\n",
      "                      'gpu_power_mean_w': 123.4658345323741,\n",
      "                      'gpu_usage_max': 86.0,\n",
      "                      'gpu_usage_mean': 79.85611510791367,\n",
      "                      'ram_usage_max': 42.5,\n",
      "                      'ram_usage_mean': 41.90431654676258},\n",
      "                     {'cpu_freq_mean': 3771.600188848921,\n",
      "                      'cpu_usage_max': 32.5,\n",
      "                      'cpu_usage_mean': 19.618705035971225,\n",
      "                      'duration_seconds': 152.541157245636,\n",
      "                      'gpu_energy_wh': 5.14568634315998,\n",
      "                      'gpu_memory_max_mb': 3118.4375,\n",
      "                      'gpu_memory_mean_mb': 3118.4375,\n",
      "                      'gpu_power_max_w': 131.434,\n",
      "                      'gpu_power_mean_w': 121.43916546762588,\n",
      "                      'gpu_usage_max': 97.0,\n",
      "                      'gpu_usage_mean': 80.31654676258992,\n",
      "                      'ram_usage_max': 43.1,\n",
      "                      'ram_usage_mean': 41.900000000000006},\n",
      "                     {'cpu_freq_mean': 3787.8276232142857,\n",
      "                      'cpu_usage_max': 39.2,\n",
      "                      'cpu_usage_mean': 20.619285714285713,\n",
      "                      'duration_seconds': 153.63555479049683,\n",
      "                      'gpu_energy_wh': 5.2420673822206005,\n",
      "                      'gpu_memory_max_mb': 3148.4375,\n",
      "                      'gpu_memory_mean_mb': 3132.280357142857,\n",
      "                      'gpu_power_max_w': 153.114,\n",
      "                      'gpu_power_mean_w': 122.83252142857143,\n",
      "                      'gpu_usage_max': 87.0,\n",
      "                      'gpu_usage_mean': 80.77857142857142,\n",
      "                      'ram_usage_max': 42.8,\n",
      "                      'ram_usage_mean': 42.082857142857144},\n",
      "                     {'cpu_freq_mean': 3761.434869642857,\n",
      "                      'cpu_usage_max': 34.6,\n",
      "                      'cpu_usage_mean': 20.267857142857142,\n",
      "                      'duration_seconds': 153.65815567970276,\n",
      "                      'gpu_energy_wh': 5.251436372374172,\n",
      "                      'gpu_memory_max_mb': 3126.4375,\n",
      "                      'gpu_memory_mean_mb': 3126.4375,\n",
      "                      'gpu_power_max_w': 160.947,\n",
      "                      'gpu_power_mean_w': 123.03395714285715,\n",
      "                      'gpu_usage_max': 86.0,\n",
      "                      'gpu_usage_mean': 80.33571428571429,\n",
      "                      'ram_usage_max': 43.1,\n",
      "                      'ram_usage_mean': 42.27857142857143},\n",
      "                     {'cpu_freq_mean': 3807.683353503184,\n",
      "                      'cpu_usage_max': 36.7,\n",
      "                      'cpu_usage_mean': 20.491082802547766,\n",
      "                      'duration_seconds': 172.4530086517334,\n",
      "                      'gpu_energy_wh': 5.912193192438273,\n",
      "                      'gpu_memory_max_mb': 3126.4375,\n",
      "                      'gpu_memory_mean_mb': 3116.501194267516,\n",
      "                      'gpu_power_max_w': 135.459,\n",
      "                      'gpu_power_mean_w': 123.41852229299363,\n",
      "                      'gpu_usage_max': 85.0,\n",
      "                      'gpu_usage_mean': 79.75796178343948,\n",
      "                      'ram_usage_max': 43.4,\n",
      "                      'ram_usage_mean': 42.64904458598726},\n",
      "                     {'cpu_freq_mean': 3830.235088375796,\n",
      "                      'cpu_usage_max': 35.4,\n",
      "                      'cpu_usage_mean': 20.742675159235667,\n",
      "                      'duration_seconds': 172.45890402793884,\n",
      "                      'gpu_energy_wh': 5.8333903902012905,\n",
      "                      'gpu_memory_max_mb': 3096.4375,\n",
      "                      'gpu_memory_mean_mb': 3096.4375,\n",
      "                      'gpu_power_max_w': 132.33,\n",
      "                      'gpu_power_mean_w': 121.76933121019111,\n",
      "                      'gpu_usage_max': 85.0,\n",
      "                      'gpu_usage_mean': 79.36942675159236,\n",
      "                      'ram_usage_max': 43.9,\n",
      "                      'ram_usage_mean': 42.95668789808917},\n",
      "                     {'cpu_freq_mean': 3799.842909821428,\n",
      "                      'cpu_usage_max': 33.3,\n",
      "                      'cpu_usage_mean': 21.226428571428574,\n",
      "                      'duration_seconds': 153.68367528915405,\n",
      "                      'gpu_energy_wh': 5.199377923770168,\n",
      "                      'gpu_memory_max_mb': 3096.4375,\n",
      "                      'gpu_memory_mean_mb': 3096.4375,\n",
      "                      'gpu_power_max_w': 132.007,\n",
      "                      'gpu_power_mean_w': 121.79407142857141,\n",
      "                      'gpu_usage_max': 85.0,\n",
      "                      'gpu_usage_mean': 79.80714285714286,\n",
      "                      'ram_usage_max': 43.9,\n",
      "                      'ram_usage_mean': 43.24285714285714},\n",
      "                     {'cpu_freq_mean': 3804.566491071428,\n",
      "                      'cpu_usage_max': 37.5,\n",
      "                      'cpu_usage_mean': 21.913571428571426,\n",
      "                      'duration_seconds': 153.638689994812,\n",
      "                      'gpu_energy_wh': 5.307935068389097,\n",
      "                      'gpu_memory_max_mb': 3096.4375,\n",
      "                      'gpu_memory_mean_mb': 3096.4375,\n",
      "                      'gpu_power_max_w': 165.257,\n",
      "                      'gpu_power_mean_w': 124.37339999999999,\n",
      "                      'gpu_usage_max': 85.0,\n",
      "                      'gpu_usage_mean': 79.87142857142857,\n",
      "                      'ram_usage_max': 44.3,\n",
      "                      'ram_usage_mean': 43.52}],\n",
      "  'stopped_epochs': [8, 9, 8, 8, 8, 8, 9, 9, 8, 8],\n",
      "  'test_acc': [87.54155039787292,\n",
      "               86.01807355880737,\n",
      "               87.91357278823853,\n",
      "               87.16556429862976,\n",
      "               87.51518130302429,\n",
      "               88.63112330436707,\n",
      "               86.93391680717468,\n",
      "               87.43272423744202,\n",
      "               87.09374070167542,\n",
      "               86.88591122627258],\n",
      "  'test_f1': [0.880699872970581,\n",
      "              0.8683828115463257,\n",
      "              0.8853573203086853,\n",
      "              0.8791452646255493,\n",
      "              0.8819841742515564,\n",
      "              0.8909186720848083,\n",
      "              0.8784775137901306,\n",
      "              0.8795209527015686,\n",
      "              0.8807828426361084,\n",
      "              0.8756141066551208],\n",
      "  'test_loss': [0.44849684834480286,\n",
      "                0.49021634459495544,\n",
      "                0.42951586842536926,\n",
      "                0.44412103295326233,\n",
      "                0.43744540214538574,\n",
      "                0.41151663661003113,\n",
      "                0.47547635436058044,\n",
      "                0.45924150943756104,\n",
      "                0.4465264081954956,\n",
      "                0.4596695005893707],\n",
      "  'test_precision': [0.9118400812149048,\n",
      "                     0.8999541401863098,\n",
      "                     0.9223659634590149,\n",
      "                     0.9163451790809631,\n",
      "                     0.9133837223052979,\n",
      "                     0.9238429665565491,\n",
      "                     0.9092313647270203,\n",
      "                     0.9116979837417603,\n",
      "                     0.9179785847663879,\n",
      "                     0.9062346816062927],\n",
      "  'test_recall': [0.8528866767883301,\n",
      "                  0.8404396176338196,\n",
      "                  0.8524535894393921,\n",
      "                  0.8464865684509277,\n",
      "                  0.8537493944168091,\n",
      "                  0.8612258434295654,\n",
      "                  0.8509195446968079,\n",
      "                  0.8509925007820129,\n",
      "                  0.8480052351951599,\n",
      "                  0.8481583595275879],\n",
      "  'val_acc': [88.33151459693909,\n",
      "              87.63323426246643,\n",
      "              87.26854920387268,\n",
      "              87.68264651298523,\n",
      "              87.77266144752502,\n",
      "              88.09351921081543,\n",
      "              88.45128417015076,\n",
      "              88.33092451095581,\n",
      "              87.10260391235352,\n",
      "              86.4510715007782],\n",
      "  'val_f1': [0.88593989610672,\n",
      "             0.8834030032157898,\n",
      "             0.8888388276100159,\n",
      "             0.8871012926101685,\n",
      "             0.8864940404891968,\n",
      "             0.8969390988349915,\n",
      "             0.8899292945861816,\n",
      "             0.8924676775932312,\n",
      "             0.8860237002372742,\n",
      "             0.8868234753608704],\n",
      "  'val_loss': [0.43283843994140625,\n",
      "               0.4724343419075012,\n",
      "               0.432187557220459,\n",
      "               0.4304915964603424,\n",
      "               0.43611469864845276,\n",
      "               0.41542553901672363,\n",
      "               0.4280576705932617,\n",
      "               0.4057460129261017,\n",
      "               0.4386984705924988,\n",
      "               0.45773234963417053],\n",
      "  'val_precision': [0.9164502620697021,\n",
      "                    0.9021806120872498,\n",
      "                    0.9039393067359924,\n",
      "                    0.9066377878189087,\n",
      "                    0.8993778824806213,\n",
      "                    0.9134026765823364,\n",
      "                    0.9177976250648499,\n",
      "                    0.9057645201683044,\n",
      "                    0.9054184556007385,\n",
      "                    0.9026130437850952],\n",
      "  'val_recall': [0.8582431674003601,\n",
      "                 0.8657945990562439,\n",
      "                 0.8746222257614136,\n",
      "                 0.8687499761581421,\n",
      "                 0.8742167353630066,\n",
      "                 0.8813072443008423,\n",
      "                 0.864308774471283,\n",
      "                 0.879807710647583,\n",
      "                 0.8678685426712036,\n",
      "                 0.8719719648361206]}]\n"
     ]
    }
   ],
   "source": [
    "with open('saved_metrics/model_1_metrics.pkl', 'rb') as f:\n",
    "    metrics = pickle.load(f)\n",
    "\n",
    "# View the structure\n",
    "print(\"Keys in metrics:\")\n",
    "print(metrics.keys())\n",
    "\n",
    "pprint.pprint(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95646718-3528-4414-991b-d5bf4434c949",
   "metadata": {},
   "source": [
    "## Consolidate All Model Metrics\n",
    "\n",
    "Load individual model metrics and save them into a single pickle file for easier analysis.\n",
    "\n",
    "**What this does:**\n",
    "- Searches for `model_1_metrics.pkl` through `model_10_metrics.pkl`\n",
    "- Loads all found metric files\n",
    "- Combines them into a single list\n",
    "- Saves consolidated metrics to `saved_metrics/all_metrics.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c0dff4-5c55-4c06-8b4c-585d1affe105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model_1\n",
      "Loaded model_2\n",
      "Loaded model_3\n",
      "Loaded model_4\n",
      "Loaded model_5\n",
      "Loaded model_6\n",
      "Loaded model_7\n",
      "Loaded model_8\n",
      "Loaded model_9\n",
      "Loaded model_10\n"
     ]
    }
   ],
   "source": [
    "def load_all_metrics(metrics_dir='saved_metrics'):\n",
    "    \"\"\"Load all model metrics from pickle files.\"\"\"\n",
    "    all_metrics = []\n",
    "    for i in range(1, 11):\n",
    "        filepath = os.path.join(metrics_dir, f'model_{i}_metrics.pkl')\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                metrics = pickle.load(f)\n",
    "                all_metrics.append(metrics)\n",
    "            print(f\"Loaded {metrics['model_name']}\")\n",
    "    return all_metrics\n",
    "\n",
    "all_metrics = load_all_metrics('saved_metrics')\n",
    "\n",
    "with open('saved_metrics/all_metrics.pkl', 'wb') as f:\n",
    "        pickle.dump(all_metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faffb721-fd37-47b1-84c0-979e0c4be1f4",
   "metadata": {},
   "source": [
    "## Compare Model Performance\n",
    "\n",
    "Display a summary table comparing test set performance across all trained models:\n",
    "- **Test Accuracy** - Average accuracy across 10 folds\n",
    "- **Test Precision** - Weighted precision score\n",
    "- **Test Recall** - Weighted recall score\n",
    "- **Test F1-Score** - Harmonic mean of precision and recall\n",
    "\n",
    "Identifies the best performing model based on test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cabcd4-dfe1-413f-9ab6-56cc234afcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "MODEL COMPARISON - TEST SET RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "Model           Test Acc     Test Prec    Test Recall  Test F1     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "model_1              42.27%      0.6791      0.2054      0.3001\n",
      "model_2              55.86%      0.7305      0.4193      0.5212\n",
      "model_3              81.10%      0.8747      0.7731      0.8196\n",
      "model_4              64.45%      0.7647      0.5648      0.6471\n",
      "model_5              78.30%      0.8417      0.7478      0.7910\n",
      "model_6              80.88%      0.8742      0.7675      0.8162\n",
      "model_7              88.61%      0.9205      0.8690      0.8935\n",
      "model_8              84.80%      0.8959      0.8222      0.8566\n",
      "model_9              88.34%      0.9192      0.8630      0.8895\n",
      "model_10             87.31%      0.9133      0.8505      0.8801\n",
      "====================================================================================================\n",
      "\n",
      "Best Model: model_7 with 88.61% test accuracy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_models(all_metrics):\n",
    "    \"\"\"Compare results across all trained models.\"\"\"\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(\"MODEL COMPARISON - TEST SET RESULTS\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    print(f\"{'Model':<15} {'Test Acc':<12} {'Test Prec':<12} {'Test Recall':<12} {'Test F1':<12}\")\n",
    "    print(f\"{'-'*100}\")\n",
    "    \n",
    "    for metrics in all_metrics:\n",
    "        model_name = metrics['model_name']\n",
    "        test_acc = np.mean(metrics['test_acc'])\n",
    "        test_prec = np.mean(metrics['test_precision'])\n",
    "        test_recall = np.mean(metrics['test_recall'])\n",
    "        test_f1 = np.mean(metrics['test_f1'])\n",
    "        \n",
    "        print(f\"{model_name:<15} {test_acc:>10.2f}%  {test_prec:>10.4f}  {test_recall:>10.4f}  {test_f1:>10.4f}\")\n",
    "    \n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_model = max(all_metrics, key=lambda x: np.mean(x['test_acc']))\n",
    "    print(f\"Best Model: {best_model['model_name']} with {np.mean(best_model['test_acc']):.2f}% test accuracy\\n\")\n",
    "\n",
    "compare_models(all_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa341b-7e8a-442d-b0cf-f1683f114cac",
   "metadata": {},
   "source": [
    "## Compare Energy Consumption & Efficiency\n",
    "\n",
    "Analyze energy consumption and computational efficiency for each model:\n",
    "- **Total Time** - Combined training time across all folds (minutes)\n",
    "- **Avg GPU Power** - Average GPU power draw during training (Watts)\n",
    "- **Total Energy** - Cumulative energy consumption (Watt-hours)\n",
    "- **Efficiency** - Test accuracy per Wh (higher = more efficient)\n",
    "\n",
    "**Efficiency metric** shows which models achieve the best accuracy relative to energy consumed. Useful for identifying models suitable for resource-constrained or sustainable deployment.\n",
    "\n",
    "**Note:** Only displays energy data if GPU monitoring was enabled during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2051ba7-c2e0-4c45-8a6a-54369bdc313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "ENERGY CONSUMPTION & EFFICIENCY COMPARISON\n",
      "====================================================================================================\n",
      "\n",
      "Model           Total Time      Avg GPU Power   Total Energy    Test Acc     Efficiency     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "model_1                   9.8m           45.1W          7.332Wh       42.27%           5.76%/Wh\n",
      "model_2                  15.4m           45.7W         11.688Wh       55.86%           4.78%/Wh\n",
      "model_3                  16.6m           47.7W         13.231Wh       81.10%           6.13%/Wh\n",
      "model_4                  10.9m           61.4W         11.156Wh       64.45%           5.78%/Wh\n",
      "model_5                  10.5m           47.3W          8.271Wh       78.30%           9.47%/Wh\n",
      "model_6                  16.1m           47.9W         12.865Wh       80.88%           6.29%/Wh\n",
      "model_7                  10.3m           83.3W         14.330Wh       88.61%           6.18%/Wh\n",
      "model_8                  14.7m           95.2W         23.307Wh       84.80%           3.64%/Wh\n",
      "model_9                  12.7m          104.4W         22.135Wh       88.34%           3.99%/Wh\n",
      "model_10                 26.6m          122.5W         54.284Wh       87.31%           1.61%/Wh\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_energy(all_metrics):\n",
    "    \"\"\"Compare energy consumption across models.\"\"\"\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(\"ENERGY CONSUMPTION & EFFICIENCY COMPARISON\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    print(f\"{'Model':<15} {'Total Time':<15} {'Avg GPU Power':<15} {'Total Energy':<15} {'Test Acc':<12} {'Efficiency':<15}\")\n",
    "    print(f\"{'-'*100}\")\n",
    "    \n",
    "    for metrics in all_metrics:\n",
    "        model_name = metrics['model_name']\n",
    "        test_acc = np.mean(metrics['test_acc'])\n",
    "        \n",
    "        if 'resource_stats' in metrics and metrics['resource_stats']:\n",
    "            total_time = sum(s['duration_seconds'] for s in metrics['resource_stats']) / 60\n",
    "            \n",
    "            if 'gpu_power_mean_w' in metrics['resource_stats'][0]:\n",
    "                avg_power = np.mean([s['gpu_power_mean_w'] for s in metrics['resource_stats']])\n",
    "                total_energy = sum(s['gpu_energy_wh'] for s in metrics['resource_stats'])\n",
    "                \n",
    "                # Efficiency: Accuracy per Wh\n",
    "                efficiency = test_acc / total_energy if total_energy > 0 else 0\n",
    "                \n",
    "                print(f\"{model_name:<15} {total_time:>13.1f}m  {avg_power:>13.1f}W  {total_energy:>13.3f}Wh  {test_acc:>10.2f}%  {efficiency:>13.2f}%/Wh\")\n",
    "            else:\n",
    "                print(f\"{model_name:<15} {total_time:>13.1f}m  {'CPU only':<15} {'N/A':<15} {test_acc:>10.2f}%  {'N/A':<15}\")\n",
    "        else:\n",
    "            print(f\"{model_name:<15} {'N/A':<15} {'N/A':<15} {'N/A':<15} {test_acc:>10.2f}%  {'N/A':<15}\")\n",
    "    \n",
    "    print(f\"{'='*100}\\n\")\n",
    "\n",
    "compare_energy(all_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd0b68-1693-49dc-8cd2-5d6d7728bc5b",
   "metadata": {},
   "source": [
    "## Calculate Electricity Costs\n",
    "\n",
    "Estimate the electricity costs for training all models based on energy consumption.\n",
    "\n",
    "**Default rate:** $0.12 per kWh (adjust `electricity_rate` parameter for your local rates)\n",
    "\n",
    "**Output:**\n",
    "- Cost per model\n",
    "- Total cost for training all models\n",
    "\n",
    "**Purpose:** Helps quantify the real-world cost of model development and compare the economic efficiency of different architectures.\n",
    "\n",
    "**Note:** Only calculates costs if GPU energy data was collected during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a05b28-2fb5-4bb4-a38c-ee82738efc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ESTIMATED ELECTRICITY COSTS\n",
      "(Rate: $0.12 per kWh)\n",
      "================================================================================\n",
      "\n",
      "model_1        : $0.0009 (0.007332 kWh)\n",
      "model_2        : $0.0014 (0.011688 kWh)\n",
      "model_3        : $0.0016 (0.013231 kWh)\n",
      "model_4        : $0.0013 (0.011156 kWh)\n",
      "model_5        : $0.0010 (0.008271 kWh)\n",
      "model_6        : $0.0015 (0.012865 kWh)\n",
      "model_7        : $0.0017 (0.014330 kWh)\n",
      "model_8        : $0.0028 (0.023307 kWh)\n",
      "model_9        : $0.0027 (0.022135 kWh)\n",
      "model_10       : $0.0065 (0.054284 kWh)\n",
      "\n",
      "Total cost for all models: $0.0214\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_costs(all_metrics, electricity_rate=0.12):\n",
    "    \"\"\"Calculate estimated electricity costs.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ESTIMATED ELECTRICITY COSTS\")\n",
    "    print(f\"(Rate: ${electricity_rate:.2f} per kWh)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    total_cost = 0\n",
    "    for metrics in all_metrics:\n",
    "        if 'resource_stats' in metrics and metrics['resource_stats']:\n",
    "            if 'gpu_power_mean_w' in metrics['resource_stats'][0]:\n",
    "                total_energy_kwh = sum(s['gpu_energy_wh'] for s in metrics['resource_stats']) / 1000\n",
    "                cost = total_energy_kwh * electricity_rate\n",
    "                total_cost += cost\n",
    "                print(f\"{metrics['model_name']:<15}: ${cost:.4f} ({total_energy_kwh:.6f} kWh)\")\n",
    "    \n",
    "    if total_cost > 0:\n",
    "        print(f\"\\n{'Total cost for all models:':<15} ${total_cost:.4f}\")\n",
    "    else:\n",
    "        print(\"No GPU energy data available\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "calculate_costs(all_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe140c9-7579-4126-a30f-58717fb2ad0a",
   "metadata": {},
   "source": [
    "## Fine-tune Single Model\n",
    "\n",
    "Fine-tune a specific pre-trained model on the fine-tuning dataset. Change `model_name='model_X'` to fine-tune different models (1-10).\n",
    "\n",
    "**Parameters:**\n",
    "- `epochs=10` - Fine-tuning epochs (fewer than initial training)\n",
    "- `batch_size=128` - Batch size for fine-tuning\n",
    "- `monitor_resources=True` - Track CPU/GPU energy consumption\n",
    "\n",
    "**Output:** Fine-tuned models saved to `finetuned_models/model_X_fold_Y_finetuned.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27c1aaa-8f98-4adb-a556-abb1890a6f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_1 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_1\n",
      "================================================================================\n",
      "\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.9744 - accuracy: 0.4230 - precision_m: 0.6500 - recall_m: 0.1941 - f1_m: 0.2980\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.9032 - accuracy: 0.4291 - precision_m: 0.6881 - recall_m: 0.2003 - f1_m: 0.3090\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.8729 - accuracy: 0.4428 - precision_m: 0.6981 - recall_m: 0.2017 - f1_m: 0.3119\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.8361 - accuracy: 0.4513 - precision_m: 0.7003 - recall_m: 0.2152 - f1_m: 0.3285\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7966 - accuracy: 0.4485 - precision_m: 0.7276 - recall_m: 0.2190 - f1_m: 0.3361\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7776 - accuracy: 0.4622 - precision_m: 0.7360 - recall_m: 0.2221 - f1_m: 0.3400\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7525 - accuracy: 0.4608 - precision_m: 0.7297 - recall_m: 0.2283 - f1_m: 0.3472\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7290 - accuracy: 0.4660 - precision_m: 0.7271 - recall_m: 0.2275 - f1_m: 0.3457\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.6977 - accuracy: 0.4783 - precision_m: 0.7479 - recall_m: 0.2341 - f1_m: 0.3556\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.6900 - accuracy: 0.4778 - precision_m: 0.7556 - recall_m: 0.2387 - f1_m: 0.3612\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 2.0095, Acc: 41.10%\n",
      "Precision: 0.6484, Recall: 0.2054, F1: 0.3064\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_1\n",
      "================================================================================\n",
      "\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 7ms/step - loss: 1.7729 - accuracy: 0.4757 - precision_m: 0.7183 - recall_m: 0.2808 - f1_m: 0.4029\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7359 - accuracy: 0.4825 - precision_m: 0.7220 - recall_m: 0.2979 - f1_m: 0.4211\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6836 - accuracy: 0.4984 - precision_m: 0.7274 - recall_m: 0.3011 - f1_m: 0.4248\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6120 - accuracy: 0.5157 - precision_m: 0.7470 - recall_m: 0.3151 - f1_m: 0.4425\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.5843 - accuracy: 0.5189 - precision_m: 0.7560 - recall_m: 0.3161 - f1_m: 0.4445\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.5527 - accuracy: 0.5370 - precision_m: 0.7640 - recall_m: 0.3268 - f1_m: 0.4570\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.5455 - accuracy: 0.5402 - precision_m: 0.7739 - recall_m: 0.3256 - f1_m: 0.4570\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.5081 - accuracy: 0.5420 - precision_m: 0.7768 - recall_m: 0.3439 - f1_m: 0.4754\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.4537 - accuracy: 0.5675 - precision_m: 0.7772 - recall_m: 0.3570 - f1_m: 0.4877\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.4296 - accuracy: 0.5706 - precision_m: 0.8017 - recall_m: 0.3585 - f1_m: 0.4948\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.8598, Acc: 46.25%\n",
      "Precision: 0.6645, Recall: 0.2921, F1: 0.4016\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_1\n",
      "================================================================================\n",
      "\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.9733 - accuracy: 0.4114 - precision_m: 0.7120 - recall_m: 0.1661 - f1_m: 0.2683\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.9324 - accuracy: 0.4128 - precision_m: 0.7429 - recall_m: 0.1706 - f1_m: 0.2765\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.9120 - accuracy: 0.4280 - precision_m: 0.7676 - recall_m: 0.1690 - f1_m: 0.2748\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.8677 - accuracy: 0.4341 - precision_m: 0.7526 - recall_m: 0.1845 - f1_m: 0.2957\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.8392 - accuracy: 0.4336 - precision_m: 0.7725 - recall_m: 0.1835 - f1_m: 0.2958\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.8284 - accuracy: 0.4410 - precision_m: 0.7700 - recall_m: 0.1842 - f1_m: 0.2966\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7952 - accuracy: 0.4456 - precision_m: 0.7705 - recall_m: 0.1903 - f1_m: 0.3045\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7799 - accuracy: 0.4461 - precision_m: 0.7841 - recall_m: 0.1895 - f1_m: 0.3037\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7659 - accuracy: 0.4516 - precision_m: 0.7810 - recall_m: 0.1987 - f1_m: 0.3163\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7431 - accuracy: 0.4540 - precision_m: 0.7965 - recall_m: 0.2041 - f1_m: 0.3239\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 2.0522, Acc: 38.84%\n",
      "Precision: 0.6554, Recall: 0.1674, F1: 0.2614\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_1\n",
      "================================================================================\n",
      "\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.6027 - accuracy: 0.2269 - precision_m: 0.5294 - recall_m: 0.0071 - f1_m: 0.0140\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.5678 - accuracy: 0.2245 - precision_m: 0.3824 - recall_m: 0.0055 - f1_m: 0.0108    \n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.5353 - accuracy: 0.2441 - precision_m: 0.4559 - recall_m: 0.0078 - f1_m: 0.0153\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.5094 - accuracy: 0.2431 - precision_m: 0.5686 - recall_m: 0.0079 - f1_m: 0.0156\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.4908 - accuracy: 0.2552 - precision_m: 0.6176 - recall_m: 0.0075 - f1_m: 0.0147\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.4794 - accuracy: 0.2562 - precision_m: 0.6275 - recall_m: 0.0079 - f1_m: 0.0156\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.4638 - accuracy: 0.2631 - precision_m: 0.5588 - recall_m: 0.0079 - f1_m: 0.0156    \n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.4538 - accuracy: 0.2552 - precision_m: 0.5196 - recall_m: 0.0069 - f1_m: 0.0136      \n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.4477 - accuracy: 0.2603 - precision_m: 0.4951 - recall_m: 0.0083 - f1_m: 0.0162\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.4392 - accuracy: 0.2589 - precision_m: 0.5931 - recall_m: 0.0087 - f1_m: 0.0171\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 2.6112, Acc: 23.11%\n",
      "Precision: 0.2666, Recall: 0.0118, F1: 0.0223\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_1\n",
      "================================================================================\n",
      "\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.1540 - accuracy: 0.3396 - precision_m: 0.6401 - recall_m: 0.0838 - f1_m: 0.1472\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.1217 - accuracy: 0.3489 - precision_m: 0.6526 - recall_m: 0.0803 - f1_m: 0.1425\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.0923 - accuracy: 0.3555 - precision_m: 0.7032 - recall_m: 0.0864 - f1_m: 0.1535\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 2.0564 - accuracy: 0.3597 - precision_m: 0.7080 - recall_m: 0.0826 - f1_m: 0.1468\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.0445 - accuracy: 0.3639 - precision_m: 0.6926 - recall_m: 0.0835 - f1_m: 0.1488\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.0212 - accuracy: 0.3690 - precision_m: 0.7245 - recall_m: 0.0906 - f1_m: 0.1601\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.0134 - accuracy: 0.3620 - precision_m: 0.7177 - recall_m: 0.0857 - f1_m: 0.1519\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.0045 - accuracy: 0.3587 - precision_m: 0.7179 - recall_m: 0.0911 - f1_m: 0.1607\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.9901 - accuracy: 0.3667 - precision_m: 0.7117 - recall_m: 0.1003 - f1_m: 0.1745\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.9634 - accuracy: 0.3775 - precision_m: 0.7097 - recall_m: 0.0922 - f1_m: 0.1621\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 2.2056, Acc: 33.36%\n",
      "Precision: 0.6216, Recall: 0.0793, F1: 0.1363\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_1\n",
      "================================================================================\n",
      "\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7755 - accuracy: 0.4529 - precision_m: 0.6770 - recall_m: 0.2630 - f1_m: 0.3773\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7059 - accuracy: 0.4870 - precision_m: 0.6894 - recall_m: 0.2777 - f1_m: 0.3949\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.6383 - accuracy: 0.5019 - precision_m: 0.7147 - recall_m: 0.2956 - f1_m: 0.4173\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.5907 - accuracy: 0.5121 - precision_m: 0.7215 - recall_m: 0.3019 - f1_m: 0.4249\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.5600 - accuracy: 0.5163 - precision_m: 0.7368 - recall_m: 0.3093 - f1_m: 0.4345\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.5120 - accuracy: 0.5387 - precision_m: 0.7557 - recall_m: 0.3157 - f1_m: 0.4441\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.4740 - accuracy: 0.5438 - precision_m: 0.7619 - recall_m: 0.3271 - f1_m: 0.4568\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.4499 - accuracy: 0.5550 - precision_m: 0.7730 - recall_m: 0.3351 - f1_m: 0.4667\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.4130 - accuracy: 0.5680 - precision_m: 0.7898 - recall_m: 0.3439 - f1_m: 0.4778\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.3832 - accuracy: 0.5732 - precision_m: 0.7964 - recall_m: 0.3542 - f1_m: 0.4894\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.8226, Acc: 46.56%\n",
      "Precision: 0.6662, Recall: 0.2962, F1: 0.4057\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_1\n",
      "================================================================================\n",
      "\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.8621 - accuracy: 0.4596 - precision_m: 0.7089 - recall_m: 0.2443 - f1_m: 0.3621\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.8085 - accuracy: 0.4638 - precision_m: 0.7079 - recall_m: 0.2496 - f1_m: 0.3682\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7595 - accuracy: 0.4786 - precision_m: 0.7397 - recall_m: 0.2632 - f1_m: 0.3877\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7197 - accuracy: 0.4929 - precision_m: 0.7461 - recall_m: 0.2570 - f1_m: 0.3811\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.6809 - accuracy: 0.4986 - precision_m: 0.7749 - recall_m: 0.2748 - f1_m: 0.4046\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.6519 - accuracy: 0.5019 - precision_m: 0.7741 - recall_m: 0.2751 - f1_m: 0.4046\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.6321 - accuracy: 0.5162 - precision_m: 0.7736 - recall_m: 0.2802 - f1_m: 0.4108\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.6159 - accuracy: 0.5209 - precision_m: 0.7778 - recall_m: 0.2854 - f1_m: 0.4168\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.5850 - accuracy: 0.5190 - precision_m: 0.7933 - recall_m: 0.2977 - f1_m: 0.4324\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.5557 - accuracy: 0.5276 - precision_m: 0.7925 - recall_m: 0.3018 - f1_m: 0.4361\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.9375, Acc: 43.62%\n",
      "Precision: 0.6695, Recall: 0.2395, F1: 0.3470\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_1\n",
      "================================================================================\n",
      "\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.9230 - accuracy: 0.4436 - precision_m: 0.6970 - recall_m: 0.2140 - f1_m: 0.3263\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.8746 - accuracy: 0.4523 - precision_m: 0.6980 - recall_m: 0.2172 - f1_m: 0.3304\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.8220 - accuracy: 0.4694 - precision_m: 0.7270 - recall_m: 0.2240 - f1_m: 0.3411\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.7695 - accuracy: 0.4800 - precision_m: 0.7595 - recall_m: 0.2323 - f1_m: 0.3542\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.7494 - accuracy: 0.4832 - precision_m: 0.7501 - recall_m: 0.2344 - f1_m: 0.3561\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.7417 - accuracy: 0.4790 - precision_m: 0.7383 - recall_m: 0.2373 - f1_m: 0.3584\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.7074 - accuracy: 0.4961 - precision_m: 0.7526 - recall_m: 0.2390 - f1_m: 0.3615\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.6694 - accuracy: 0.5062 - precision_m: 0.7584 - recall_m: 0.2459 - f1_m: 0.3700\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.6489 - accuracy: 0.5012 - precision_m: 0.7644 - recall_m: 0.2575 - f1_m: 0.3843\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.6213 - accuracy: 0.5108 - precision_m: 0.7808 - recall_m: 0.2630 - f1_m: 0.3921\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 2.0152, Acc: 41.70%\n",
      "Precision: 0.6487, Recall: 0.2158, F1: 0.3187\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_1\n",
      "================================================================================\n",
      "\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.4889 - accuracy: 0.5705 - precision_m: 0.7522 - recall_m: 0.4327 - f1_m: 0.5485\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.4130 - accuracy: 0.5923 - precision_m: 0.7749 - recall_m: 0.4328 - f1_m: 0.5548\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.3308 - accuracy: 0.6025 - precision_m: 0.7893 - recall_m: 0.4545 - f1_m: 0.5761\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.2795 - accuracy: 0.6294 - precision_m: 0.8127 - recall_m: 0.4691 - f1_m: 0.5939\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.2384 - accuracy: 0.6396 - precision_m: 0.8271 - recall_m: 0.4780 - f1_m: 0.6052\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1873 - accuracy: 0.6549 - precision_m: 0.8315 - recall_m: 0.4947 - f1_m: 0.6196\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1547 - accuracy: 0.6665 - precision_m: 0.8378 - recall_m: 0.4966 - f1_m: 0.6230\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.1088 - accuracy: 0.6721 - precision_m: 0.8558 - recall_m: 0.5142 - f1_m: 0.6415\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0675 - accuracy: 0.6878 - precision_m: 0.8692 - recall_m: 0.5267 - f1_m: 0.6554\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.0298 - accuracy: 0.7050 - precision_m: 0.8754 - recall_m: 0.5500 - f1_m: 0.6747\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.5652, Acc: 55.33%\n",
      "Precision: 0.7205, Recall: 0.4267, F1: 0.5318\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_1\n",
      "================================================================================\n",
      "\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.7722 - accuracy: 0.4739 - precision_m: 0.6985 - recall_m: 0.2832 - f1_m: 0.4021\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.7102 - accuracy: 0.4881 - precision_m: 0.7087 - recall_m: 0.2939 - f1_m: 0.4149\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.6621 - accuracy: 0.4952 - precision_m: 0.7468 - recall_m: 0.2993 - f1_m: 0.4264\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.6179 - accuracy: 0.5190 - precision_m: 0.7474 - recall_m: 0.3061 - f1_m: 0.4336\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.5814 - accuracy: 0.5219 - precision_m: 0.7646 - recall_m: 0.3110 - f1_m: 0.4415\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.5492 - accuracy: 0.5295 - precision_m: 0.7581 - recall_m: 0.3210 - f1_m: 0.4505\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.5223 - accuracy: 0.5456 - precision_m: 0.7846 - recall_m: 0.3306 - f1_m: 0.4646\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.4812 - accuracy: 0.5551 - precision_m: 0.7896 - recall_m: 0.3332 - f1_m: 0.4680\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1.4527 - accuracy: 0.5618 - precision_m: 0.7945 - recall_m: 0.3409 - f1_m: 0.4765\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.4388 - accuracy: 0.5599 - precision_m: 0.7905 - recall_m: 0.3455 - f1_m: 0.4803\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.8613, Acc: 46.56%\n",
      "Precision: 0.6887, Recall: 0.2842, F1: 0.3965\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_1_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_1\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  41.64% ± 8.25%\n",
      "  Precision: 0.6250 ± 0.1220\n",
      "  Recall:    0.2218 ± 0.1115\n",
      "  F1 Score:  0.3128 ± 0.1382\n",
      "\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finetuned_metrics_1 = finetune_all_folds(\n",
    "    model_name='model_1',\n",
    "    folds_dir='new_Data_particions',\n",
    "    models_dir='trained_models',\n",
    "    num_folds=10,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    save_dir='finetuned_models',\n",
    "    monitor_resources=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346db28-49fe-41df-a064-ae5dcd022301",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_before_after_finetuning(metrics_1, finetuned_metrics_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54dc034-cf55-41bf-8d18-2c132caf37ba",
   "metadata": {},
   "source": [
    "## Fine-tune All Trained Models\n",
    "\n",
    "Automatically fine-tune all previously trained models and compare performance before/after fine-tuning.\n",
    "\n",
    "**Process:**\n",
    "1. Loads each model from `all_metrics`\n",
    "2. Fine-tunes on the fine-tuning dataset (10 epochs)\n",
    "3. Evaluates on final test set\n",
    "4. Displays before/after comparison for each model\n",
    "5. Saves fine-tuned models and metrics\n",
    "\n",
    "**Memory Management:** Uses `clear_session()` and garbage collection after each model to prevent RAM overflow.\n",
    "\n",
    "**Output:** \n",
    "- Fine-tuned models saved to `finetuned_models/`\n",
    "- Consolidated metrics in `all_finetuned_metrics`\n",
    "\n",
    "**Note:** Fine-tuning typically takes 10-20% of the time required for initial training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b65093-7171-4b72-9ce9-21febb9a778e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning model_1...\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_1 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 2.4869 - accuracy: 0.2472 - precision_m: 0.5800 - recall_m: 0.0285 - f1_m: 0.0542\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.4564 - accuracy: 0.2576 - precision_m: 0.6204 - recall_m: 0.0285 - f1_m: 0.0540\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.4371 - accuracy: 0.2571 - precision_m: 0.5857 - recall_m: 0.0280 - f1_m: 0.0531\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.4288 - accuracy: 0.2595 - precision_m: 0.6431 - recall_m: 0.0261 - f1_m: 0.0499\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.4075 - accuracy: 0.2665 - precision_m: 0.6595 - recall_m: 0.0288 - f1_m: 0.0550\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.3972 - accuracy: 0.2637 - precision_m: 0.6543 - recall_m: 0.0297 - f1_m: 0.0564\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.3841 - accuracy: 0.2647 - precision_m: 0.6655 - recall_m: 0.0319 - f1_m: 0.0604\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.3717 - accuracy: 0.2736 - precision_m: 0.6251 - recall_m: 0.0285 - f1_m: 0.0542\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.3622 - accuracy: 0.2741 - precision_m: 0.6322 - recall_m: 0.0294 - f1_m: 0.0560\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.3683 - accuracy: 0.2732 - precision_m: 0.6141 - recall_m: 0.0280 - f1_m: 0.0532\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.7%\n",
      "  Usage (max):  35.4%\n",
      "  Frequency:    4006 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.3%\n",
      "  Usage (max):  39.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  13.0%\n",
      "  Usage (max):   22.0%\n",
      "  Memory (mean): 3096 MB\n",
      "  Memory (max):  3096 MB\n",
      "  Power (mean):  40.4 W\n",
      "  Power (max):   41.0 W\n",
      "  Energy used:   0.025 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 2.5043, Acc: 25.34%\n",
      "Precision: 0.3276, Recall: 0.0229, F1: 0.0420\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 4ms/step - loss: 1.7191 - accuracy: 0.5030 - precision_m: 0.7375 - recall_m: 0.3082 - f1_m: 0.4338\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6666 - accuracy: 0.5134 - precision_m: 0.7570 - recall_m: 0.3211 - f1_m: 0.4497\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6105 - accuracy: 0.5302 - precision_m: 0.7603 - recall_m: 0.3281 - f1_m: 0.4570\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5686 - accuracy: 0.5402 - precision_m: 0.7695 - recall_m: 0.3323 - f1_m: 0.4635\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5520 - accuracy: 0.5375 - precision_m: 0.7846 - recall_m: 0.3354 - f1_m: 0.4689\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5135 - accuracy: 0.5502 - precision_m: 0.7855 - recall_m: 0.3498 - f1_m: 0.4837\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4904 - accuracy: 0.5611 - precision_m: 0.7928 - recall_m: 0.3573 - f1_m: 0.4914\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4586 - accuracy: 0.5629 - precision_m: 0.8153 - recall_m: 0.3601 - f1_m: 0.4980\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4409 - accuracy: 0.5734 - precision_m: 0.8107 - recall_m: 0.3677 - f1_m: 0.5051\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4190 - accuracy: 0.5797 - precision_m: 0.8171 - recall_m: 0.3627 - f1_m: 0.5001\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 21.4%\n",
      "  Usage (max):  27.8%\n",
      "  Frequency:    3608 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.2%\n",
      "  Usage (max):  39.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  15.5%\n",
      "  Usage (max):   29.0%\n",
      "  Memory (mean): 3102 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  41.5 W\n",
      "  Power (max):   43.8 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.7311, Acc: 49.88%\n",
      "Precision: 0.7045, Recall: 0.3252, F1: 0.4403\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.8877 - accuracy: 0.4345 - precision_m: 0.7162 - recall_m: 0.1716 - f1_m: 0.2763\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8426 - accuracy: 0.4637 - precision_m: 0.7335 - recall_m: 0.1848 - f1_m: 0.2945\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8158 - accuracy: 0.4632 - precision_m: 0.7348 - recall_m: 0.1973 - f1_m: 0.3100\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7862 - accuracy: 0.4688 - precision_m: 0.7400 - recall_m: 0.1996 - f1_m: 0.3135\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7751 - accuracy: 0.4683 - precision_m: 0.7366 - recall_m: 0.1999 - f1_m: 0.3139\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7508 - accuracy: 0.4752 - precision_m: 0.7513 - recall_m: 0.2054 - f1_m: 0.3222\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7420 - accuracy: 0.4743 - precision_m: 0.7398 - recall_m: 0.2039 - f1_m: 0.3189\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7236 - accuracy: 0.4789 - precision_m: 0.7561 - recall_m: 0.2070 - f1_m: 0.3243\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6989 - accuracy: 0.4882 - precision_m: 0.7534 - recall_m: 0.2188 - f1_m: 0.3384\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6878 - accuracy: 0.4910 - precision_m: 0.7588 - recall_m: 0.2171 - f1_m: 0.3370\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.8%\n",
      "  Usage (max):  34.2%\n",
      "  Frequency:    3403 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.6%\n",
      "  Usage (max):  39.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  15.0%\n",
      "  Usage (max):   30.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  42.1 W\n",
      "  Power (max):   44.1 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.9701, Acc: 41.81%\n",
      "Precision: 0.6664, Recall: 0.1911, F1: 0.2914\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 2.6384 - accuracy: 0.1939 - precision_m: 0.2059 - recall_m: 0.0018 - f1_m: 0.0036       \n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.6184 - accuracy: 0.2115 - precision_m: 0.2843 - recall_m: 0.0032 - f1_m: 0.0063\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.6025 - accuracy: 0.2148 - precision_m: 0.3431 - recall_m: 0.0037 - f1_m: 0.0073        \n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5917 - accuracy: 0.2055 - precision_m: 0.2843 - recall_m: 0.0041 - f1_m: 0.0081\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5836 - accuracy: 0.2101 - precision_m: 0.2353 - recall_m: 0.0039 - f1_m: 0.0077\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5807 - accuracy: 0.2125 - precision_m: 0.3824 - recall_m: 0.0056 - f1_m: 0.0111\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5681 - accuracy: 0.2069 - precision_m: 0.4412 - recall_m: 0.0055 - f1_m: 0.0109\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5665 - accuracy: 0.2120 - precision_m: 0.4020 - recall_m: 0.0046 - f1_m: 0.0091\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5668 - accuracy: 0.2069 - precision_m: 0.3725 - recall_m: 0.0056 - f1_m: 0.0111        \n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5523 - accuracy: 0.2157 - precision_m: 0.2745 - recall_m: 0.0039 - f1_m: 0.0077        \n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.5%\n",
      "  Usage (max):  26.0%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.4%\n",
      "  Usage (max):  39.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  20.5%\n",
      "  Usage (max):   27.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  41.6 W\n",
      "  Power (max):   43.1 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 2.6664, Acc: 18.91%\n",
      "Precision: 0.1031, Recall: 0.0060, F1: 0.0111\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 2.6292 - accuracy: 0.1904 - precision_m: 0.2353 - recall_m: 0.0037 - f1_m: 0.0072       \n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.6156 - accuracy: 0.1946 - precision_m: 0.2353 - recall_m: 0.0034 - f1_m: 0.0067        \n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.6025 - accuracy: 0.1997 - precision_m: 0.3824 - recall_m: 0.0039 - f1_m: 0.0077\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5901 - accuracy: 0.2030 - precision_m: 0.3431 - recall_m: 0.0037 - f1_m: 0.0073        \n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5846 - accuracy: 0.1997 - precision_m: 0.1961 - recall_m: 0.0032 - f1_m: 0.0063\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5773 - accuracy: 0.2058 - precision_m: 0.2451 - recall_m: 0.0028 - f1_m: 0.0054\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5711 - accuracy: 0.2067 - precision_m: 0.2941 - recall_m: 0.0028 - f1_m: 0.0055        \n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5703 - accuracy: 0.2039 - precision_m: 0.2451 - recall_m: 0.0034 - f1_m: 0.0067        \n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5638 - accuracy: 0.2053 - precision_m: 0.2941 - recall_m: 0.0034 - f1_m: 0.0067        \n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5548 - accuracy: 0.2138 - precision_m: 0.2941 - recall_m: 0.0032 - f1_m: 0.0064        \n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.1%\n",
      "  Usage (max):  27.8%\n",
      "  Frequency:    3999 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.5%\n",
      "  Usage (max):  39.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  18.0%\n",
      "  Usage (max):   35.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  42.0 W\n",
      "  Power (max):   44.6 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 2.6821, Acc: 18.50%\n",
      "Precision: 0.1178, Recall: 0.0050, F1: 0.0095\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 2.0332 - accuracy: 0.3924 - precision_m: 0.6530 - recall_m: 0.1518 - f1_m: 0.2456\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.9883 - accuracy: 0.3993 - precision_m: 0.6583 - recall_m: 0.1580 - f1_m: 0.2537\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.9549 - accuracy: 0.4077 - precision_m: 0.6575 - recall_m: 0.1628 - f1_m: 0.2599\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.9268 - accuracy: 0.4152 - precision_m: 0.6632 - recall_m: 0.1585 - f1_m: 0.2545\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.9026 - accuracy: 0.4161 - precision_m: 0.6785 - recall_m: 0.1651 - f1_m: 0.2649\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8825 - accuracy: 0.4157 - precision_m: 0.6771 - recall_m: 0.1686 - f1_m: 0.2691\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8748 - accuracy: 0.4236 - precision_m: 0.6773 - recall_m: 0.1709 - f1_m: 0.2719\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8563 - accuracy: 0.4292 - precision_m: 0.6910 - recall_m: 0.1695 - f1_m: 0.2712\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8316 - accuracy: 0.4343 - precision_m: 0.6968 - recall_m: 0.1716 - f1_m: 0.2746\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8190 - accuracy: 0.4408 - precision_m: 0.6896 - recall_m: 0.1794 - f1_m: 0.2841\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 26.4%\n",
      "  Usage (max):  31.2%\n",
      "  Frequency:    3800 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.0%\n",
      "  Usage (max):  40.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  17.5%\n",
      "  Usage (max):   27.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  41.3 W\n",
      "  Power (max):   42.6 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 2.0376, Acc: 39.22%\n",
      "Precision: 0.6556, Recall: 0.1561, F1: 0.2460\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.8823 - accuracy: 0.4415 - precision_m: 0.6824 - recall_m: 0.2168 - f1_m: 0.3282\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8291 - accuracy: 0.4619 - precision_m: 0.6815 - recall_m: 0.2350 - f1_m: 0.3480\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8005 - accuracy: 0.4715 - precision_m: 0.7020 - recall_m: 0.2469 - f1_m: 0.3641\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7703 - accuracy: 0.4805 - precision_m: 0.6964 - recall_m: 0.2477 - f1_m: 0.3649\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7391 - accuracy: 0.4872 - precision_m: 0.6988 - recall_m: 0.2466 - f1_m: 0.3631\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7182 - accuracy: 0.4910 - precision_m: 0.7141 - recall_m: 0.2612 - f1_m: 0.3813\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6904 - accuracy: 0.4957 - precision_m: 0.7234 - recall_m: 0.2655 - f1_m: 0.3871\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6705 - accuracy: 0.5000 - precision_m: 0.7287 - recall_m: 0.2610 - f1_m: 0.3837\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6589 - accuracy: 0.5067 - precision_m: 0.7282 - recall_m: 0.2706 - f1_m: 0.3939\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6323 - accuracy: 0.5162 - precision_m: 0.7316 - recall_m: 0.2645 - f1_m: 0.3870\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.6%\n",
      "  Usage (max):  32.1%\n",
      "  Frequency:    3405 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 39.8%\n",
      "  Usage (max):  40.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  15.0%\n",
      "  Usage (max):   27.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  42.7 W\n",
      "  Power (max):   46.0 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.9569, Acc: 42.62%\n",
      "Precision: 0.6736, Recall: 0.2303, F1: 0.3387\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.8516 - accuracy: 0.4606 - precision_m: 0.7150 - recall_m: 0.2626 - f1_m: 0.3831\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8032 - accuracy: 0.4721 - precision_m: 0.7370 - recall_m: 0.2722 - f1_m: 0.3969\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7616 - accuracy: 0.4712 - precision_m: 0.7407 - recall_m: 0.2795 - f1_m: 0.4052\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7161 - accuracy: 0.4836 - precision_m: 0.7727 - recall_m: 0.2884 - f1_m: 0.4189\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6898 - accuracy: 0.4933 - precision_m: 0.7567 - recall_m: 0.2902 - f1_m: 0.4184\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6699 - accuracy: 0.4961 - precision_m: 0.7760 - recall_m: 0.2914 - f1_m: 0.4220\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6433 - accuracy: 0.5025 - precision_m: 0.7750 - recall_m: 0.2952 - f1_m: 0.4264\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6198 - accuracy: 0.5094 - precision_m: 0.7736 - recall_m: 0.2910 - f1_m: 0.4222\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5947 - accuracy: 0.5177 - precision_m: 0.8004 - recall_m: 0.3025 - f1_m: 0.4381\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5776 - accuracy: 0.5182 - precision_m: 0.7983 - recall_m: 0.3067 - f1_m: 0.4423\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 28.7%\n",
      "  Usage (max):  36.7%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.1%\n",
      "  Usage (max):  40.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  17.5%\n",
      "  Usage (max):   27.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  42.6 W\n",
      "  Power (max):   44.5 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.8602, Acc: 45.87%\n",
      "Precision: 0.6877, Recall: 0.2677, F1: 0.3795\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.8832 - accuracy: 0.4383 - precision_m: 0.6975 - recall_m: 0.2146 - f1_m: 0.3268\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8219 - accuracy: 0.4532 - precision_m: 0.7030 - recall_m: 0.2205 - f1_m: 0.3348\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.7947 - accuracy: 0.4620 - precision_m: 0.7128 - recall_m: 0.2200 - f1_m: 0.3358\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.7653 - accuracy: 0.4680 - precision_m: 0.7153 - recall_m: 0.2247 - f1_m: 0.3409\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7500 - accuracy: 0.4759 - precision_m: 0.7230 - recall_m: 0.2244 - f1_m: 0.3417\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7252 - accuracy: 0.4828 - precision_m: 0.7315 - recall_m: 0.2369 - f1_m: 0.3567\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7179 - accuracy: 0.4745 - precision_m: 0.7254 - recall_m: 0.2334 - f1_m: 0.3518\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7009 - accuracy: 0.4833 - precision_m: 0.7353 - recall_m: 0.2328 - f1_m: 0.3529\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6857 - accuracy: 0.4954 - precision_m: 0.7300 - recall_m: 0.2402 - f1_m: 0.3606\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6607 - accuracy: 0.4958 - precision_m: 0.7488 - recall_m: 0.2434 - f1_m: 0.3667\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 21.4%\n",
      "  Usage (max):  30.4%\n",
      "  Frequency:    2401 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.3%\n",
      "  Usage (max):  40.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  15.7%\n",
      "  Usage (max):   25.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  41.5 W\n",
      "  Power (max):   45.1 W\n",
      "  Energy used:   0.026 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.9303, Acc: 44.28%\n",
      "Precision: 0.6802, Recall: 0.2301, F1: 0.3388\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_1\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.8591 - accuracy: 0.4582 - precision_m: 0.6934 - recall_m: 0.2306 - f1_m: 0.3447\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8106 - accuracy: 0.4653 - precision_m: 0.7111 - recall_m: 0.2407 - f1_m: 0.3592\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7771 - accuracy: 0.4734 - precision_m: 0.7180 - recall_m: 0.2428 - f1_m: 0.3617\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7516 - accuracy: 0.4843 - precision_m: 0.7348 - recall_m: 0.2486 - f1_m: 0.3705\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7262 - accuracy: 0.4891 - precision_m: 0.7257 - recall_m: 0.2587 - f1_m: 0.3804\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7033 - accuracy: 0.4957 - precision_m: 0.7387 - recall_m: 0.2597 - f1_m: 0.3835\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6711 - accuracy: 0.4967 - precision_m: 0.7424 - recall_m: 0.2672 - f1_m: 0.3914\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6482 - accuracy: 0.5147 - precision_m: 0.7562 - recall_m: 0.2729 - f1_m: 0.3996\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6334 - accuracy: 0.5095 - precision_m: 0.7585 - recall_m: 0.2797 - f1_m: 0.4077\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6196 - accuracy: 0.5124 - precision_m: 0.7604 - recall_m: 0.2780 - f1_m: 0.4061\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.6%\n",
      "  Usage (max):  32.1%\n",
      "  Frequency:    3000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.4%\n",
      "  Usage (max):  40.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  15.0%\n",
      "  Usage (max):   30.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  42.0 W\n",
      "  Power (max):   44.7 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.8931, Acc: 45.01%\n",
      "Precision: 0.6953, Recall: 0.2444, F1: 0.3557\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_1_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_1_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_1\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  37.15% ± 11.07%\n",
      "  Precision: 0.5312 ± 0.2352\n",
      "  Recall:    0.1679 ± 0.1108\n",
      "  F1 Score:  0.2453 ± 0.1548\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING RESOURCE USAGE SUMMARY: model_1\n",
      "================================================================================\n",
      "\n",
      "Total fine-tuning time: 13.3 seconds (0.2 minutes)\n",
      "Average CPU usage: 24.3%\n",
      "Average RAM usage: 39.8%\n",
      "Average GPU usage: 16.3%\n",
      "Average GPU power: 41.8 W\n",
      "Total energy consumed: 0.154 Wh (0.000154 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: model_1 - BEFORE vs AFTER FINE-TUNING\n",
      "====================================================================================================\n",
      "\n",
      "Metric               Before (Test)        After (Fine-tuned)   Improvement         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy             36.85%               37.15%               +0.29%              \n",
      "Precision            0.5362               0.5312               -0.0050             \n",
      "Recall               0.1586               0.1679               +0.0093             \n",
      "F1 Score             0.2353               0.2453               +0.0100             \n",
      "====================================================================================================\n",
      "\n",
      "ENERGY COMPARISON:\n",
      "  Training energy:    12.713 Wh\n",
      "  Fine-tuning energy: 0.154 Wh\n",
      "  Total energy:       12.867 Wh\n",
      "\n",
      "\n",
      "Fine-tuning model_2...\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_2 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_2\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.2028 - accuracy: 0.6578 - precision_m: 0.7767 - recall_m: 0.5783 - f1_m: 0.6626\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1018 - accuracy: 0.6706 - precision_m: 0.7912 - recall_m: 0.5827 - f1_m: 0.6706\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9787 - accuracy: 0.7089 - precision_m: 0.8328 - recall_m: 0.6161 - f1_m: 0.7079\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9012 - accuracy: 0.7292 - precision_m: 0.8551 - recall_m: 0.6372 - f1_m: 0.7300\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8336 - accuracy: 0.7434 - precision_m: 0.8605 - recall_m: 0.6565 - f1_m: 0.7444\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7809 - accuracy: 0.7656 - precision_m: 0.8878 - recall_m: 0.6669 - f1_m: 0.7613\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7231 - accuracy: 0.7826 - precision_m: 0.9041 - recall_m: 0.6896 - f1_m: 0.7820\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.8053 - precision_m: 0.9125 - recall_m: 0.7069 - f1_m: 0.7962\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.8105 - precision_m: 0.9192 - recall_m: 0.7224 - f1_m: 0.8086\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.8228 - precision_m: 0.9349 - recall_m: 0.7358 - f1_m: 0.8231\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.5%\n",
      "  Usage (max):  32.5%\n",
      "  Frequency:    3471 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.4%\n",
      "  Usage (max):  40.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  10.0%\n",
      "  Usage (max):   27.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  46.5 W\n",
      "  Power (max):   57.7 W\n",
      "  Energy used:   0.029 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.3212, Acc: 64.18%\n",
      "Precision: 0.7465, Recall: 0.5712, F1: 0.6453\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_2_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_2\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 4ms/step - loss: 1.5565 - accuracy: 0.5411 - precision_m: 0.7487 - recall_m: 0.3855 - f1_m: 0.5086\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4777 - accuracy: 0.5616 - precision_m: 0.7680 - recall_m: 0.4000 - f1_m: 0.5252\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.4335 - accuracy: 0.5756 - precision_m: 0.7682 - recall_m: 0.4072 - f1_m: 0.5313\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3556 - accuracy: 0.5938 - precision_m: 0.8027 - recall_m: 0.4256 - f1_m: 0.5555\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.3212 - accuracy: 0.6025 - precision_m: 0.7944 - recall_m: 0.4271 - f1_m: 0.5544\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2940 - accuracy: 0.6079 - precision_m: 0.8154 - recall_m: 0.4315 - f1_m: 0.5631\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2584 - accuracy: 0.6284 - precision_m: 0.8218 - recall_m: 0.4511 - f1_m: 0.5814\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2273 - accuracy: 0.6297 - precision_m: 0.8216 - recall_m: 0.4608 - f1_m: 0.5889\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2023 - accuracy: 0.6352 - precision_m: 0.8242 - recall_m: 0.4490 - f1_m: 0.5795\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1853 - accuracy: 0.6456 - precision_m: 0.8476 - recall_m: 0.4708 - f1_m: 0.6046\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 26.5%\n",
      "  Usage (max):  36.7%\n",
      "  Frequency:    3206 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.6%\n",
      "  Usage (max):  40.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  20.0%\n",
      "  Usage (max):   38.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  43.8 W\n",
      "  Power (max):   48.2 W\n",
      "  Energy used:   0.014 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.6141, Acc: 53.30%\n",
      "Precision: 0.7143, Recall: 0.3905, F1: 0.5006\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_2_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_2\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.4956 - accuracy: 0.5516 - precision_m: 0.7322 - recall_m: 0.3898 - f1_m: 0.5079\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.4010 - accuracy: 0.5683 - precision_m: 0.7679 - recall_m: 0.4065 - f1_m: 0.5307\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3517 - accuracy: 0.5868 - precision_m: 0.7800 - recall_m: 0.4214 - f1_m: 0.5466\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2917 - accuracy: 0.6043 - precision_m: 0.7965 - recall_m: 0.4349 - f1_m: 0.5619\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2453 - accuracy: 0.6201 - precision_m: 0.8154 - recall_m: 0.4400 - f1_m: 0.5700\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2065 - accuracy: 0.6298 - precision_m: 0.8202 - recall_m: 0.4587 - f1_m: 0.5874\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1774 - accuracy: 0.6340 - precision_m: 0.8210 - recall_m: 0.4594 - f1_m: 0.5884\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1582 - accuracy: 0.6437 - precision_m: 0.8254 - recall_m: 0.4642 - f1_m: 0.5938\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1183 - accuracy: 0.6580 - precision_m: 0.8446 - recall_m: 0.4710 - f1_m: 0.6036\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1022 - accuracy: 0.6640 - precision_m: 0.8443 - recall_m: 0.4846 - f1_m: 0.6150\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 29.4%\n",
      "  Usage (max):  32.9%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.5%\n",
      "  Usage (max):  40.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  22.0%\n",
      "  Usage (max):   39.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  44.2 W\n",
      "  Power (max):   48.9 W\n",
      "  Energy used:   0.014 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.5723, Acc: 54.46%\n",
      "Precision: 0.7188, Recall: 0.4081, F1: 0.5168\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_2_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_2\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.9071 - accuracy: 0.4110 - precision_m: 0.6743 - recall_m: 0.1818 - f1_m: 0.2855\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8490 - accuracy: 0.4277 - precision_m: 0.6818 - recall_m: 0.1907 - f1_m: 0.2965\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8086 - accuracy: 0.4328 - precision_m: 0.6767 - recall_m: 0.1933 - f1_m: 0.3000\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7758 - accuracy: 0.4430 - precision_m: 0.7049 - recall_m: 0.1982 - f1_m: 0.3085\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7495 - accuracy: 0.4510 - precision_m: 0.7122 - recall_m: 0.1946 - f1_m: 0.3052\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7278 - accuracy: 0.4603 - precision_m: 0.7124 - recall_m: 0.1956 - f1_m: 0.3055\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.7133 - accuracy: 0.4603 - precision_m: 0.7111 - recall_m: 0.2035 - f1_m: 0.3157\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.6849 - accuracy: 0.4686 - precision_m: 0.7497 - recall_m: 0.2094 - f1_m: 0.3261\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6681 - accuracy: 0.4635 - precision_m: 0.7370 - recall_m: 0.2073 - f1_m: 0.3225\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6370 - accuracy: 0.4747 - precision_m: 0.7608 - recall_m: 0.2153 - f1_m: 0.3345\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 27.5%\n",
      "  Usage (max):  38.7%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.8%\n",
      "  Usage (max):  40.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  18.0%\n",
      "  Usage (max):   36.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  44.5 W\n",
      "  Power (max):   49.0 W\n",
      "  Energy used:   0.014 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.9413, Acc: 41.91%\n",
      "Precision: 0.6704, Recall: 0.2010, F1: 0.3041\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_2_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_2\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.5198 - accuracy: 0.5463 - precision_m: 0.7187 - recall_m: 0.3967 - f1_m: 0.5106\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.4507 - accuracy: 0.5585 - precision_m: 0.7407 - recall_m: 0.4049 - f1_m: 0.5225\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.5706 - precision_m: 0.7458 - recall_m: 0.4092 - f1_m: 0.5278\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3735 - accuracy: 0.5861 - precision_m: 0.7700 - recall_m: 0.4285 - f1_m: 0.5500\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3156 - accuracy: 0.5931 - precision_m: 0.7757 - recall_m: 0.4280 - f1_m: 0.5505\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.2631 - accuracy: 0.6151 - precision_m: 0.8002 - recall_m: 0.4439 - f1_m: 0.5700\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2282 - accuracy: 0.6151 - precision_m: 0.8019 - recall_m: 0.4508 - f1_m: 0.5761\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2009 - accuracy: 0.6277 - precision_m: 0.8174 - recall_m: 0.4642 - f1_m: 0.5916\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1756 - accuracy: 0.6342 - precision_m: 0.8135 - recall_m: 0.4678 - f1_m: 0.5930\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1473 - accuracy: 0.6413 - precision_m: 0.8295 - recall_m: 0.4787 - f1_m: 0.6065\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 21.9%\n",
      "  Usage (max):  32.1%\n",
      "  Frequency:    3389 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.8%\n",
      "  Usage (max):  40.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  23.5%\n",
      "  Usage (max):   33.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  42.0 W\n",
      "  Power (max):   44.4 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.5786, Acc: 53.57%\n",
      "Precision: 0.7081, Recall: 0.3952, F1: 0.5035\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_2_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_2\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.4205 - accuracy: 0.6062 - precision_m: 0.7449 - recall_m: 0.5021 - f1_m: 0.5995\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2820 - accuracy: 0.6281 - precision_m: 0.7717 - recall_m: 0.5171 - f1_m: 0.6185\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1954 - accuracy: 0.6594 - precision_m: 0.7945 - recall_m: 0.5230 - f1_m: 0.6305\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1319 - accuracy: 0.6710 - precision_m: 0.8201 - recall_m: 0.5425 - f1_m: 0.6523\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0785 - accuracy: 0.6817 - precision_m: 0.8225 - recall_m: 0.5530 - f1_m: 0.6608\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0118 - accuracy: 0.6966 - precision_m: 0.8508 - recall_m: 0.5750 - f1_m: 0.6858\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9709 - accuracy: 0.7102 - precision_m: 0.8641 - recall_m: 0.5835 - f1_m: 0.6961\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9311 - accuracy: 0.7279 - precision_m: 0.8766 - recall_m: 0.6013 - f1_m: 0.7129\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9001 - accuracy: 0.7400 - precision_m: 0.8875 - recall_m: 0.6123 - f1_m: 0.7240\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8741 - accuracy: 0.7549 - precision_m: 0.8939 - recall_m: 0.6210 - f1_m: 0.7325\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.1%\n",
      "  Usage (max):  34.9%\n",
      "  Frequency:    3214 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.6%\n",
      "  Usage (max):  40.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  16.5%\n",
      "  Usage (max):   33.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  43.2 W\n",
      "  Power (max):   46.9 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.3857, Acc: 60.96%\n",
      "Precision: 0.7466, Recall: 0.5038, F1: 0.5989\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_2_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_2\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.7451 - accuracy: 0.4971 - precision_m: 0.7159 - recall_m: 0.2923 - f1_m: 0.4139\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6846 - accuracy: 0.5171 - precision_m: 0.7364 - recall_m: 0.3102 - f1_m: 0.4357\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6371 - accuracy: 0.5224 - precision_m: 0.7346 - recall_m: 0.3220 - f1_m: 0.4465\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6092 - accuracy: 0.5285 - precision_m: 0.7501 - recall_m: 0.3219 - f1_m: 0.4487\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5663 - accuracy: 0.5452 - precision_m: 0.7520 - recall_m: 0.3245 - f1_m: 0.4520\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.5383 - accuracy: 0.5509 - precision_m: 0.7679 - recall_m: 0.3299 - f1_m: 0.4602\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5072 - accuracy: 0.5561 - precision_m: 0.7675 - recall_m: 0.3384 - f1_m: 0.4686\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.4825 - accuracy: 0.5585 - precision_m: 0.7928 - recall_m: 0.3424 - f1_m: 0.4776\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.4639 - accuracy: 0.5680 - precision_m: 0.7992 - recall_m: 0.3496 - f1_m: 0.4851\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.4335 - accuracy: 0.5780 - precision_m: 0.8029 - recall_m: 0.3551 - f1_m: 0.4911\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.9%\n",
      "  Usage (max):  32.5%\n",
      "  Frequency:    3011 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.6%\n",
      "  Usage (max):  40.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  16.5%\n",
      "  Usage (max):   33.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  42.8 W\n",
      "  Power (max):   46.1 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.7729, Acc: 47.91%\n",
      "Precision: 0.6889, Recall: 0.2975, F1: 0.4098\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_2_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_2\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.2941 - accuracy: 0.6435 - precision_m: 0.7680 - recall_m: 0.5324 - f1_m: 0.6284\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1598 - accuracy: 0.6647 - precision_m: 0.8200 - recall_m: 0.5557 - f1_m: 0.6619\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0598 - accuracy: 0.6914 - precision_m: 0.8415 - recall_m: 0.5735 - f1_m: 0.6816\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9776 - accuracy: 0.7149 - precision_m: 0.8623 - recall_m: 0.5974 - f1_m: 0.7056\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9185 - accuracy: 0.7342 - precision_m: 0.8758 - recall_m: 0.6099 - f1_m: 0.7184\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8648 - accuracy: 0.7494 - precision_m: 0.8894 - recall_m: 0.6278 - f1_m: 0.7354\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8192 - accuracy: 0.7660 - precision_m: 0.9060 - recall_m: 0.6440 - f1_m: 0.7526\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7658 - accuracy: 0.7886 - precision_m: 0.9218 - recall_m: 0.6637 - f1_m: 0.7712\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7263 - accuracy: 0.8006 - precision_m: 0.9243 - recall_m: 0.6724 - f1_m: 0.7779\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.8102 - precision_m: 0.9318 - recall_m: 0.6876 - f1_m: 0.7906\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 27.6%\n",
      "  Usage (max):  36.3%\n",
      "  Frequency:    3800 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.6%\n",
      "  Usage (max):  40.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  16.5%\n",
      "  Usage (max):   33.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  43.4 W\n",
      "  Power (max):   46.5 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.3153, Acc: 63.16%\n",
      "Precision: 0.7574, Recall: 0.5394, F1: 0.6275\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_2_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_2\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 1.3061 - accuracy: 0.6215 - precision_m: 0.7696 - recall_m: 0.5249 - f1_m: 0.6239\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2085 - accuracy: 0.6503 - precision_m: 0.7997 - recall_m: 0.5359 - f1_m: 0.6412\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1406 - accuracy: 0.6637 - precision_m: 0.8119 - recall_m: 0.5446 - f1_m: 0.6516\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0899 - accuracy: 0.6725 - precision_m: 0.8162 - recall_m: 0.5570 - f1_m: 0.6619\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0247 - accuracy: 0.6981 - precision_m: 0.8517 - recall_m: 0.5778 - f1_m: 0.6878\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9677 - accuracy: 0.7171 - precision_m: 0.8572 - recall_m: 0.5961 - f1_m: 0.7022\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9269 - accuracy: 0.7356 - precision_m: 0.8664 - recall_m: 0.6082 - f1_m: 0.7144\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8885 - accuracy: 0.7384 - precision_m: 0.8819 - recall_m: 0.6186 - f1_m: 0.7265\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8551 - accuracy: 0.7509 - precision_m: 0.8904 - recall_m: 0.6305 - f1_m: 0.7375\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8255 - accuracy: 0.7648 - precision_m: 0.8976 - recall_m: 0.6401 - f1_m: 0.7468\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.3 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 18.1%\n",
      "  Usage (max):  33.3%\n",
      "  Frequency:    2269 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.7%\n",
      "  Usage (max):  40.9%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  9.7%\n",
      "  Usage (max):   27.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  43.2 W\n",
      "  Power (max):   48.9 W\n",
      "  Energy used:   0.027 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.3740, Acc: 60.95%\n",
      "Precision: 0.7507, Recall: 0.5156, F1: 0.6082\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_2_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_2\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.3487 - accuracy: 0.6117 - precision_m: 0.7517 - recall_m: 0.5008 - f1_m: 0.6007\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2607 - accuracy: 0.6407 - precision_m: 0.7881 - recall_m: 0.5202 - f1_m: 0.6263\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1761 - accuracy: 0.6568 - precision_m: 0.8120 - recall_m: 0.5330 - f1_m: 0.6430\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0945 - accuracy: 0.6744 - precision_m: 0.8303 - recall_m: 0.5602 - f1_m: 0.6686\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0575 - accuracy: 0.6939 - precision_m: 0.8426 - recall_m: 0.5649 - f1_m: 0.6756\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9910 - accuracy: 0.7120 - precision_m: 0.8576 - recall_m: 0.5880 - f1_m: 0.6972\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9515 - accuracy: 0.7267 - precision_m: 0.8725 - recall_m: 0.5973 - f1_m: 0.7088\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9170 - accuracy: 0.7410 - precision_m: 0.8785 - recall_m: 0.6100 - f1_m: 0.7197\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8759 - accuracy: 0.7476 - precision_m: 0.8894 - recall_m: 0.6267 - f1_m: 0.7349\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8425 - accuracy: 0.7652 - precision_m: 0.8951 - recall_m: 0.6383 - f1_m: 0.7448\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.7%\n",
      "  Usage (max):  35.8%\n",
      "  Frequency:    3414 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.8%\n",
      "  Usage (max):  40.9%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  17.5%\n",
      "  Usage (max):   35.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  43.5 W\n",
      "  Power (max):   46.8 W\n",
      "  Energy used:   0.013 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.4198, Acc: 60.12%\n",
      "Precision: 0.7384, Recall: 0.4915, F1: 0.5876\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_2_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_2_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_2\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  56.05% ± 6.81%\n",
      "  Precision: 0.7240 ± 0.0274\n",
      "  Recall:    0.4314 ± 0.1103\n",
      "  F1 Score:  0.5302 ± 0.1021\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING RESOURCE USAGE SUMMARY: model_2\n",
      "================================================================================\n",
      "\n",
      "Total fine-tuning time: 13.4 seconds (0.2 minutes)\n",
      "Average CPU usage: 24.4%\n",
      "Average RAM usage: 40.6%\n",
      "Average GPU usage: 17.0%\n",
      "Average GPU power: 43.7 W\n",
      "Total energy consumed: 0.163 Wh (0.000163 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: model_2 - BEFORE vs AFTER FINE-TUNING\n",
      "====================================================================================================\n",
      "\n",
      "Metric               Before (Test)        After (Fine-tuned)   Improvement         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy             55.86%               56.05%               +0.19%              \n",
      "Precision            0.7305               0.7240               -0.0065             \n",
      "Recall               0.4193               0.4314               +0.0121             \n",
      "F1 Score             0.5212               0.5302               +0.0090             \n",
      "====================================================================================================\n",
      "\n",
      "ENERGY COMPARISON:\n",
      "  Training energy:    11.688 Wh\n",
      "  Fine-tuning energy: 0.163 Wh\n",
      "  Total energy:       11.851 Wh\n",
      "\n",
      "\n",
      "Fine-tuning model_3...\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_3 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_3\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 0.9372 - accuracy: 0.7448 - precision_m: 0.8370 - recall_m: 0.6904 - f1_m: 0.7565\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8449 - accuracy: 0.7467 - precision_m: 0.8290 - recall_m: 0.6852 - f1_m: 0.7500\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.7817 - precision_m: 0.8782 - recall_m: 0.7075 - f1_m: 0.7831\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.7977 - precision_m: 0.8837 - recall_m: 0.7331 - f1_m: 0.8010\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.8275 - precision_m: 0.8997 - recall_m: 0.7541 - f1_m: 0.8203\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.8228 - precision_m: 0.8954 - recall_m: 0.7659 - f1_m: 0.8253\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.8422 - precision_m: 0.9097 - recall_m: 0.7794 - f1_m: 0.8391\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8526 - precision_m: 0.9174 - recall_m: 0.8041 - f1_m: 0.8569\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.8563 - precision_m: 0.9160 - recall_m: 0.7927 - f1_m: 0.8496\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8625 - precision_m: 0.9220 - recall_m: 0.8164 - f1_m: 0.8657\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 11.9%\n",
      "  Usage (max):  12.5%\n",
      "  Frequency:    2025 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.8%\n",
      "  Usage (max):  40.9%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  11.0%\n",
      "  Usage (max):   25.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  43.1 W\n",
      "  Power (max):   47.4 W\n",
      "  Energy used:   0.026 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6373, Acc: 82.17%\n",
      "Precision: 0.8789, Recall: 0.7839, F1: 0.8278\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_3_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_3\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 5ms/step - loss: 0.9365 - accuracy: 0.7438 - precision_m: 0.8223 - recall_m: 0.6937 - f1_m: 0.7521\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8353 - accuracy: 0.7524 - precision_m: 0.8401 - recall_m: 0.6901 - f1_m: 0.7574\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7428 - accuracy: 0.7837 - precision_m: 0.8701 - recall_m: 0.7127 - f1_m: 0.7829\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.8060 - precision_m: 0.8831 - recall_m: 0.7414 - f1_m: 0.8058\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.8174 - precision_m: 0.8970 - recall_m: 0.7591 - f1_m: 0.8220\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.8128 - precision_m: 0.8828 - recall_m: 0.7561 - f1_m: 0.8145\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.8319 - precision_m: 0.9023 - recall_m: 0.7744 - f1_m: 0.8332\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.8437 - precision_m: 0.9025 - recall_m: 0.7862 - f1_m: 0.8401\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.8428 - precision_m: 0.9048 - recall_m: 0.7947 - f1_m: 0.8458\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.8614 - precision_m: 0.9184 - recall_m: 0.8153 - f1_m: 0.8637\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 27.7%\n",
      "  Usage (max):  36.7%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.7%\n",
      "  Usage (max):  40.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  12.0%\n",
      "  Usage (max):   23.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  51.6 W\n",
      "  Power (max):   62.1 W\n",
      "  Energy used:   0.032 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6397, Acc: 81.70%\n",
      "Precision: 0.8741, Recall: 0.7848, F1: 0.8260\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_3_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_3\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 0.9064 - accuracy: 0.7450 - precision_m: 0.8209 - recall_m: 0.6846 - f1_m: 0.7464\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8098 - accuracy: 0.7635 - precision_m: 0.8378 - recall_m: 0.6934 - f1_m: 0.7583\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7093 - accuracy: 0.7871 - precision_m: 0.8710 - recall_m: 0.7243 - f1_m: 0.7907\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.8033 - precision_m: 0.8818 - recall_m: 0.7404 - f1_m: 0.8048\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.8070 - precision_m: 0.8826 - recall_m: 0.7599 - f1_m: 0.8163\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.8325 - precision_m: 0.9016 - recall_m: 0.7703 - f1_m: 0.8305\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8320 - precision_m: 0.8993 - recall_m: 0.7812 - f1_m: 0.8358\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8478 - precision_m: 0.9066 - recall_m: 0.7912 - f1_m: 0.8446\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8602 - precision_m: 0.9062 - recall_m: 0.8036 - f1_m: 0.8516\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8565 - precision_m: 0.9090 - recall_m: 0.8145 - f1_m: 0.8590\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.6%\n",
      "  Usage (max):  28.7%\n",
      "  Frequency:    3333 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 40.7%\n",
      "  Usage (max):  40.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  9.0%\n",
      "  Usage (max):   22.0%\n",
      "  Memory (mean): 3108 MB\n",
      "  Memory (max):  3108 MB\n",
      "  Power (mean):  54.9 W\n",
      "  Power (max):   64.8 W\n",
      "  Energy used:   0.034 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6081, Acc: 82.58%\n",
      "Precision: 0.8794, Recall: 0.7932, F1: 0.8332\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_3_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_3\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 1.0015 - accuracy: 0.7104 - precision_m: 0.7985 - recall_m: 0.6580 - f1_m: 0.7212\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8361 - accuracy: 0.7480 - precision_m: 0.8472 - recall_m: 0.6821 - f1_m: 0.7553\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.7750 - precision_m: 0.8606 - recall_m: 0.7036 - f1_m: 0.7739\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7030 - accuracy: 0.7782 - precision_m: 0.8639 - recall_m: 0.7157 - f1_m: 0.7825\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.8020 - precision_m: 0.8828 - recall_m: 0.7301 - f1_m: 0.7988\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.8052 - precision_m: 0.8881 - recall_m: 0.7439 - f1_m: 0.8094\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.8229 - precision_m: 0.8926 - recall_m: 0.7581 - f1_m: 0.8198\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.8289 - precision_m: 0.9040 - recall_m: 0.7589 - f1_m: 0.8248\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.8508 - precision_m: 0.9145 - recall_m: 0.7886 - f1_m: 0.8467\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8526 - precision_m: 0.9146 - recall_m: 0.7959 - f1_m: 0.8508\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 20.9%\n",
      "  Usage (max):  27.2%\n",
      "  Frequency:    3600 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.1%\n",
      "  Usage (max):  41.2%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  6.7%\n",
      "  Usage (max):   18.0%\n",
      "  Memory (mean): 3110 MB\n",
      "  Memory (max):  3110 MB\n",
      "  Power (mean):  59.8 W\n",
      "  Power (max):   74.4 W\n",
      "  Energy used:   0.037 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6498, Acc: 81.30%\n",
      "Precision: 0.8738, Recall: 0.7760, F1: 0.8210\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_3_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_3\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 0.8736 - accuracy: 0.7343 - precision_m: 0.8232 - recall_m: 0.6743 - f1_m: 0.7410\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7943 - accuracy: 0.7521 - precision_m: 0.8460 - recall_m: 0.6850 - f1_m: 0.7567\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6972 - accuracy: 0.7797 - precision_m: 0.8686 - recall_m: 0.7107 - f1_m: 0.7814\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7881 - precision_m: 0.8673 - recall_m: 0.7247 - f1_m: 0.7893\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.8167 - precision_m: 0.8936 - recall_m: 0.7530 - f1_m: 0.8170\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.8129 - precision_m: 0.8844 - recall_m: 0.7596 - f1_m: 0.8170\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.8321 - precision_m: 0.9010 - recall_m: 0.7739 - f1_m: 0.8324\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.8447 - precision_m: 0.9044 - recall_m: 0.7931 - f1_m: 0.8447\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.8508 - precision_m: 0.9093 - recall_m: 0.7885 - f1_m: 0.8443\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8630 - precision_m: 0.9170 - recall_m: 0.8166 - f1_m: 0.8637\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 20.1%\n",
      "  Usage (max):  29.5%\n",
      "  Frequency:    3482 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.3%\n",
      "  Usage (max):  41.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  6.3%\n",
      "  Usage (max):   18.0%\n",
      "  Memory (mean): 3103 MB\n",
      "  Memory (max):  3104 MB\n",
      "  Power (mean):  59.7 W\n",
      "  Power (max):   74.8 W\n",
      "  Energy used:   0.037 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6489, Acc: 81.54%\n",
      "Precision: 0.8775, Recall: 0.7821, F1: 0.8259\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_3_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_3\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 0.9403 - accuracy: 0.7428 - precision_m: 0.8179 - recall_m: 0.6893 - f1_m: 0.7479\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8314 - accuracy: 0.7586 - precision_m: 0.8465 - recall_m: 0.6977 - f1_m: 0.7646\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.7842 - precision_m: 0.8662 - recall_m: 0.7251 - f1_m: 0.7891\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.7964 - precision_m: 0.8759 - recall_m: 0.7345 - f1_m: 0.7985\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8122 - precision_m: 0.8907 - recall_m: 0.7540 - f1_m: 0.8164\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.8206 - precision_m: 0.8949 - recall_m: 0.7709 - f1_m: 0.8281\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.8336 - precision_m: 0.9069 - recall_m: 0.7757 - f1_m: 0.8359\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8504 - precision_m: 0.9139 - recall_m: 0.8023 - f1_m: 0.8542\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.8583 - precision_m: 0.9114 - recall_m: 0.8088 - f1_m: 0.8569\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8597 - precision_m: 0.9101 - recall_m: 0.8077 - f1_m: 0.8556\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 19.3%\n",
      "  Usage (max):  31.3%\n",
      "  Frequency:    2948 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.4%\n",
      "  Usage (max):  41.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  15.3%\n",
      "  Usage (max):   27.0%\n",
      "  Memory (mean): 3104 MB\n",
      "  Memory (max):  3104 MB\n",
      "  Power (mean):  55.5 W\n",
      "  Power (max):   64.1 W\n",
      "  Energy used:   0.034 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6045, Acc: 83.10%\n",
      "Precision: 0.8832, Recall: 0.7984, F1: 0.8379\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_3_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_3\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 0.9595 - accuracy: 0.7355 - precision_m: 0.8215 - recall_m: 0.6783 - f1_m: 0.7428\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8435 - accuracy: 0.7483 - precision_m: 0.8349 - recall_m: 0.6910 - f1_m: 0.7560\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7635 - accuracy: 0.7802 - precision_m: 0.8613 - recall_m: 0.7053 - f1_m: 0.7752\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7069 - accuracy: 0.7788 - precision_m: 0.8738 - recall_m: 0.7245 - f1_m: 0.7919\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.7921 - precision_m: 0.8758 - recall_m: 0.7383 - f1_m: 0.8007\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.8159 - precision_m: 0.8887 - recall_m: 0.7551 - f1_m: 0.8162\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.8354 - precision_m: 0.9026 - recall_m: 0.7706 - f1_m: 0.8313\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.8402 - precision_m: 0.9123 - recall_m: 0.7860 - f1_m: 0.8441\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.8435 - precision_m: 0.9130 - recall_m: 0.8002 - f1_m: 0.8526\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.8573 - precision_m: 0.9164 - recall_m: 0.7978 - f1_m: 0.8528\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 21.9%\n",
      "  Usage (max):  28.4%\n",
      "  Frequency:    3200 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.6%\n",
      "  Usage (max):  41.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  7.3%\n",
      "  Usage (max):   18.0%\n",
      "  Memory (mean): 3103 MB\n",
      "  Memory (max):  3104 MB\n",
      "  Power (mean):  57.9 W\n",
      "  Power (max):   70.0 W\n",
      "  Energy used:   0.036 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6425, Acc: 82.30%\n",
      "Precision: 0.8779, Recall: 0.7922, F1: 0.8320\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_3_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_3\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 0.9980 - accuracy: 0.7370 - precision_m: 0.8115 - recall_m: 0.6803 - f1_m: 0.7397\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8347 - accuracy: 0.7600 - precision_m: 0.8446 - recall_m: 0.6900 - f1_m: 0.7593\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7794 - precision_m: 0.8651 - recall_m: 0.7121 - f1_m: 0.7809\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7129 - accuracy: 0.7923 - precision_m: 0.8664 - recall_m: 0.7184 - f1_m: 0.7852\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.8010 - precision_m: 0.8754 - recall_m: 0.7324 - f1_m: 0.7972\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.8222 - precision_m: 0.8907 - recall_m: 0.7628 - f1_m: 0.8216\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.8319 - precision_m: 0.8899 - recall_m: 0.7687 - f1_m: 0.8246\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.8397 - precision_m: 0.9000 - recall_m: 0.7877 - f1_m: 0.8400\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8443 - precision_m: 0.9109 - recall_m: 0.7923 - f1_m: 0.8472\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.8448 - precision_m: 0.9040 - recall_m: 0.8019 - f1_m: 0.8497\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.4%\n",
      "  Usage (max):  34.6%\n",
      "  Frequency:    3881 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.6%\n",
      "  Usage (max):  41.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  4.0%\n",
      "  Usage (max):   7.0%\n",
      "  Memory (mean): 3102 MB\n",
      "  Memory (max):  3102 MB\n",
      "  Power (mean):  52.6 W\n",
      "  Power (max):   54.1 W\n",
      "  Energy used:   0.033 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6638, Acc: 80.93%\n",
      "Precision: 0.8642, Recall: 0.7727, F1: 0.8148\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_3_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_3\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 0.9758 - accuracy: 0.7361 - precision_m: 0.8155 - recall_m: 0.6858 - f1_m: 0.7446\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8268 - accuracy: 0.7519 - precision_m: 0.8396 - recall_m: 0.6968 - f1_m: 0.7613\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7523 - accuracy: 0.7732 - precision_m: 0.8592 - recall_m: 0.7087 - f1_m: 0.7765\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.8043 - precision_m: 0.8796 - recall_m: 0.7375 - f1_m: 0.8020\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.8182 - precision_m: 0.8953 - recall_m: 0.7542 - f1_m: 0.8184\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.8340 - precision_m: 0.8963 - recall_m: 0.7759 - f1_m: 0.8316\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.8358 - precision_m: 0.9075 - recall_m: 0.7876 - f1_m: 0.8430\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.8349 - precision_m: 0.9099 - recall_m: 0.7829 - f1_m: 0.8414\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8530 - precision_m: 0.9154 - recall_m: 0.8071 - f1_m: 0.8576\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8664 - precision_m: 0.9100 - recall_m: 0.8131 - f1_m: 0.8584\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 20.5%\n",
      "  Usage (max):  22.5%\n",
      "  Frequency:    3601 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.2%\n",
      "  Usage (max):  41.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  7.7%\n",
      "  Usage (max):   17.0%\n",
      "  Memory (mean): 3102 MB\n",
      "  Memory (max):  3102 MB\n",
      "  Power (mean):  58.3 W\n",
      "  Power (max):   69.5 W\n",
      "  Energy used:   0.036 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6179, Acc: 82.37%\n",
      "Precision: 0.8833, Recall: 0.7929, F1: 0.8346\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_3_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_3\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 0.9278 - accuracy: 0.7462 - precision_m: 0.8199 - recall_m: 0.6979 - f1_m: 0.7537\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7932 - accuracy: 0.7790 - precision_m: 0.8605 - recall_m: 0.7154 - f1_m: 0.7810\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.8028 - precision_m: 0.8720 - recall_m: 0.7392 - f1_m: 0.7998\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.8104 - precision_m: 0.8879 - recall_m: 0.7429 - f1_m: 0.8086\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.8256 - precision_m: 0.8951 - recall_m: 0.7518 - f1_m: 0.8169\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.8170 - precision_m: 0.8945 - recall_m: 0.7700 - f1_m: 0.8275\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8384 - precision_m: 0.8987 - recall_m: 0.7798 - f1_m: 0.8349\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8574 - precision_m: 0.9140 - recall_m: 0.8034 - f1_m: 0.8550\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8569 - precision_m: 0.9151 - recall_m: 0.8063 - f1_m: 0.8570\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8750 - precision_m: 0.9273 - recall_m: 0.8287 - f1_m: 0.8749\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 21.3%\n",
      "  Usage (max):  25.3%\n",
      "  Frequency:    3333 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.3%\n",
      "  Usage (max):  41.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  13.7%\n",
      "  Usage (max):   22.0%\n",
      "  Memory (mean): 3102 MB\n",
      "  Memory (max):  3102 MB\n",
      "  Power (mean):  60.1 W\n",
      "  Power (max):   75.0 W\n",
      "  Energy used:   0.037 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6191, Acc: 82.85%\n",
      "Precision: 0.8821, Recall: 0.7974, F1: 0.8368\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_3_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_3_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_3\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  82.08% ± 0.66%\n",
      "  Precision: 0.8774 ± 0.0054\n",
      "  Recall:    0.7874 ± 0.0084\n",
      "  F1 Score:  0.8290 ± 0.0070\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING RESOURCE USAGE SUMMARY: model_3\n",
      "================================================================================\n",
      "\n",
      "Total fine-tuning time: 22.2 seconds (0.4 minutes)\n",
      "Average CPU usage: 21.1%\n",
      "Average RAM usage: 41.2%\n",
      "Average GPU usage: 9.3%\n",
      "Average GPU power: 55.3 W\n",
      "Total energy consumed: 0.342 Wh (0.000342 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: model_3 - BEFORE vs AFTER FINE-TUNING\n",
      "====================================================================================================\n",
      "\n",
      "Metric               Before (Test)        After (Fine-tuned)   Improvement         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy             81.10%               82.08%               +0.98%              \n",
      "Precision            0.8747               0.8774               +0.0027             \n",
      "Recall               0.7731               0.7874               +0.0143             \n",
      "F1 Score             0.8196               0.8290               +0.0094             \n",
      "====================================================================================================\n",
      "\n",
      "ENERGY COMPARISON:\n",
      "  Training energy:    13.231 Wh\n",
      "  Fine-tuning energy: 0.342 Wh\n",
      "  Total energy:       13.573 Wh\n",
      "\n",
      "\n",
      "Fine-tuning model_4...\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_4 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_4\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.1775 - accuracy: 0.6512 - precision_m: 0.7894 - recall_m: 0.5583 - f1_m: 0.6536\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0273 - accuracy: 0.6871 - precision_m: 0.8270 - recall_m: 0.5959 - f1_m: 0.6924\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9008 - accuracy: 0.7264 - precision_m: 0.8599 - recall_m: 0.6296 - f1_m: 0.7267\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8314 - accuracy: 0.7495 - precision_m: 0.8782 - recall_m: 0.6508 - f1_m: 0.7473\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7546 - accuracy: 0.7802 - precision_m: 0.9028 - recall_m: 0.6844 - f1_m: 0.7778\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.7996 - precision_m: 0.9084 - recall_m: 0.7005 - f1_m: 0.7906\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.8171 - precision_m: 0.9298 - recall_m: 0.7216 - f1_m: 0.8120\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.8336 - precision_m: 0.9363 - recall_m: 0.7395 - f1_m: 0.8261\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.8601 - precision_m: 0.9426 - recall_m: 0.7667 - f1_m: 0.8453\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.8625 - precision_m: 0.9545 - recall_m: 0.7848 - f1_m: 0.8610\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.7%\n",
      "  Usage (max):  26.6%\n",
      "  Frequency:    3600 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.2%\n",
      "  Usage (max):  41.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  16.0%\n",
      "  Usage (max):   30.0%\n",
      "  Memory (mean): 3102 MB\n",
      "  Memory (max):  3102 MB\n",
      "  Power (mean):  58.9 W\n",
      "  Power (max):   66.6 W\n",
      "  Energy used:   0.036 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.2543, Acc: 65.59%\n",
      "Precision: 0.7685, Recall: 0.5859, F1: 0.6626\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_4_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_4\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 4ms/step - loss: 1.1995 - accuracy: 0.6552 - precision_m: 0.7752 - recall_m: 0.5745 - f1_m: 0.6597\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.0463 - accuracy: 0.6883 - precision_m: 0.8135 - recall_m: 0.6199 - f1_m: 0.7029\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9170 - accuracy: 0.7274 - precision_m: 0.8452 - recall_m: 0.6366 - f1_m: 0.7259\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8319 - accuracy: 0.7537 - precision_m: 0.8689 - recall_m: 0.6720 - f1_m: 0.7573\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7514 - accuracy: 0.7851 - precision_m: 0.8895 - recall_m: 0.6897 - f1_m: 0.7766\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.8033 - precision_m: 0.9113 - recall_m: 0.7101 - f1_m: 0.7975\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.8137 - precision_m: 0.9077 - recall_m: 0.7262 - f1_m: 0.8067\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.8260 - precision_m: 0.9225 - recall_m: 0.7455 - f1_m: 0.8243\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.8496 - precision_m: 0.9355 - recall_m: 0.7734 - f1_m: 0.8461\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.8596 - precision_m: 0.9522 - recall_m: 0.7776 - f1_m: 0.8557\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.8%\n",
      "  Usage (max):  34.6%\n",
      "  Frequency:    3422 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.2%\n",
      "  Usage (max):  41.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  22.0%\n",
      "  Usage (max):   38.0%\n",
      "  Memory (mean): 3102 MB\n",
      "  Memory (max):  3102 MB\n",
      "  Power (mean):  57.7 W\n",
      "  Power (max):   64.7 W\n",
      "  Energy used:   0.018 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.3146, Acc: 65.16%\n",
      "Precision: 0.7505, Recall: 0.5791, F1: 0.6519\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_4_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_4\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 1.1891 - accuracy: 0.6590 - precision_m: 0.7674 - recall_m: 0.5791 - f1_m: 0.6596\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0249 - accuracy: 0.6969 - precision_m: 0.8158 - recall_m: 0.6153 - f1_m: 0.7011\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9096 - accuracy: 0.7233 - precision_m: 0.8511 - recall_m: 0.6312 - f1_m: 0.7245\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8321 - accuracy: 0.7497 - precision_m: 0.8742 - recall_m: 0.6552 - f1_m: 0.7488\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7932 - accuracy: 0.7719 - precision_m: 0.8846 - recall_m: 0.6728 - f1_m: 0.7640\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7291 - accuracy: 0.7820 - precision_m: 0.8988 - recall_m: 0.6928 - f1_m: 0.7821\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.8038 - precision_m: 0.9083 - recall_m: 0.7054 - f1_m: 0.7937\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.8255 - precision_m: 0.9220 - recall_m: 0.7267 - f1_m: 0.8123\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.8413 - precision_m: 0.9292 - recall_m: 0.7431 - f1_m: 0.8254\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.8533 - precision_m: 0.9430 - recall_m: 0.7615 - f1_m: 0.8423\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.0%\n",
      "  Usage (max):  34.2%\n",
      "  Frequency:    3207 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.4%\n",
      "  Usage (max):  41.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  18.0%\n",
      "  Usage (max):   35.0%\n",
      "  Memory (mean): 3102 MB\n",
      "  Memory (max):  3102 MB\n",
      "  Power (mean):  60.2 W\n",
      "  Power (max):   68.4 W\n",
      "  Energy used:   0.019 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.2642, Acc: 65.06%\n",
      "Precision: 0.7625, Recall: 0.5792, F1: 0.6563\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_4_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_4\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 1.0551 - accuracy: 0.7053 - precision_m: 0.7947 - recall_m: 0.6348 - f1_m: 0.7053\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8712 - accuracy: 0.7378 - precision_m: 0.8341 - recall_m: 0.6585 - f1_m: 0.7357\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7519 - accuracy: 0.7778 - precision_m: 0.8835 - recall_m: 0.6985 - f1_m: 0.7795\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.8136 - precision_m: 0.9057 - recall_m: 0.7284 - f1_m: 0.8070\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.8457 - precision_m: 0.9269 - recall_m: 0.7665 - f1_m: 0.8387\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8694 - precision_m: 0.9427 - recall_m: 0.7878 - f1_m: 0.8580\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8884 - precision_m: 0.9573 - recall_m: 0.8214 - f1_m: 0.8837\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.9014 - precision_m: 0.9663 - recall_m: 0.8368 - f1_m: 0.8967\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.9117 - precision_m: 0.9656 - recall_m: 0.8512 - f1_m: 0.9044\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.9261 - precision_m: 0.9726 - recall_m: 0.8677 - f1_m: 0.9170\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.9%\n",
      "  Usage (max):  35.4%\n",
      "  Frequency:    3806 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.4%\n",
      "  Usage (max):  41.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  26.0%\n",
      "  Usage (max):   38.0%\n",
      "  Memory (mean): 3102 MB\n",
      "  Memory (max):  3102 MB\n",
      "  Power (mean):  62.3 W\n",
      "  Power (max):   73.8 W\n",
      "  Energy used:   0.019 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.1618, Acc: 68.75%\n",
      "Precision: 0.7742, Recall: 0.6338, F1: 0.6955\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_4_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_4\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.1401 - accuracy: 0.6562 - precision_m: 0.7703 - recall_m: 0.5945 - f1_m: 0.6706\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9743 - accuracy: 0.6941 - precision_m: 0.8081 - recall_m: 0.6114 - f1_m: 0.6959\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8728 - accuracy: 0.7254 - precision_m: 0.8354 - recall_m: 0.6417 - f1_m: 0.7255\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7755 - accuracy: 0.7535 - precision_m: 0.8691 - recall_m: 0.6765 - f1_m: 0.7603\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.7764 - precision_m: 0.8836 - recall_m: 0.6884 - f1_m: 0.7736\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.8036 - precision_m: 0.9072 - recall_m: 0.7194 - f1_m: 0.8021\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.8237 - precision_m: 0.9140 - recall_m: 0.7397 - f1_m: 0.8172\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.8461 - precision_m: 0.9339 - recall_m: 0.7724 - f1_m: 0.8454\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8527 - precision_m: 0.9412 - recall_m: 0.7882 - f1_m: 0.8576\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.8714 - precision_m: 0.9424 - recall_m: 0.7877 - f1_m: 0.8578\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.8%\n",
      "  Usage (max):  34.6%\n",
      "  Frequency:    3803 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.4%\n",
      "  Usage (max):  41.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  20.0%\n",
      "  Usage (max):   40.0%\n",
      "  Memory (mean): 3102 MB\n",
      "  Memory (max):  3102 MB\n",
      "  Power (mean):  63.3 W\n",
      "  Power (max):   75.7 W\n",
      "  Energy used:   0.019 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.1948, Acc: 66.73%\n",
      "Precision: 0.7645, Recall: 0.6008, F1: 0.6713\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_4_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_4\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 1.2072 - accuracy: 0.6654 - precision_m: 0.7646 - recall_m: 0.5882 - f1_m: 0.6642\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9970 - accuracy: 0.7074 - precision_m: 0.8166 - recall_m: 0.6289 - f1_m: 0.7102\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8626 - accuracy: 0.7460 - precision_m: 0.8433 - recall_m: 0.6643 - f1_m: 0.7426\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7641 - accuracy: 0.7731 - precision_m: 0.8789 - recall_m: 0.6846 - f1_m: 0.7693\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.8015 - precision_m: 0.8947 - recall_m: 0.7164 - f1_m: 0.7953\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.8215 - precision_m: 0.9157 - recall_m: 0.7343 - f1_m: 0.8147\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.8350 - precision_m: 0.9238 - recall_m: 0.7517 - f1_m: 0.8287\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.8555 - precision_m: 0.9392 - recall_m: 0.7743 - f1_m: 0.8483\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.8705 - precision_m: 0.9512 - recall_m: 0.7998 - f1_m: 0.8686\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.8826 - precision_m: 0.9530 - recall_m: 0.8121 - f1_m: 0.8767\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.5%\n",
      "  Usage (max):  31.6%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.5%\n",
      "  Usage (max):  41.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  26.5%\n",
      "  Usage (max):   41.0%\n",
      "  Memory (mean): 3102 MB\n",
      "  Memory (max):  3102 MB\n",
      "  Power (mean):  64.3 W\n",
      "  Power (max):   76.5 W\n",
      "  Energy used:   0.020 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.2134, Acc: 67.33%\n",
      "Precision: 0.7688, Recall: 0.6122, F1: 0.6800\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_4_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_4\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.2118 - accuracy: 0.6660 - precision_m: 0.7770 - recall_m: 0.5732 - f1_m: 0.6592\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0777 - accuracy: 0.6912 - precision_m: 0.8144 - recall_m: 0.5886 - f1_m: 0.6830\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9777 - accuracy: 0.7022 - precision_m: 0.8345 - recall_m: 0.5950 - f1_m: 0.6940\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8839 - accuracy: 0.7402 - precision_m: 0.8662 - recall_m: 0.6344 - f1_m: 0.7318\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8125 - accuracy: 0.7588 - precision_m: 0.8877 - recall_m: 0.6491 - f1_m: 0.7494\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.7845 - precision_m: 0.9097 - recall_m: 0.6803 - f1_m: 0.7780\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.8021 - precision_m: 0.9095 - recall_m: 0.6832 - f1_m: 0.7798\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.8145 - precision_m: 0.9224 - recall_m: 0.7083 - f1_m: 0.8009\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.8354 - precision_m: 0.9386 - recall_m: 0.7269 - f1_m: 0.8189\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.8478 - precision_m: 0.9393 - recall_m: 0.7443 - f1_m: 0.8301\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.9%\n",
      "  Usage (max):  31.7%\n",
      "  Frequency:    4003 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.5%\n",
      "  Usage (max):  41.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  25.5%\n",
      "  Usage (max):   43.0%\n",
      "  Memory (mean): 3103 MB\n",
      "  Memory (max):  3104 MB\n",
      "  Power (mean):  58.9 W\n",
      "  Power (max):   65.8 W\n",
      "  Energy used:   0.018 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.2541, Acc: 64.88%\n",
      "Precision: 0.7735, Recall: 0.5689, F1: 0.6534\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_4_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_4\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 1.1812 - accuracy: 0.6610 - precision_m: 0.7800 - recall_m: 0.5782 - f1_m: 0.6634\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0421 - accuracy: 0.6946 - precision_m: 0.8329 - recall_m: 0.5989 - f1_m: 0.6962\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9253 - accuracy: 0.7241 - precision_m: 0.8623 - recall_m: 0.6290 - f1_m: 0.7268\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8261 - accuracy: 0.7522 - precision_m: 0.8858 - recall_m: 0.6545 - f1_m: 0.7525\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7621 - accuracy: 0.7646 - precision_m: 0.8981 - recall_m: 0.6712 - f1_m: 0.7680\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.8010 - precision_m: 0.9150 - recall_m: 0.7098 - f1_m: 0.7989\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.8185 - precision_m: 0.9288 - recall_m: 0.7135 - f1_m: 0.8065\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.8406 - precision_m: 0.9403 - recall_m: 0.7417 - f1_m: 0.8290\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.8600 - precision_m: 0.9536 - recall_m: 0.7602 - f1_m: 0.8456\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8696 - precision_m: 0.9627 - recall_m: 0.7836 - f1_m: 0.8636\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 30.1%\n",
      "  Usage (max):  41.8%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.0%\n",
      "  Usage (max):  42.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  20.5%\n",
      "  Usage (max):   41.0%\n",
      "  Memory (mean): 3104 MB\n",
      "  Memory (max):  3104 MB\n",
      "  Power (mean):  63.7 W\n",
      "  Power (max):   76.5 W\n",
      "  Energy used:   0.020 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.2375, Acc: 65.92%\n",
      "Precision: 0.7750, Recall: 0.5840, F1: 0.6641\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_4_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_4\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 1.1174 - accuracy: 0.6814 - precision_m: 0.7934 - recall_m: 0.5960 - f1_m: 0.6800\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9762 - accuracy: 0.7096 - precision_m: 0.8377 - recall_m: 0.6176 - f1_m: 0.7105\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8676 - accuracy: 0.7449 - precision_m: 0.8569 - recall_m: 0.6514 - f1_m: 0.7397\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7676 - accuracy: 0.7820 - precision_m: 0.8949 - recall_m: 0.6850 - f1_m: 0.7758\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.8033 - precision_m: 0.9119 - recall_m: 0.7091 - f1_m: 0.7975\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.8205 - precision_m: 0.9258 - recall_m: 0.7248 - f1_m: 0.8128\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.8395 - precision_m: 0.9319 - recall_m: 0.7548 - f1_m: 0.8337\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.8558 - precision_m: 0.9523 - recall_m: 0.7736 - f1_m: 0.8535\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.8780 - precision_m: 0.9543 - recall_m: 0.7928 - f1_m: 0.8657\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.8896 - precision_m: 0.9555 - recall_m: 0.8074 - f1_m: 0.8750\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 19.7%\n",
      "  Usage (max):  26.9%\n",
      "  Frequency:    3603 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.7%\n",
      "  Usage (max):  41.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  9.0%\n",
      "  Usage (max):   21.0%\n",
      "  Memory (mean): 3096 MB\n",
      "  Memory (max):  3096 MB\n",
      "  Power (mean):  60.4 W\n",
      "  Power (max):   72.6 W\n",
      "  Energy used:   0.037 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.2242, Acc: 66.80%\n",
      "Precision: 0.7753, Recall: 0.5956, F1: 0.6715\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_4_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_4\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 1.3304 - accuracy: 0.6174 - precision_m: 0.7662 - recall_m: 0.5102 - f1_m: 0.6121\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.2208 - accuracy: 0.6445 - precision_m: 0.7996 - recall_m: 0.5243 - f1_m: 0.6330\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1237 - accuracy: 0.6630 - precision_m: 0.8227 - recall_m: 0.5433 - f1_m: 0.6539\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0373 - accuracy: 0.6835 - precision_m: 0.8429 - recall_m: 0.5611 - f1_m: 0.6735\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9969 - accuracy: 0.7091 - precision_m: 0.8628 - recall_m: 0.5771 - f1_m: 0.6909\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9197 - accuracy: 0.7272 - precision_m: 0.8729 - recall_m: 0.5995 - f1_m: 0.7102\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8725 - accuracy: 0.7448 - precision_m: 0.8896 - recall_m: 0.6148 - f1_m: 0.7267\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8198 - accuracy: 0.7619 - precision_m: 0.9024 - recall_m: 0.6366 - f1_m: 0.7461\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7859 - accuracy: 0.7704 - precision_m: 0.9075 - recall_m: 0.6515 - f1_m: 0.7580\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7524 - accuracy: 0.7790 - precision_m: 0.9182 - recall_m: 0.6683 - f1_m: 0.7726\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 1.1 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.0%\n",
      "  Usage (max):  33.8%\n",
      "  Frequency:    3413 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.4%\n",
      "  Usage (max):  41.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  17.0%\n",
      "  Usage (max):   32.0%\n",
      "  Memory (mean): 3096 MB\n",
      "  Memory (max):  3096 MB\n",
      "  Power (mean):  54.3 W\n",
      "  Power (max):   57.7 W\n",
      "  Energy used:   0.017 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 1.3782, Acc: 61.12%\n",
      "Precision: 0.7430, Recall: 0.5100, F1: 0.6023\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_4_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_4_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_4\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  65.74% ± 1.92%\n",
      "  Precision: 0.7656 ± 0.0104\n",
      "  Recall:    0.5849 ± 0.0307\n",
      "  F1 Score:  0.6609 ± 0.0232\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING RESOURCE USAGE SUMMARY: model_4\n",
      "================================================================================\n",
      "\n",
      "Total fine-tuning time: 13.3 seconds (0.2 minutes)\n",
      "Average CPU usage: 24.5%\n",
      "Average RAM usage: 41.5%\n",
      "Average GPU usage: 20.1%\n",
      "Average GPU power: 60.4 W\n",
      "Total energy consumed: 0.223 Wh (0.000223 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: model_4 - BEFORE vs AFTER FINE-TUNING\n",
      "====================================================================================================\n",
      "\n",
      "Metric               Before (Test)        After (Fine-tuned)   Improvement         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy             64.45%               65.74%               +1.28%              \n",
      "Precision            0.7647               0.7656               +0.0009             \n",
      "Recall               0.5648               0.5849               +0.0201             \n",
      "F1 Score             0.6471               0.6609               +0.0138             \n",
      "====================================================================================================\n",
      "\n",
      "ENERGY COMPARISON:\n",
      "  Training energy:    11.156 Wh\n",
      "  Fine-tuning energy: 0.223 Wh\n",
      "  Total energy:       11.379 Wh\n",
      "\n",
      "\n",
      "Fine-tuning model_5...\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_5 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_5\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.7317 - accuracy: 0.7911 - precision_m: 0.8403 - recall_m: 0.7617 - f1_m: 0.7989\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.8247 - precision_m: 0.8834 - recall_m: 0.7889 - f1_m: 0.8333\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8620 - precision_m: 0.9210 - recall_m: 0.8291 - f1_m: 0.8725\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8922 - precision_m: 0.9406 - recall_m: 0.8571 - f1_m: 0.8968\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.9216 - precision_m: 0.9667 - recall_m: 0.8914 - f1_m: 0.9274\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2294 - accuracy: 0.9400 - precision_m: 0.9774 - recall_m: 0.9169 - f1_m: 0.9460\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1905 - accuracy: 0.9570 - precision_m: 0.9826 - recall_m: 0.9340 - f1_m: 0.9575\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9660 - precision_m: 0.9867 - recall_m: 0.9479 - f1_m: 0.9668\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.9783 - precision_m: 0.9929 - recall_m: 0.9624 - f1_m: 0.9774\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9806 - precision_m: 0.9953 - recall_m: 0.9688 - f1_m: 0.9818\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 27.5%\n",
      "  Usage (max):  41.6%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.5%\n",
      "  Usage (max):  41.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  6.3%\n",
      "  Usage (max):   10.0%\n",
      "  Memory (mean): 3110 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  50.2 W\n",
      "  Power (max):   51.8 W\n",
      "  Energy used:   0.031 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.7837, Acc: 79.87%\n",
      "Precision: 0.8394, Recall: 0.7785, F1: 0.8073\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_5_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_5\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 3ms/step - loss: 0.7211 - accuracy: 0.7860 - precision_m: 0.8446 - recall_m: 0.7401 - f1_m: 0.7886\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.8274 - precision_m: 0.8894 - recall_m: 0.7780 - f1_m: 0.8296\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8569 - precision_m: 0.9194 - recall_m: 0.8106 - f1_m: 0.8612\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8841 - precision_m: 0.9377 - recall_m: 0.8309 - f1_m: 0.8810\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.9014 - precision_m: 0.9516 - recall_m: 0.8556 - f1_m: 0.9009\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.9237 - precision_m: 0.9653 - recall_m: 0.8835 - f1_m: 0.9225\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.9373 - precision_m: 0.9735 - recall_m: 0.9105 - f1_m: 0.9408\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9537 - precision_m: 0.9816 - recall_m: 0.9265 - f1_m: 0.9532\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9605 - precision_m: 0.9877 - recall_m: 0.9347 - f1_m: 0.9603\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9691 - precision_m: 0.9918 - recall_m: 0.9466 - f1_m: 0.9686\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.4%\n",
      "  Usage (max):  34.6%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.8%\n",
      "  Usage (max):  42.2%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  5.7%\n",
      "  Usage (max):   16.0%\n",
      "  Memory (mean): 3117 MB\n",
      "  Memory (max):  3117 MB\n",
      "  Power (mean):  55.9 W\n",
      "  Power (max):   67.2 W\n",
      "  Energy used:   0.034 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.8194, Acc: 78.46%\n",
      "Precision: 0.8324, Recall: 0.7556, F1: 0.7914\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_5_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_5\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.7124 - accuracy: 0.7834 - precision_m: 0.8416 - recall_m: 0.7453 - f1_m: 0.7903\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.8334 - precision_m: 0.8872 - recall_m: 0.7861 - f1_m: 0.8334\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8723 - precision_m: 0.9189 - recall_m: 0.8293 - f1_m: 0.8716\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.9010 - precision_m: 0.9454 - recall_m: 0.8626 - f1_m: 0.9020\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.9287 - precision_m: 0.9594 - recall_m: 0.8949 - f1_m: 0.9259\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9440 - precision_m: 0.9709 - recall_m: 0.9192 - f1_m: 0.9442\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.9621 - precision_m: 0.9787 - recall_m: 0.9350 - f1_m: 0.9563\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9699 - precision_m: 0.9851 - recall_m: 0.9490 - f1_m: 0.9666\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9755 - precision_m: 0.9900 - recall_m: 0.9608 - f1_m: 0.9751\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9820 - precision_m: 0.9929 - recall_m: 0.9699 - f1_m: 0.9812\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 31.4%\n",
      "  Usage (max):  42.5%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.0%\n",
      "  Usage (max):  42.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  9.0%\n",
      "  Usage (max):   19.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  56.2 W\n",
      "  Power (max):   66.8 W\n",
      "  Energy used:   0.035 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.7767, Acc: 79.34%\n",
      "Precision: 0.8377, Recall: 0.7685, F1: 0.8010\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_5_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_5\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.6790 - accuracy: 0.8131 - precision_m: 0.8640 - recall_m: 0.7840 - f1_m: 0.8219\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.8484 - precision_m: 0.9057 - recall_m: 0.8123 - f1_m: 0.8564\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8745 - precision_m: 0.9281 - recall_m: 0.8407 - f1_m: 0.8821\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.9089 - precision_m: 0.9499 - recall_m: 0.8754 - f1_m: 0.9110\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2639 - accuracy: 0.9312 - precision_m: 0.9649 - recall_m: 0.9012 - f1_m: 0.9319\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9447 - precision_m: 0.9690 - recall_m: 0.9210 - f1_m: 0.9443\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.9530 - precision_m: 0.9797 - recall_m: 0.9324 - f1_m: 0.9553\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9661 - precision_m: 0.9847 - recall_m: 0.9510 - f1_m: 0.9675\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9726 - precision_m: 0.9883 - recall_m: 0.9621 - f1_m: 0.9750\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9791 - precision_m: 0.9928 - recall_m: 0.9707 - f1_m: 0.9816\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 29.5%\n",
      "  Usage (max):  33.8%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.4%\n",
      "  Usage (max):  42.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  11.7%\n",
      "  Usage (max):   18.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  56.3 W\n",
      "  Power (max):   67.8 W\n",
      "  Energy used:   0.035 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.8268, Acc: 79.44%\n",
      "Precision: 0.8346, Recall: 0.7744, F1: 0.8028\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_5_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_5\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.6428 - accuracy: 0.7951 - precision_m: 0.8538 - recall_m: 0.7484 - f1_m: 0.7975\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.8377 - precision_m: 0.8995 - recall_m: 0.7936 - f1_m: 0.8430\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8817 - precision_m: 0.9301 - recall_m: 0.8407 - f1_m: 0.8829\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.9107 - precision_m: 0.9513 - recall_m: 0.8710 - f1_m: 0.9093\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2430 - accuracy: 0.9341 - precision_m: 0.9672 - recall_m: 0.9021 - f1_m: 0.9334\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.9546 - precision_m: 0.9792 - recall_m: 0.9269 - f1_m: 0.9522\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1617 - accuracy: 0.9682 - precision_m: 0.9835 - recall_m: 0.9417 - f1_m: 0.9621\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9813 - precision_m: 0.9922 - recall_m: 0.9590 - f1_m: 0.9753\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9836 - precision_m: 0.9942 - recall_m: 0.9691 - f1_m: 0.9814\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9892 - precision_m: 0.9958 - recall_m: 0.9748 - f1_m: 0.9851\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.4%\n",
      "  Usage (max):  33.8%\n",
      "  Frequency:    3867 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.4%\n",
      "  Usage (max):  42.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  8.7%\n",
      "  Usage (max):   19.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  56.8 W\n",
      "  Power (max):   69.5 W\n",
      "  Energy used:   0.035 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.8126, Acc: 79.35%\n",
      "Precision: 0.8338, Recall: 0.7715, F1: 0.8009\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_5_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_5\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.7733 - accuracy: 0.7838 - precision_m: 0.8467 - recall_m: 0.7440 - f1_m: 0.7919\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.8215 - precision_m: 0.8838 - recall_m: 0.7804 - f1_m: 0.8287\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.8472 - precision_m: 0.9058 - recall_m: 0.8040 - f1_m: 0.8517\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8695 - precision_m: 0.9218 - recall_m: 0.8279 - f1_m: 0.8721\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8933 - precision_m: 0.9385 - recall_m: 0.8542 - f1_m: 0.8942\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.9101 - precision_m: 0.9522 - recall_m: 0.8689 - f1_m: 0.9084\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.9250 - precision_m: 0.9639 - recall_m: 0.8947 - f1_m: 0.9279\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2398 - accuracy: 0.9376 - precision_m: 0.9710 - recall_m: 0.9131 - f1_m: 0.9411\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9511 - precision_m: 0.9800 - recall_m: 0.9298 - f1_m: 0.9541\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.9576 - precision_m: 0.9852 - recall_m: 0.9402 - f1_m: 0.9621\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 27.8%\n",
      "  Usage (max):  38.5%\n",
      "  Frequency:    3477 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.3%\n",
      "  Usage (max):  42.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  9.7%\n",
      "  Usage (max):   22.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  56.7 W\n",
      "  Power (max):   68.4 W\n",
      "  Energy used:   0.035 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.7905, Acc: 79.41%\n",
      "Precision: 0.8416, Recall: 0.7661, F1: 0.8015\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_5_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_5\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.7369 - accuracy: 0.7959 - precision_m: 0.8466 - recall_m: 0.7673 - f1_m: 0.8049\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.8292 - precision_m: 0.8876 - recall_m: 0.7862 - f1_m: 0.8335\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8706 - precision_m: 0.9221 - recall_m: 0.8265 - f1_m: 0.8715\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.9020 - precision_m: 0.9424 - recall_m: 0.8734 - f1_m: 0.9065\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.9310 - precision_m: 0.9603 - recall_m: 0.8976 - f1_m: 0.9278\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9524 - precision_m: 0.9752 - recall_m: 0.9262 - f1_m: 0.9500\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1728 - accuracy: 0.9619 - precision_m: 0.9817 - recall_m: 0.9431 - f1_m: 0.9620\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9767 - precision_m: 0.9872 - recall_m: 0.9537 - f1_m: 0.9701\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9819 - precision_m: 0.9923 - recall_m: 0.9653 - f1_m: 0.9786\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9872 - precision_m: 0.9958 - recall_m: 0.9769 - f1_m: 0.9862\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.5%\n",
      "  Usage (max):  32.9%\n",
      "  Frequency:    3349 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.5%\n",
      "  Usage (max):  43.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  7.3%\n",
      "  Usage (max):   20.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  55.1 W\n",
      "  Power (max):   66.8 W\n",
      "  Energy used:   0.034 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.8012, Acc: 79.74%\n",
      "Precision: 0.8326, Recall: 0.7711, F1: 0.8002\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_5_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_5\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.7851 - accuracy: 0.7683 - precision_m: 0.8310 - recall_m: 0.7379 - f1_m: 0.7815\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.8135 - precision_m: 0.8736 - recall_m: 0.7583 - f1_m: 0.8117\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8632 - precision_m: 0.9190 - recall_m: 0.8171 - f1_m: 0.8648\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8862 - precision_m: 0.9387 - recall_m: 0.8457 - f1_m: 0.8897\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3188 - accuracy: 0.9139 - precision_m: 0.9582 - recall_m: 0.8762 - f1_m: 0.9152\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.9355 - precision_m: 0.9697 - recall_m: 0.9005 - f1_m: 0.9337\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2187 - accuracy: 0.9526 - precision_m: 0.9785 - recall_m: 0.9235 - f1_m: 0.9501\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9632 - precision_m: 0.9855 - recall_m: 0.9424 - f1_m: 0.9634\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9701 - precision_m: 0.9885 - recall_m: 0.9502 - f1_m: 0.9689\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9770 - precision_m: 0.9915 - recall_m: 0.9636 - f1_m: 0.9773\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.5%\n",
      "  Usage (max):  44.3%\n",
      "  Frequency:    3343 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.7%\n",
      "  Usage (max):  42.9%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  4.3%\n",
      "  Usage (max):   9.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  49.3 W\n",
      "  Power (max):   52.0 W\n",
      "  Energy used:   0.030 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.8839, Acc: 77.35%\n",
      "Precision: 0.8215, Recall: 0.7445, F1: 0.7803\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_5_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_5\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 3ms/step - loss: 0.7474 - accuracy: 0.7834 - precision_m: 0.8446 - recall_m: 0.7456 - f1_m: 0.7919\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.8302 - precision_m: 0.8882 - recall_m: 0.7795 - f1_m: 0.8301\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.8650 - precision_m: 0.9246 - recall_m: 0.8123 - f1_m: 0.8645\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8989 - precision_m: 0.9465 - recall_m: 0.8588 - f1_m: 0.9004\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.9258 - precision_m: 0.9625 - recall_m: 0.8873 - f1_m: 0.9233\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.9439 - precision_m: 0.9757 - recall_m: 0.9115 - f1_m: 0.9424\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9583 - precision_m: 0.9839 - recall_m: 0.9318 - f1_m: 0.9571\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9708 - precision_m: 0.9892 - recall_m: 0.9495 - f1_m: 0.9689\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9754 - precision_m: 0.9932 - recall_m: 0.9563 - f1_m: 0.9743\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9856 - precision_m: 0.9947 - recall_m: 0.9702 - f1_m: 0.9822\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 27.4%\n",
      "  Usage (max):  38.7%\n",
      "  Frequency:    3734 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.5%\n",
      "  Usage (max):  42.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  10.0%\n",
      "  Usage (max):   24.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  49.7 W\n",
      "  Power (max):   51.6 W\n",
      "  Energy used:   0.031 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.8013, Acc: 79.32%\n",
      "Precision: 0.8343, Recall: 0.7697, F1: 0.8000\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_5_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_5\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 3ms/step - loss: 0.7071 - accuracy: 0.7990 - precision_m: 0.8558 - recall_m: 0.7655 - f1_m: 0.8078\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.8379 - precision_m: 0.8954 - recall_m: 0.8004 - f1_m: 0.8451\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8821 - precision_m: 0.9294 - recall_m: 0.8442 - f1_m: 0.8845\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.9173 - precision_m: 0.9513 - recall_m: 0.8778 - f1_m: 0.9129\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.9363 - precision_m: 0.9665 - recall_m: 0.9047 - f1_m: 0.9345\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9529 - precision_m: 0.9755 - recall_m: 0.9277 - f1_m: 0.9509\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9625 - precision_m: 0.9836 - recall_m: 0.9400 - f1_m: 0.9612\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9743 - precision_m: 0.9890 - recall_m: 0.9570 - f1_m: 0.9727\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9800 - precision_m: 0.9929 - recall_m: 0.9636 - f1_m: 0.9779\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9857 - precision_m: 0.9938 - recall_m: 0.9725 - f1_m: 0.9830\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 21.6%\n",
      "  Usage (max):  30.4%\n",
      "  Frequency:    3360 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.8%\n",
      "  Usage (max):  43.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  8.3%\n",
      "  Usage (max):   18.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  55.2 W\n",
      "  Power (max):   68.6 W\n",
      "  Energy used:   0.034 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.8140, Acc: 79.50%\n",
      "Precision: 0.8373, Recall: 0.7723, F1: 0.8029\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_5_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_5_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_5\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  79.18% ± 0.70%\n",
      "  Precision: 0.8345 ± 0.0052\n",
      "  Recall:    0.7672 ± 0.0095\n",
      "  F1 Score:  0.7988 ± 0.0072\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING RESOURCE USAGE SUMMARY: model_5\n",
      "================================================================================\n",
      "\n",
      "Total fine-tuning time: 22.2 seconds (0.4 minutes)\n",
      "Average CPU usage: 26.5%\n",
      "Average RAM usage: 42.3%\n",
      "Average GPU usage: 8.1%\n",
      "Average GPU power: 54.1 W\n",
      "Total energy consumed: 0.333 Wh (0.000333 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: model_5 - BEFORE vs AFTER FINE-TUNING\n",
      "====================================================================================================\n",
      "\n",
      "Metric               Before (Test)        After (Fine-tuned)   Improvement         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy             78.30%               79.18%               +0.87%              \n",
      "Precision            0.8417               0.8345               -0.0072             \n",
      "Recall               0.7478               0.7672               +0.0194             \n",
      "F1 Score             0.7910               0.7988               +0.0078             \n",
      "====================================================================================================\n",
      "\n",
      "ENERGY COMPARISON:\n",
      "  Training energy:    8.271 Wh\n",
      "  Fine-tuning energy: 0.333 Wh\n",
      "  Total energy:       8.604 Wh\n",
      "\n",
      "\n",
      "Fine-tuning model_6...\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_6 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_6\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.9523 - accuracy: 0.7363 - precision_m: 0.8263 - recall_m: 0.6757 - f1_m: 0.7429\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8704 - accuracy: 0.7543 - precision_m: 0.8473 - recall_m: 0.6850 - f1_m: 0.7572\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.7713 - precision_m: 0.8678 - recall_m: 0.6927 - f1_m: 0.7699\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.7973 - precision_m: 0.8844 - recall_m: 0.7179 - f1_m: 0.7923\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.8081 - precision_m: 0.8891 - recall_m: 0.7425 - f1_m: 0.8086\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.8162 - precision_m: 0.8921 - recall_m: 0.7558 - f1_m: 0.8182\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.8327 - precision_m: 0.9029 - recall_m: 0.7704 - f1_m: 0.8311\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8341 - precision_m: 0.8977 - recall_m: 0.7851 - f1_m: 0.8373\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.8492 - precision_m: 0.9061 - recall_m: 0.7902 - f1_m: 0.8439\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.8648 - precision_m: 0.9112 - recall_m: 0.8109 - f1_m: 0.8579\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 26.4%\n",
      "  Usage (max):  34.2%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.2%\n",
      "  Usage (max):  42.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  8.3%\n",
      "  Usage (max):   18.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  55.6 W\n",
      "  Power (max):   66.6 W\n",
      "  Energy used:   0.034 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6532, Acc: 81.32%\n",
      "Precision: 0.8751, Recall: 0.7812, F1: 0.8244\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_6_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_6\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 4ms/step - loss: 0.9347 - accuracy: 0.7378 - precision_m: 0.8297 - recall_m: 0.6798 - f1_m: 0.7470\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8249 - accuracy: 0.7474 - precision_m: 0.8361 - recall_m: 0.6788 - f1_m: 0.7489\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7152 - accuracy: 0.7756 - precision_m: 0.8656 - recall_m: 0.7044 - f1_m: 0.7764\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7016 - accuracy: 0.7815 - precision_m: 0.8581 - recall_m: 0.6944 - f1_m: 0.7673\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.8092 - precision_m: 0.8888 - recall_m: 0.7471 - f1_m: 0.8115\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.8151 - precision_m: 0.8937 - recall_m: 0.7501 - f1_m: 0.8153\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.8292 - precision_m: 0.8989 - recall_m: 0.7679 - f1_m: 0.8281\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.8487 - precision_m: 0.9085 - recall_m: 0.7895 - f1_m: 0.8446\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.8419 - precision_m: 0.9135 - recall_m: 0.7892 - f1_m: 0.8465\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8578 - precision_m: 0.9138 - recall_m: 0.8053 - f1_m: 0.8560\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.9%\n",
      "  Usage (max):  33.8%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.2%\n",
      "  Usage (max):  42.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  6.3%\n",
      "  Usage (max):   18.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  56.6 W\n",
      "  Power (max):   69.0 W\n",
      "  Energy used:   0.035 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6387, Acc: 81.98%\n",
      "Precision: 0.8726, Recall: 0.7848, F1: 0.8255\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_6_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_6\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.9210 - accuracy: 0.7376 - precision_m: 0.8173 - recall_m: 0.6829 - f1_m: 0.7437\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7990 - accuracy: 0.7598 - precision_m: 0.8415 - recall_m: 0.6935 - f1_m: 0.7599\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7200 - accuracy: 0.7709 - precision_m: 0.8562 - recall_m: 0.7007 - f1_m: 0.7706\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.8019 - precision_m: 0.8781 - recall_m: 0.7343 - f1_m: 0.7995\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.8066 - precision_m: 0.8818 - recall_m: 0.7480 - f1_m: 0.8092\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.8163 - precision_m: 0.9016 - recall_m: 0.7713 - f1_m: 0.8311\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.8404 - precision_m: 0.8997 - recall_m: 0.7867 - f1_m: 0.8393\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.8404 - precision_m: 0.8957 - recall_m: 0.7875 - f1_m: 0.8379\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8630 - precision_m: 0.9165 - recall_m: 0.8067 - f1_m: 0.8580\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8704 - precision_m: 0.9217 - recall_m: 0.8272 - f1_m: 0.8716\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 32.7%\n",
      "  Usage (max):  41.2%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.7%\n",
      "  Usage (max):  43.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  6.0%\n",
      "  Usage (max):   18.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  54.3 W\n",
      "  Power (max):   62.8 W\n",
      "  Energy used:   0.034 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6154, Acc: 82.00%\n",
      "Precision: 0.8790, Recall: 0.7870, F1: 0.8296\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_6_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_6\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.8844 - accuracy: 0.7522 - precision_m: 0.8296 - recall_m: 0.6911 - f1_m: 0.7539\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7981 - accuracy: 0.7592 - precision_m: 0.8438 - recall_m: 0.6976 - f1_m: 0.7635\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7225 - accuracy: 0.7787 - precision_m: 0.8690 - recall_m: 0.7158 - f1_m: 0.7847\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.7954 - precision_m: 0.8787 - recall_m: 0.7332 - f1_m: 0.7992\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.7954 - precision_m: 0.8797 - recall_m: 0.7460 - f1_m: 0.8071\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.8215 - precision_m: 0.8975 - recall_m: 0.7648 - f1_m: 0.8256\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.8271 - precision_m: 0.9057 - recall_m: 0.7680 - f1_m: 0.8310\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.8457 - precision_m: 0.9101 - recall_m: 0.7904 - f1_m: 0.8458\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.8470 - precision_m: 0.9084 - recall_m: 0.7894 - f1_m: 0.8445\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8573 - precision_m: 0.9169 - recall_m: 0.8113 - f1_m: 0.8607\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 31.9%\n",
      "  Usage (max):  48.1%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.4%\n",
      "  Usage (max):  42.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  8.3%\n",
      "  Usage (max):   22.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  47.0 W\n",
      "  Power (max):   50.7 W\n",
      "  Energy used:   0.029 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6564, Acc: 81.35%\n",
      "Precision: 0.8678, Recall: 0.7834, F1: 0.8226\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_6_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_6\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.8469 - accuracy: 0.7493 - precision_m: 0.8259 - recall_m: 0.7091 - f1_m: 0.7630\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7595 - accuracy: 0.7788 - precision_m: 0.8607 - recall_m: 0.7268 - f1_m: 0.7878\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.8054 - precision_m: 0.8778 - recall_m: 0.7444 - f1_m: 0.8054\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.8176 - precision_m: 0.8890 - recall_m: 0.7626 - f1_m: 0.8208\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.8302 - precision_m: 0.8911 - recall_m: 0.7646 - f1_m: 0.8229\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.8466 - precision_m: 0.9029 - recall_m: 0.7959 - f1_m: 0.8459\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.8522 - precision_m: 0.9125 - recall_m: 0.8088 - f1_m: 0.8574\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8616 - precision_m: 0.9132 - recall_m: 0.8206 - f1_m: 0.8642\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8775 - precision_m: 0.9189 - recall_m: 0.8361 - f1_m: 0.8753\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8854 - precision_m: 0.9266 - recall_m: 0.8485 - f1_m: 0.8857\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.7%\n",
      "  Usage (max):  31.6%\n",
      "  Frequency:    3472 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.0%\n",
      "  Usage (max):  42.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  16.7%\n",
      "  Usage (max):   29.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  45.3 W\n",
      "  Power (max):   53.0 W\n",
      "  Energy used:   0.028 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6301, Acc: 82.80%\n",
      "Precision: 0.8749, Recall: 0.8006, F1: 0.8353\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_6_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_6\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.9002 - accuracy: 0.7339 - precision_m: 0.8145 - recall_m: 0.6743 - f1_m: 0.7376\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8164 - accuracy: 0.7521 - precision_m: 0.8450 - recall_m: 0.6759 - f1_m: 0.7508\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7552 - accuracy: 0.7656 - precision_m: 0.8559 - recall_m: 0.6867 - f1_m: 0.7615\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.7870 - precision_m: 0.8688 - recall_m: 0.7209 - f1_m: 0.7877\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.7982 - precision_m: 0.8897 - recall_m: 0.7424 - f1_m: 0.8089\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.8136 - precision_m: 0.8908 - recall_m: 0.7485 - f1_m: 0.8131\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.8229 - precision_m: 0.8993 - recall_m: 0.7613 - f1_m: 0.8242\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.8439 - precision_m: 0.9025 - recall_m: 0.7850 - f1_m: 0.8394\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.8430 - precision_m: 0.8999 - recall_m: 0.7828 - f1_m: 0.8370\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8653 - precision_m: 0.9150 - recall_m: 0.8118 - f1_m: 0.8600\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 28.1%\n",
      "  Usage (max):  36.7%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.4%\n",
      "  Usage (max):  42.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  15.7%\n",
      "  Usage (max):   26.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  46.0 W\n",
      "  Power (max):   51.3 W\n",
      "  Energy used:   0.028 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6294, Acc: 81.79%\n",
      "Precision: 0.8759, Recall: 0.7890, F1: 0.8294\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_6_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_6\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.9339 - accuracy: 0.7412 - precision_m: 0.8160 - recall_m: 0.6855 - f1_m: 0.7447\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8467 - accuracy: 0.7578 - precision_m: 0.8370 - recall_m: 0.6863 - f1_m: 0.7539\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7702 - accuracy: 0.7678 - precision_m: 0.8602 - recall_m: 0.7006 - f1_m: 0.7717\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7750 - precision_m: 0.8585 - recall_m: 0.7077 - f1_m: 0.7754\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.7992 - precision_m: 0.8756 - recall_m: 0.7279 - f1_m: 0.7947\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.8140 - precision_m: 0.8916 - recall_m: 0.7583 - f1_m: 0.8193\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.8306 - precision_m: 0.9028 - recall_m: 0.7712 - f1_m: 0.8317\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.8406 - precision_m: 0.9065 - recall_m: 0.7897 - f1_m: 0.8439\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.8530 - precision_m: 0.9184 - recall_m: 0.7968 - f1_m: 0.8530\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.8525 - precision_m: 0.9124 - recall_m: 0.7989 - f1_m: 0.8516\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.8%\n",
      "  Usage (max):  31.2%\n",
      "  Frequency:    2808 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.9%\n",
      "  Usage (max):  42.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  14.3%\n",
      "  Usage (max):   22.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  46.5 W\n",
      "  Power (max):   53.8 W\n",
      "  Energy used:   0.029 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6655, Acc: 81.78%\n",
      "Precision: 0.8796, Recall: 0.7859, F1: 0.8289\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_6_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_6\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.9578 - accuracy: 0.7305 - precision_m: 0.8215 - recall_m: 0.6702 - f1_m: 0.7379\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8485 - accuracy: 0.7379 - precision_m: 0.8456 - recall_m: 0.6586 - f1_m: 0.7400\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7264 - accuracy: 0.7789 - precision_m: 0.8718 - recall_m: 0.7025 - f1_m: 0.7776\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.7830 - precision_m: 0.8690 - recall_m: 0.7180 - f1_m: 0.7860\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.8019 - precision_m: 0.8808 - recall_m: 0.7397 - f1_m: 0.8036\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.8217 - precision_m: 0.8914 - recall_m: 0.7453 - f1_m: 0.8114\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.8254 - precision_m: 0.8932 - recall_m: 0.7651 - f1_m: 0.8240\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8415 - precision_m: 0.8994 - recall_m: 0.7849 - f1_m: 0.8381\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.8498 - precision_m: 0.9100 - recall_m: 0.7977 - f1_m: 0.8500\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8604 - precision_m: 0.9116 - recall_m: 0.8066 - f1_m: 0.8556\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.0%\n",
      "  Usage (max):  35.9%\n",
      "  Frequency:    3217 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.9%\n",
      "  Usage (max):  42.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  0.7%\n",
      "  Usage (max):   1.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  43.3 W\n",
      "  Power (max):   45.8 W\n",
      "  Energy used:   0.027 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6870, Acc: 80.68%\n",
      "Precision: 0.8667, Recall: 0.7689, F1: 0.8140\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_6_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_6\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.9461 - accuracy: 0.7421 - precision_m: 0.8180 - recall_m: 0.6788 - f1_m: 0.7416\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8208 - accuracy: 0.7556 - precision_m: 0.8445 - recall_m: 0.6962 - f1_m: 0.7630\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.7917 - precision_m: 0.8652 - recall_m: 0.7309 - f1_m: 0.7922\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.7982 - precision_m: 0.8858 - recall_m: 0.7325 - f1_m: 0.8012\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.8033 - precision_m: 0.8823 - recall_m: 0.7387 - f1_m: 0.8039\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.8353 - precision_m: 0.9027 - recall_m: 0.7707 - f1_m: 0.8314\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.8358 - precision_m: 0.9080 - recall_m: 0.7812 - f1_m: 0.8397\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8432 - precision_m: 0.9090 - recall_m: 0.7798 - f1_m: 0.8391\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8525 - precision_m: 0.9111 - recall_m: 0.8030 - f1_m: 0.8534\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8576 - precision_m: 0.9143 - recall_m: 0.8028 - f1_m: 0.8546\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 26.8%\n",
      "  Usage (max):  35.4%\n",
      "  Frequency:    3333 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.6%\n",
      "  Usage (max):  41.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  8.7%\n",
      "  Usage (max):   21.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  50.8 W\n",
      "  Power (max):   61.5 W\n",
      "  Energy used:   0.031 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6431, Acc: 82.04%\n",
      "Precision: 0.8802, Recall: 0.7887, F1: 0.8311\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_6_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_6\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 0.9441 - accuracy: 0.7467 - precision_m: 0.8133 - recall_m: 0.6901 - f1_m: 0.7464\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7915 - accuracy: 0.7666 - precision_m: 0.8556 - recall_m: 0.7123 - f1_m: 0.7767\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6988 - accuracy: 0.7918 - precision_m: 0.8772 - recall_m: 0.7308 - f1_m: 0.7971\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.7923 - precision_m: 0.8726 - recall_m: 0.7304 - f1_m: 0.7947\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.8104 - precision_m: 0.8868 - recall_m: 0.7560 - f1_m: 0.8159\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.8370 - precision_m: 0.8961 - recall_m: 0.7749 - f1_m: 0.8309\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.8370 - precision_m: 0.9008 - recall_m: 0.7853 - f1_m: 0.8388\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8441 - precision_m: 0.9024 - recall_m: 0.7983 - f1_m: 0.8470\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8508 - precision_m: 0.9068 - recall_m: 0.8025 - f1_m: 0.8513\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8721 - precision_m: 0.9229 - recall_m: 0.8256 - f1_m: 0.8715\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.7%\n",
      "  Usage (max):  34.1%\n",
      "  Frequency:    3200 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.8%\n",
      "  Usage (max):  42.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  9.7%\n",
      "  Usage (max):   18.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  48.8 W\n",
      "  Power (max):   58.4 W\n",
      "  Energy used:   0.030 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.6381, Acc: 82.07%\n",
      "Precision: 0.8768, Recall: 0.7906, F1: 0.8305\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_6_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_6_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_6\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  81.78% ± 0.54%\n",
      "  Precision: 0.8749 ± 0.0044\n",
      "  Recall:    0.7860 ± 0.0076\n",
      "  F1 Score:  0.8271 ± 0.0056\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING RESOURCE USAGE SUMMARY: model_6\n",
      "================================================================================\n",
      "\n",
      "Total fine-tuning time: 22.2 seconds (0.4 minutes)\n",
      "Average CPU usage: 26.7%\n",
      "Average RAM usage: 42.1%\n",
      "Average GPU usage: 9.5%\n",
      "Average GPU power: 49.4 W\n",
      "Total energy consumed: 0.305 Wh (0.000305 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: model_6 - BEFORE vs AFTER FINE-TUNING\n",
      "====================================================================================================\n",
      "\n",
      "Metric               Before (Test)        After (Fine-tuned)   Improvement         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy             80.88%               81.78%               +0.90%              \n",
      "Precision            0.8742               0.8749               +0.0006             \n",
      "Recall               0.7675               0.7860               +0.0185             \n",
      "F1 Score             0.8162               0.8271               +0.0110             \n",
      "====================================================================================================\n",
      "\n",
      "ENERGY COMPARISON:\n",
      "  Training energy:    12.865 Wh\n",
      "  Fine-tuning energy: 0.305 Wh\n",
      "  Total energy:       13.169 Wh\n",
      "\n",
      "\n",
      "Fine-tuning model_7...\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_7 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_7\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 8ms/step - loss: 0.4993 - accuracy: 0.8748 - precision_m: 0.9127 - recall_m: 0.8479 - f1_m: 0.8790\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3136 - accuracy: 0.9050 - precision_m: 0.9451 - recall_m: 0.8803 - f1_m: 0.9114\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2189 - accuracy: 0.9386 - precision_m: 0.9659 - recall_m: 0.9139 - f1_m: 0.9390\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1643 - accuracy: 0.9490 - precision_m: 0.9738 - recall_m: 0.9353 - f1_m: 0.9541\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1496 - accuracy: 0.9565 - precision_m: 0.9739 - recall_m: 0.9393 - f1_m: 0.9562\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1102 - accuracy: 0.9683 - precision_m: 0.9788 - recall_m: 0.9566 - f1_m: 0.9675\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9778 - precision_m: 0.9851 - recall_m: 0.9667 - f1_m: 0.9758\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9783 - precision_m: 0.9829 - recall_m: 0.9694 - f1_m: 0.9761\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9872 - precision_m: 0.9894 - recall_m: 0.9790 - f1_m: 0.9842\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0458 - accuracy: 0.9872 - precision_m: 0.9912 - recall_m: 0.9813 - f1_m: 0.9862\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.0%\n",
      "  Usage (max):  31.3%\n",
      "  Frequency:    3345 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.5%\n",
      "  Usage (max):  41.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  18.0%\n",
      "  Usage (max):   52.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  63.9 W\n",
      "  Power (max):   103.4 W\n",
      "  Energy used:   0.039 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4193, Acc: 90.29%\n",
      "Precision: 0.9281, Recall: 0.8919, F1: 0.9094\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_7_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_7\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 8ms/step - loss: 0.5190 - accuracy: 0.8569 - precision_m: 0.9107 - recall_m: 0.8284 - f1_m: 0.8674\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8991 - precision_m: 0.9355 - recall_m: 0.8565 - f1_m: 0.8940\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2829 - accuracy: 0.9178 - precision_m: 0.9523 - recall_m: 0.8945 - f1_m: 0.9223\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2124 - accuracy: 0.9309 - precision_m: 0.9607 - recall_m: 0.9105 - f1_m: 0.9348\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1511 - accuracy: 0.9550 - precision_m: 0.9728 - recall_m: 0.9360 - f1_m: 0.9539\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9614 - precision_m: 0.9770 - recall_m: 0.9452 - f1_m: 0.9608\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1132 - accuracy: 0.9637 - precision_m: 0.9771 - recall_m: 0.9443 - f1_m: 0.9603\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.9727 - precision_m: 0.9801 - recall_m: 0.9605 - f1_m: 0.9702\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9832 - precision_m: 0.9876 - recall_m: 0.9683 - f1_m: 0.9778\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9809 - precision_m: 0.9859 - recall_m: 0.9731 - f1_m: 0.9794\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 18.6%\n",
      "  Usage (max):  27.8%\n",
      "  Frequency:    3339 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 41.8%\n",
      "  Usage (max):  42.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  18.7%\n",
      "  Usage (max):   54.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  53.5 W\n",
      "  Power (max):   57.1 W\n",
      "  Energy used:   0.033 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.3981, Acc: 89.90%\n",
      "Precision: 0.9208, Recall: 0.8929, F1: 0.9064\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_7_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_7\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 8ms/step - loss: 0.5274 - accuracy: 0.8723 - precision_m: 0.9086 - recall_m: 0.8488 - f1_m: 0.8775\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8982 - precision_m: 0.9414 - recall_m: 0.8713 - f1_m: 0.9048\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2446 - accuracy: 0.9320 - precision_m: 0.9575 - recall_m: 0.9075 - f1_m: 0.9317\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9454 - precision_m: 0.9675 - recall_m: 0.9256 - f1_m: 0.9460\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1386 - accuracy: 0.9607 - precision_m: 0.9785 - recall_m: 0.9446 - f1_m: 0.9612\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.9658 - precision_m: 0.9796 - recall_m: 0.9528 - f1_m: 0.9659\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9778 - precision_m: 0.9868 - recall_m: 0.9635 - f1_m: 0.9749\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9824 - precision_m: 0.9892 - recall_m: 0.9716 - f1_m: 0.9803\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9852 - precision_m: 0.9901 - recall_m: 0.9759 - f1_m: 0.9829\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9894 - precision_m: 0.9921 - recall_m: 0.9829 - f1_m: 0.9875\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 19.5%\n",
      "  Usage (max):  27.2%\n",
      "  Frequency:    2676 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.1%\n",
      "  Usage (max):  42.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  19.7%\n",
      "  Usage (max):   57.0%\n",
      "  Memory (mean): 3116 MB\n",
      "  Memory (max):  3116 MB\n",
      "  Power (mean):  51.8 W\n",
      "  Power (max):   52.3 W\n",
      "  Energy used:   0.032 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.3638, Acc: 90.38%\n",
      "Precision: 0.9310, Recall: 0.8943, F1: 0.9119\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_7_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_7\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 8ms/step - loss: 0.5016 - accuracy: 0.8666 - precision_m: 0.9055 - recall_m: 0.8429 - f1_m: 0.8730\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8982 - precision_m: 0.9353 - recall_m: 0.8675 - f1_m: 0.9000\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2253 - accuracy: 0.9307 - precision_m: 0.9657 - recall_m: 0.9042 - f1_m: 0.9339\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1710 - accuracy: 0.9456 - precision_m: 0.9672 - recall_m: 0.9296 - f1_m: 0.9480\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.9623 - precision_m: 0.9782 - recall_m: 0.9399 - f1_m: 0.9586\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.9642 - precision_m: 0.9770 - recall_m: 0.9506 - f1_m: 0.9636\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9754 - precision_m: 0.9841 - recall_m: 0.9649 - f1_m: 0.9744\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9791 - precision_m: 0.9868 - recall_m: 0.9715 - f1_m: 0.9791\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9865 - precision_m: 0.9901 - recall_m: 0.9778 - f1_m: 0.9839\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9833 - precision_m: 0.9870 - recall_m: 0.9761 - f1_m: 0.9815\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 19.8%\n",
      "  Usage (max):  28.8%\n",
      "  Frequency:    3336 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.2%\n",
      "  Usage (max):  42.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  20.7%\n",
      "  Usage (max):   54.0%\n",
      "  Memory (mean): 3120 MB\n",
      "  Memory (max):  3124 MB\n",
      "  Power (mean):  52.1 W\n",
      "  Power (max):   52.9 W\n",
      "  Energy used:   0.032 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4372, Acc: 89.77%\n",
      "Precision: 0.9181, Recall: 0.8883, F1: 0.9027\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_7_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_7\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 8ms/step - loss: 0.4667 - accuracy: 0.8793 - precision_m: 0.9160 - recall_m: 0.8540 - f1_m: 0.8838\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3252 - accuracy: 0.9069 - precision_m: 0.9391 - recall_m: 0.8754 - f1_m: 0.9060\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2229 - accuracy: 0.9284 - precision_m: 0.9582 - recall_m: 0.8982 - f1_m: 0.9271\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1806 - accuracy: 0.9462 - precision_m: 0.9640 - recall_m: 0.9248 - f1_m: 0.9439\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1544 - accuracy: 0.9518 - precision_m: 0.9709 - recall_m: 0.9367 - f1_m: 0.9535\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9677 - precision_m: 0.9769 - recall_m: 0.9538 - f1_m: 0.9652\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9804 - precision_m: 0.9885 - recall_m: 0.9677 - f1_m: 0.9779\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9808 - precision_m: 0.9865 - recall_m: 0.9710 - f1_m: 0.9787\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9860 - precision_m: 0.9888 - recall_m: 0.9766 - f1_m: 0.9827\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9855 - precision_m: 0.9891 - recall_m: 0.9817 - f1_m: 0.9854\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 17.9%\n",
      "  Usage (max):  28.4%\n",
      "  Frequency:    3073 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.4%\n",
      "  Usage (max):  42.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  19.3%\n",
      "  Usage (max):   56.0%\n",
      "  Memory (mean): 3118 MB\n",
      "  Memory (max):  3118 MB\n",
      "  Power (mean):  52.0 W\n",
      "  Power (max):   52.6 W\n",
      "  Energy used:   0.032 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4125, Acc: 90.07%\n",
      "Precision: 0.9216, Recall: 0.8925, F1: 0.9065\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_7_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_7\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 8ms/step - loss: 0.5017 - accuracy: 0.8644 - precision_m: 0.9099 - recall_m: 0.8352 - f1_m: 0.8708\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8975 - precision_m: 0.9375 - recall_m: 0.8643 - f1_m: 0.8992\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2213 - accuracy: 0.9334 - precision_m: 0.9578 - recall_m: 0.9027 - f1_m: 0.9293\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1796 - accuracy: 0.9436 - precision_m: 0.9653 - recall_m: 0.9265 - f1_m: 0.9455\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1439 - accuracy: 0.9548 - precision_m: 0.9726 - recall_m: 0.9390 - f1_m: 0.9554\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9651 - precision_m: 0.9804 - recall_m: 0.9489 - f1_m: 0.9643\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9748 - precision_m: 0.9857 - recall_m: 0.9649 - f1_m: 0.9752\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 0.9734 - precision_m: 0.9825 - recall_m: 0.9645 - f1_m: 0.9734\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9832 - precision_m: 0.9896 - recall_m: 0.9748 - f1_m: 0.9821\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9865 - precision_m: 0.9921 - recall_m: 0.9815 - f1_m: 0.9868\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 18.3%\n",
      "  Usage (max):  27.5%\n",
      "  Frequency:    3340 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.6%\n",
      "  Usage (max):  43.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  8.3%\n",
      "  Usage (max):   25.0%\n",
      "  Memory (mean): 3118 MB\n",
      "  Memory (max):  3118 MB\n",
      "  Power (mean):  51.9 W\n",
      "  Power (max):   52.7 W\n",
      "  Energy used:   0.032 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.3977, Acc: 90.39%\n",
      "Precision: 0.9254, Recall: 0.8967, F1: 0.9106\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_7_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_7\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 8ms/step - loss: 0.5683 - accuracy: 0.8544 - precision_m: 0.8935 - recall_m: 0.8278 - f1_m: 0.8593\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8996 - precision_m: 0.9336 - recall_m: 0.8634 - f1_m: 0.8969\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2632 - accuracy: 0.9263 - precision_m: 0.9578 - recall_m: 0.9001 - f1_m: 0.9280\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1904 - accuracy: 0.9472 - precision_m: 0.9682 - recall_m: 0.9217 - f1_m: 0.9443\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1417 - accuracy: 0.9591 - precision_m: 0.9756 - recall_m: 0.9387 - f1_m: 0.9567\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9681 - precision_m: 0.9758 - recall_m: 0.9491 - f1_m: 0.9622\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.9696 - precision_m: 0.9802 - recall_m: 0.9596 - f1_m: 0.9697\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9805 - precision_m: 0.9887 - recall_m: 0.9692 - f1_m: 0.9788\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9824 - precision_m: 0.9868 - recall_m: 0.9764 - f1_m: 0.9816\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9886 - precision_m: 0.9913 - recall_m: 0.9808 - f1_m: 0.9860\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.1%\n",
      "  Usage (max):  28.4%\n",
      "  Frequency:    3867 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.8%\n",
      "  Usage (max):  43.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  14.3%\n",
      "  Usage (max):   41.0%\n",
      "  Memory (mean): 3118 MB\n",
      "  Memory (max):  3118 MB\n",
      "  Power (mean):  52.7 W\n",
      "  Power (max):   53.2 W\n",
      "  Energy used:   0.033 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4134, Acc: 89.96%\n",
      "Precision: 0.9235, Recall: 0.8893, F1: 0.9057\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_7_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_7\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 9ms/step - loss: 0.4994 - accuracy: 0.8623 - precision_m: 0.8965 - recall_m: 0.8494 - f1_m: 0.8722\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8977 - precision_m: 0.9364 - recall_m: 0.8775 - f1_m: 0.9059\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2058 - accuracy: 0.9401 - precision_m: 0.9599 - recall_m: 0.9184 - f1_m: 0.9386\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1432 - accuracy: 0.9567 - precision_m: 0.9729 - recall_m: 0.9428 - f1_m: 0.9576\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1281 - accuracy: 0.9641 - precision_m: 0.9753 - recall_m: 0.9448 - f1_m: 0.9597\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9784 - precision_m: 0.9836 - recall_m: 0.9632 - f1_m: 0.9733\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9825 - precision_m: 0.9901 - recall_m: 0.9724 - f1_m: 0.9812\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9784 - precision_m: 0.9855 - recall_m: 0.9692 - f1_m: 0.9772\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9816 - precision_m: 0.9842 - recall_m: 0.9728 - f1_m: 0.9785\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9894 - precision_m: 0.9908 - recall_m: 0.9848 - f1_m: 0.9878\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 20.0%\n",
      "  Usage (max):  26.6%\n",
      "  Frequency:    2802 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.9%\n",
      "  Usage (max):  42.9%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  21.3%\n",
      "  Usage (max):   58.0%\n",
      "  Memory (mean): 3118 MB\n",
      "  Memory (max):  3118 MB\n",
      "  Power (mean):  52.9 W\n",
      "  Power (max):   54.6 W\n",
      "  Energy used:   0.033 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4495, Acc: 89.49%\n",
      "Precision: 0.9144, Recall: 0.8871, F1: 0.9003\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_7_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_7\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 8ms/step - loss: 0.4951 - accuracy: 0.8748 - precision_m: 0.9098 - recall_m: 0.8555 - f1_m: 0.8817\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.9035 - precision_m: 0.9393 - recall_m: 0.8713 - f1_m: 0.9038\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2397 - accuracy: 0.9323 - precision_m: 0.9602 - recall_m: 0.9043 - f1_m: 0.9313\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1830 - accuracy: 0.9425 - precision_m: 0.9686 - recall_m: 0.9248 - f1_m: 0.9461\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1493 - accuracy: 0.9550 - precision_m: 0.9764 - recall_m: 0.9404 - f1_m: 0.9580\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9657 - precision_m: 0.9842 - recall_m: 0.9498 - f1_m: 0.9666\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9712 - precision_m: 0.9844 - recall_m: 0.9569 - f1_m: 0.9704\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9768 - precision_m: 0.9863 - recall_m: 0.9670 - f1_m: 0.9765\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9819 - precision_m: 0.9905 - recall_m: 0.9736 - f1_m: 0.9819\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9838 - precision_m: 0.9879 - recall_m: 0.9788 - f1_m: 0.9833\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 18.3%\n",
      "  Usage (max):  30.9%\n",
      "  Frequency:    2542 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.3%\n",
      "  Usage (max):  43.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  20.0%\n",
      "  Usage (max):   59.0%\n",
      "  Memory (mean): 3118 MB\n",
      "  Memory (max):  3118 MB\n",
      "  Power (mean):  52.6 W\n",
      "  Power (max):   54.1 W\n",
      "  Energy used:   0.032 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4005, Acc: 90.37%\n",
      "Precision: 0.9268, Recall: 0.8939, F1: 0.9097\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_7_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_7\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 8ms/step - loss: 0.5043 - accuracy: 0.8650 - precision_m: 0.9081 - recall_m: 0.8350 - f1_m: 0.8698\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8959 - precision_m: 0.9318 - recall_m: 0.8697 - f1_m: 0.8995\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2305 - accuracy: 0.9325 - precision_m: 0.9605 - recall_m: 0.9061 - f1_m: 0.9324\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1763 - accuracy: 0.9477 - precision_m: 0.9713 - recall_m: 0.9259 - f1_m: 0.9480\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1329 - accuracy: 0.9606 - precision_m: 0.9783 - recall_m: 0.9431 - f1_m: 0.9603\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9701 - precision_m: 0.9815 - recall_m: 0.9578 - f1_m: 0.9695\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.9762 - precision_m: 0.9845 - recall_m: 0.9665 - f1_m: 0.9754\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9753 - precision_m: 0.9873 - recall_m: 0.9666 - f1_m: 0.9768\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9810 - precision_m: 0.9874 - recall_m: 0.9738 - f1_m: 0.9805\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9810 - precision_m: 0.9878 - recall_m: 0.9723 - f1_m: 0.9800\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.5%\n",
      "  Usage (max):  27.5%\n",
      "  Frequency:    3071 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.6%\n",
      "  Usage (max):  43.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  5.7%\n",
      "  Usage (max):   17.0%\n",
      "  Memory (mean): 3118 MB\n",
      "  Memory (max):  3118 MB\n",
      "  Power (mean):  52.3 W\n",
      "  Power (max):   52.8 W\n",
      "  Energy used:   0.032 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4121, Acc: 89.65%\n",
      "Precision: 0.9211, Recall: 0.8883, F1: 0.9041\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_7_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_7_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_7\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  90.03% ± 0.31%\n",
      "  Precision: 0.9231 ± 0.0047\n",
      "  Recall:    0.8915 ± 0.0030\n",
      "  F1 Score:  0.9067 ± 0.0035\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING RESOURCE USAGE SUMMARY: model_7\n",
      "================================================================================\n",
      "\n",
      "Total fine-tuning time: 22.2 seconds (0.4 minutes)\n",
      "Average CPU usage: 20.2%\n",
      "Average RAM usage: 42.4%\n",
      "Average GPU usage: 16.6%\n",
      "Average GPU power: 53.6 W\n",
      "Total energy consumed: 0.330 Wh (0.000330 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: model_7 - BEFORE vs AFTER FINE-TUNING\n",
      "====================================================================================================\n",
      "\n",
      "Metric               Before (Test)        After (Fine-tuned)   Improvement         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy             88.61%               90.03%               +1.41%              \n",
      "Precision            0.9205               0.9231               +0.0025             \n",
      "Recall               0.8690               0.8915               +0.0225             \n",
      "F1 Score             0.8935               0.9067               +0.0132             \n",
      "====================================================================================================\n",
      "\n",
      "ENERGY COMPARISON:\n",
      "  Training energy:    14.330 Wh\n",
      "  Fine-tuning energy: 0.330 Wh\n",
      "  Total energy:       14.661 Wh\n",
      "\n",
      "\n",
      "Fine-tuning model_8...\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_8 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_8\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 0.7414 - accuracy: 0.7949 - precision_m: 0.8596 - recall_m: 0.7451 - f1_m: 0.7980\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.6119 - accuracy: 0.8114 - precision_m: 0.8799 - recall_m: 0.7576 - f1_m: 0.8138\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5610 - accuracy: 0.8412 - precision_m: 0.9035 - recall_m: 0.7790 - f1_m: 0.8365\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.8729 - precision_m: 0.9244 - recall_m: 0.8221 - f1_m: 0.8700\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4097 - accuracy: 0.8719 - precision_m: 0.9165 - recall_m: 0.8295 - f1_m: 0.8707\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3412 - accuracy: 0.9074 - precision_m: 0.9499 - recall_m: 0.8707 - f1_m: 0.9084\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2890 - accuracy: 0.9078 - precision_m: 0.9488 - recall_m: 0.8719 - f1_m: 0.9086\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2560 - accuracy: 0.9220 - precision_m: 0.9549 - recall_m: 0.8934 - f1_m: 0.9229\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2304 - accuracy: 0.9367 - precision_m: 0.9609 - recall_m: 0.9023 - f1_m: 0.9306\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2126 - accuracy: 0.9348 - precision_m: 0.9627 - recall_m: 0.9111 - f1_m: 0.9361\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 20.8%\n",
      "  Usage (max):  27.8%\n",
      "  Frequency:    3338 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.4%\n",
      "  Usage (max):  42.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  26.7%\n",
      "  Usage (max):   63.0%\n",
      "  Memory (mean): 3124 MB\n",
      "  Memory (max):  3124 MB\n",
      "  Power (mean):  68.8 W\n",
      "  Power (max):   99.8 W\n",
      "  Energy used:   0.042 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.5272, Acc: 85.15%\n",
      "Precision: 0.8964, Recall: 0.8276, F1: 0.8599\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_8_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_8\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 9ms/step - loss: 0.6925 - accuracy: 0.8024 - precision_m: 0.8715 - recall_m: 0.7583 - f1_m: 0.8108\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5708 - accuracy: 0.8351 - precision_m: 0.8880 - recall_m: 0.7862 - f1_m: 0.8339\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.8564 - precision_m: 0.9111 - recall_m: 0.8234 - f1_m: 0.8647\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8796 - precision_m: 0.9225 - recall_m: 0.8357 - f1_m: 0.8769\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8923 - precision_m: 0.9321 - recall_m: 0.8496 - f1_m: 0.8887\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2822 - accuracy: 0.9159 - precision_m: 0.9458 - recall_m: 0.8788 - f1_m: 0.9109\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2415 - accuracy: 0.9250 - precision_m: 0.9508 - recall_m: 0.8995 - f1_m: 0.9243\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9300 - precision_m: 0.9541 - recall_m: 0.9067 - f1_m: 0.9296\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1985 - accuracy: 0.9450 - precision_m: 0.9654 - recall_m: 0.9219 - f1_m: 0.9430\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1897 - accuracy: 0.9396 - precision_m: 0.9582 - recall_m: 0.9187 - f1_m: 0.9380\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 28.1%\n",
      "  Usage (max):  29.5%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.7%\n",
      "  Usage (max):  43.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  23.7%\n",
      "  Usage (max):   63.0%\n",
      "  Memory (mean): 3124 MB\n",
      "  Memory (max):  3124 MB\n",
      "  Power (mean):  92.3 W\n",
      "  Power (max):   113.6 W\n",
      "  Energy used:   0.057 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.5077, Acc: 85.70%\n",
      "Precision: 0.8965, Recall: 0.8408, F1: 0.8673\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_8_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_8\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 0.7254 - accuracy: 0.8029 - precision_m: 0.8586 - recall_m: 0.7737 - f1_m: 0.8138\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5465 - accuracy: 0.8427 - precision_m: 0.8994 - recall_m: 0.8036 - f1_m: 0.8486\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.8658 - precision_m: 0.9145 - recall_m: 0.8308 - f1_m: 0.8705\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3265 - accuracy: 0.8973 - precision_m: 0.9447 - recall_m: 0.8688 - f1_m: 0.9050\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3101 - accuracy: 0.9037 - precision_m: 0.9358 - recall_m: 0.8732 - f1_m: 0.9032\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2792 - accuracy: 0.9107 - precision_m: 0.9427 - recall_m: 0.8853 - f1_m: 0.9130\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2032 - accuracy: 0.9445 - precision_m: 0.9685 - recall_m: 0.9219 - f1_m: 0.9446\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1834 - accuracy: 0.9426 - precision_m: 0.9654 - recall_m: 0.9308 - f1_m: 0.9477\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1608 - accuracy: 0.9542 - precision_m: 0.9679 - recall_m: 0.9349 - f1_m: 0.9510\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1414 - accuracy: 0.9584 - precision_m: 0.9729 - recall_m: 0.9446 - f1_m: 0.9585\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.7%\n",
      "  Usage (max):  30.0%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.9%\n",
      "  Usage (max):  43.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  22.0%\n",
      "  Usage (max):   63.0%\n",
      "  Memory (mean): 3124 MB\n",
      "  Memory (max):  3124 MB\n",
      "  Power (mean):  88.6 W\n",
      "  Power (max):   108.9 W\n",
      "  Energy used:   0.055 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4991, Acc: 86.79%\n",
      "Precision: 0.9021, Recall: 0.8508, F1: 0.8751\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_8_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_8\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 0.7168 - accuracy: 0.8001 - precision_m: 0.8508 - recall_m: 0.7766 - f1_m: 0.8118\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.8377 - precision_m: 0.8865 - recall_m: 0.8045 - f1_m: 0.8434\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8647 - precision_m: 0.9086 - recall_m: 0.8401 - f1_m: 0.8729\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3344 - accuracy: 0.8907 - precision_m: 0.9278 - recall_m: 0.8625 - f1_m: 0.8939\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2824 - accuracy: 0.9042 - precision_m: 0.9413 - recall_m: 0.8815 - f1_m: 0.9102\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2547 - accuracy: 0.9168 - precision_m: 0.9456 - recall_m: 0.8943 - f1_m: 0.9191\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2030 - accuracy: 0.9335 - precision_m: 0.9583 - recall_m: 0.9148 - f1_m: 0.9360\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1888 - accuracy: 0.9372 - precision_m: 0.9531 - recall_m: 0.9202 - f1_m: 0.9363\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1657 - accuracy: 0.9433 - precision_m: 0.9596 - recall_m: 0.9240 - f1_m: 0.9414\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1578 - accuracy: 0.9554 - precision_m: 0.9688 - recall_m: 0.9395 - f1_m: 0.9539\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.1%\n",
      "  Usage (max):  28.7%\n",
      "  Frequency:    3200 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.4%\n",
      "  Usage (max):  43.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  27.3%\n",
      "  Usage (max):   65.0%\n",
      "  Memory (mean): 3125 MB\n",
      "  Memory (max):  3126 MB\n",
      "  Power (mean):  84.4 W\n",
      "  Power (max):   108.5 W\n",
      "  Energy used:   0.052 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.5472, Acc: 86.03%\n",
      "Precision: 0.8942, Recall: 0.8463, F1: 0.8691\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_8_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_8\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 0.6407 - accuracy: 0.8040 - precision_m: 0.8660 - recall_m: 0.7736 - f1_m: 0.8171\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.8522 - precision_m: 0.9002 - recall_m: 0.8146 - f1_m: 0.8552\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3686 - accuracy: 0.8821 - precision_m: 0.9282 - recall_m: 0.8521 - f1_m: 0.8884\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3108 - accuracy: 0.9018 - precision_m: 0.9382 - recall_m: 0.8751 - f1_m: 0.9054\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2626 - accuracy: 0.9144 - precision_m: 0.9438 - recall_m: 0.8860 - f1_m: 0.9138\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2083 - accuracy: 0.9331 - precision_m: 0.9576 - recall_m: 0.9092 - f1_m: 0.9327\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9383 - precision_m: 0.9618 - recall_m: 0.9227 - f1_m: 0.9417\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1858 - accuracy: 0.9373 - precision_m: 0.9587 - recall_m: 0.9196 - f1_m: 0.9386\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1554 - accuracy: 0.9490 - precision_m: 0.9656 - recall_m: 0.9314 - f1_m: 0.9481\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1218 - accuracy: 0.9630 - precision_m: 0.9741 - recall_m: 0.9536 - f1_m: 0.9637\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 31.5%\n",
      "  Usage (max):  34.6%\n",
      "  Frequency:    3600 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.9%\n",
      "  Usage (max):  44.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  24.3%\n",
      "  Usage (max):   64.0%\n",
      "  Memory (mean): 3130 MB\n",
      "  Memory (max):  3130 MB\n",
      "  Power (mean):  92.0 W\n",
      "  Power (max):   112.0 W\n",
      "  Energy used:   0.057 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.5315, Acc: 86.14%\n",
      "Precision: 0.8946, Recall: 0.8449, F1: 0.8685\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_8_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_8\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 10ms/step - loss: 0.7697 - accuracy: 0.7870 - precision_m: 0.8429 - recall_m: 0.7491 - f1_m: 0.7932\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5984 - accuracy: 0.8225 - precision_m: 0.8863 - recall_m: 0.7887 - f1_m: 0.8345\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.8514 - precision_m: 0.9080 - recall_m: 0.8099 - f1_m: 0.8559\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8779 - precision_m: 0.9254 - recall_m: 0.8390 - f1_m: 0.8799\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3373 - accuracy: 0.8938 - precision_m: 0.9359 - recall_m: 0.8599 - f1_m: 0.8961\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2890 - accuracy: 0.9133 - precision_m: 0.9468 - recall_m: 0.8801 - f1_m: 0.9122\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2593 - accuracy: 0.9208 - precision_m: 0.9503 - recall_m: 0.8970 - f1_m: 0.9228\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2568 - accuracy: 0.9189 - precision_m: 0.9477 - recall_m: 0.8936 - f1_m: 0.9198\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2080 - accuracy: 0.9343 - precision_m: 0.9601 - recall_m: 0.9100 - f1_m: 0.9343\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1827 - accuracy: 0.9455 - precision_m: 0.9692 - recall_m: 0.9226 - f1_m: 0.9452\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 27.3%\n",
      "  Usage (max):  36.3%\n",
      "  Frequency:    4000 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.7%\n",
      "  Usage (max):  44.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  24.3%\n",
      "  Usage (max):   66.0%\n",
      "  Memory (mean): 3133 MB\n",
      "  Memory (max):  3134 MB\n",
      "  Power (mean):  93.4 W\n",
      "  Power (max):   115.2 W\n",
      "  Energy used:   0.057 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.5150, Acc: 85.88%\n",
      "Precision: 0.8997, Recall: 0.8383, F1: 0.8673\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_8_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_8\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 9ms/step - loss: 0.7681 - accuracy: 0.7902 - precision_m: 0.8419 - recall_m: 0.7586 - f1_m: 0.7979\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5954 - accuracy: 0.8273 - precision_m: 0.8871 - recall_m: 0.7884 - f1_m: 0.8345\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.8563 - precision_m: 0.9080 - recall_m: 0.8157 - f1_m: 0.8589\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8830 - precision_m: 0.9284 - recall_m: 0.8423 - f1_m: 0.8832\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8949 - precision_m: 0.9353 - recall_m: 0.8579 - f1_m: 0.8947\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2948 - accuracy: 0.9091 - precision_m: 0.9408 - recall_m: 0.8815 - f1_m: 0.9101\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2632 - accuracy: 0.9172 - precision_m: 0.9455 - recall_m: 0.8871 - f1_m: 0.9153\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2158 - accuracy: 0.9324 - precision_m: 0.9575 - recall_m: 0.9051 - f1_m: 0.9304\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1997 - accuracy: 0.9424 - precision_m: 0.9601 - recall_m: 0.9187 - f1_m: 0.9389\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1606 - accuracy: 0.9534 - precision_m: 0.9692 - recall_m: 0.9335 - f1_m: 0.9510\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.3%\n",
      "  Usage (max):  28.4%\n",
      "  Frequency:    3074 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.9%\n",
      "  Usage (max):  43.9%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  20.0%\n",
      "  Usage (max):   56.0%\n",
      "  Memory (mean): 3134 MB\n",
      "  Memory (max):  3134 MB\n",
      "  Power (mean):  78.2 W\n",
      "  Power (max):   130.1 W\n",
      "  Energy used:   0.048 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.5138, Acc: 86.09%\n",
      "Precision: 0.8946, Recall: 0.8421, F1: 0.8670\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_8_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_8\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 0.7616 - accuracy: 0.8010 - precision_m: 0.8570 - recall_m: 0.7796 - f1_m: 0.8163\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5524 - accuracy: 0.8351 - precision_m: 0.8847 - recall_m: 0.7927 - f1_m: 0.8360\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8632 - precision_m: 0.9100 - recall_m: 0.8288 - f1_m: 0.8673\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3403 - accuracy: 0.8908 - precision_m: 0.9346 - recall_m: 0.8599 - f1_m: 0.8954\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2612 - accuracy: 0.9166 - precision_m: 0.9491 - recall_m: 0.8868 - f1_m: 0.9167\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2220 - accuracy: 0.9323 - precision_m: 0.9565 - recall_m: 0.9034 - f1_m: 0.9291\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1940 - accuracy: 0.9355 - precision_m: 0.9612 - recall_m: 0.9111 - f1_m: 0.9354\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1715 - accuracy: 0.9521 - precision_m: 0.9721 - recall_m: 0.9281 - f1_m: 0.9495\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1693 - accuracy: 0.9456 - precision_m: 0.9675 - recall_m: 0.9295 - f1_m: 0.9480\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1447 - accuracy: 0.9572 - precision_m: 0.9731 - recall_m: 0.9373 - f1_m: 0.9548\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.1%\n",
      "  Usage (max):  26.6%\n",
      "  Frequency:    3215 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.9%\n",
      "  Usage (max):  43.0%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  22.0%\n",
      "  Usage (max):   65.0%\n",
      "  Memory (mean): 3134 MB\n",
      "  Memory (max):  3134 MB\n",
      "  Power (mean):  87.0 W\n",
      "  Power (max):   154.4 W\n",
      "  Energy used:   0.053 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.5471, Acc: 86.07%\n",
      "Precision: 0.8910, Recall: 0.8448, F1: 0.8668\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_8_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_8\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 0.7459 - accuracy: 0.7913 - precision_m: 0.8458 - recall_m: 0.7585 - f1_m: 0.7996\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5693 - accuracy: 0.8279 - precision_m: 0.8904 - recall_m: 0.7851 - f1_m: 0.8343\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4855 - accuracy: 0.8562 - precision_m: 0.9084 - recall_m: 0.8189 - f1_m: 0.8612\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8655 - precision_m: 0.9131 - recall_m: 0.8280 - f1_m: 0.8682\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3556 - accuracy: 0.8952 - precision_m: 0.9290 - recall_m: 0.8625 - f1_m: 0.8944\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3012 - accuracy: 0.8989 - precision_m: 0.9391 - recall_m: 0.8612 - f1_m: 0.8984\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2608 - accuracy: 0.9202 - precision_m: 0.9480 - recall_m: 0.8875 - f1_m: 0.9167\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2357 - accuracy: 0.9295 - precision_m: 0.9502 - recall_m: 0.8969 - f1_m: 0.9227\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2182 - accuracy: 0.9281 - precision_m: 0.9486 - recall_m: 0.9058 - f1_m: 0.9266\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1718 - accuracy: 0.9476 - precision_m: 0.9675 - recall_m: 0.9263 - f1_m: 0.9464\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 18.8%\n",
      "  Usage (max):  29.1%\n",
      "  Frequency:    3304 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 42.9%\n",
      "  Usage (max):  43.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  23.8%\n",
      "  Usage (max):   64.0%\n",
      "  Memory (mean): 3134 MB\n",
      "  Memory (max):  3134 MB\n",
      "  Power (mean):  67.2 W\n",
      "  Power (max):   114.2 W\n",
      "  Energy used:   0.062 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.5038, Acc: 86.09%\n",
      "Precision: 0.9030, Recall: 0.8407, F1: 0.8701\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_8_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_8\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 9ms/step - loss: 0.7217 - accuracy: 0.8013 - precision_m: 0.8573 - recall_m: 0.7656 - f1_m: 0.8088\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5557 - accuracy: 0.8332 - precision_m: 0.8898 - recall_m: 0.7965 - f1_m: 0.8405\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.8503 - precision_m: 0.9163 - recall_m: 0.8090 - f1_m: 0.8592\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8826 - precision_m: 0.9337 - recall_m: 0.8455 - f1_m: 0.8873\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3202 - accuracy: 0.8992 - precision_m: 0.9384 - recall_m: 0.8598 - f1_m: 0.8972\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2821 - accuracy: 0.9106 - precision_m: 0.9458 - recall_m: 0.8758 - f1_m: 0.9093\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2357 - accuracy: 0.9263 - precision_m: 0.9550 - recall_m: 0.9029 - f1_m: 0.9281\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2087 - accuracy: 0.9349 - precision_m: 0.9588 - recall_m: 0.9104 - f1_m: 0.9339\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1838 - accuracy: 0.9444 - precision_m: 0.9635 - recall_m: 0.9195 - f1_m: 0.9409\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1640 - accuracy: 0.9506 - precision_m: 0.9681 - recall_m: 0.9284 - f1_m: 0.9477\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 2.2 seconds (0.0 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.0%\n",
      "  Usage (max):  26.6%\n",
      "  Frequency:    2935 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.6%\n",
      "  Usage (max):  44.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  19.7%\n",
      "  Usage (max):   58.0%\n",
      "  Memory (mean): 3134 MB\n",
      "  Memory (max):  3134 MB\n",
      "  Power (mean):  72.3 W\n",
      "  Power (max):   109.2 W\n",
      "  Energy used:   0.044 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.5248, Acc: 86.03%\n",
      "Precision: 0.8986, Recall: 0.8425, F1: 0.8691\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_8_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_8_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_8\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  86.00% ± 0.39%\n",
      "  Precision: 0.8971 ± 0.0036\n",
      "  Recall:    0.8419 ± 0.0058\n",
      "  F1 Score:  0.8680 ± 0.0036\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING RESOURCE USAGE SUMMARY: model_8\n",
      "================================================================================\n",
      "\n",
      "Total fine-tuning time: 23.3 seconds (0.4 minutes)\n",
      "Average CPU usage: 24.2%\n",
      "Average RAM usage: 43.2%\n",
      "Average GPU usage: 23.4%\n",
      "Average GPU power: 82.4 W\n",
      "Total energy consumed: 0.529 Wh (0.000529 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: model_8 - BEFORE vs AFTER FINE-TUNING\n",
      "====================================================================================================\n",
      "\n",
      "Metric               Before (Test)        After (Fine-tuned)   Improvement         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy             84.80%               86.00%               +1.20%              \n",
      "Precision            0.8959               0.8971               +0.0011             \n",
      "Recall               0.8222               0.8419               +0.0197             \n",
      "F1 Score             0.8566               0.8680               +0.0114             \n",
      "====================================================================================================\n",
      "\n",
      "ENERGY COMPARISON:\n",
      "  Training energy:    23.307 Wh\n",
      "  Fine-tuning energy: 0.529 Wh\n",
      "  Total energy:       23.835 Wh\n",
      "\n",
      "\n",
      "Fine-tuning model_9...\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_9 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_9\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 0.4674 - accuracy: 0.8738 - precision_m: 0.9129 - recall_m: 0.8557 - f1_m: 0.8832\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2371 - accuracy: 0.9291 - precision_m: 0.9597 - recall_m: 0.9040 - f1_m: 0.9309\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1399 - accuracy: 0.9584 - precision_m: 0.9739 - recall_m: 0.9387 - f1_m: 0.9559\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0791 - accuracy: 0.9811 - precision_m: 0.9911 - recall_m: 0.9735 - f1_m: 0.9822\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 0.9872 - precision_m: 0.9912 - recall_m: 0.9808 - f1_m: 0.9859\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0321 - accuracy: 0.9929 - precision_m: 0.9954 - recall_m: 0.9881 - f1_m: 0.9917\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9943 - precision_m: 0.9946 - recall_m: 0.9914 - f1_m: 0.9930\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 0.9976 - precision_m: 0.9973 - recall_m: 0.9968 - f1_m: 0.9971\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.9943 - precision_m: 0.9963 - recall_m: 0.9940 - f1_m: 0.9952\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0177 - accuracy: 0.9957 - precision_m: 0.9959 - recall_m: 0.9954 - f1_m: 0.9956\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.0%\n",
      "  Usage (max):  26.3%\n",
      "  Frequency:    3610 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.1%\n",
      "  Usage (max):  43.2%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  29.8%\n",
      "  Usage (max):   73.0%\n",
      "  Memory (mean): 3134 MB\n",
      "  Memory (max):  3134 MB\n",
      "  Power (mean):  83.5 W\n",
      "  Power (max):   118.6 W\n",
      "  Energy used:   0.077 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4362, Acc: 90.01%\n",
      "Precision: 0.9181, Recall: 0.8926, F1: 0.9050\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_9_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_9\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 11ms/step - loss: 0.4421 - accuracy: 0.8796 - precision_m: 0.9243 - recall_m: 0.8505 - f1_m: 0.8858\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2672 - accuracy: 0.9205 - precision_m: 0.9548 - recall_m: 0.8970 - f1_m: 0.9249\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1673 - accuracy: 0.9532 - precision_m: 0.9724 - recall_m: 0.9314 - f1_m: 0.9514\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1038 - accuracy: 0.9709 - precision_m: 0.9858 - recall_m: 0.9640 - f1_m: 0.9747\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0659 - accuracy: 0.9850 - precision_m: 0.9912 - recall_m: 0.9766 - f1_m: 0.9838\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 0.9923 - precision_m: 0.9943 - recall_m: 0.9874 - f1_m: 0.9908\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9950 - precision_m: 0.9956 - recall_m: 0.9922 - f1_m: 0.9939\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9950 - precision_m: 0.9956 - recall_m: 0.9944 - f1_m: 0.9950\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 0.9955 - precision_m: 0.9965 - recall_m: 0.9939 - f1_m: 0.9952\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0181 - accuracy: 0.9959 - precision_m: 0.9947 - recall_m: 0.9930 - f1_m: 0.9939\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.0%\n",
      "  Usage (max):  27.5%\n",
      "  Frequency:    3510 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.0%\n",
      "  Usage (max):  43.2%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  21.8%\n",
      "  Usage (max):   73.0%\n",
      "  Memory (mean): 3134 MB\n",
      "  Memory (max):  3134 MB\n",
      "  Power (mean):  72.9 W\n",
      "  Power (max):   109.2 W\n",
      "  Energy used:   0.067 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4237, Acc: 89.63%\n",
      "Precision: 0.9179, Recall: 0.8888, F1: 0.9028\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_9_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_9\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 0.4664 - accuracy: 0.8686 - precision_m: 0.9017 - recall_m: 0.8421 - f1_m: 0.8708\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2828 - accuracy: 0.9144 - precision_m: 0.9518 - recall_m: 0.8870 - f1_m: 0.9181\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1509 - accuracy: 0.9593 - precision_m: 0.9775 - recall_m: 0.9407 - f1_m: 0.9587\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0843 - accuracy: 0.9769 - precision_m: 0.9845 - recall_m: 0.9676 - f1_m: 0.9760\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0529 - accuracy: 0.9884 - precision_m: 0.9921 - recall_m: 0.9814 - f1_m: 0.9867\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 0.9907 - precision_m: 0.9928 - recall_m: 0.9883 - f1_m: 0.9905\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 0.9931 - precision_m: 0.9945 - recall_m: 0.9908 - f1_m: 0.9926\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0204 - accuracy: 0.9958 - precision_m: 0.9963 - recall_m: 0.9959 - f1_m: 0.9961\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0169 - accuracy: 0.9958 - precision_m: 0.9962 - recall_m: 0.9957 - f1_m: 0.9960\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0105 - accuracy: 1.0000 - precision_m: 1.0000 - recall_m: 0.9995 - f1_m: 0.9998\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.9%\n",
      "  Usage (max):  33.3%\n",
      "  Frequency:    3401 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.4%\n",
      "  Usage (max):  43.5%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  26.8%\n",
      "  Usage (max):   63.0%\n",
      "  Memory (mean): 3134 MB\n",
      "  Memory (max):  3134 MB\n",
      "  Power (mean):  70.6 W\n",
      "  Power (max):   125.3 W\n",
      "  Energy used:   0.065 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4179, Acc: 89.99%\n",
      "Precision: 0.9210, Recall: 0.8935, F1: 0.9068\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_9_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_9\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 0.4641 - accuracy: 0.8759 - precision_m: 0.9016 - recall_m: 0.8636 - f1_m: 0.8821\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2427 - accuracy: 0.9321 - precision_m: 0.9588 - recall_m: 0.9077 - f1_m: 0.9325\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1185 - accuracy: 0.9665 - precision_m: 0.9782 - recall_m: 0.9507 - f1_m: 0.9642\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0641 - accuracy: 0.9823 - precision_m: 0.9874 - recall_m: 0.9760 - f1_m: 0.9817\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0449 - accuracy: 0.9861 - precision_m: 0.9884 - recall_m: 0.9829 - f1_m: 0.9856\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0302 - accuracy: 0.9916 - precision_m: 0.9940 - recall_m: 0.9890 - f1_m: 0.9915\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0220 - accuracy: 0.9963 - precision_m: 0.9968 - recall_m: 0.9944 - f1_m: 0.9956\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0176 - accuracy: 0.9972 - precision_m: 0.9971 - recall_m: 0.9962 - f1_m: 0.9967\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 0.9977 - precision_m: 0.9977 - recall_m: 0.9972 - f1_m: 0.9975\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0110 - accuracy: 0.9972 - precision_m: 0.9972 - recall_m: 0.9963 - f1_m: 0.9968\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.4%\n",
      "  Usage (max):  30.4%\n",
      "  Frequency:    3304 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 44.0%\n",
      "  Usage (max):  44.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  19.5%\n",
      "  Usage (max):   72.0%\n",
      "  Memory (mean): 3134 MB\n",
      "  Memory (max):  3134 MB\n",
      "  Power (mean):  75.4 W\n",
      "  Power (max):   117.5 W\n",
      "  Energy used:   0.070 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4591, Acc: 90.17%\n",
      "Precision: 0.9184, Recall: 0.8967, F1: 0.9072\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_9_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_9\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 0.4508 - accuracy: 0.8765 - precision_m: 0.9140 - recall_m: 0.8570 - f1_m: 0.8844\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2346 - accuracy: 0.9289 - precision_m: 0.9540 - recall_m: 0.9007 - f1_m: 0.9264\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1260 - accuracy: 0.9659 - precision_m: 0.9788 - recall_m: 0.9512 - f1_m: 0.9647\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0602 - accuracy: 0.9874 - precision_m: 0.9930 - recall_m: 0.9805 - f1_m: 0.9867\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0451 - accuracy: 0.9906 - precision_m: 0.9940 - recall_m: 0.9844 - f1_m: 0.9892\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9935 - precision_m: 0.9947 - recall_m: 0.9913 - f1_m: 0.9930\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9935 - precision_m: 0.9943 - recall_m: 0.9929 - f1_m: 0.9936\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9977 - precision_m: 0.9982 - recall_m: 0.9968 - f1_m: 0.9975\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0157 - accuracy: 0.9981 - precision_m: 0.9982 - recall_m: 0.9972 - f1_m: 0.9977\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0127 - accuracy: 0.9967 - precision_m: 0.9968 - recall_m: 0.9968 - f1_m: 0.9968\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 20.9%\n",
      "  Usage (max):  31.2%\n",
      "  Frequency:    3213 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 44.8%\n",
      "  Usage (max):  45.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  23.0%\n",
      "  Usage (max):   75.0%\n",
      "  Memory (mean): 3135 MB\n",
      "  Memory (max):  3136 MB\n",
      "  Power (mean):  75.7 W\n",
      "  Power (max):   119.9 W\n",
      "  Energy used:   0.070 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.3940, Acc: 90.74%\n",
      "Precision: 0.9273, Recall: 0.9005, F1: 0.9134\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_9_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_9\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 0.4652 - accuracy: 0.8644 - precision_m: 0.8977 - recall_m: 0.8401 - f1_m: 0.8678\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2570 - accuracy: 0.9175 - precision_m: 0.9462 - recall_m: 0.8963 - f1_m: 0.9204\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1477 - accuracy: 0.9553 - precision_m: 0.9727 - recall_m: 0.9397 - f1_m: 0.9558\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0909 - accuracy: 0.9772 - precision_m: 0.9881 - recall_m: 0.9642 - f1_m: 0.9760\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0573 - accuracy: 0.9897 - precision_m: 0.9944 - recall_m: 0.9823 - f1_m: 0.9883\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0409 - accuracy: 0.9911 - precision_m: 0.9940 - recall_m: 0.9888 - f1_m: 0.9914\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9935 - precision_m: 0.9954 - recall_m: 0.9899 - f1_m: 0.9926\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9953 - precision_m: 0.9963 - recall_m: 0.9926 - f1_m: 0.9945\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0191 - accuracy: 0.9953 - precision_m: 0.9963 - recall_m: 0.9945 - f1_m: 0.9954\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0164 - accuracy: 0.9972 - precision_m: 0.9972 - recall_m: 0.9954 - f1_m: 0.9963\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.9%\n",
      "  Usage (max):  32.5%\n",
      "  Frequency:    3400 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 45.0%\n",
      "  Usage (max):  45.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  29.0%\n",
      "  Usage (max):   73.0%\n",
      "  Memory (mean): 3136 MB\n",
      "  Memory (max):  3136 MB\n",
      "  Power (mean):  75.4 W\n",
      "  Power (max):   120.0 W\n",
      "  Energy used:   0.070 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4455, Acc: 89.76%\n",
      "Precision: 0.9166, Recall: 0.8919, F1: 0.9038\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_9_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_9\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 0.4968 - accuracy: 0.8582 - precision_m: 0.9016 - recall_m: 0.8354 - f1_m: 0.8671\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2781 - accuracy: 0.9077 - precision_m: 0.9470 - recall_m: 0.8857 - f1_m: 0.9151\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1310 - accuracy: 0.9567 - precision_m: 0.9715 - recall_m: 0.9408 - f1_m: 0.9558\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0684 - accuracy: 0.9853 - precision_m: 0.9888 - recall_m: 0.9764 - f1_m: 0.9825\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0363 - accuracy: 0.9938 - precision_m: 0.9948 - recall_m: 0.9897 - f1_m: 0.9922\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9933 - precision_m: 0.9936 - recall_m: 0.9922 - f1_m: 0.9929\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 0.9976 - precision_m: 0.9982 - recall_m: 0.9963 - f1_m: 0.9972\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0203 - accuracy: 0.9943 - precision_m: 0.9945 - recall_m: 0.9936 - f1_m: 0.9940\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0126 - accuracy: 0.9981 - precision_m: 0.9982 - recall_m: 0.9972 - f1_m: 0.9977\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0098 - accuracy: 0.9976 - precision_m: 0.9977 - recall_m: 0.9977 - f1_m: 0.9977\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.1%\n",
      "  Usage (max):  38.7%\n",
      "  Frequency:    3002 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.9%\n",
      "  Usage (max):  44.2%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  20.0%\n",
      "  Usage (max):   74.0%\n",
      "  Memory (mean): 3136 MB\n",
      "  Memory (max):  3136 MB\n",
      "  Power (mean):  67.6 W\n",
      "  Power (max):   115.3 W\n",
      "  Energy used:   0.063 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4769, Acc: 89.60%\n",
      "Precision: 0.9126, Recall: 0.8904, F1: 0.9012\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_9_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_9\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 0.4515 - accuracy: 0.8577 - precision_m: 0.9085 - recall_m: 0.8319 - f1_m: 0.8683\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2537 - accuracy: 0.9208 - precision_m: 0.9493 - recall_m: 0.8909 - f1_m: 0.9190\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1361 - accuracy: 0.9627 - precision_m: 0.9773 - recall_m: 0.9485 - f1_m: 0.9626\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0721 - accuracy: 0.9807 - precision_m: 0.9901 - recall_m: 0.9710 - f1_m: 0.9804\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0495 - accuracy: 0.9894 - precision_m: 0.9916 - recall_m: 0.9811 - f1_m: 0.9863\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9908 - precision_m: 0.9926 - recall_m: 0.9862 - f1_m: 0.9893\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 0.9949 - precision_m: 0.9949 - recall_m: 0.9931 - f1_m: 0.9940\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9926 - precision_m: 0.9931 - recall_m: 0.9926 - f1_m: 0.9928\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0167 - accuracy: 0.9977 - precision_m: 0.9986 - recall_m: 0.9968 - f1_m: 0.9977\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0197 - accuracy: 0.9959 - precision_m: 0.9963 - recall_m: 0.9954 - f1_m: 0.9959\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 21.1%\n",
      "  Usage (max):  30.4%\n",
      "  Frequency:    3304 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 43.6%\n",
      "  Usage (max):  43.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  20.8%\n",
      "  Usage (max):   69.0%\n",
      "  Memory (mean): 3136 MB\n",
      "  Memory (max):  3136 MB\n",
      "  Power (mean):  76.2 W\n",
      "  Power (max):   121.0 W\n",
      "  Energy used:   0.070 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4483, Acc: 89.34%\n",
      "Precision: 0.9137, Recall: 0.8869, F1: 0.8999\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_9_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_9\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 0.4557 - accuracy: 0.8655 - precision_m: 0.9133 - recall_m: 0.8405 - f1_m: 0.8752\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2508 - accuracy: 0.9263 - precision_m: 0.9536 - recall_m: 0.8992 - f1_m: 0.9254\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1483 - accuracy: 0.9541 - precision_m: 0.9733 - recall_m: 0.9441 - f1_m: 0.9584\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0990 - accuracy: 0.9712 - precision_m: 0.9849 - recall_m: 0.9600 - f1_m: 0.9722\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9828 - precision_m: 0.9865 - recall_m: 0.9738 - f1_m: 0.9801\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0440 - accuracy: 0.9884 - precision_m: 0.9907 - recall_m: 0.9825 - f1_m: 0.9866\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9935 - precision_m: 0.9963 - recall_m: 0.9913 - f1_m: 0.9938\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9958 - precision_m: 0.9963 - recall_m: 0.9954 - f1_m: 0.9959\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0173 - accuracy: 0.9940 - precision_m: 0.9945 - recall_m: 0.9936 - f1_m: 0.9940\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0143 - accuracy: 0.9972 - precision_m: 0.9982 - recall_m: 0.9963 - f1_m: 0.9972\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.6%\n",
      "  Usage (max):  38.3%\n",
      "  Frequency:    3602 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 44.1%\n",
      "  Usage (max):  44.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  22.0%\n",
      "  Usage (max):   72.0%\n",
      "  Memory (mean): 3136 MB\n",
      "  Memory (max):  3136 MB\n",
      "  Power (mean):  70.3 W\n",
      "  Power (max):   99.8 W\n",
      "  Energy used:   0.065 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4332, Acc: 89.22%\n",
      "Precision: 0.9168, Recall: 0.8829, F1: 0.8992\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_9_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_9\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 0.4404 - accuracy: 0.8878 - precision_m: 0.9108 - recall_m: 0.8703 - f1_m: 0.8900\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2120 - accuracy: 0.9339 - precision_m: 0.9618 - recall_m: 0.9163 - f1_m: 0.9383\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1102 - accuracy: 0.9729 - precision_m: 0.9843 - recall_m: 0.9587 - f1_m: 0.9713\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9886 - precision_m: 0.9930 - recall_m: 0.9802 - f1_m: 0.9866\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 0.9924 - precision_m: 0.9944 - recall_m: 0.9871 - f1_m: 0.9907\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9943 - precision_m: 0.9948 - recall_m: 0.9911 - f1_m: 0.9930\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9948 - precision_m: 0.9954 - recall_m: 0.9940 - f1_m: 0.9947\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0124 - accuracy: 0.9981 - precision_m: 0.9986 - recall_m: 0.9963 - f1_m: 0.9975\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9962 - precision_m: 0.9963 - recall_m: 0.9945 - f1_m: 0.9954\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0114 - accuracy: 0.9976 - precision_m: 0.9977 - recall_m: 0.9963 - f1_m: 0.9970\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 3.3 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.5%\n",
      "  Usage (max):  32.9%\n",
      "  Frequency:    3406 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 44.3%\n",
      "  Usage (max):  44.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  26.2%\n",
      "  Usage (max):   74.0%\n",
      "  Memory (mean): 3136 MB\n",
      "  Memory (max):  3136 MB\n",
      "  Power (mean):  75.2 W\n",
      "  Power (max):   116.3 W\n",
      "  Energy used:   0.069 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4287, Acc: 90.92%\n",
      "Precision: 0.9261, Recall: 0.9042, F1: 0.9148\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_9_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_9_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_9\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  89.94% ± 0.53%\n",
      "  Precision: 0.9189 ± 0.0045\n",
      "  Recall:    0.8928 ± 0.0060\n",
      "  F1 Score:  0.9054 ± 0.0050\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING RESOURCE USAGE SUMMARY: model_9\n",
      "================================================================================\n",
      "\n",
      "Total fine-tuning time: 33.3 seconds (0.6 minutes)\n",
      "Average CPU usage: 22.9%\n",
      "Average RAM usage: 43.9%\n",
      "Average GPU usage: 23.9%\n",
      "Average GPU power: 74.3 W\n",
      "Total energy consumed: 0.687 Wh (0.000687 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: model_9 - BEFORE vs AFTER FINE-TUNING\n",
      "====================================================================================================\n",
      "\n",
      "Metric               Before (Test)        After (Fine-tuned)   Improvement         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy             88.34%               89.94%               +1.60%              \n",
      "Precision            0.9192               0.9189               -0.0004             \n",
      "Recall               0.8630               0.8928               +0.0299             \n",
      "F1 Score             0.8895               0.9054               +0.0159             \n",
      "====================================================================================================\n",
      "\n",
      "ENERGY COMPARISON:\n",
      "  Training energy:    22.135 Wh\n",
      "  Fine-tuning energy: 0.687 Wh\n",
      "  Total energy:       22.822 Wh\n",
      "\n",
      "\n",
      "Fine-tuning model_10...\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING model_10 ACROSS 10 FOLDS\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 1 - model_10\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2116, Final Test=7521\n",
      "Fine-tuning with 2116 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 34ms/step - loss: 0.4701 - accuracy: 0.8644 - precision_m: 0.9075 - recall_m: 0.8383 - f1_m: 0.8713\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2308 - accuracy: 0.9334 - precision_m: 0.9632 - recall_m: 0.9119 - f1_m: 0.9366\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1036 - accuracy: 0.9740 - precision_m: 0.9887 - recall_m: 0.9633 - f1_m: 0.9758\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0531 - accuracy: 0.9891 - precision_m: 0.9958 - recall_m: 0.9793 - f1_m: 0.9874\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0314 - accuracy: 0.9924 - precision_m: 0.9963 - recall_m: 0.9890 - f1_m: 0.9926\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0185 - accuracy: 0.9967 - precision_m: 0.9968 - recall_m: 0.9959 - f1_m: 0.9963\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0141 - accuracy: 0.9967 - precision_m: 0.9968 - recall_m: 0.9949 - f1_m: 0.9959\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0102 - accuracy: 0.9976 - precision_m: 0.9977 - recall_m: 0.9977 - f1_m: 0.9977\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0087 - accuracy: 0.9981 - precision_m: 0.9982 - recall_m: 0.9982 - f1_m: 0.9982\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 0.9991 - precision_m: 0.9995 - recall_m: 0.9991 - f1_m: 0.9993\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 6.6 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.0%\n",
      "  Usage (max):  30.0%\n",
      "  Frequency:    3771 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 45.1%\n",
      "  Usage (max):  45.9%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  52.3%\n",
      "  Usage (max):   89.0%\n",
      "  Memory (mean): 3136 MB\n",
      "  Memory (max):  3136 MB\n",
      "  Power (mean):  103.1 W\n",
      "  Power (max):   137.1 W\n",
      "  Energy used:   0.190 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 1 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4608, Acc: 89.31%\n",
      "Precision: 0.9121, Recall: 0.8855, F1: 0.8984\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_10_fold_1_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 2 - model_10\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2201, Final Test=7524\n",
      "Fine-tuning with 2201 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 2s 25ms/step - loss: 0.5048 - accuracy: 0.8673 - precision_m: 0.9115 - recall_m: 0.8457 - f1_m: 0.8773\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.2470 - accuracy: 0.9241 - precision_m: 0.9504 - recall_m: 0.9048 - f1_m: 0.9269\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.1144 - accuracy: 0.9668 - precision_m: 0.9774 - recall_m: 0.9557 - f1_m: 0.9663\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0533 - accuracy: 0.9832 - precision_m: 0.9890 - recall_m: 0.9774 - f1_m: 0.9831\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0344 - accuracy: 0.9950 - precision_m: 0.9961 - recall_m: 0.9909 - f1_m: 0.9935\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0247 - accuracy: 0.9932 - precision_m: 0.9921 - recall_m: 0.9908 - f1_m: 0.9915\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0201 - accuracy: 0.9959 - precision_m: 0.9965 - recall_m: 0.9948 - f1_m: 0.9957\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0106 - accuracy: 0.9991 - precision_m: 0.9991 - recall_m: 0.9991 - f1_m: 0.9991\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0145 - accuracy: 0.9959 - precision_m: 0.9965 - recall_m: 0.9957 - f1_m: 0.9961\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0109 - accuracy: 0.9982 - precision_m: 0.9983 - recall_m: 0.9978 - f1_m: 0.9980\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 6.6 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.1%\n",
      "  Usage (max):  25.9%\n",
      "  Frequency:    3492 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 44.4%\n",
      "  Usage (max):  44.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  46.3%\n",
      "  Usage (max):   88.0%\n",
      "  Memory (mean): 3136 MB\n",
      "  Memory (max):  3136 MB\n",
      "  Power (mean):  98.1 W\n",
      "  Power (max):   135.3 W\n",
      "  Energy used:   0.181 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 2 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4769, Acc: 88.61%\n",
      "Precision: 0.9028, Recall: 0.8778, F1: 0.8899\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_10_fold_2_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 3 - model_10\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2161, Final Test=7405\n",
      "Fine-tuning with 2161 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 42ms/step - loss: 0.4587 - accuracy: 0.8718 - precision_m: 0.9122 - recall_m: 0.8519 - f1_m: 0.8809\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2351 - accuracy: 0.9297 - precision_m: 0.9580 - recall_m: 0.9075 - f1_m: 0.9320\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1101 - accuracy: 0.9690 - precision_m: 0.9785 - recall_m: 0.9551 - f1_m: 0.9666\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0518 - accuracy: 0.9884 - precision_m: 0.9940 - recall_m: 0.9834 - f1_m: 0.9886\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0293 - accuracy: 0.9926 - precision_m: 0.9953 - recall_m: 0.9911 - f1_m: 0.9932\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0180 - accuracy: 0.9972 - precision_m: 0.9977 - recall_m: 0.9949 - f1_m: 0.9963\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0129 - accuracy: 0.9986 - precision_m: 0.9991 - recall_m: 0.9986 - f1_m: 0.9989\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0115 - accuracy: 0.9977 - precision_m: 0.9977 - recall_m: 0.9972 - f1_m: 0.9975\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0086 - accuracy: 0.9991 - precision_m: 0.9991 - recall_m: 0.9991 - f1_m: 0.9991\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0080 - accuracy: 0.9986 - precision_m: 0.9986 - recall_m: 0.9986 - f1_m: 0.9986\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 6.7 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.5%\n",
      "  Usage (max):  28.7%\n",
      "  Frequency:    3657 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 45.2%\n",
      "  Usage (max):  45.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  58.7%\n",
      "  Usage (max):   89.0%\n",
      "  Memory (mean): 4307 MB\n",
      "  Memory (max):  5184 MB\n",
      "  Power (mean):  109.5 W\n",
      "  Power (max):   138.4 W\n",
      "  Energy used:   0.202 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 3 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4063, Acc: 90.02%\n",
      "Precision: 0.9215, Recall: 0.8924, F1: 0.9065\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_10_fold_3_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 4 - model_10\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2151, Final Test=7550\n",
      "Fine-tuning with 2151 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 39ms/step - loss: 0.4521 - accuracy: 0.8629 - precision_m: 0.9005 - recall_m: 0.8357 - f1_m: 0.8668\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2333 - accuracy: 0.9303 - precision_m: 0.9614 - recall_m: 0.9077 - f1_m: 0.9336\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1071 - accuracy: 0.9740 - precision_m: 0.9824 - recall_m: 0.9612 - f1_m: 0.9716\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0620 - accuracy: 0.9847 - precision_m: 0.9888 - recall_m: 0.9768 - f1_m: 0.9827\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0341 - accuracy: 0.9921 - precision_m: 0.9935 - recall_m: 0.9890 - f1_m: 0.9912\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0236 - accuracy: 0.9949 - precision_m: 0.9963 - recall_m: 0.9939 - f1_m: 0.9951\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0234 - accuracy: 0.9944 - precision_m: 0.9956 - recall_m: 0.9937 - f1_m: 0.9947\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0141 - accuracy: 0.9972 - precision_m: 0.9977 - recall_m: 0.9959 - f1_m: 0.9968\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0081 - accuracy: 0.9995 - precision_m: 0.9995 - recall_m: 0.9991 - f1_m: 0.9993\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0082 - accuracy: 0.9986 - precision_m: 0.9991 - recall_m: 0.9982 - f1_m: 0.9986\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 6.6 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.3%\n",
      "  Usage (max):  32.1%\n",
      "  Frequency:    3660 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 45.0%\n",
      "  Usage (max):  45.7%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  53.4%\n",
      "  Usage (max):   90.0%\n",
      "  Memory (mean): 5184 MB\n",
      "  Memory (max):  5184 MB\n",
      "  Power (mean):  108.1 W\n",
      "  Power (max):   140.2 W\n",
      "  Energy used:   0.199 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 4 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4941, Acc: 88.38%\n",
      "Precision: 0.9045, Recall: 0.8780, F1: 0.8908\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_10_fold_4_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 5 - model_10\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2138, Final Test=7409\n",
      "Fine-tuning with 2138 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 39ms/step - loss: 0.4607 - accuracy: 0.8761 - precision_m: 0.9220 - recall_m: 0.8487 - f1_m: 0.8836\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2261 - accuracy: 0.9359 - precision_m: 0.9648 - recall_m: 0.9115 - f1_m: 0.9373\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1081 - accuracy: 0.9729 - precision_m: 0.9838 - recall_m: 0.9603 - f1_m: 0.9719\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0524 - accuracy: 0.9864 - precision_m: 0.9912 - recall_m: 0.9816 - f1_m: 0.9864\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0288 - accuracy: 0.9944 - precision_m: 0.9970 - recall_m: 0.9913 - f1_m: 0.9942\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0209 - accuracy: 0.9977 - precision_m: 0.9980 - recall_m: 0.9966 - f1_m: 0.9973\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0155 - accuracy: 0.9977 - precision_m: 0.9977 - recall_m: 0.9954 - f1_m: 0.9965\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0124 - accuracy: 0.9972 - precision_m: 0.9972 - recall_m: 0.9968 - f1_m: 0.9970\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0098 - accuracy: 0.9977 - precision_m: 0.9977 - recall_m: 0.9972 - f1_m: 0.9975\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0062 - accuracy: 0.9991 - precision_m: 0.9991 - recall_m: 0.9991 - f1_m: 0.9991\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 6.6 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 24.0%\n",
      "  Usage (max):  27.5%\n",
      "  Frequency:    3887 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 45.6%\n",
      "  Usage (max):  46.8%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  47.3%\n",
      "  Usage (max):   88.0%\n",
      "  Memory (mean): 5184 MB\n",
      "  Memory (max):  5184 MB\n",
      "  Power (mean):  106.8 W\n",
      "  Power (max):   140.0 W\n",
      "  Energy used:   0.197 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 5 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4543, Acc: 89.67%\n",
      "Precision: 0.9132, Recall: 0.8889, F1: 0.9006\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_10_fold_5_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 6 - model_10\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2146, Final Test=7371\n",
      "Fine-tuning with 2146 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 38ms/step - loss: 0.4423 - accuracy: 0.8705 - precision_m: 0.9066 - recall_m: 0.8386 - f1_m: 0.8713\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2293 - accuracy: 0.9320 - precision_m: 0.9564 - recall_m: 0.9083 - f1_m: 0.9315\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1133 - accuracy: 0.9697 - precision_m: 0.9829 - recall_m: 0.9562 - f1_m: 0.9693\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0575 - accuracy: 0.9893 - precision_m: 0.9935 - recall_m: 0.9806 - f1_m: 0.9870\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0359 - accuracy: 0.9939 - precision_m: 0.9956 - recall_m: 0.9910 - f1_m: 0.9933\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0223 - accuracy: 0.9972 - precision_m: 0.9986 - recall_m: 0.9968 - f1_m: 0.9977\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0160 - accuracy: 0.9977 - precision_m: 0.9982 - recall_m: 0.9966 - f1_m: 0.9974\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0143 - accuracy: 0.9972 - precision_m: 0.9980 - recall_m: 0.9960 - f1_m: 0.9970\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0094 - accuracy: 0.9995 - precision_m: 0.9995 - recall_m: 0.9985 - f1_m: 0.9990\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0088 - accuracy: 0.9981 - precision_m: 0.9986 - recall_m: 0.9982 - f1_m: 0.9984\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 6.6 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 22.8%\n",
      "  Usage (max):  32.1%\n",
      "  Frequency:    3829 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 46.7%\n",
      "  Usage (max):  47.3%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  61.1%\n",
      "  Usage (max):   90.0%\n",
      "  Memory (mean): 5184 MB\n",
      "  Memory (max):  5184 MB\n",
      "  Power (mean):  109.6 W\n",
      "  Power (max):   141.1 W\n",
      "  Energy used:   0.202 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 6 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4244, Acc: 90.30%\n",
      "Precision: 0.9213, Recall: 0.8966, F1: 0.9086\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_10_fold_6_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 7 - model_10\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2102, Final Test=7309\n",
      "Fine-tuning with 2102 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 33ms/step - loss: 0.5065 - accuracy: 0.8554 - precision_m: 0.8974 - recall_m: 0.8359 - f1_m: 0.8654\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2426 - accuracy: 0.9282 - precision_m: 0.9584 - recall_m: 0.8996 - f1_m: 0.9279\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.1156 - accuracy: 0.9667 - precision_m: 0.9777 - recall_m: 0.9474 - f1_m: 0.9622\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0560 - accuracy: 0.9857 - precision_m: 0.9878 - recall_m: 0.9805 - f1_m: 0.9841\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0335 - accuracy: 0.9938 - precision_m: 0.9932 - recall_m: 0.9898 - f1_m: 0.9915\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0239 - accuracy: 0.9962 - precision_m: 0.9968 - recall_m: 0.9959 - f1_m: 0.9963\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0161 - accuracy: 0.9976 - precision_m: 0.9977 - recall_m: 0.9972 - f1_m: 0.9975\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0114 - accuracy: 0.9976 - precision_m: 0.9971 - recall_m: 0.9971 - f1_m: 0.9971\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0102 - accuracy: 0.9986 - precision_m: 0.9986 - recall_m: 0.9982 - f1_m: 0.9984\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0085 - accuracy: 0.9971 - precision_m: 0.9972 - recall_m: 0.9972 - f1_m: 0.9972\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 6.7 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 26.9%\n",
      "  Usage (max):  34.6%\n",
      "  Frequency:    3945 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 46.1%\n",
      "  Usage (max):  46.4%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  52.1%\n",
      "  Usage (max):   90.0%\n",
      "  Memory (mean): 5184 MB\n",
      "  Memory (max):  5184 MB\n",
      "  Power (mean):  103.2 W\n",
      "  Power (max):   139.0 W\n",
      "  Energy used:   0.191 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 7 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.5127, Acc: 88.38%\n",
      "Precision: 0.9054, Recall: 0.8753, F1: 0.8898\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_10_fold_7_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 8 - model_10\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2171, Final Test=7432\n",
      "Fine-tuning with 2171 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 41ms/step - loss: 0.4511 - accuracy: 0.8660 - precision_m: 0.9043 - recall_m: 0.8430 - f1_m: 0.8724\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2086 - accuracy: 0.9392 - precision_m: 0.9640 - recall_m: 0.9153 - f1_m: 0.9389\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0847 - accuracy: 0.9774 - precision_m: 0.9897 - recall_m: 0.9678 - f1_m: 0.9786\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0485 - accuracy: 0.9899 - precision_m: 0.9930 - recall_m: 0.9815 - f1_m: 0.9872\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0211 - accuracy: 0.9977 - precision_m: 0.9982 - recall_m: 0.9935 - f1_m: 0.9958\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0168 - accuracy: 0.9963 - precision_m: 0.9972 - recall_m: 0.9945 - f1_m: 0.9958\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.0122 - accuracy: 0.9986 - precision_m: 0.9986 - recall_m: 0.9982 - f1_m: 0.9984\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0061 - accuracy: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - f1_m: 1.0000\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0059 - accuracy: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - f1_m: 1.0000\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0072 - accuracy: 0.9986 - precision_m: 0.9986 - recall_m: 0.9986 - f1_m: 0.9986\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 6.7 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.9%\n",
      "  Usage (max):  29.5%\n",
      "  Frequency:    3660 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 46.0%\n",
      "  Usage (max):  46.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  61.0%\n",
      "  Usage (max):   89.0%\n",
      "  Memory (mean): 5184 MB\n",
      "  Memory (max):  5184 MB\n",
      "  Power (mean):  104.7 W\n",
      "  Power (max):   137.4 W\n",
      "  Energy used:   0.194 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 8 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4783, Acc: 89.38%\n",
      "Precision: 0.9121, Recall: 0.8856, F1: 0.8984\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_10_fold_8_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 9 - model_10\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2156, Final Test=7446\n",
      "Fine-tuning with 2156 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 40ms/step - loss: 0.4332 - accuracy: 0.8697 - precision_m: 0.9149 - recall_m: 0.8481 - f1_m: 0.8802\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.2224 - accuracy: 0.9397 - precision_m: 0.9642 - recall_m: 0.9142 - f1_m: 0.9384\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1122 - accuracy: 0.9703 - precision_m: 0.9828 - recall_m: 0.9564 - f1_m: 0.9694\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0618 - accuracy: 0.9847 - precision_m: 0.9896 - recall_m: 0.9776 - f1_m: 0.9835\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0376 - accuracy: 0.9912 - precision_m: 0.9958 - recall_m: 0.9870 - f1_m: 0.9914\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0247 - accuracy: 0.9963 - precision_m: 0.9972 - recall_m: 0.9945 - f1_m: 0.9959\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0160 - accuracy: 0.9981 - precision_m: 0.9981 - recall_m: 0.9967 - f1_m: 0.9974\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0117 - accuracy: 0.9977 - precision_m: 0.9977 - recall_m: 0.9977 - f1_m: 0.9977\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0079 - accuracy: 0.9995 - precision_m: 1.0000 - recall_m: 0.9991 - f1_m: 0.9995\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0067 - accuracy: 0.9986 - precision_m: 0.9991 - recall_m: 0.9986 - f1_m: 0.9989\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 6.6 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 23.1%\n",
      "  Usage (max):  31.3%\n",
      "  Frequency:    3491 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 46.0%\n",
      "  Usage (max):  47.6%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  58.1%\n",
      "  Usage (max):   89.0%\n",
      "  Memory (mean): 5184 MB\n",
      "  Memory (max):  5184 MB\n",
      "  Power (mean):  107.5 W\n",
      "  Power (max):   140.4 W\n",
      "  Energy used:   0.198 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 9 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4976, Acc: 89.24%\n",
      "Precision: 0.9135, Recall: 0.8835, F1: 0.8980\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_10_fold_9_finetuned.h5\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING FOLD 10 - model_10\n",
      "================================================================================\n",
      "\n",
      "GPU monitoring initialized: 1 device(s) found\n",
      "Resource monitoring started\n",
      "Loaded: Fine-tune=2104, Final Test=7389\n",
      "Fine-tuning with 2104 samples for 10 epochs...\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 33ms/step - loss: 0.4826 - accuracy: 0.8660 - precision_m: 0.9055 - recall_m: 0.8397 - f1_m: 0.8713\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.2588 - accuracy: 0.9268 - precision_m: 0.9580 - recall_m: 0.8988 - f1_m: 0.9273\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.1288 - accuracy: 0.9577 - precision_m: 0.9787 - recall_m: 0.9494 - f1_m: 0.9638\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0720 - accuracy: 0.9838 - precision_m: 0.9922 - recall_m: 0.9737 - f1_m: 0.9829\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0360 - accuracy: 0.9938 - precision_m: 0.9963 - recall_m: 0.9899 - f1_m: 0.9931\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0230 - accuracy: 0.9933 - precision_m: 0.9934 - recall_m: 0.9911 - f1_m: 0.9923\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0142 - accuracy: 0.9990 - precision_m: 0.9991 - recall_m: 0.9986 - f1_m: 0.9989\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.0096 - accuracy: 0.9986 - precision_m: 0.9991 - recall_m: 0.9986 - f1_m: 0.9989\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0070 - accuracy: 0.9995 - precision_m: 1.0000 - recall_m: 0.9995 - f1_m: 0.9998\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.0094 - accuracy: 0.9976 - precision_m: 0.9977 - recall_m: 0.9977 - f1_m: 0.9977\n",
      "Resource monitoring stopped\n",
      "\n",
      "================================================================================\n",
      "RESOURCE USAGE STATISTICS\n",
      "================================================================================\n",
      "Duration: 6.6 seconds (0.1 minutes)\n",
      "\n",
      "CPU:\n",
      "  Usage (mean): 25.8%\n",
      "  Usage (max):  31.0%\n",
      "  Frequency:    3657 MHz\n",
      "\n",
      "RAM:\n",
      "  Usage (mean): 46.3%\n",
      "  Usage (max):  47.1%\n",
      "\n",
      "GPU:\n",
      "  Usage (mean):  50.0%\n",
      "  Usage (max):   89.0%\n",
      "  Memory (mean): 5184 MB\n",
      "  Memory (max):  5184 MB\n",
      "  Power (mean):  103.3 W\n",
      "  Power (max):   133.3 W\n",
      "  Energy used:   0.191 Wh\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FOLD 10 FINE-TUNING RESULTS\n",
      "================================================================================\n",
      "Final Test - Loss: 0.4728, Acc: 89.19%\n",
      "Precision: 0.9116, Recall: 0.8848, F1: 0.8978\n",
      "================================================================================\n",
      "\n",
      "Saved fine-tuned model to: finetuned_models/model_10_fold_10_finetuned.h5\n",
      "Fine-tuning results saved to: results/model_10_finetuning_metrics.txt\n",
      "\n",
      "################################################################################\n",
      "FINE-TUNING SUMMARY: model_10\n",
      "################################################################################\n",
      "\n",
      "AVERAGE FINAL TEST METRICS (After Fine-tuning):\n",
      "  Accuracy:  89.25% ± 0.62%\n",
      "  Precision: 0.9118 ± 0.0060\n",
      "  Recall:    0.8848 ± 0.0064\n",
      "  F1 Score:  0.8979 ± 0.0061\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING RESOURCE USAGE SUMMARY: model_10\n",
      "================================================================================\n",
      "\n",
      "Total fine-tuning time: 66.5 seconds (1.1 minutes)\n",
      "Average CPU usage: 24.3%\n",
      "Average RAM usage: 45.6%\n",
      "Average GPU usage: 54.0%\n",
      "Average GPU power: 105.4 W\n",
      "Total energy consumed: 1.947 Wh (0.001947 kWh)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: model_10 - BEFORE vs AFTER FINE-TUNING\n",
      "====================================================================================================\n",
      "\n",
      "Metric               Before (Test)        After (Fine-tuned)   Improvement         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy             87.31%               89.25%               +1.94%              \n",
      "Precision            0.9133               0.9118               -0.0015             \n",
      "Recall               0.8505               0.8848               +0.0343             \n",
      "F1 Score             0.8801               0.8979               +0.0178             \n",
      "====================================================================================================\n",
      "\n",
      "ENERGY COMPARISON:\n",
      "  Training energy:    54.284 Wh\n",
      "  Fine-tuning energy: 1.947 Wh\n",
      "  Total energy:       56.231 Wh\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_finetuned_metrics = []\n",
    "\n",
    "for metrics in all_metrics:\n",
    "    model_name = metrics['model_name']\n",
    "    print(f\"\\nFine-tuning {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        finetuned = finetune_all_folds(\n",
    "            model_name=model_name,\n",
    "            num_folds=10,\n",
    "            epochs=10,\n",
    "            monitor_resources=True\n",
    "        )\n",
    "        all_finetuned_metrics.append(finetuned)\n",
    "        \n",
    "        compare_before_after_finetuning(metrics, finetuned)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fine-tuning {model_name}: {e}\")\n",
    "    finally:\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a7b56-c342-4914-835c-e3b525617b75",
   "metadata": {},
   "source": [
    "## Fine-tuning Energy & Cost Analysis\n",
    "\n",
    "Compare energy consumption and costs between initial training and fine-tuning:\n",
    "\n",
    "**Metrics displayed:**\n",
    "- **FT Time** - Fine-tuning duration across all folds\n",
    "- **FT Energy** - Energy consumed during fine-tuning only\n",
    "- **Final Acc** - Test accuracy after fine-tuning\n",
    "- **Total Energy** - Combined energy (training + fine-tuning)\n",
    "\n",
    "**Cost Analysis:**\n",
    "- Individual fine-tuning cost per model\n",
    "- Total fine-tuning cost for all models\n",
    "- Based on electricity rate ($0.12/kWh by default)\n",
    "\n",
    "**Use Case:** Evaluate whether fine-tuning provides sufficient accuracy improvement to justify the additional energy cost and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5c64ea0-5bf5-46e8-b978-2dfed1621667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "FINE-TUNING ENERGY COMPARISON\n",
      "====================================================================================================\n",
      "\n",
      "Model           FT Time      FT Energy       Final Acc    Total Energy   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "model_1                0.2m          0.154Wh       37.15%         12.867Wh\n",
      "model_2                0.2m          0.163Wh       56.05%         11.851Wh\n",
      "model_3                0.4m          0.342Wh       82.08%         13.573Wh\n",
      "model_4                0.2m          0.223Wh       65.74%         11.379Wh\n",
      "model_5                0.4m          0.333Wh       79.18%          8.604Wh\n",
      "model_6                0.4m          0.305Wh       81.78%         13.169Wh\n",
      "model_7                0.4m          0.330Wh       90.03%         14.661Wh\n",
      "model_8                0.4m          0.529Wh       86.00%         23.835Wh\n",
      "model_9                0.6m          0.687Wh       89.94%         22.822Wh\n",
      "model_10               1.1m          1.947Wh       89.25%         56.231Wh\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "ESTIMATED FINE-TUNING COSTS (Rate: $0.12/kWh):\n",
      "  model_1        : $0.0000\n",
      "  model_2        : $0.0000\n",
      "  model_3        : $0.0000\n",
      "  model_4        : $0.0000\n",
      "  model_5        : $0.0000\n",
      "  model_6        : $0.0000\n",
      "  model_7        : $0.0000\n",
      "  model_8        : $0.0001\n",
      "  model_9        : $0.0001\n",
      "  model_10       : $0.0002\n",
      "\n",
      "  Total fine-tuning cost: $0.0006\n"
     ]
    }
   ],
   "source": [
    "if all_finetuned_metrics:\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"FINE-TUNING ENERGY COMPARISON\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    print(f\"{'Model':<15} {'FT Time':<12} {'FT Energy':<15} {'Final Acc':<12} {'Total Energy':<15}\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    for i, (orig_metrics, ft_metrics) in enumerate(zip(all_metrics, all_finetuned_metrics)):\n",
    "        model_name = orig_metrics['model_name']\n",
    "        final_acc = np.mean(ft_metrics['test_acc'])\n",
    "        \n",
    "        if 'resource_stats' in ft_metrics and 'gpu_power_mean_w' in ft_metrics['resource_stats'][0]:\n",
    "            ft_time = sum(s['duration_seconds'] for s in ft_metrics['resource_stats']) / 60\n",
    "            ft_energy = sum(s['gpu_energy_wh'] for s in ft_metrics['resource_stats'])\n",
    "            \n",
    "            # Get original training energy\n",
    "            orig_energy = 0\n",
    "            if 'resource_stats' in orig_metrics and 'gpu_power_mean_w' in orig_metrics['resource_stats'][0]:\n",
    "                orig_energy = sum(s['gpu_energy_wh'] for s in orig_metrics['resource_stats'])\n",
    "            \n",
    "            total_energy = orig_energy + ft_energy\n",
    "            \n",
    "            print(f\"{model_name:<15} {ft_time:>10.1f}m  {ft_energy:>13.3f}Wh  {final_acc:>10.2f}%  {total_energy:>13.3f}Wh\")\n",
    "    \n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    electricity_rate = 0.12\n",
    "    print(f\"\\nESTIMATED FINE-TUNING COSTS (Rate: ${electricity_rate:.2f}/kWh):\")\n",
    "    total_ft_cost = 0\n",
    "    \n",
    "    for ft_metrics in all_finetuned_metrics:\n",
    "        if 'resource_stats' in ft_metrics and 'gpu_power_mean_w' in ft_metrics['resource_stats'][0]:\n",
    "            ft_energy_kwh = sum(s['gpu_energy_wh'] for s in ft_metrics['resource_stats']) / 1000\n",
    "            cost = ft_energy_kwh * electricity_rate\n",
    "            total_ft_cost += cost\n",
    "            print(f\"  {ft_metrics['model_name']:<15}: ${cost:.4f}\")\n",
    "    \n",
    "    if total_ft_cost > 0:\n",
    "        print(f\"\\n  Total fine-tuning cost: ${total_ft_cost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bbde04-4143-462e-b468-041dac27e460",
   "metadata": {},
   "source": [
    "## Save Fine-tuned Model Metrics\n",
    "\n",
    "Save all fine-tuned model metrics to a consolidated pickle file for later analysis and visualization.\n",
    "\n",
    "**Output:** `saved_finetuned_metrics/all_finetuned_metrics.pkl`\n",
    "\n",
    "**Purpose:** Preserves fine-tuning results for:\n",
    "- Comparison with original trained models\n",
    "- Energy consumption analysis\n",
    "- Performance visualization\n",
    "- Future reference without re-running fine-tuning\n",
    "\n",
    "**Note:** Only saves if fine-tuning has been completed (checks if `all_finetuned_metrics` exists in memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaa91853-b805-4df5-9034-1826610a00af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all_finetuned_metrics to all_finetuned_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('saved_finetuned_metrics', exist_ok=True)\n",
    "if 'all_finetuned_metrics' in locals():\n",
    "    with open('saved_finetuned_metrics/all_finetuned_metrics.pkl', 'wb') as f:\n",
    "        pickle.dump(all_finetuned_metrics, f)\n",
    "    print(\"Saved all_finetuned_metrics to all_finetuned_metrics.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f993a5-768b-4fff-a3db-a0d8a8d04c5b",
   "metadata": {},
   "source": [
    "## Compare all model\n",
    "\n",
    "Compare all models before and after fine-tuning.\n",
    "\n",
    "- Normal models: individual pickle files (model_1_metrics.pkl, model_2_metrics.pkl, ...)\n",
    "- Fine-tuned models: single pickle file with list of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4943e6a4-0a6d-42d0-b50e-e8ffa93650c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_before_after_all_models(normal_metrics_dir='saved_metrics', \n",
    "                                     finetuned_file='saved_finetuned_metrics/all_finetuned_metrics.pkl'):\n",
    "    \"\"\"\n",
    "    Compare all models before and after fine-tuning.\n",
    "    Normal models: individual pickle files (model_1_metrics.pkl, model_2_metrics.pkl, ...)\n",
    "    Fine-tuned models: single pickle file with list of all models\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(\"COMPREHENSIVE COMPARISON: NORMAL vs FINE-TUNED MODELS\")\n",
    "    print(f\"{'='*120}\\n\")\n",
    "    \n",
    "    # Load normal models\n",
    "    normal_models = []\n",
    "    for i in range(1, 11):\n",
    "        filepath = os.path.join(normal_metrics_dir, f'model_{i}_metrics.pkl')\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                normal_models.append(pickle.load(f))\n",
    "    \n",
    "    # Load fine-tuned models\n",
    "    if not os.path.exists(finetuned_file):\n",
    "        print(f\"Fine-tuned metrics file not found: {finetuned_file}\")\n",
    "        return\n",
    "    \n",
    "    with open(finetuned_file, 'rb') as f:\n",
    "        finetuned_models = pickle.load(f)\n",
    "    \n",
    "    # Match models by name\n",
    "    matched_pairs = []\n",
    "    for normal in normal_models:\n",
    "        normal_name = normal['model_name']\n",
    "        # Find matching fine-tuned model\n",
    "        finetuned = next((ft for ft in finetuned_models if ft['model_name'] == normal_name), None)\n",
    "        if finetuned:\n",
    "            matched_pairs.append((normal, finetuned))\n",
    "    \n",
    "    if not matched_pairs:\n",
    "        print(\"No matching model pairs found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(matched_pairs)} model pairs to compare\\n\")\n",
    "    \n",
    "    # Detailed comparison for each model\n",
    "    for normal, finetuned in matched_pairs:\n",
    "        model_name = normal['model_name']\n",
    "        \n",
    "        print(f\"\\n{'#'*120}\")\n",
    "        print(f\"MODEL: {model_name}\")\n",
    "        print(f\"{'#'*120}\\n\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics_comparison = {\n",
    "            'Test Accuracy (%)': ('test_acc', '%'),\n",
    "            'Test Precision': ('test_precision', ''),\n",
    "            'Test Recall': ('test_recall', ''),\n",
    "            'Test F1 Score': ('test_f1', ''),\n",
    "        }\n",
    "        \n",
    "        print(f\"{'Metric':<20} {'Normal':<15} {'Fine-tuned':<15} {'Difference':<15} {'% Change':<15}\")\n",
    "        print(f\"{'-'*120}\")\n",
    "        \n",
    "        for metric_name, (key, unit) in metrics_comparison.items():\n",
    "            normal_mean = np.mean(normal[key])\n",
    "            finetuned_mean = np.mean(finetuned[key])\n",
    "            \n",
    "            numeric_diff = finetuned_mean - normal_mean\n",
    "            percent_change = (numeric_diff / normal_mean) * 100 if normal_mean != 0 else 0\n",
    "            \n",
    "            if unit == '%':\n",
    "                print(f\"{metric_name:<20} {normal_mean:>13.2f}%  {finetuned_mean:>13.2f}%  {numeric_diff:>+13.2f}%  {percent_change:>+13.2f}%\")\n",
    "            else:\n",
    "                print(f\"{metric_name:<20} {normal_mean:>13.4f}  {finetuned_mean:>13.4f}  {numeric_diff:>+13.4f}  {percent_change:>+13.2f}%\")\n",
    "        \n",
    "        # Energy comparison if available\n",
    "        if 'resource_stats' in normal and 'resource_stats' in finetuned:\n",
    "            if normal['resource_stats'] and finetuned['resource_stats']:\n",
    "                if 'gpu_energy_wh' in normal['resource_stats'][0] and 'gpu_energy_wh' in finetuned['resource_stats'][0]:\n",
    "                    print(f\"\\n{'Energy & Time':<20} {'Normal':<15} {'Fine-tuned':<15} {'Difference':<15} {'% Change':<15}\")\n",
    "                    print(f\"{'-'*120}\")\n",
    "                    \n",
    "                    normal_energy = sum(s['gpu_energy_wh'] for s in normal['resource_stats'])\n",
    "                    finetuned_energy = sum(s['gpu_energy_wh'] for s in finetuned['resource_stats'])\n",
    "                    energy_diff = finetuned_energy - normal_energy\n",
    "                    energy_percent = (energy_diff / normal_energy) * 100 if normal_energy != 0 else 0\n",
    "                    \n",
    "                    print(f\"{'GPU Energy (Wh)':<20} {normal_energy:>13.3f}  {finetuned_energy:>13.3f}  {energy_diff:>+13.3f}  {energy_percent:>+13.2f}%\")\n",
    "                    \n",
    "                    normal_time = sum(s['duration_seconds'] for s in normal['resource_stats']) / 60\n",
    "                    finetuned_time = sum(s['duration_seconds'] for s in finetuned['resource_stats']) / 60\n",
    "                    time_diff = finetuned_time - normal_time\n",
    "                    time_percent = (time_diff / normal_time) * 100 if normal_time != 0 else 0\n",
    "                    \n",
    "                    print(f\"{'Training Time (min)':<20} {normal_time:>13.1f}  {finetuned_time:>13.1f}  {time_diff:>+13.1f}  {time_percent:>+13.2f}%\")\n",
    "                    \n",
    "                    total_energy = normal_energy + finetuned_energy\n",
    "                    print(f\"{'Total Energy (Wh)':<20} {'-':<15} {'-':<15} {total_energy:>13.3f}\")\n",
    "    \n",
    "    # Overall summary across all models\n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(\"OVERALL SUMMARY - AVERAGE ACROSS ALL MODELS\")\n",
    "    print(f\"{'='*120}\\n\")\n",
    "    \n",
    "    print(f\"{'Metric':<20} {'Avg Normal':<15} {'Avg Fine-tuned':<15} {'Avg Difference':<15} {'Avg % Change':<15}\")\n",
    "    print(f\"{'-'*120}\")\n",
    "    \n",
    "    for metric_name, (key, unit) in metrics_comparison.items():\n",
    "        all_normal = [np.mean(m[0][key]) for m in matched_pairs]\n",
    "        all_finetuned = [np.mean(m[1][key]) for m in matched_pairs]\n",
    "        \n",
    "        avg_normal = np.mean(all_normal)\n",
    "        avg_finetuned = np.mean(all_finetuned)\n",
    "        avg_diff = avg_finetuned - avg_normal\n",
    "        avg_percent = (avg_diff / avg_normal) * 100 if avg_normal != 0 else 0\n",
    "        \n",
    "        if unit == '%':\n",
    "            print(f\"{metric_name:<20} {avg_normal:>13.2f}%  {avg_finetuned:>13.2f}%  {avg_diff:>+13.2f}%  {avg_percent:>+13.2f}%\")\n",
    "        else:\n",
    "            print(f\"{metric_name:<20} {avg_normal:>13.4f}  {avg_finetuned:>13.4f}  {avg_diff:>+13.4f}  {avg_percent:>+13.2f}%\")\n",
    "    \n",
    "    print(f\"{'='*120}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcc96cd9-46c3-45df-80fd-83591ef31384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "COMPREHENSIVE COMPARISON: NORMAL vs FINE-TUNED MODELS\n",
      "========================================================================================================================\n",
      "\n",
      "Found 10 model pairs to compare\n",
      "\n",
      "\n",
      "########################################################################################################################\n",
      "MODEL: model_1\n",
      "########################################################################################################################\n",
      "\n",
      "Metric               Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            36.85%          37.15%          +0.29%          +0.79%\n",
      "Test Precision              0.5362         0.5312        -0.0050          -0.93%\n",
      "Test Recall                 0.1586         0.1679        +0.0093          +5.84%\n",
      "Test F1 Score               0.2353         0.2453        +0.0100          +4.23%\n",
      "\n",
      "Energy & Time        Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "GPU Energy (Wh)             12.713          0.154        -12.559         -98.79%\n",
      "Training Time (min)           17.6            0.2          -17.4         -98.74%\n",
      "Total Energy (Wh)    -               -                      12.867\n",
      "\n",
      "########################################################################################################################\n",
      "MODEL: model_2\n",
      "########################################################################################################################\n",
      "\n",
      "Metric               Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            55.86%          56.05%          +0.19%          +0.34%\n",
      "Test Precision              0.7305         0.7240        -0.0065          -0.89%\n",
      "Test Recall                 0.4193         0.4314        +0.0121          +2.89%\n",
      "Test F1 Score               0.5212         0.5302        +0.0090          +1.74%\n",
      "\n",
      "Energy & Time        Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "GPU Energy (Wh)             11.688          0.163        -11.525         -98.61%\n",
      "Training Time (min)           15.4            0.2          -15.1         -98.55%\n",
      "Total Energy (Wh)    -               -                      11.851\n",
      "\n",
      "########################################################################################################################\n",
      "MODEL: model_3\n",
      "########################################################################################################################\n",
      "\n",
      "Metric               Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            81.10%          82.08%          +0.98%          +1.21%\n",
      "Test Precision              0.8747         0.8774        +0.0027          +0.31%\n",
      "Test Recall                 0.7731         0.7874        +0.0143          +1.84%\n",
      "Test F1 Score               0.8196         0.8290        +0.0094          +1.15%\n",
      "\n",
      "Energy & Time        Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "GPU Energy (Wh)             13.231          0.342        -12.889         -97.42%\n",
      "Training Time (min)           16.6            0.4          -16.3         -97.77%\n",
      "Total Energy (Wh)    -               -                      13.573\n",
      "\n",
      "########################################################################################################################\n",
      "MODEL: model_4\n",
      "########################################################################################################################\n",
      "\n",
      "Metric               Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            64.45%          65.74%          +1.28%          +1.99%\n",
      "Test Precision              0.7647         0.7656        +0.0009          +0.11%\n",
      "Test Recall                 0.5648         0.5849        +0.0201          +3.56%\n",
      "Test F1 Score               0.6471         0.6609        +0.0138          +2.13%\n",
      "\n",
      "Energy & Time        Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "GPU Energy (Wh)             11.156          0.223        -10.933         -98.00%\n",
      "Training Time (min)           10.9            0.2          -10.6         -97.96%\n",
      "Total Energy (Wh)    -               -                      11.379\n",
      "\n",
      "########################################################################################################################\n",
      "MODEL: model_5\n",
      "########################################################################################################################\n",
      "\n",
      "Metric               Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            78.30%          79.18%          +0.87%          +1.12%\n",
      "Test Precision              0.8417         0.8345        -0.0072          -0.85%\n",
      "Test Recall                 0.7478         0.7672        +0.0194          +2.59%\n",
      "Test F1 Score               0.7910         0.7988        +0.0078          +0.99%\n",
      "\n",
      "Energy & Time        Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "GPU Energy (Wh)              8.271          0.333         -7.937         -95.97%\n",
      "Training Time (min)           10.5            0.4          -10.2         -96.49%\n",
      "Total Energy (Wh)    -               -                       8.604\n",
      "\n",
      "########################################################################################################################\n",
      "MODEL: model_6\n",
      "########################################################################################################################\n",
      "\n",
      "Metric               Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            80.88%          81.78%          +0.90%          +1.11%\n",
      "Test Precision              0.8742         0.8749        +0.0006          +0.07%\n",
      "Test Recall                 0.7675         0.7860        +0.0185          +2.41%\n",
      "Test F1 Score               0.8162         0.8271        +0.0110          +1.34%\n",
      "\n",
      "Energy & Time        Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "GPU Energy (Wh)             12.865          0.305        -12.560         -97.63%\n",
      "Training Time (min)           16.1            0.4          -15.7         -97.70%\n",
      "Total Energy (Wh)    -               -                      13.169\n",
      "\n",
      "########################################################################################################################\n",
      "MODEL: model_7\n",
      "########################################################################################################################\n",
      "\n",
      "Metric               Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            88.61%          90.03%          +1.41%          +1.60%\n",
      "Test Precision              0.9205         0.9231        +0.0025          +0.27%\n",
      "Test Recall                 0.8690         0.8915        +0.0225          +2.59%\n",
      "Test F1 Score               0.8935         0.9067        +0.0132          +1.48%\n",
      "\n",
      "Energy & Time        Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "GPU Energy (Wh)             14.330          0.330        -14.000         -97.69%\n",
      "Training Time (min)           10.3            0.4          -10.0         -96.42%\n",
      "Total Energy (Wh)    -               -                      14.661\n",
      "\n",
      "########################################################################################################################\n",
      "MODEL: model_8\n",
      "########################################################################################################################\n",
      "\n",
      "Metric               Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            84.80%          86.00%          +1.20%          +1.42%\n",
      "Test Precision              0.8959         0.8971        +0.0011          +0.13%\n",
      "Test Recall                 0.8222         0.8419        +0.0197          +2.39%\n",
      "Test F1 Score               0.8566         0.8680        +0.0114          +1.33%\n",
      "\n",
      "Energy & Time        Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "GPU Energy (Wh)             23.307          0.529        -22.778         -97.73%\n",
      "Training Time (min)           14.7            0.4          -14.3         -97.36%\n",
      "Total Energy (Wh)    -               -                      23.835\n",
      "\n",
      "########################################################################################################################\n",
      "MODEL: model_9\n",
      "########################################################################################################################\n",
      "\n",
      "Metric               Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            88.34%          89.94%          +1.60%          +1.81%\n",
      "Test Precision              0.9192         0.9189        -0.0004          -0.04%\n",
      "Test Recall                 0.8630         0.8928        +0.0299          +3.46%\n",
      "Test F1 Score               0.8895         0.9054        +0.0159          +1.79%\n",
      "\n",
      "Energy & Time        Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "GPU Energy (Wh)             22.135          0.687        -21.447         -96.90%\n",
      "Training Time (min)           12.7            0.6          -12.2         -95.63%\n",
      "Total Energy (Wh)    -               -                      22.822\n",
      "\n",
      "########################################################################################################################\n",
      "MODEL: model_10\n",
      "########################################################################################################################\n",
      "\n",
      "Metric               Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            87.31%          89.25%          +1.94%          +2.22%\n",
      "Test Precision              0.9133         0.9118        -0.0015          -0.16%\n",
      "Test Recall                 0.8505         0.8848        +0.0343          +4.03%\n",
      "Test F1 Score               0.8801         0.8979        +0.0178          +2.02%\n",
      "\n",
      "Energy & Time        Normal          Fine-tuned      Difference      % Change       \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "GPU Energy (Wh)             54.284          1.947        -52.337         -96.41%\n",
      "Training Time (min)           26.6            1.1          -25.5         -95.83%\n",
      "Total Energy (Wh)    -               -                      56.231\n",
      "\n",
      "========================================================================================================================\n",
      "OVERALL SUMMARY - AVERAGE ACROSS ALL MODELS\n",
      "========================================================================================================================\n",
      "\n",
      "Metric               Avg Normal      Avg Fine-tuned  Avg Difference  Avg % Change   \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy (%)            74.65%          75.72%          +1.07%          +1.43%\n",
      "Test Precision              0.8271         0.8258        -0.0013          -0.15%\n",
      "Test Recall                 0.6836         0.7036        +0.0200          +2.93%\n",
      "Test F1 Score               0.7350         0.7469        +0.0119          +1.62%\n",
      "========================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_before_after_all_models('saved_metrics', 'saved_finetuned_metrics/all_finetuned_metrics.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab41b91-0da7-4982-aa86-bd6f1cdabc0d",
   "metadata": {},
   "source": [
    "## Measure Test Energy Consumption\n",
    "\n",
    "Measure CPU and GPU energy consumption during model inference on the test set.\n",
    "\n",
    "**What this does:**\n",
    "- Loads trained models (.h5 files)\n",
    "- Runs inference on the final test set\n",
    "- Monitors CPU energy (via RAPL) and GPU energy (via NVML)\n",
    "- Records power consumption, duration, and accuracy\n",
    "- Saves detailed results to CSV\n",
    "\n",
    "**Requirements:**\n",
    "- RAPL permissions: `sudo chmod -R a+r /sys/class/powercap/intel-rapl/`\n",
    "- GPU monitoring: `pynvml` library installed\n",
    "\n",
    "**Output CSV columns:**\n",
    "- `model`, `fold` - Model identification\n",
    "- `test_acc` - Test accuracy\n",
    "- `cpu_energy_wh`, `gpu_energy_wh` - Energy consumed by each device\n",
    "- `cpu_power_mean_w`, `gpu_power_mean_w` - Average power draw\n",
    "- `duration_s` - Inference time\n",
    "\n",
    "**Purpose:** Separate test energy from training energy for fair comparison between deployment scenarios (Keras vs TFLite, CPU vs GPU).\n",
    "\n",
    "**Note:** This measures inference energy only, not training energy. Run after all models are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a58034e5-4544-476d-9425-02b10c32beb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEASURING TEST POWER FOR ALL NORMAL MODELS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "model_1:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 63.7W/0.003693Wh | GPU: 39.9W/0.002314Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 69.7W/0.003972Wh | GPU: 40.1W/0.002287Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.8W/0.004601Wh | GPU: 40.0W/0.004620Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 44.7W/0.005126Wh | GPU: 40.5W/0.004646Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.1W/0.003821Wh | GPU: 40.1W/0.002285Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 45.1W/0.005150Wh | GPU: 40.2W/0.004593Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 45.6W/0.005207Wh | GPU: 40.2W/0.004587Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 49.7W/0.005709Wh | GPU: 40.1W/0.004598Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 70.1W/0.004058Wh | GPU: 40.9W/0.002367Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 43.2W/0.004984Wh | GPU: 40.6W/0.004679Wh\n",
      "\n",
      "model_2:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 60.2W/0.006870Wh | GPU: 40.9W/0.004667Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.2W/0.004574Wh | GPU: 40.5W/0.004607Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 63.3W/0.003655Wh | GPU: 40.6W/0.002346Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.1W/0.003911Wh | GPU: 41.0W/0.002391Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 62.7W/0.003567Wh | GPU: 40.6W/0.002308Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 63.3W/0.003597Wh | GPU: 40.8W/0.002320Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 62.6W/0.003599Wh | GPU: 40.7W/0.002342Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.4W/0.004633Wh | GPU: 40.6W/0.004660Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.4W/0.003849Wh | GPU: 41.6W/0.002374Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 45.3W/0.005160Wh | GPU: 41.0W/0.004671Wh\n",
      "\n",
      "model_3:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.6W/0.003733Wh | GPU: 40.9W/0.002331Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.0W/0.003800Wh | GPU: 41.3W/0.002378Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 45.0W/0.005147Wh | GPU: 41.0W/0.004685Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 48.6W/0.005583Wh | GPU: 41.1W/0.004725Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.4W/0.004258Wh | GPU: 40.6W/0.004627Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 64.9W/0.003697Wh | GPU: 41.2W/0.002350Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 64.6W/0.003663Wh | GPU: 41.2W/0.002340Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.4W/0.003725Wh | GPU: 41.3W/0.002354Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.9W/0.004425Wh | GPU: 41.4W/0.004709Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.2W/0.004236Wh | GPU: 40.7W/0.004635Wh\n",
      "\n",
      "model_4:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.5W/0.003731Wh | GPU: 42.3W/0.002411Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.9W/0.004727Wh | GPU: 41.2W/0.004766Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 41.3W/0.004727Wh | GPU: 41.7W/0.004769Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.1W/0.003703Wh | GPU: 42.1W/0.002397Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 62.4W/0.003580Wh | GPU: 42.6W/0.002444Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 45.0W/0.005119Wh | GPU: 41.9W/0.004769Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 63.6W/0.003615Wh | GPU: 42.2W/0.002399Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.3W/0.004371Wh | GPU: 41.4W/0.004721Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 54.4W/0.006250Wh | GPU: 41.9W/0.004821Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 48.0W/0.005471Wh | GPU: 42.4W/0.004834Wh\n",
      "\n",
      "model_5:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.4W/0.004599Wh | GPU: 40.7W/0.004635Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.1W/0.004169Wh | GPU: 40.5W/0.004673Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.5W/0.003841Wh | GPU: 41.1W/0.002338Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 35.6W/0.004044Wh | GPU: 40.6W/0.004616Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.9W/0.003800Wh | GPU: 41.2W/0.002344Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.8W/0.003796Wh | GPU: 41.2W/0.002345Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 64.1W/0.003729Wh | GPU: 41.1W/0.002394Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 35.6W/0.004098Wh | GPU: 40.4W/0.004659Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.9W/0.003775Wh | GPU: 41.4W/0.002371Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.5W/0.003783Wh | GPU: 41.6W/0.002366Wh\n",
      "\n",
      "model_6:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.4W/0.003827Wh | GPU: 42.1W/0.002424Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.4W/0.004257Wh | GPU: 40.7W/0.004633Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.2W/0.003827Wh | GPU: 41.1W/0.002338Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.1W/0.003821Wh | GPU: 41.3W/0.002355Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.8W/0.003804Wh | GPU: 41.0W/0.002337Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 44.7W/0.005187Wh | GPU: 40.7W/0.004729Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.9W/0.003780Wh | GPU: 41.6W/0.002385Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.1W/0.004129Wh | GPU: 40.6W/0.004655Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.3W/0.004161Wh | GPU: 40.6W/0.004651Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.4W/0.003806Wh | GPU: 41.4W/0.002376Wh\n",
      "\n",
      "model_7:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.8W/0.004427Wh | GPU: 43.7W/0.004975Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.2W/0.004233Wh | GPU: 44.7W/0.005088Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 44.5W/0.005123Wh | GPU: 42.9W/0.004944Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.1W/0.004372Wh | GPU: 43.3W/0.004971Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.7W/0.004289Wh | GPU: 43.7W/0.004973Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.9W/0.004201Wh | GPU: 43.9W/0.004993Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 42.8W/0.004930Wh | GPU: 42.8W/0.004934Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.3W/0.004416Wh | GPU: 42.9W/0.004946Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.0W/0.004220Wh | GPU: 44.0W/0.005009Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.7W/0.004181Wh | GPU: 44.0W/0.005019Wh\n",
      "\n",
      "model_8:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.7W/0.004283Wh | GPU: 46.8W/0.005324Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.8W/0.004410Wh | GPU: 46.2W/0.005246Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.1W/0.004339Wh | GPU: 46.2W/0.005262Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.7W/0.004297Wh | GPU: 46.1W/0.005249Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.6W/0.004173Wh | GPU: 46.1W/0.005265Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.6W/0.004168Wh | GPU: 46.5W/0.005295Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.5W/0.004267Wh | GPU: 45.9W/0.005214Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.2W/0.004233Wh | GPU: 46.6W/0.005295Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.1W/0.004220Wh | GPU: 46.9W/0.005332Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.7W/0.004211Wh | GPU: 45.5W/0.005216Wh\n",
      "\n",
      "model_9:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.2W/0.004572Wh | GPU: 57.1W/0.006495Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 41.0W/0.004676Wh | GPU: 64.9W/0.007395Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.0W/0.004589Wh | GPU: 66.6W/0.007641Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.6W/0.004640Wh | GPU: 69.4W/0.007925Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.4W/0.004403Wh | GPU: 70.8W/0.008125Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.9W/0.004439Wh | GPU: 72.6W/0.008285Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.8W/0.004460Wh | GPU: 73.3W/0.008425Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.7W/0.004514Wh | GPU: 78.8W/0.008975Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.7W/0.004454Wh | GPU: 76.6W/0.008807Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.9W/0.004419Wh | GPU: 76.0W/0.008643Wh\n",
      "\n",
      "model_10:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 15.1W/0.003512Wh | GPU: 90.8W/0.021142Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 19.4W/0.004429Wh | GPU: 99.7W/0.022785Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 15.8W/0.003623Wh | GPU: 97.4W/0.022389Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 28.9W/0.006590Wh | GPU: 93.4W/0.021290Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 28.3W/0.006470Wh | GPU: 88.6W/0.020250Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 27.6W/0.006256Wh | GPU: 94.5W/0.021453Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 26.3W/0.006199Wh | GPU: 82.0W/0.019312Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 28.6W/0.006526Wh | GPU: 90.1W/0.020547Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 23.4W/0.005356Wh | GPU: 90.4W/0.020680Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 27.4W/0.006244Wh | GPU: 91.7W/0.020916Wh\n",
      "\n",
      "================================================================================\n",
      "Results saved to: saved_metrics/normal_models_test_power.csv\n",
      "================================================================================\n",
      "\n",
      "SUMMARY BY MODEL:\n",
      "Model        CPU Power (W)   GPU Power (W)   Total Energy (Wh)    Avg Accuracy (%)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model_1      53.9            40.2            0.083296             42.27          \n",
      "model_2      57.2            40.8            0.076102             55.86          \n",
      "model_3      53.3            41.1            0.077401             81.10          \n",
      "model_4      52.4            42.0            0.083623             64.45          \n",
      "model_5      54.5            41.0            0.072375             78.30          \n",
      "model_6      55.4            41.1            0.073482             80.88          \n",
      "model_7      38.8            43.6            0.094241             88.61          \n",
      "model_8      37.4            46.3            0.095298             84.80          \n",
      "model_9      39.5            70.6            0.125884             88.34          \n",
      "model_10     24.1            91.8            0.265971             87.31          \n",
      "\n",
      "====================================================================================================\n",
      "OVERALL AVERAGE:\n",
      "  CPU Power:     46.7 W\n",
      "  GPU Power:     49.9 W\n",
      "  Total Energy:  1.047673 Wh\n",
      "  Avg Accuracy:  75.19%\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "df_normal = measure_all_test_power(\n",
    "    models_dir='trained_models',\n",
    "    output_file='saved_metrics/normal_models_test_power.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c468a5-672e-4415-93c4-0610e9e6e0ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEASURING TEST POWER FOR ALL FINE-TUNED MODELS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "model_1:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 72.8W/0.004157Wh | GPU: 53.0W/0.003029Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.0W/0.004445Wh | GPU: 52.6W/0.005990Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 72.4W/0.004116Wh | GPU: 47.7W/0.002714Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 44.9W/0.005117Wh | GPU: 41.1W/0.004685Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.8W/0.003807Wh | GPU: 40.9W/0.002332Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 74.7W/0.004304Wh | GPU: 42.4W/0.002439Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 64.6W/0.003674Wh | GPU: 41.0W/0.002331Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.3W/0.003774Wh | GPU: 41.0W/0.002333Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.4W/0.003769Wh | GPU: 40.7W/0.002310Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 62.5W/0.003640Wh | GPU: 41.1W/0.002395Wh\n",
      "\n",
      "model_2:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.6W/0.003739Wh | GPU: 41.4W/0.002361Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 64.9W/0.003684Wh | GPU: 41.4W/0.002352Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 63.9W/0.003629Wh | GPU: 41.4W/0.002351Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.2W/0.004127Wh | GPU: 41.7W/0.004756Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.3W/0.003712Wh | GPU: 41.4W/0.002351Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 63.0W/0.003599Wh | GPU: 41.5W/0.002369Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 63.4W/0.003607Wh | GPU: 41.4W/0.002353Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.0W/0.003817Wh | GPU: 42.4W/0.002414Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 63.2W/0.003685Wh | GPU: 41.3W/0.002409Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 64.2W/0.003712Wh | GPU: 41.3W/0.002391Wh\n",
      "\n",
      "model_3:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.8W/0.004640Wh | GPU: 42.3W/0.004806Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.3W/0.004138Wh | GPU: 41.2W/0.004693Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.7W/0.004184Wh | GPU: 41.2W/0.004694Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.0W/0.004151Wh | GPU: 42.0W/0.004838Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.7W/0.004522Wh | GPU: 41.3W/0.004703Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.3W/0.003777Wh | GPU: 41.8W/0.002380Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.7W/0.003780Wh | GPU: 41.7W/0.002401Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.9W/0.003804Wh | GPU: 43.0W/0.002444Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.8W/0.003804Wh | GPU: 42.0W/0.002393Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.2W/0.003820Wh | GPU: 42.1W/0.002397Wh\n",
      "\n",
      "model_4:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.5W/0.003726Wh | GPU: 43.0W/0.002445Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.1W/0.003762Wh | GPU: 44.3W/0.002520Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 64.9W/0.003767Wh | GPU: 42.8W/0.002485Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.0W/0.003845Wh | GPU: 42.7W/0.002490Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.7W/0.003789Wh | GPU: 43.1W/0.002451Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.5W/0.003787Wh | GPU: 43.8W/0.002497Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.0W/0.003822Wh | GPU: 43.0W/0.002456Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.6W/0.003783Wh | GPU: 43.1W/0.002450Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.1W/0.003790Wh | GPU: 43.0W/0.002502Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 64.7W/0.003679Wh | GPU: 44.2W/0.002514Wh\n",
      "\n",
      "model_5:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 32.7W/0.005738Wh | GPU: 40.8W/0.007161Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.8W/0.004188Wh | GPU: 41.2W/0.004688Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.2W/0.003813Wh | GPU: 42.8W/0.002424Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 50.8W/0.005876Wh | GPU: 41.2W/0.004763Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.5W/0.003846Wh | GPU: 41.5W/0.002366Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.2W/0.003820Wh | GPU: 41.6W/0.002434Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.1W/0.003884Wh | GPU: 42.8W/0.002481Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.8W/0.003857Wh | GPU: 42.0W/0.002387Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 45.3W/0.005185Wh | GPU: 41.0W/0.004698Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.5W/0.003880Wh | GPU: 41.5W/0.002385Wh\n",
      "\n",
      "model_6:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.6W/0.003881Wh | GPU: 43.0W/0.002507Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.3W/0.004374Wh | GPU: 41.1W/0.004699Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.2W/0.004152Wh | GPU: 40.9W/0.004692Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.6W/0.004428Wh | GPU: 41.2W/0.004719Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.1W/0.004120Wh | GPU: 41.1W/0.004686Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.1W/0.003778Wh | GPU: 41.5W/0.002412Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 65.2W/0.003770Wh | GPU: 41.5W/0.002399Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.8W/0.003903Wh | GPU: 42.5W/0.002446Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 67.2W/0.003819Wh | GPU: 41.9W/0.002380Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 66.9W/0.003821Wh | GPU: 41.6W/0.002376Wh\n",
      "\n",
      "model_7:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 47.0W/0.005344Wh | GPU: 44.2W/0.005017Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.8W/0.004411Wh | GPU: 43.7W/0.004963Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.9W/0.004543Wh | GPU: 43.7W/0.004975Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.1W/0.004454Wh | GPU: 45.2W/0.005148Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.1W/0.004444Wh | GPU: 44.2W/0.005022Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.7W/0.004352Wh | GPU: 43.5W/0.005016Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.8W/0.004253Wh | GPU: 44.3W/0.005112Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.8W/0.004296Wh | GPU: 44.2W/0.005024Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.8W/0.004415Wh | GPU: 44.2W/0.005025Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.0W/0.004210Wh | GPU: 44.1W/0.005028Wh\n",
      "\n",
      "model_8:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 37.4W/0.004295Wh | GPU: 46.0W/0.005278Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.1W/0.004368Wh | GPU: 46.2W/0.005286Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 46.7W/0.005336Wh | GPU: 46.1W/0.005258Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.5W/0.004535Wh | GPU: 46.7W/0.005357Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.5W/0.004438Wh | GPU: 45.4W/0.005241Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 36.3W/0.004187Wh | GPU: 45.5W/0.005253Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.4W/0.004370Wh | GPU: 46.6W/0.005306Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 32.7W/0.005993Wh | GPU: 44.6W/0.008167Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.0W/0.004340Wh | GPU: 46.8W/0.005344Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.8W/0.004637Wh | GPU: 46.2W/0.005250Wh\n",
      "\n",
      "model_9:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 41.8W/0.004752Wh | GPU: 57.2W/0.006507Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.5W/0.004641Wh | GPU: 61.0W/0.006994Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.4W/0.004654Wh | GPU: 63.9W/0.007347Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.8W/0.004586Wh | GPU: 67.8W/0.007812Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.0W/0.004541Wh | GPU: 68.9W/0.007835Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.5W/0.004662Wh | GPU: 68.5W/0.007886Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 40.9W/0.004646Wh | GPU: 69.9W/0.007937Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.8W/0.004581Wh | GPU: 68.9W/0.007933Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 39.4W/0.004519Wh | GPU: 69.5W/0.007956Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 38.8W/0.004411Wh | GPU: 69.3W/0.007872Wh\n",
      "\n",
      "model_10:\n",
      "  Fold 1... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 29.9W/0.006915Wh | GPU: 84.1W/0.019470Wh\n",
      "  Fold 2... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 29.3W/0.006726Wh | GPU: 100.9W/0.023165Wh\n",
      "  Fold 3... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 26.9W/0.006163Wh | GPU: 93.2W/0.021381Wh\n",
      "  Fold 4... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 26.5W/0.006025Wh | GPU: 95.5W/0.021726Wh\n",
      "  Fold 5... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 26.3W/0.006038Wh | GPU: 95.0W/0.021779Wh\n",
      "  Fold 6... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 27.8W/0.006360Wh | GPU: 95.8W/0.021902Wh\n",
      "  Fold 7... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 26.9W/0.006137Wh | GPU: 92.4W/0.021107Wh\n",
      "  Fold 8... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 29.3W/0.006718Wh | GPU: 100.0W/0.022917Wh\n",
      "  Fold 9... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 28.9W/0.006571Wh | GPU: 95.4W/0.021720Wh\n",
      "  Fold 10... GPU monitoring initialized: 1 device(s) found\n",
      "CPU energy monitoring (RAPL) initialized: 1 domain(s) found\n",
      "  - package-0 (intel-rapl:0)\n",
      "Resource monitoring started\n",
      "Resource monitoring stopped\n",
      "CPU: 26.9W/0.006182Wh | GPU: 91.9W/0.021094Wh\n",
      "\n",
      "================================================================================\n",
      "Results saved to: saved_finetuned_metrics/finetuned_models_test_power.csv\n",
      "================================================================================\n",
      "\n",
      "SUMMARY BY MODEL:\n",
      "Model        CPU Power (W)   GPU Power (W)   Total Energy (Wh)    Avg Accuracy (%)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model_1      63.0            44.1            0.071363             37.15          \n",
      "model_2      61.7            41.5            0.063420             56.05          \n",
      "model_3      52.2            41.8            0.076370             82.08          \n",
      "model_4      65.9            43.3            0.062560             65.74          \n",
      "model_5      56.8            41.6            0.079875             79.18          \n",
      "model_6      54.8            41.6            0.073363             81.78          \n",
      "model_7      39.2            44.1            0.095053             90.03          \n",
      "model_8      38.7            46.0            0.102240             86.00          \n",
      "model_9      40.2            66.5            0.122072             89.94          \n",
      "model_10     27.9            94.4            0.280097             89.25          \n",
      "\n",
      "====================================================================================================\n",
      "OVERALL AVERAGE:\n",
      "  CPU Power:     50.0 W\n",
      "  GPU Power:     50.5 W\n",
      "  Total Energy:  1.026410 Wh\n",
      "  Avg Accuracy:  75.72%\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "df_finetuned = measure_all_test_power(\n",
    "    models_dir='finetuned_models',\n",
    "    output_file='saved_finetuned_metrics/finetuned_models_test_power.csv',\n",
    "    is_finetuned=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
